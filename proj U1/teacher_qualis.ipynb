{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import balanced_accuracy_score, roc_auc_score, make_scorer\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Integer, Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>siape</th>\n",
       "      <th>formacao</th>\n",
       "      <th>tipo_jornada_trabalho</th>\n",
       "      <th>vinculo</th>\n",
       "      <th>lotacao</th>\n",
       "      <th>admissao</th>\n",
       "      <th>categoria</th>\n",
       "      <th>classe_funcional</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1543339</td>\n",
       "      <td>MESTRADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Ativo Permanente</td>\n",
       "      <td>NÚCLEO DE EDUCAÇÃO DA INFÂNCIA</td>\n",
       "      <td>2006/07/24 00:00:00.000000000</td>\n",
       "      <td>PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO</td>\n",
       "      <td>DIV                                           ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1554468</td>\n",
       "      <td>DOUTORADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Ativo Permanente</td>\n",
       "      <td>ESCOLA AGRÍCOLA DE JUNDIAÍ</td>\n",
       "      <td>2008/09/12 00:00:00.000000000</td>\n",
       "      <td>PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO</td>\n",
       "      <td>DV                                            ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1177821</td>\n",
       "      <td>MESTRADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Ativo Permanente</td>\n",
       "      <td>ESCOLA DE MÚSICA</td>\n",
       "      <td>1998/04/28 00:00:00.000000000</td>\n",
       "      <td>PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO</td>\n",
       "      <td>DIV                                           ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2360824</td>\n",
       "      <td>MESTRADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Ativo Permanente</td>\n",
       "      <td>ESCOLA AGRÍCOLA DE JUNDIAÍ</td>\n",
       "      <td>2017/01/25 00:00:00.000000000</td>\n",
       "      <td>PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO</td>\n",
       "      <td>DIII                                          ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2364334</td>\n",
       "      <td>DOUTORADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Ativo Permanente</td>\n",
       "      <td>ESCOLA AGRÍCOLA DE JUNDIAÍ</td>\n",
       "      <td>2009/10/13 00:00:00.000000000</td>\n",
       "      <td>PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO</td>\n",
       "      <td>DIV                                           ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2765</th>\n",
       "      <td>4246363</td>\n",
       "      <td>DOUTORADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Professor Visitante</td>\n",
       "      <td>INSTITUTO DE POLÍTICAS PÚBLICAS</td>\n",
       "      <td>2023/05/23 00:00:00.000000000</td>\n",
       "      <td>PROFESSOR MAGISTERIO SUPERIOR - VISITANTE</td>\n",
       "      <td>Adjunto                                       ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2766</th>\n",
       "      <td>3304576</td>\n",
       "      <td>DOUTORADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Professor Visitante</td>\n",
       "      <td>ESCOLA DE CIÊNCIAS E TECNOLOGIA</td>\n",
       "      <td>2022/08/12 00:00:00.000000000</td>\n",
       "      <td>PROFESSOR MAGISTERIO SUPERIOR - VISITANTE</td>\n",
       "      <td>Titular                                       ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2767</th>\n",
       "      <td>1056188</td>\n",
       "      <td>DOUTORADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Professor Visitante</td>\n",
       "      <td>DEPARTAMENTO DE BIOLOGIA CELULAR E GENÉTICA</td>\n",
       "      <td>2022/10/03 00:00:00.000000000</td>\n",
       "      <td>PROFESSOR MAGISTERIO SUPERIOR - VISITANTE</td>\n",
       "      <td>A                                             ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2768</th>\n",
       "      <td>3330361</td>\n",
       "      <td>DOUTORADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Professor Visitante</td>\n",
       "      <td>INSTITUTO METROPOLE DIGITAL</td>\n",
       "      <td>2023/02/15 00:00:00.000000000</td>\n",
       "      <td>PROFESSOR MAGISTERIO SUPERIOR - VISITANTE</td>\n",
       "      <td>A                                             ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2769</th>\n",
       "      <td>3309092</td>\n",
       "      <td>DOUTORADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Professor Visitante</td>\n",
       "      <td>DEPARTAMENTO DE GEOFÍSICA</td>\n",
       "      <td>2022/09/06 00:00:00.000000000</td>\n",
       "      <td>PROFESSOR MAGISTERIO SUPERIOR - VISITANTE</td>\n",
       "      <td>Titular                                       ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2770 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        siape   formacao           tipo_jornada_trabalho              vinculo  \\\n",
       "0     1543339   MESTRADO  Dedicação exclusiva                Ativo Permanente   \n",
       "1     1554468  DOUTORADO  Dedicação exclusiva                Ativo Permanente   \n",
       "2     1177821   MESTRADO  Dedicação exclusiva                Ativo Permanente   \n",
       "3     2360824   MESTRADO  Dedicação exclusiva                Ativo Permanente   \n",
       "4     2364334  DOUTORADO  Dedicação exclusiva                Ativo Permanente   \n",
       "...       ...        ...                             ...                  ...   \n",
       "2765  4246363  DOUTORADO  Dedicação exclusiva             Professor Visitante   \n",
       "2766  3304576  DOUTORADO  Dedicação exclusiva             Professor Visitante   \n",
       "2767  1056188  DOUTORADO  Dedicação exclusiva             Professor Visitante   \n",
       "2768  3330361  DOUTORADO  Dedicação exclusiva             Professor Visitante   \n",
       "2769  3309092  DOUTORADO  Dedicação exclusiva             Professor Visitante   \n",
       "\n",
       "                                          lotacao  \\\n",
       "0                  NÚCLEO DE EDUCAÇÃO DA INFÂNCIA   \n",
       "1                      ESCOLA AGRÍCOLA DE JUNDIAÍ   \n",
       "2                                ESCOLA DE MÚSICA   \n",
       "3                      ESCOLA AGRÍCOLA DE JUNDIAÍ   \n",
       "4                      ESCOLA AGRÍCOLA DE JUNDIAÍ   \n",
       "...                                           ...   \n",
       "2765              INSTITUTO DE POLÍTICAS PÚBLICAS   \n",
       "2766              ESCOLA DE CIÊNCIAS E TECNOLOGIA   \n",
       "2767  DEPARTAMENTO DE BIOLOGIA CELULAR E GENÉTICA   \n",
       "2768                  INSTITUTO METROPOLE DIGITAL   \n",
       "2769                    DEPARTAMENTO DE GEOFÍSICA   \n",
       "\n",
       "                           admissao  \\\n",
       "0     2006/07/24 00:00:00.000000000   \n",
       "1     2008/09/12 00:00:00.000000000   \n",
       "2     1998/04/28 00:00:00.000000000   \n",
       "3     2017/01/25 00:00:00.000000000   \n",
       "4     2009/10/13 00:00:00.000000000   \n",
       "...                             ...   \n",
       "2765  2023/05/23 00:00:00.000000000   \n",
       "2766  2022/08/12 00:00:00.000000000   \n",
       "2767  2022/10/03 00:00:00.000000000   \n",
       "2768  2023/02/15 00:00:00.000000000   \n",
       "2769  2022/09/06 00:00:00.000000000   \n",
       "\n",
       "                                             categoria  \\\n",
       "0     PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO   \n",
       "1     PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO   \n",
       "2     PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO   \n",
       "3     PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO   \n",
       "4     PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO   \n",
       "...                                                ...   \n",
       "2765         PROFESSOR MAGISTERIO SUPERIOR - VISITANTE   \n",
       "2766         PROFESSOR MAGISTERIO SUPERIOR - VISITANTE   \n",
       "2767         PROFESSOR MAGISTERIO SUPERIOR - VISITANTE   \n",
       "2768         PROFESSOR MAGISTERIO SUPERIOR - VISITANTE   \n",
       "2769         PROFESSOR MAGISTERIO SUPERIOR - VISITANTE   \n",
       "\n",
       "                                       classe_funcional  \n",
       "0     DIV                                           ...  \n",
       "1     DV                                            ...  \n",
       "2     DIV                                           ...  \n",
       "3     DIII                                          ...  \n",
       "4     DIV                                           ...  \n",
       "...                                                 ...  \n",
       "2765  Adjunto                                       ...  \n",
       "2766  Titular                                       ...  \n",
       "2767  A                                             ...  \n",
       "2768  A                                             ...  \n",
       "2769  Titular                                       ...  \n",
       "\n",
       "[2770 rows x 8 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# selecionar atributos dos professores que sao de interesse\n",
    "\n",
    "tp_cols = [\"siape\", \"formacao\", \"tipo_jornada_trabalho\",\n",
    "           \"vinculo\", \"lotacao\", \"admissao\", \"categoria\",\n",
    "           \"classe_funcional\"]\n",
    "\n",
    "tp_df = pd.read_csv(\"./perfis/docentes.csv\", sep=\";\")\n",
    "tp_df = tp_df[tp_cols]\n",
    "\n",
    "tp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "siape                     int64\n",
       "formacao                 object\n",
       "tipo_jornada_trabalho    object\n",
       "vinculo                  object\n",
       "lotacao                  object\n",
       "admissao                 object\n",
       "categoria                object\n",
       "classe_funcional         object\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>siape</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.770000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.114588e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.142222e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.274600e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.297595e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.810985e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.722937e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.350807e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              siape\n",
       "count  2.770000e+03\n",
       "mean   2.114588e+06\n",
       "std    1.142222e+06\n",
       "min    1.274600e+04\n",
       "25%    1.297595e+06\n",
       "50%    1.810985e+06\n",
       "75%    2.722937e+06\n",
       "max    9.350807e+06"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>siape</th>\n",
       "      <th>revista_a1</th>\n",
       "      <th>revista_a2</th>\n",
       "      <th>revista_b1</th>\n",
       "      <th>revista_b2</th>\n",
       "      <th>revista_b3</th>\n",
       "      <th>revista_b4</th>\n",
       "      <th>revista_b5</th>\n",
       "      <th>revista_c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.756000e+03</td>\n",
       "      <td>2756.000000</td>\n",
       "      <td>2756.000000</td>\n",
       "      <td>2756.000000</td>\n",
       "      <td>2756.000000</td>\n",
       "      <td>2756.000000</td>\n",
       "      <td>2756.000000</td>\n",
       "      <td>2756.000000</td>\n",
       "      <td>2756.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.112227e+06</td>\n",
       "      <td>2.634978</td>\n",
       "      <td>1.933599</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>1.269231</td>\n",
       "      <td>0.818215</td>\n",
       "      <td>0.568578</td>\n",
       "      <td>0.054790</td>\n",
       "      <td>0.889332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.137681e+06</td>\n",
       "      <td>6.073799</td>\n",
       "      <td>3.917333</td>\n",
       "      <td>5.375914</td>\n",
       "      <td>2.891393</td>\n",
       "      <td>2.413658</td>\n",
       "      <td>1.778480</td>\n",
       "      <td>0.330389</td>\n",
       "      <td>3.855806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.274600e+04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.296285e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.808676e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.721404e+06</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.350807e+06</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>124.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              siape   revista_a1   revista_a2   revista_b1   revista_b2  \\\n",
       "count  2.756000e+03  2756.000000  2756.000000  2756.000000  2756.000000   \n",
       "mean   2.112227e+06     2.634978     1.933599     1.750000     1.269231   \n",
       "std    1.137681e+06     6.073799     3.917333     5.375914     2.891393   \n",
       "min    1.274600e+04     0.000000     0.000000     0.000000     0.000000   \n",
       "25%    1.296285e+06     0.000000     0.000000     0.000000     0.000000   \n",
       "50%    1.808676e+06     0.000000     0.000000     0.000000     0.000000   \n",
       "75%    2.721404e+06     3.000000     2.000000     2.000000     1.000000   \n",
       "max    9.350807e+06    71.000000    51.000000    99.000000    46.000000   \n",
       "\n",
       "        revista_b3   revista_b4   revista_b5    revista_c  \n",
       "count  2756.000000  2756.000000  2756.000000  2756.000000  \n",
       "mean      0.818215     0.568578     0.054790     0.889332  \n",
       "std       2.413658     1.778480     0.330389     3.855806  \n",
       "min       0.000000     0.000000     0.000000     0.000000  \n",
       "25%       0.000000     0.000000     0.000000     0.000000  \n",
       "50%       0.000000     0.000000     0.000000     0.000000  \n",
       "75%       1.000000     0.000000     0.000000     1.000000  \n",
       "max      41.000000    32.000000     8.000000   124.000000  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# selecionar atributos que desejamos prever. o siape é incluso para unir as tabelas.\n",
    "\n",
    "qualis = [\"siape\", \"revista_a1\", \"revista_a2\", \"revista_b1\",\n",
    "          \"revista_b2\", \"revista_b3\", \"revista_b4\", \"revista_b5\", \"revista_c\"]\n",
    "\n",
    "ti_df_list = []\n",
    "for year in range(2010, 2021):\n",
    "    ti_df_y = pd.read_csv(\n",
    "        \"./indicadores/indicadores-pesquisa-\" + str(year) + \".csv\", sep=\";\")\n",
    "    ti_df_y = ti_df_y[qualis]\n",
    "    ti_df_list.append(ti_df_y)\n",
    "\n",
    "ti_df = pd.concat(ti_df_list)\n",
    "ti_df = ti_df.groupby(\"siape\", as_index=False).sum()\n",
    "ti_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>formacao</th>\n",
       "      <th>tipo_jornada_trabalho</th>\n",
       "      <th>vinculo</th>\n",
       "      <th>lotacao</th>\n",
       "      <th>admissao</th>\n",
       "      <th>categoria</th>\n",
       "      <th>classe_funcional</th>\n",
       "      <th>revista_a1</th>\n",
       "      <th>revista_a2</th>\n",
       "      <th>revista_b1</th>\n",
       "      <th>revista_b2</th>\n",
       "      <th>revista_b3</th>\n",
       "      <th>revista_b4</th>\n",
       "      <th>revista_b5</th>\n",
       "      <th>revista_c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MESTRADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Ativo Permanente</td>\n",
       "      <td>NÚCLEO DE EDUCAÇÃO DA INFÂNCIA</td>\n",
       "      <td>2006/07/24 00:00:00.000000000</td>\n",
       "      <td>PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO</td>\n",
       "      <td>DIV                                           ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DOUTORADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Ativo Permanente</td>\n",
       "      <td>ESCOLA AGRÍCOLA DE JUNDIAÍ</td>\n",
       "      <td>2008/09/12 00:00:00.000000000</td>\n",
       "      <td>PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO</td>\n",
       "      <td>DV                                            ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MESTRADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Ativo Permanente</td>\n",
       "      <td>ESCOLA DE MÚSICA</td>\n",
       "      <td>1998/04/28 00:00:00.000000000</td>\n",
       "      <td>PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO</td>\n",
       "      <td>DIV                                           ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MESTRADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Ativo Permanente</td>\n",
       "      <td>ESCOLA AGRÍCOLA DE JUNDIAÍ</td>\n",
       "      <td>2017/01/25 00:00:00.000000000</td>\n",
       "      <td>PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO</td>\n",
       "      <td>DIII                                          ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DOUTORADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Ativo Permanente</td>\n",
       "      <td>ESCOLA AGRÍCOLA DE JUNDIAÍ</td>\n",
       "      <td>2009/10/13 00:00:00.000000000</td>\n",
       "      <td>PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO</td>\n",
       "      <td>DIV                                           ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2748</th>\n",
       "      <td>DOUTORADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Professor Visitante</td>\n",
       "      <td>INSTITUTO DE POLÍTICAS PÚBLICAS</td>\n",
       "      <td>2023/05/23 00:00:00.000000000</td>\n",
       "      <td>PROFESSOR MAGISTERIO SUPERIOR - VISITANTE</td>\n",
       "      <td>Adjunto                                       ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2749</th>\n",
       "      <td>DOUTORADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Professor Visitante</td>\n",
       "      <td>ESCOLA DE CIÊNCIAS E TECNOLOGIA</td>\n",
       "      <td>2022/08/12 00:00:00.000000000</td>\n",
       "      <td>PROFESSOR MAGISTERIO SUPERIOR - VISITANTE</td>\n",
       "      <td>Titular                                       ...</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2750</th>\n",
       "      <td>DOUTORADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Professor Visitante</td>\n",
       "      <td>DEPARTAMENTO DE BIOLOGIA CELULAR E GENÉTICA</td>\n",
       "      <td>2022/10/03 00:00:00.000000000</td>\n",
       "      <td>PROFESSOR MAGISTERIO SUPERIOR - VISITANTE</td>\n",
       "      <td>A                                             ...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2751</th>\n",
       "      <td>DOUTORADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Professor Visitante</td>\n",
       "      <td>INSTITUTO METROPOLE DIGITAL</td>\n",
       "      <td>2023/02/15 00:00:00.000000000</td>\n",
       "      <td>PROFESSOR MAGISTERIO SUPERIOR - VISITANTE</td>\n",
       "      <td>A                                             ...</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2752</th>\n",
       "      <td>DOUTORADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Professor Visitante</td>\n",
       "      <td>DEPARTAMENTO DE GEOFÍSICA</td>\n",
       "      <td>2022/09/06 00:00:00.000000000</td>\n",
       "      <td>PROFESSOR MAGISTERIO SUPERIOR - VISITANTE</td>\n",
       "      <td>Titular                                       ...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2753 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       formacao           tipo_jornada_trabalho              vinculo  \\\n",
       "0      MESTRADO  Dedicação exclusiva                Ativo Permanente   \n",
       "1     DOUTORADO  Dedicação exclusiva                Ativo Permanente   \n",
       "2      MESTRADO  Dedicação exclusiva                Ativo Permanente   \n",
       "3      MESTRADO  Dedicação exclusiva                Ativo Permanente   \n",
       "4     DOUTORADO  Dedicação exclusiva                Ativo Permanente   \n",
       "...         ...                             ...                  ...   \n",
       "2748  DOUTORADO  Dedicação exclusiva             Professor Visitante   \n",
       "2749  DOUTORADO  Dedicação exclusiva             Professor Visitante   \n",
       "2750  DOUTORADO  Dedicação exclusiva             Professor Visitante   \n",
       "2751  DOUTORADO  Dedicação exclusiva             Professor Visitante   \n",
       "2752  DOUTORADO  Dedicação exclusiva             Professor Visitante   \n",
       "\n",
       "                                          lotacao  \\\n",
       "0                  NÚCLEO DE EDUCAÇÃO DA INFÂNCIA   \n",
       "1                      ESCOLA AGRÍCOLA DE JUNDIAÍ   \n",
       "2                                ESCOLA DE MÚSICA   \n",
       "3                      ESCOLA AGRÍCOLA DE JUNDIAÍ   \n",
       "4                      ESCOLA AGRÍCOLA DE JUNDIAÍ   \n",
       "...                                           ...   \n",
       "2748              INSTITUTO DE POLÍTICAS PÚBLICAS   \n",
       "2749              ESCOLA DE CIÊNCIAS E TECNOLOGIA   \n",
       "2750  DEPARTAMENTO DE BIOLOGIA CELULAR E GENÉTICA   \n",
       "2751                  INSTITUTO METROPOLE DIGITAL   \n",
       "2752                    DEPARTAMENTO DE GEOFÍSICA   \n",
       "\n",
       "                           admissao  \\\n",
       "0     2006/07/24 00:00:00.000000000   \n",
       "1     2008/09/12 00:00:00.000000000   \n",
       "2     1998/04/28 00:00:00.000000000   \n",
       "3     2017/01/25 00:00:00.000000000   \n",
       "4     2009/10/13 00:00:00.000000000   \n",
       "...                             ...   \n",
       "2748  2023/05/23 00:00:00.000000000   \n",
       "2749  2022/08/12 00:00:00.000000000   \n",
       "2750  2022/10/03 00:00:00.000000000   \n",
       "2751  2023/02/15 00:00:00.000000000   \n",
       "2752  2022/09/06 00:00:00.000000000   \n",
       "\n",
       "                                             categoria  \\\n",
       "0     PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO   \n",
       "1     PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO   \n",
       "2     PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO   \n",
       "3     PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO   \n",
       "4     PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO   \n",
       "...                                                ...   \n",
       "2748         PROFESSOR MAGISTERIO SUPERIOR - VISITANTE   \n",
       "2749         PROFESSOR MAGISTERIO SUPERIOR - VISITANTE   \n",
       "2750         PROFESSOR MAGISTERIO SUPERIOR - VISITANTE   \n",
       "2751         PROFESSOR MAGISTERIO SUPERIOR - VISITANTE   \n",
       "2752         PROFESSOR MAGISTERIO SUPERIOR - VISITANTE   \n",
       "\n",
       "                                       classe_funcional  revista_a1  \\\n",
       "0     DIV                                           ...           0   \n",
       "1     DV                                            ...           1   \n",
       "2     DIV                                           ...           0   \n",
       "3     DIII                                          ...           0   \n",
       "4     DIV                                           ...           0   \n",
       "...                                                 ...         ...   \n",
       "2748  Adjunto                                       ...           0   \n",
       "2749  Titular                                       ...           8   \n",
       "2750  A                                             ...           4   \n",
       "2751  A                                             ...          44   \n",
       "2752  Titular                                       ...           4   \n",
       "\n",
       "      revista_a2  revista_b1  revista_b2  revista_b3  revista_b4  revista_b5  \\\n",
       "0              0           0           0           0           0           0   \n",
       "1              1           5           0           0           4           0   \n",
       "2              0           0           0           0           0           0   \n",
       "3              0           0           0           0           0           0   \n",
       "4              0           0           1           0           0           0   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "2748           0           0           1           0           0           0   \n",
       "2749           4           7           0           2           0           0   \n",
       "2750           2           5           0           0           0           0   \n",
       "2751           1           0           0           0           0           0   \n",
       "2752           0           0           0           0           0           0   \n",
       "\n",
       "      revista_c  \n",
       "0             0  \n",
       "1             0  \n",
       "2             0  \n",
       "3             0  \n",
       "4             0  \n",
       "...         ...  \n",
       "2748          1  \n",
       "2749          0  \n",
       "2750          0  \n",
       "2751          0  \n",
       "2752          0  \n",
       "\n",
       "[2753 rows x 15 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unir ambas as tabelas e manter apenas as entradas que possuem siapes em comum\n",
    "\n",
    "df = tp_df.merge(ti_df, on=\"siape\", how=\"inner\")\n",
    "del df[\"siape\"]\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>formacao</th>\n",
       "      <th>tipo_jornada_trabalho</th>\n",
       "      <th>vinculo</th>\n",
       "      <th>categoria</th>\n",
       "      <th>classe_funcional</th>\n",
       "      <th>lotacao</th>\n",
       "      <th>num_semestres</th>\n",
       "      <th>revista_a1</th>\n",
       "      <th>revista_a2</th>\n",
       "      <th>revista_b1</th>\n",
       "      <th>revista_b2</th>\n",
       "      <th>revista_b3</th>\n",
       "      <th>revista_b4</th>\n",
       "      <th>revista_c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MESTRADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Ativo Permanente</td>\n",
       "      <td>PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO</td>\n",
       "      <td>DIV                                           ...</td>\n",
       "      <td>NÚCLEO DE EDUCAÇÃO DA INFÂNCIA</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DOUTORADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Ativo Permanente</td>\n",
       "      <td>PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO</td>\n",
       "      <td>DV                                            ...</td>\n",
       "      <td>ESCOLA AGRÍCOLA DE JUNDIAÍ</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MESTRADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Ativo Permanente</td>\n",
       "      <td>PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO</td>\n",
       "      <td>DIV                                           ...</td>\n",
       "      <td>ESCOLA DE MÚSICA</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MESTRADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Ativo Permanente</td>\n",
       "      <td>PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO</td>\n",
       "      <td>DIII                                          ...</td>\n",
       "      <td>ESCOLA AGRÍCOLA DE JUNDIAÍ</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DOUTORADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Ativo Permanente</td>\n",
       "      <td>PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO</td>\n",
       "      <td>DIV                                           ...</td>\n",
       "      <td>ESCOLA AGRÍCOLA DE JUNDIAÍ</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2748</th>\n",
       "      <td>DOUTORADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Professor Visitante</td>\n",
       "      <td>PROFESSOR MAGISTERIO SUPERIOR - VISITANTE</td>\n",
       "      <td>Adjunto                                       ...</td>\n",
       "      <td>INSTITUTO DE POLÍTICAS PÚBLICAS</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2749</th>\n",
       "      <td>DOUTORADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Professor Visitante</td>\n",
       "      <td>PROFESSOR MAGISTERIO SUPERIOR - VISITANTE</td>\n",
       "      <td>Titular                                       ...</td>\n",
       "      <td>ESCOLA DE CIÊNCIAS E TECNOLOGIA</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2750</th>\n",
       "      <td>DOUTORADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Professor Visitante</td>\n",
       "      <td>PROFESSOR MAGISTERIO SUPERIOR - VISITANTE</td>\n",
       "      <td>A                                             ...</td>\n",
       "      <td>DEPARTAMENTO DE BIOLOGIA CELULAR E GENÉTICA</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2751</th>\n",
       "      <td>DOUTORADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Professor Visitante</td>\n",
       "      <td>PROFESSOR MAGISTERIO SUPERIOR - VISITANTE</td>\n",
       "      <td>A                                             ...</td>\n",
       "      <td>INSTITUTO METROPOLE DIGITAL</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2752</th>\n",
       "      <td>DOUTORADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Professor Visitante</td>\n",
       "      <td>PROFESSOR MAGISTERIO SUPERIOR - VISITANTE</td>\n",
       "      <td>Titular                                       ...</td>\n",
       "      <td>DEPARTAMENTO DE GEOFÍSICA</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2753 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       formacao           tipo_jornada_trabalho              vinculo  \\\n",
       "0      MESTRADO  Dedicação exclusiva                Ativo Permanente   \n",
       "1     DOUTORADO  Dedicação exclusiva                Ativo Permanente   \n",
       "2      MESTRADO  Dedicação exclusiva                Ativo Permanente   \n",
       "3      MESTRADO  Dedicação exclusiva                Ativo Permanente   \n",
       "4     DOUTORADO  Dedicação exclusiva                Ativo Permanente   \n",
       "...         ...                             ...                  ...   \n",
       "2748  DOUTORADO  Dedicação exclusiva             Professor Visitante   \n",
       "2749  DOUTORADO  Dedicação exclusiva             Professor Visitante   \n",
       "2750  DOUTORADO  Dedicação exclusiva             Professor Visitante   \n",
       "2751  DOUTORADO  Dedicação exclusiva             Professor Visitante   \n",
       "2752  DOUTORADO  Dedicação exclusiva             Professor Visitante   \n",
       "\n",
       "                                             categoria  \\\n",
       "0     PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO   \n",
       "1     PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO   \n",
       "2     PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO   \n",
       "3     PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO   \n",
       "4     PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO   \n",
       "...                                                ...   \n",
       "2748         PROFESSOR MAGISTERIO SUPERIOR - VISITANTE   \n",
       "2749         PROFESSOR MAGISTERIO SUPERIOR - VISITANTE   \n",
       "2750         PROFESSOR MAGISTERIO SUPERIOR - VISITANTE   \n",
       "2751         PROFESSOR MAGISTERIO SUPERIOR - VISITANTE   \n",
       "2752         PROFESSOR MAGISTERIO SUPERIOR - VISITANTE   \n",
       "\n",
       "                                       classe_funcional  \\\n",
       "0     DIV                                           ...   \n",
       "1     DV                                            ...   \n",
       "2     DIV                                           ...   \n",
       "3     DIII                                          ...   \n",
       "4     DIV                                           ...   \n",
       "...                                                 ...   \n",
       "2748  Adjunto                                       ...   \n",
       "2749  Titular                                       ...   \n",
       "2750  A                                             ...   \n",
       "2751  A                                             ...   \n",
       "2752  Titular                                       ...   \n",
       "\n",
       "                                          lotacao  num_semestres  revista_a1  \\\n",
       "0                  NÚCLEO DE EDUCAÇÃO DA INFÂNCIA             34           0   \n",
       "1                      ESCOLA AGRÍCOLA DE JUNDIAÍ             30           1   \n",
       "2                                ESCOLA DE MÚSICA             51           0   \n",
       "3                      ESCOLA AGRÍCOLA DE JUNDIAÍ             13           0   \n",
       "4                      ESCOLA AGRÍCOLA DE JUNDIAÍ             28           0   \n",
       "...                                           ...            ...         ...   \n",
       "2748              INSTITUTO DE POLÍTICAS PÚBLICAS              1           0   \n",
       "2749              ESCOLA DE CIÊNCIAS E TECNOLOGIA              2           8   \n",
       "2750  DEPARTAMENTO DE BIOLOGIA CELULAR E GENÉTICA              2           4   \n",
       "2751                  INSTITUTO METROPOLE DIGITAL              1          44   \n",
       "2752                    DEPARTAMENTO DE GEOFÍSICA              2           4   \n",
       "\n",
       "      revista_a2  revista_b1  revista_b2  revista_b3  revista_b4  revista_c  \n",
       "0              0           0           0           0           0          0  \n",
       "1              1           5           0           0           4          0  \n",
       "2              0           0           0           0           0          0  \n",
       "3              0           0           0           0           0          0  \n",
       "4              0           0           1           0           0          0  \n",
       "...          ...         ...         ...         ...         ...        ...  \n",
       "2748           0           0           1           0           0          1  \n",
       "2749           4           7           0           2           0          0  \n",
       "2750           2           5           0           0           0          0  \n",
       "2751           1           0           0           0           0          0  \n",
       "2752           0           0           0           0           0          0  \n",
       "\n",
       "[2753 rows x 14 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converter a data de admissao para quantos semestres o professor está na universidade.\n",
    "\n",
    "def num_semestres(data: str, data_atual: str):\n",
    "    data = data[:10]\n",
    "    anos = int(data_atual[6:]) - int(data[:4])\n",
    "    if int(data_atual[3:5]) < 7 and int(data[5:7]) < 7 or int(data_atual[3:5]) >= 7 and int(data[5:7]) >= 7:\n",
    "        return 2*anos\n",
    "    elif int(data_atual[3:5]) < 7 and int(data[5:7]) > 7:\n",
    "        return 2*anos - 1\n",
    "    else:\n",
    "        return 2*anos + 1\n",
    "\n",
    "data_atual = \"18/10/2023\"\n",
    "\n",
    "df['num_semestres'] = df['admissao'].apply(lambda x: num_semestres(x, data_atual))\n",
    "df = df[[\"formacao\", \"tipo_jornada_trabalho\", \"vinculo\", \"categoria\",\"classe_funcional\", \"lotacao\", \"num_semestres\", \"revista_a1\",\n",
    "         \"revista_a2\", \"revista_b1\", \"revista_b2\", \"revista_b3\", \"revista_b4\", \"revista_c\"]]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "formacao                 object\n",
       "tipo_jornada_trabalho    object\n",
       "vinculo                  object\n",
       "categoria                object\n",
       "classe_funcional         object\n",
       "lotacao                  object\n",
       "num_semestres             int64\n",
       "revista_a1                int64\n",
       "revista_a2                int64\n",
       "revista_b1                int64\n",
       "revista_b2                int64\n",
       "revista_b3                int64\n",
       "revista_b4                int64\n",
       "revista_c                 int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "existem 2753 entradas diferentes;\n",
      "existem 6 formacoes diferentes;\n",
      "existem 3 tipos de jornada de trabalho diferentes;\n",
      "existem 8 tipos de vinculo diferentes;\n",
      "existem 18 classes funcionais diferentes;\n",
      "existem 7 categorias diferentes;\n",
      "existem 135 lotacoes diferentes;\n",
      "existem 89 datas de admissao diferentes;\n"
     ]
    }
   ],
   "source": [
    "print(\"existem\", len(df), \"entradas diferentes;\")\n",
    "print(\"existem\", len(df[\"formacao\"].unique()), \"formacoes diferentes;\")\n",
    "print(\"existem\", len(df[\"tipo_jornada_trabalho\"].unique()),\n",
    "      \"tipos de jornada de trabalho diferentes;\")\n",
    "print(\"existem\", len(df[\"vinculo\"].unique()), \"tipos de vinculo diferentes;\")\n",
    "print(\"existem\", len(df[\"classe_funcional\"].unique()),\"classes funcionais diferentes;\")\n",
    "print(\"existem\", len(df[\"categoria\"].unique()),\"categorias diferentes;\")\n",
    "print(\"existem\", len(df[\"lotacao\"].unique()), \"lotacoes diferentes;\")\n",
    "print(\"existem\", len(df[\"num_semestres\"].unique()),\"datas de admissao diferentes;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MESTRADO: 431\n",
      "DOUTORADO: 2189\n",
      "ESPECIALIZAÇÃO: 120\n",
      "GRADUAÇÃO: 11\n",
      "PÓS-DOUTORADO: 1\n",
      "DESCONHECIDA: 1\n"
     ]
    }
   ],
   "source": [
    "for formacao in df[\"formacao\"].unique():\n",
    "    print(formacao, \": \", len(df[df[\"formacao\"] == formacao]), sep=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MESTRADO: 431\n",
      "DOUTORADO: 2189\n",
      "ESPECIALIZAÇÃO: 120\n",
      "GRADUAÇÃO: 11\n",
      "PÓS-DOUTORADO: 1\n"
     ]
    }
   ],
   "source": [
    "# retirar professores de formação desconhecida.\n",
    "\n",
    "df = df[df[\"formacao\"] != \"DESCONHECIDA\"]\n",
    "for formacao in df[\"formacao\"].unique():\n",
    "    print(formacao, \": \", len(df[df[\"formacao\"] == formacao]), sep=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3: 431\n",
      "4: 2189\n",
      "2: 120\n",
      "1: 11\n",
      "5: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mathe\\AppData\\Local\\Temp\\ipykernel_15912\\852662980.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"formacao\"].replace(nivel_formacao, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# colocar uma ordem de classificacao. pos-doc > doc > mestrado > esp > grad\n",
    "\n",
    "nivel_formacao = {\"GRADUAÇÃO\":1, \"ESPECIALIZAÇÃO\":2, \"MESTRADO\":3,\"DOUTORADO\":4,\"PÓS-DOUTORADO\":5}\n",
    "\n",
    "df[\"formacao\"].replace(nivel_formacao, inplace=True)\n",
    "for formacao in df[\"formacao\"].unique():\n",
    "    print(formacao, \": \", len(df[df[\"formacao\"] == formacao]), sep=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dedicação exclusiva           : 2155\n",
      "20 horas semanais             : 307\n",
      "40 horas semanais             : 290\n"
     ]
    }
   ],
   "source": [
    "for tipo_jornada_trabalho in df[\"tipo_jornada_trabalho\"].unique():\n",
    "    print(tipo_jornada_trabalho, \": \", len(\n",
    "        df[df[\"tipo_jornada_trabalho\"] == tipo_jornada_trabalho]), sep=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ativo Permanente: 2376\n",
      "Celetista: 1\n",
      "Colaborador PCCTAE e Magistério Federal: 2\n",
      "Excedente de lotação: 3\n",
      "Exercicio provisorio: 18\n",
      "Professor Substituto: 260\n",
      "Professor Temporario: 50\n",
      "Professor Visitante: 42\n"
     ]
    }
   ],
   "source": [
    "for vinculo in df[\"vinculo\"].unique():\n",
    "    print(vinculo, \": \", len(df[df[\"vinculo\"] == vinculo]), sep=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ativo Permanente: 2376\n",
      "Exercicio provisorio: 18\n",
      "Professor Substituto: 260\n",
      "Professor Temporario: 50\n",
      "Professor Visitante: 42\n"
     ]
    }
   ],
   "source": [
    "# há poucas pessoas com esses atributos:\n",
    "\n",
    "df = df[df[\"vinculo\"] != \"Celetista\"]\n",
    "df = df[df[\"vinculo\"] != \"Colaborador PCCTAE e Magistério Federal\"]\n",
    "df = df[df[\"vinculo\"] != \"Excedente de lotação\"]\n",
    "for vinculo in df[\"vinculo\"].unique():\n",
    "    print(vinculo, \": \", len(df[df[\"vinculo\"] == vinculo]), sep=\"\")\n",
    "\n",
    "# então decidi retirá-los"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO: 215\n",
      "PROFESSOR DO MAGISTERIO SUPERIOR: 2178\n",
      "PROFESSOR 3 GRAU                        : 1\n",
      "PROF ENS BAS TEC TECNOLOGICO-SUBSTITUTO: 29\n",
      "PROFESSOR DO MAGISTERIO SUPERIOR - SUBSTITUTO: 231\n",
      "PROFESSOR DO MAGISTERIO SUPERIOR - TEMPORARIO: 50\n",
      "PROFESSOR MAGISTERIO SUPERIOR - VISITANTE: 42\n"
     ]
    }
   ],
   "source": [
    "for categoria in df[\"categoria\"].unique():\n",
    "    print(categoria, \": \", len(df[df[\"categoria\"] == categoria]), sep=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veja que a informação de \"SUBSTITUTO\", \"TEMPORARIO\" e \"VISITANTE\" já está informada na coluna \"vínculo\". Então, irei retirá-la dos dados, assim como o único professor de terceiro grau."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO: 244\n",
      "PROFESSOR DO MAGISTERIO SUPERIOR: 2501\n"
     ]
    }
   ],
   "source": [
    "retirar_vinculo = {\"PROF ENS BAS TEC TECNOLOGICO-SUBSTITUTO\":\"PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO\",\n",
    "                   \"PROFESSOR DO MAGISTERIO SUPERIOR - SUBSTITUTO\":\"PROFESSOR DO MAGISTERIO SUPERIOR\",\n",
    "                   \"PROFESSOR DO MAGISTERIO SUPERIOR - TEMPORARIO\":\"PROFESSOR DO MAGISTERIO SUPERIOR\",\n",
    "                   \"PROFESSOR MAGISTERIO SUPERIOR - VISITANTE\":\"PROFESSOR DO MAGISTERIO SUPERIOR\"}\n",
    "\n",
    "df = df[df[\"categoria\"] != \"PROFESSOR 3 GRAU                        \"]\n",
    "\n",
    "df[\"categoria\"].replace(retirar_vinculo, inplace=True)\n",
    "\n",
    "for categoria in df[\"categoria\"].unique():\n",
    "    print(categoria, \": \", len(df[df[\"categoria\"] == categoria]), sep=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verifique que a soma de elementos de uma mesma categoria se manteve. Agora, iremos ranquear os professores com base em sua classe funcional:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DIV                                                                                                 : 75\n",
      "DV                                                                                                  : 32\n",
      "DIII                                                                                                : 78\n",
      "DI                                                                                                  : 47\n",
      "D                                                                                                   : 7\n",
      "DII                                                                                                 : 4\n",
      "Classe A - Adjunto A                                                                                : 141\n",
      "Classe C - Adjunto                                                                                  : 757\n",
      "Classe A - Auxiliar                                                                                 : 46\n",
      "Classe E - Titular                                                                                  : 307\n",
      "Classe D - Associado                                                                                : 834\n",
      "Classe B - Assistente                                                                               : 59\n",
      "Classe A - Assistente A                                                                             : 22\n",
      "Não Informada                                                                                       : 16\n",
      "Auxiliar                                                                                            : 278\n",
      "A                                                                                                   : 20\n",
      "Titular                                                                                             : 13\n",
      "Adjunto                                                                                             : 9\n"
     ]
    }
   ],
   "source": [
    "for classe_funcional in df[\"classe_funcional\"].unique():\n",
    "    print(classe_funcional, \": \", len(df[df[\"classe_funcional\"] == classe_funcional]), sep=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver, há 17 professores com classes não-informadas, e algmas estão repetidas e com outros nomes. Ainda, há 20 professores de classe A sem uma subclasse. O mapeamento, segundo a [PROGESP](https://progesp.ufrn.br/secao/carreira), se dá da seguinte maneira:\n",
    "\n",
    "| Original | Mapeamento |\n",
    "|-|-|\n",
    "|DV|1|\n",
    "|DIV|2|\n",
    "|DIII|3|\n",
    "|DII|4|\n",
    "|DI|5|\n",
    "|Classe E - Titular<br>Titular|6|\n",
    "|Classe D - Associado<br>D|7|\n",
    "|Classe C - Adjunto<br>Adjunto|8|\n",
    "|Classe B - Assistente|9|\n",
    "|Classe A - Auxiliar<br>Auxiliar|10|\n",
    "|Classe A - Assistente A<br>A|11|\n",
    "|Classe A - Adjunto A|12|\n",
    "\n",
    "É importante notar também que iremos retirar professores sem categoria. E professores classe A sem denominação específica serão tratados como Assistentes, pois têm o valor médio da classe A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapear_class_func = {\n",
    "    \"DV                                                                                                  \":1,\n",
    "    \"DIV                                                                                                 \":2,\n",
    "    \"DIII                                                                                                \":3,\n",
    "    \"DII                                                                                                 \":4,\n",
    "    \"DI                                                                                                  \":5,\n",
    "    \"Classe E - Titular                                                                                  \":6,\n",
    "    \"Titular                                                                                             \":6,\n",
    "    \"Classe D - Associado                                                                                \":7,\n",
    "    \"D                                                                                                   \":7,\n",
    "    \"Classe C - Adjunto                                                                                  \":8,\n",
    "    \"Adjunto                                                                                             \":8,\n",
    "    \"Classe B - Assistente                                                                               \":9,\n",
    "    \"Classe A - Auxiliar                                                                                 \":10,\n",
    "    \"Auxiliar                                                                                            \":10,\n",
    "    \"Classe A - Assistente A                                                                             \":11,\n",
    "    \"A                                                                                                   \":11,\n",
    "    \"Classe A - Adjunto A                                                                                \":12,\n",
    "}\n",
    "\n",
    "df = df[df[\"classe_funcional\"] != \"Não Informada                                                                                       \"]\n",
    "\n",
    "df[\"classe_funcional\"].replace(mapear_class_func, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2: 75\n",
      "1: 32\n",
      "3: 78\n",
      "5: 47\n",
      "7: 841\n",
      "4: 4\n",
      "12: 141\n",
      "8: 766\n",
      "10: 324\n",
      "6: 320\n",
      "9: 59\n",
      "11: 42\n"
     ]
    }
   ],
   "source": [
    "for classe_funcional in df[\"classe_funcional\"].unique():\n",
    "    print(classe_funcional, \": \", len(df[df[\"classe_funcional\"] == classe_funcional]), sep=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>formacao</th>\n",
       "      <th>classe_funcional</th>\n",
       "      <th>num_semestres</th>\n",
       "      <th>revista_a1</th>\n",
       "      <th>revista_a2</th>\n",
       "      <th>revista_b1</th>\n",
       "      <th>revista_b2</th>\n",
       "      <th>revista_b3</th>\n",
       "      <th>revista_b4</th>\n",
       "      <th>revista_c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2729.000000</td>\n",
       "      <td>2729.000000</td>\n",
       "      <td>2729.000000</td>\n",
       "      <td>2729.000000</td>\n",
       "      <td>2729.000000</td>\n",
       "      <td>2729.000000</td>\n",
       "      <td>2729.000000</td>\n",
       "      <td>2729.000000</td>\n",
       "      <td>2729.000000</td>\n",
       "      <td>2729.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.744229</td>\n",
       "      <td>7.521803</td>\n",
       "      <td>25.477831</td>\n",
       "      <td>2.646757</td>\n",
       "      <td>1.939538</td>\n",
       "      <td>1.755955</td>\n",
       "      <td>1.270429</td>\n",
       "      <td>0.814584</td>\n",
       "      <td>0.569073</td>\n",
       "      <td>0.890070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.548749</td>\n",
       "      <td>2.113959</td>\n",
       "      <td>20.856943</td>\n",
       "      <td>6.095930</td>\n",
       "      <td>3.929876</td>\n",
       "      <td>5.398132</td>\n",
       "      <td>2.900249</td>\n",
       "      <td>2.394411</td>\n",
       "      <td>1.780601</td>\n",
       "      <td>3.868675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>124.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          formacao  classe_funcional  num_semestres   revista_a1   revista_a2  \\\n",
       "count  2729.000000       2729.000000    2729.000000  2729.000000  2729.000000   \n",
       "mean      3.744229          7.521803      25.477831     2.646757     1.939538   \n",
       "std       0.548749          2.113959      20.856943     6.095930     3.929876   \n",
       "min       1.000000          1.000000       0.000000     0.000000     0.000000   \n",
       "25%       4.000000          7.000000      10.000000     0.000000     0.000000   \n",
       "50%       4.000000          7.000000      24.000000     0.000000     0.000000   \n",
       "75%       4.000000          8.000000      30.000000     3.000000     2.000000   \n",
       "max       5.000000         12.000000      97.000000    71.000000    51.000000   \n",
       "\n",
       "        revista_b1   revista_b2   revista_b3   revista_b4    revista_c  \n",
       "count  2729.000000  2729.000000  2729.000000  2729.000000  2729.000000  \n",
       "mean      1.755955     1.270429     0.814584     0.569073     0.890070  \n",
       "std       5.398132     2.900249     2.394411     1.780601     3.868675  \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "75%       2.000000     1.000000     1.000000     0.000000     1.000000  \n",
       "max      99.000000    46.000000    41.000000    32.000000   124.000000  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.reset_index(drop=True, inplace=True)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tipo_jornada_trabalho</th>\n",
       "      <th>vinculo</th>\n",
       "      <th>categoria</th>\n",
       "      <th>lotacao</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2729</td>\n",
       "      <td>2729</td>\n",
       "      <td>2729</td>\n",
       "      <td>2729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Ativo Permanente</td>\n",
       "      <td>PROFESSOR DO MAGISTERIO SUPERIOR</td>\n",
       "      <td>ESCOLA AGRÍCOLA DE JUNDIAÍ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>2133</td>\n",
       "      <td>2376</td>\n",
       "      <td>2486</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 tipo_jornada_trabalho           vinculo  \\\n",
       "count                             2729              2729   \n",
       "unique                               3                 5   \n",
       "top     Dedicação exclusiva             Ativo Permanente   \n",
       "freq                              2133              2376   \n",
       "\n",
       "                               categoria                     lotacao  \n",
       "count                               2729                        2729  \n",
       "unique                                 2                         134  \n",
       "top     PROFESSOR DO MAGISTERIO SUPERIOR  ESCOLA AGRÍCOLA DE JUNDIAÍ  \n",
       "freq                                2486                         119  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include=\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.drop(\"lotacao\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>formacao</th>\n",
       "      <th>tipo_jornada_trabalho</th>\n",
       "      <th>vinculo</th>\n",
       "      <th>categoria</th>\n",
       "      <th>classe_funcional</th>\n",
       "      <th>lotacao</th>\n",
       "      <th>num_semestres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Ativo Permanente</td>\n",
       "      <td>PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO</td>\n",
       "      <td>2</td>\n",
       "      <td>NÚCLEO DE EDUCAÇÃO DA INFÂNCIA</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Ativo Permanente</td>\n",
       "      <td>PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO</td>\n",
       "      <td>1</td>\n",
       "      <td>ESCOLA AGRÍCOLA DE JUNDIAÍ</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Ativo Permanente</td>\n",
       "      <td>PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO</td>\n",
       "      <td>2</td>\n",
       "      <td>ESCOLA DE MÚSICA</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Ativo Permanente</td>\n",
       "      <td>PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO</td>\n",
       "      <td>3</td>\n",
       "      <td>ESCOLA AGRÍCOLA DE JUNDIAÍ</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Ativo Permanente</td>\n",
       "      <td>PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO</td>\n",
       "      <td>2</td>\n",
       "      <td>ESCOLA AGRÍCOLA DE JUNDIAÍ</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2724</th>\n",
       "      <td>4</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Professor Visitante</td>\n",
       "      <td>PROFESSOR DO MAGISTERIO SUPERIOR</td>\n",
       "      <td>8</td>\n",
       "      <td>INSTITUTO DE POLÍTICAS PÚBLICAS</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2725</th>\n",
       "      <td>4</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Professor Visitante</td>\n",
       "      <td>PROFESSOR DO MAGISTERIO SUPERIOR</td>\n",
       "      <td>6</td>\n",
       "      <td>ESCOLA DE CIÊNCIAS E TECNOLOGIA</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2726</th>\n",
       "      <td>4</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Professor Visitante</td>\n",
       "      <td>PROFESSOR DO MAGISTERIO SUPERIOR</td>\n",
       "      <td>11</td>\n",
       "      <td>DEPARTAMENTO DE BIOLOGIA CELULAR E GENÉTICA</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2727</th>\n",
       "      <td>4</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Professor Visitante</td>\n",
       "      <td>PROFESSOR DO MAGISTERIO SUPERIOR</td>\n",
       "      <td>11</td>\n",
       "      <td>INSTITUTO METROPOLE DIGITAL</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2728</th>\n",
       "      <td>4</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Professor Visitante</td>\n",
       "      <td>PROFESSOR DO MAGISTERIO SUPERIOR</td>\n",
       "      <td>6</td>\n",
       "      <td>DEPARTAMENTO DE GEOFÍSICA</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2729 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      formacao           tipo_jornada_trabalho              vinculo  \\\n",
       "0            3  Dedicação exclusiva                Ativo Permanente   \n",
       "1            4  Dedicação exclusiva                Ativo Permanente   \n",
       "2            3  Dedicação exclusiva                Ativo Permanente   \n",
       "3            3  Dedicação exclusiva                Ativo Permanente   \n",
       "4            4  Dedicação exclusiva                Ativo Permanente   \n",
       "...        ...                             ...                  ...   \n",
       "2724         4  Dedicação exclusiva             Professor Visitante   \n",
       "2725         4  Dedicação exclusiva             Professor Visitante   \n",
       "2726         4  Dedicação exclusiva             Professor Visitante   \n",
       "2727         4  Dedicação exclusiva             Professor Visitante   \n",
       "2728         4  Dedicação exclusiva             Professor Visitante   \n",
       "\n",
       "                                             categoria  classe_funcional  \\\n",
       "0     PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO                 2   \n",
       "1     PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO                 1   \n",
       "2     PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO                 2   \n",
       "3     PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO                 3   \n",
       "4     PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO                 2   \n",
       "...                                                ...               ...   \n",
       "2724                  PROFESSOR DO MAGISTERIO SUPERIOR                 8   \n",
       "2725                  PROFESSOR DO MAGISTERIO SUPERIOR                 6   \n",
       "2726                  PROFESSOR DO MAGISTERIO SUPERIOR                11   \n",
       "2727                  PROFESSOR DO MAGISTERIO SUPERIOR                11   \n",
       "2728                  PROFESSOR DO MAGISTERIO SUPERIOR                 6   \n",
       "\n",
       "                                          lotacao  num_semestres  \n",
       "0                  NÚCLEO DE EDUCAÇÃO DA INFÂNCIA             34  \n",
       "1                      ESCOLA AGRÍCOLA DE JUNDIAÍ             30  \n",
       "2                                ESCOLA DE MÚSICA             51  \n",
       "3                      ESCOLA AGRÍCOLA DE JUNDIAÍ             13  \n",
       "4                      ESCOLA AGRÍCOLA DE JUNDIAÍ             28  \n",
       "...                                           ...            ...  \n",
       "2724              INSTITUTO DE POLÍTICAS PÚBLICAS              1  \n",
       "2725              ESCOLA DE CIÊNCIAS E TECNOLOGIA              2  \n",
       "2726  DEPARTAMENTO DE BIOLOGIA CELULAR E GENÉTICA              2  \n",
       "2727                  INSTITUTO METROPOLE DIGITAL              1  \n",
       "2728                    DEPARTAMENTO DE GEOFÍSICA              2  \n",
       "\n",
       "[2729 rows x 7 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keep = ['revista_a1',\n",
    "        'revista_a2',\n",
    "        'revista_b1',\n",
    "        'revista_b2',\n",
    "        'revista_b3',\n",
    "        'revista_b4',\n",
    "        'revista_c']\n",
    "\n",
    "X = df.drop(keep, axis=1).copy()\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0        0\n",
       " 1        1\n",
       " 2        0\n",
       " 3        0\n",
       " 4        0\n",
       "         ..\n",
       " 2724     0\n",
       " 2725     8\n",
       " 2726     4\n",
       " 2727    44\n",
       " 2728     4\n",
       " Name: revista_a1, Length: 2729, dtype: int64,\n",
       " 0       0\n",
       " 1       1\n",
       " 2       0\n",
       " 3       0\n",
       " 4       0\n",
       "        ..\n",
       " 2724    0\n",
       " 2725    4\n",
       " 2726    2\n",
       " 2727    1\n",
       " 2728    0\n",
       " Name: revista_a2, Length: 2729, dtype: int64,\n",
       " 0       0\n",
       " 1       5\n",
       " 2       0\n",
       " 3       0\n",
       " 4       0\n",
       "        ..\n",
       " 2724    0\n",
       " 2725    7\n",
       " 2726    5\n",
       " 2727    0\n",
       " 2728    0\n",
       " Name: revista_b1, Length: 2729, dtype: int64,\n",
       " 0       0\n",
       " 1       0\n",
       " 2       0\n",
       " 3       0\n",
       " 4       1\n",
       "        ..\n",
       " 2724    1\n",
       " 2725    0\n",
       " 2726    0\n",
       " 2727    0\n",
       " 2728    0\n",
       " Name: revista_b2, Length: 2729, dtype: int64,\n",
       " 0       0\n",
       " 1       0\n",
       " 2       0\n",
       " 3       0\n",
       " 4       0\n",
       "        ..\n",
       " 2724    0\n",
       " 2725    2\n",
       " 2726    0\n",
       " 2727    0\n",
       " 2728    0\n",
       " Name: revista_b3, Length: 2729, dtype: int64,\n",
       " 0       0\n",
       " 1       4\n",
       " 2       0\n",
       " 3       0\n",
       " 4       0\n",
       "        ..\n",
       " 2724    0\n",
       " 2725    0\n",
       " 2726    0\n",
       " 2727    0\n",
       " 2728    0\n",
       " Name: revista_b4, Length: 2729, dtype: int64,\n",
       " 0       0\n",
       " 1       0\n",
       " 2       0\n",
       " 3       0\n",
       " 4       0\n",
       "        ..\n",
       " 2724    1\n",
       " 2725    0\n",
       " 2726    0\n",
       " 2727    0\n",
       " 2728    0\n",
       " Name: revista_c, Length: 2729, dtype: int64]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[ya1,\n",
    " ya2,\n",
    " yb1,\n",
    " yb2,\n",
    " yb3,\n",
    " yb4,\n",
    " yc] = [df[col].copy() for col in keep]\n",
    "\n",
    "[ya1, ya2, yb1, yb2, yb3, yb4, yc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>formacao</th>\n",
       "      <th>classe_funcional</th>\n",
       "      <th>num_semestres</th>\n",
       "      <th>tipo_jornada_trabalho_20 horas semanais</th>\n",
       "      <th>tipo_jornada_trabalho_40 horas semanais</th>\n",
       "      <th>tipo_jornada_trabalho_Dedicação exclusiva</th>\n",
       "      <th>vinculo_Ativo Permanente</th>\n",
       "      <th>vinculo_Exercicio provisorio</th>\n",
       "      <th>vinculo_Professor Substituto</th>\n",
       "      <th>vinculo_Professor Temporario</th>\n",
       "      <th>...</th>\n",
       "      <th>lotacao_SECRETARIA DE EDUCAÇÃO BÁSICA, TÉCNICA E TECNOLÓGICA DA UFRN</th>\n",
       "      <th>lotacao_SECRETARIA DE GESTÃO DE PROJETOS</th>\n",
       "      <th>lotacao_SECRETARIA DE GOVERNANÇA INSTITUCIONAL</th>\n",
       "      <th>lotacao_SECRETARIA DE INCLUSÃO E ACESSIBILIDADE- SIA</th>\n",
       "      <th>lotacao_SECRETARIA DE RELAÇOES INTERNACIONAIS</th>\n",
       "      <th>lotacao_SUPERINTENDENCIA DE COMUNICACAO</th>\n",
       "      <th>lotacao_SUPERINTENDÊNCIA DE INFRAESTRUTURA</th>\n",
       "      <th>lotacao_SUPERINTENDÊNCIA DE TECNOLOGIA DA INFORMAÇÃO</th>\n",
       "      <th>lotacao_SUPERINTENDÊNCIA DO HUOL - EBSERH</th>\n",
       "      <th>lotacao_UNIVERSIDADE FEDERAL DO RIO GRANDE DO NORTE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>51</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2724</th>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2725</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2726</th>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2727</th>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2728</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2729 rows × 147 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      formacao  classe_funcional  num_semestres  \\\n",
       "0            3                 2             34   \n",
       "1            4                 1             30   \n",
       "2            3                 2             51   \n",
       "3            3                 3             13   \n",
       "4            4                 2             28   \n",
       "...        ...               ...            ...   \n",
       "2724         4                 8              1   \n",
       "2725         4                 6              2   \n",
       "2726         4                11              2   \n",
       "2727         4                11              1   \n",
       "2728         4                 6              2   \n",
       "\n",
       "      tipo_jornada_trabalho_20 horas semanais               \\\n",
       "0                                                 False      \n",
       "1                                                 False      \n",
       "2                                                 False      \n",
       "3                                                 False      \n",
       "4                                                 False      \n",
       "...                                                 ...      \n",
       "2724                                              False      \n",
       "2725                                              False      \n",
       "2726                                              False      \n",
       "2727                                              False      \n",
       "2728                                              False      \n",
       "\n",
       "      tipo_jornada_trabalho_40 horas semanais               \\\n",
       "0                                                 False      \n",
       "1                                                 False      \n",
       "2                                                 False      \n",
       "3                                                 False      \n",
       "4                                                 False      \n",
       "...                                                 ...      \n",
       "2724                                              False      \n",
       "2725                                              False      \n",
       "2726                                              False      \n",
       "2727                                              False      \n",
       "2728                                              False      \n",
       "\n",
       "      tipo_jornada_trabalho_Dedicação exclusiva             \\\n",
       "0                                                  True      \n",
       "1                                                  True      \n",
       "2                                                  True      \n",
       "3                                                  True      \n",
       "4                                                  True      \n",
       "...                                                 ...      \n",
       "2724                                               True      \n",
       "2725                                               True      \n",
       "2726                                               True      \n",
       "2727                                               True      \n",
       "2728                                               True      \n",
       "\n",
       "      vinculo_Ativo Permanente  vinculo_Exercicio provisorio  \\\n",
       "0                         True                         False   \n",
       "1                         True                         False   \n",
       "2                         True                         False   \n",
       "3                         True                         False   \n",
       "4                         True                         False   \n",
       "...                        ...                           ...   \n",
       "2724                     False                         False   \n",
       "2725                     False                         False   \n",
       "2726                     False                         False   \n",
       "2727                     False                         False   \n",
       "2728                     False                         False   \n",
       "\n",
       "      vinculo_Professor Substituto  vinculo_Professor Temporario  ...  \\\n",
       "0                            False                         False  ...   \n",
       "1                            False                         False  ...   \n",
       "2                            False                         False  ...   \n",
       "3                            False                         False  ...   \n",
       "4                            False                         False  ...   \n",
       "...                            ...                           ...  ...   \n",
       "2724                         False                         False  ...   \n",
       "2725                         False                         False  ...   \n",
       "2726                         False                         False  ...   \n",
       "2727                         False                         False  ...   \n",
       "2728                         False                         False  ...   \n",
       "\n",
       "      lotacao_SECRETARIA DE EDUCAÇÃO BÁSICA, TÉCNICA E TECNOLÓGICA DA UFRN  \\\n",
       "0                                                 False                      \n",
       "1                                                 False                      \n",
       "2                                                 False                      \n",
       "3                                                 False                      \n",
       "4                                                 False                      \n",
       "...                                                 ...                      \n",
       "2724                                              False                      \n",
       "2725                                              False                      \n",
       "2726                                              False                      \n",
       "2727                                              False                      \n",
       "2728                                              False                      \n",
       "\n",
       "      lotacao_SECRETARIA DE GESTÃO DE PROJETOS  \\\n",
       "0                                        False   \n",
       "1                                        False   \n",
       "2                                        False   \n",
       "3                                        False   \n",
       "4                                        False   \n",
       "...                                        ...   \n",
       "2724                                     False   \n",
       "2725                                     False   \n",
       "2726                                     False   \n",
       "2727                                     False   \n",
       "2728                                     False   \n",
       "\n",
       "      lotacao_SECRETARIA DE GOVERNANÇA INSTITUCIONAL  \\\n",
       "0                                              False   \n",
       "1                                              False   \n",
       "2                                              False   \n",
       "3                                              False   \n",
       "4                                              False   \n",
       "...                                              ...   \n",
       "2724                                           False   \n",
       "2725                                           False   \n",
       "2726                                           False   \n",
       "2727                                           False   \n",
       "2728                                           False   \n",
       "\n",
       "      lotacao_SECRETARIA DE INCLUSÃO E ACESSIBILIDADE- SIA  \\\n",
       "0                                                 False      \n",
       "1                                                 False      \n",
       "2                                                 False      \n",
       "3                                                 False      \n",
       "4                                                 False      \n",
       "...                                                 ...      \n",
       "2724                                              False      \n",
       "2725                                              False      \n",
       "2726                                              False      \n",
       "2727                                              False      \n",
       "2728                                              False      \n",
       "\n",
       "      lotacao_SECRETARIA DE RELAÇOES INTERNACIONAIS  \\\n",
       "0                                             False   \n",
       "1                                             False   \n",
       "2                                             False   \n",
       "3                                             False   \n",
       "4                                             False   \n",
       "...                                             ...   \n",
       "2724                                          False   \n",
       "2725                                          False   \n",
       "2726                                          False   \n",
       "2727                                          False   \n",
       "2728                                          False   \n",
       "\n",
       "      lotacao_SUPERINTENDENCIA DE COMUNICACAO  \\\n",
       "0                                       False   \n",
       "1                                       False   \n",
       "2                                       False   \n",
       "3                                       False   \n",
       "4                                       False   \n",
       "...                                       ...   \n",
       "2724                                    False   \n",
       "2725                                    False   \n",
       "2726                                    False   \n",
       "2727                                    False   \n",
       "2728                                    False   \n",
       "\n",
       "      lotacao_SUPERINTENDÊNCIA DE INFRAESTRUTURA  \\\n",
       "0                                          False   \n",
       "1                                          False   \n",
       "2                                          False   \n",
       "3                                          False   \n",
       "4                                          False   \n",
       "...                                          ...   \n",
       "2724                                       False   \n",
       "2725                                       False   \n",
       "2726                                       False   \n",
       "2727                                       False   \n",
       "2728                                       False   \n",
       "\n",
       "      lotacao_SUPERINTENDÊNCIA DE TECNOLOGIA DA INFORMAÇÃO  \\\n",
       "0                                                 False      \n",
       "1                                                 False      \n",
       "2                                                 False      \n",
       "3                                                 False      \n",
       "4                                                 False      \n",
       "...                                                 ...      \n",
       "2724                                              False      \n",
       "2725                                              False      \n",
       "2726                                              False      \n",
       "2727                                              False      \n",
       "2728                                              False      \n",
       "\n",
       "      lotacao_SUPERINTENDÊNCIA DO HUOL - EBSERH  \\\n",
       "0                                         False   \n",
       "1                                         False   \n",
       "2                                         False   \n",
       "3                                         False   \n",
       "4                                         False   \n",
       "...                                         ...   \n",
       "2724                                      False   \n",
       "2725                                      False   \n",
       "2726                                      False   \n",
       "2727                                      False   \n",
       "2728                                      False   \n",
       "\n",
       "      lotacao_UNIVERSIDADE FEDERAL DO RIO GRANDE DO NORTE  \n",
       "0                                                 False    \n",
       "1                                                 False    \n",
       "2                                                 False    \n",
       "3                                                 False    \n",
       "4                                                 False    \n",
       "...                                                 ...    \n",
       "2724                                              False    \n",
       "2725                                              False    \n",
       "2726                                              False    \n",
       "2727                                              False    \n",
       "2728                                              False    \n",
       "\n",
       "[2729 rows x 147 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_encoded = pd.get_dummies(X, columns=[\"tipo_jornada_trabalho\",\n",
    "                                       \"vinculo\",\n",
    "                                       \"categoria\",\n",
    "                                       \"lotacao\"])\n",
    "\n",
    "X_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.646757053865885,\n",
       " 1.939538292414804,\n",
       " 1.7559545621106631,\n",
       " 1.2704287284719677,\n",
       " 0.8145840967387321,\n",
       " 0.5690729204836936,\n",
       " 0.8900696225723709]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(sum(ya1) / len(ya1)),\n",
    " (sum(ya2) / len(ya2)),\n",
    " (sum(yb1) / len(yb1)),\n",
    " (sum(yb2) / len(yb2)),\n",
    " (sum(yb3) / len(yb3)),\n",
    " (sum(yb4) / len(yb4)),\n",
    " (sum(yc) / len(yc))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de variáveis alvo\n",
    "target_vars = [(ya1, \"ya1\"), (ya2, \"ya2\"), (yb1, \"yb1\"), (yb2, \"yb2\"), (yb3, \"yb3\"), (yb4, \"yb4\"), (yc, \"yc\")]\n",
    "\n",
    "# Dicionário para armazenar os conjuntos de treinamento e teste\n",
    "train_test_sets = {}\n",
    "\n",
    "# Loop sobre as variáveis alvo\n",
    "for var, var_name in target_vars:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_encoded, var, random_state=42)\n",
    "    train_test_sets[var_name] = (X_train, X_test, y_train, y_test)\n",
    "\n",
    "# Agora, você pode acessar os conjuntos de treinamento e teste usando o nome da variável alvo desejada\n",
    "X_train_ya1, X_test_ya1, ya1_train, ya1_test = train_test_sets[\"ya1\"]\n",
    "X_train_ya2, X_test_ya2, ya2_train, ya2_test = train_test_sets[\"ya2\"]\n",
    "X_train_yb1, X_test_yb1, yb1_train, yb1_test = train_test_sets[\"yb1\"]\n",
    "X_train_yb2, X_test_yb2, yb2_train, yb2_test = train_test_sets[\"yb2\"]\n",
    "X_train_yb3, X_test_yb3, yb3_train, yb3_test = train_test_sets[\"yb3\"]\n",
    "X_train_yb4, X_test_yb4, yb4_train, yb4_test = train_test_sets[\"yb4\"]\n",
    "X_train_yc, X_test_yc, yc_train, yc_test = train_test_sets[\"yc\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.639784946236559,\n",
       " 1.9472140762463344,\n",
       " 1.6715542521994136,\n",
       " 1.1901270772238515,\n",
       " 0.8093841642228738,\n",
       " 0.5650048875855328,\n",
       " 0.9496578690127078]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(sum(ya1_train) / len(ya1_train)),\n",
    " (sum(ya2_train) / len(ya2_train)),\n",
    " (sum(yb1_train) / len(yb1_train)),\n",
    " (sum(yb2_train) / len(yb2_train)),\n",
    " (sum(yb3_train) / len(yb3_train)),\n",
    " (sum(yb4_train) / len(yb4_train)),\n",
    " (sum(yc_train) / len(yc_train))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.6676427525622253,\n",
       " 1.916544655929722,\n",
       " 2.0087847730600292,\n",
       " 1.5109809663250366,\n",
       " 0.8301610541727672,\n",
       " 0.5812591508052709,\n",
       " 0.7115666178623719]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(sum(ya1_test) / len(ya1_test)),\n",
    " (sum(ya2_test) / len(ya2_test)),\n",
    " (sum(yb1_test) / len(yb1_test)),\n",
    " (sum(yb2_test) / len(yb2_test)),\n",
    " (sum(yb3_test) / len(yb3_test)),\n",
    " (sum(yb4_test) / len(yb4_test)),\n",
    " (sum(yc_test) / len(yc_test))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_space = {\n",
    "    \"max_depth\": Integer(1,20),\n",
    "    \"n_estimators\": Integer(10,1000),\n",
    "    \"reg_lambda\": Real(0, 10),\n",
    "    \"eta\": Real(0.01, 1),\n",
    "    \"gamma\": Real(0,7)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\data.py:335: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(dtype):\n",
      "c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\data.py:338: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  is_categorical_dtype(dtype) or is_pa_ext_categorical_dtype(dtype)\n",
      "c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\data.py:384: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_categorical_dtype(dtype):\n",
      "c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\data.py:359: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  return is_int or is_bool or is_float or is_categorical_dtype(dtype)\n",
      "c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\data.py:520: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(data):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BayesSearchCV(cv=5,\n",
       "              estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "              search_spaces={&#x27;eta&#x27;: Real(low=0.01, high=1, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;gamma&#x27;: Real(low=0, high=7, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;max_depth&#x27;: Integer(low=1, high=20, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;n_estimators&#x27;: Integer(low=10, high=1000, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;reg_lambda&#x27;: Real(low=0, high=10, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;)},\n",
       "              verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BayesSearchCV</label><div class=\"sk-toggleable__content\"><pre>BayesSearchCV(cv=5,\n",
       "              estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "              search_spaces={&#x27;eta&#x27;: Real(low=0.01, high=1, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;gamma&#x27;: Real(low=0, high=7, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;max_depth&#x27;: Integer(low=1, high=20, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;n_estimators&#x27;: Integer(low=10, high=1000, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;reg_lambda&#x27;: Real(low=0, high=10, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;)},\n",
       "              verbose=True)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "BayesSearchCV(cv=5,\n",
       "              estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "              search_spaces={'eta': Real(low=0.01, high=1, prior='uniform', transform='normalize'),\n",
       "                             'gamma': Real(low=0, high=7, prior='uniform', transform='normalize'),\n",
       "                             'max_depth': Integer(low=1, high=20, prior='uniform', transform='normalize'),\n",
       "                             'n_estimators': Integer(low=10, high=1000, prior='uniform', transform='normalize'),\n",
       "                             'reg_lambda': Real(low=0, high=10, prior='uniform', transform='normalize')},\n",
       "              verbose=True)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_xgb_ya1 = xgb.XGBRegressor()\n",
    "\n",
    "xgb_bayes_ya1 = BayesSearchCV(reg_xgb_ya1, param_space, n_iter=32,\n",
    "                                 scoring=\"neg_root_mean_squared_error\",\n",
    "                                 verbose=True, cv=5, n_jobs=8, random_state=42)\n",
    "\n",
    "xgb_bayes_ya1.fit(X_train_ya1, ya1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\data.py:335: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(dtype):\n",
      "c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\data.py:338: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  is_categorical_dtype(dtype) or is_pa_ext_categorical_dtype(dtype)\n",
      "c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\data.py:384: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_categorical_dtype(dtype):\n",
      "c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\data.py:359: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  return is_int or is_bool or is_float or is_categorical_dtype(dtype)\n",
      "c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\data.py:520: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(data):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BayesSearchCV(cv=5,\n",
       "              estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "              search_spaces={&#x27;eta&#x27;: Real(low=0.01, high=1, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;gamma&#x27;: Real(low=0, high=7, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;max_depth&#x27;: Integer(low=1, high=20, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;n_estimators&#x27;: Integer(low=10, high=1000, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;reg_lambda&#x27;: Real(low=0, high=10, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;)},\n",
       "              verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BayesSearchCV</label><div class=\"sk-toggleable__content\"><pre>BayesSearchCV(cv=5,\n",
       "              estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "              search_spaces={&#x27;eta&#x27;: Real(low=0.01, high=1, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;gamma&#x27;: Real(low=0, high=7, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;max_depth&#x27;: Integer(low=1, high=20, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;n_estimators&#x27;: Integer(low=10, high=1000, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;reg_lambda&#x27;: Real(low=0, high=10, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;)},\n",
       "              verbose=True)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "BayesSearchCV(cv=5,\n",
       "              estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "              search_spaces={'eta': Real(low=0.01, high=1, prior='uniform', transform='normalize'),\n",
       "                             'gamma': Real(low=0, high=7, prior='uniform', transform='normalize'),\n",
       "                             'max_depth': Integer(low=1, high=20, prior='uniform', transform='normalize'),\n",
       "                             'n_estimators': Integer(low=10, high=1000, prior='uniform', transform='normalize'),\n",
       "                             'reg_lambda': Real(low=0, high=10, prior='uniform', transform='normalize')},\n",
       "              verbose=True)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_xgb_ya2 = xgb.XGBRegressor()\n",
    "\n",
    "xgb_bayes_ya2 = BayesSearchCV(reg_xgb_ya2, param_space, n_iter=32,\n",
    "                                 scoring=\"neg_root_mean_squared_error\",\n",
    "                                 verbose=True, cv=5, n_jobs=8, random_state=42)\n",
    "\n",
    "xgb_bayes_ya2.fit(X_train_ya2, ya2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\data.py:335: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(dtype):\n",
      "c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\data.py:338: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  is_categorical_dtype(dtype) or is_pa_ext_categorical_dtype(dtype)\n",
      "c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\data.py:384: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_categorical_dtype(dtype):\n",
      "c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\data.py:359: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  return is_int or is_bool or is_float or is_categorical_dtype(dtype)\n",
      "c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\data.py:520: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(data):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BayesSearchCV(cv=5,\n",
       "              estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "              search_spaces={&#x27;eta&#x27;: Real(low=0.01, high=1, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;gamma&#x27;: Real(low=0, high=7, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;max_depth&#x27;: Integer(low=1, high=20, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;n_estimators&#x27;: Integer(low=10, high=1000, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;reg_lambda&#x27;: Real(low=0, high=10, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;)},\n",
       "              verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BayesSearchCV</label><div class=\"sk-toggleable__content\"><pre>BayesSearchCV(cv=5,\n",
       "              estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "              search_spaces={&#x27;eta&#x27;: Real(low=0.01, high=1, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;gamma&#x27;: Real(low=0, high=7, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;max_depth&#x27;: Integer(low=1, high=20, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;n_estimators&#x27;: Integer(low=10, high=1000, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;reg_lambda&#x27;: Real(low=0, high=10, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;)},\n",
       "              verbose=True)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "BayesSearchCV(cv=5,\n",
       "              estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "              search_spaces={'eta': Real(low=0.01, high=1, prior='uniform', transform='normalize'),\n",
       "                             'gamma': Real(low=0, high=7, prior='uniform', transform='normalize'),\n",
       "                             'max_depth': Integer(low=1, high=20, prior='uniform', transform='normalize'),\n",
       "                             'n_estimators': Integer(low=10, high=1000, prior='uniform', transform='normalize'),\n",
       "                             'reg_lambda': Real(low=0, high=10, prior='uniform', transform='normalize')},\n",
       "              verbose=True)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_xgb_yb1 = xgb.XGBRegressor()\n",
    "\n",
    "xgb_bayes_yb1 = BayesSearchCV(reg_xgb_yb1, param_space, n_iter=32,\n",
    "                                 scoring=\"neg_root_mean_squared_error\",\n",
    "                                 verbose=True, cv=5, n_jobs=8, random_state=42)\n",
    "\n",
    "xgb_bayes_yb1.fit(X_train_yb1, yb1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\data.py:335: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(dtype):\n",
      "c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\data.py:338: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  is_categorical_dtype(dtype) or is_pa_ext_categorical_dtype(dtype)\n",
      "c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\data.py:384: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_categorical_dtype(dtype):\n",
      "c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\data.py:359: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  return is_int or is_bool or is_float or is_categorical_dtype(dtype)\n",
      "c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\data.py:520: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(data):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BayesSearchCV(cv=5,\n",
       "              estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "              search_spaces={&#x27;eta&#x27;: Real(low=0.01, high=1, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;gamma&#x27;: Real(low=0, high=7, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;max_depth&#x27;: Integer(low=1, high=20, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;n_estimators&#x27;: Integer(low=10, high=1000, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;reg_lambda&#x27;: Real(low=0, high=10, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;)},\n",
       "              verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BayesSearchCV</label><div class=\"sk-toggleable__content\"><pre>BayesSearchCV(cv=5,\n",
       "              estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "              search_spaces={&#x27;eta&#x27;: Real(low=0.01, high=1, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;gamma&#x27;: Real(low=0, high=7, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;max_depth&#x27;: Integer(low=1, high=20, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;n_estimators&#x27;: Integer(low=10, high=1000, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;reg_lambda&#x27;: Real(low=0, high=10, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;)},\n",
       "              verbose=True)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "BayesSearchCV(cv=5,\n",
       "              estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "              search_spaces={'eta': Real(low=0.01, high=1, prior='uniform', transform='normalize'),\n",
       "                             'gamma': Real(low=0, high=7, prior='uniform', transform='normalize'),\n",
       "                             'max_depth': Integer(low=1, high=20, prior='uniform', transform='normalize'),\n",
       "                             'n_estimators': Integer(low=10, high=1000, prior='uniform', transform='normalize'),\n",
       "                             'reg_lambda': Real(low=0, high=10, prior='uniform', transform='normalize')},\n",
       "              verbose=True)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_xgb_yb2 = xgb.XGBRegressor()\n",
    "\n",
    "xgb_bayes_yb2 = BayesSearchCV(reg_xgb_yb2, param_space, n_iter=32,\n",
    "                                 scoring=\"neg_root_mean_squared_error\",\n",
    "                                 verbose=True, cv=5, n_jobs=8, random_state=42)\n",
    "\n",
    "xgb_bayes_yb2.fit(X_train_yb2, yb2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\data.py:335: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(dtype):\n",
      "c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\data.py:338: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  is_categorical_dtype(dtype) or is_pa_ext_categorical_dtype(dtype)\n",
      "c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\data.py:384: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_categorical_dtype(dtype):\n",
      "c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\data.py:359: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  return is_int or is_bool or is_float or is_categorical_dtype(dtype)\n",
      "c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\data.py:520: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(data):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BayesSearchCV(cv=5,\n",
       "              estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "              search_spaces={&#x27;eta&#x27;: Real(low=0.01, high=1, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;gamma&#x27;: Real(low=0, high=7, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;max_depth&#x27;: Integer(low=1, high=20, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;n_estimators&#x27;: Integer(low=10, high=1000, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;reg_lambda&#x27;: Real(low=0, high=10, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;)},\n",
       "              verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BayesSearchCV</label><div class=\"sk-toggleable__content\"><pre>BayesSearchCV(cv=5,\n",
       "              estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "              search_spaces={&#x27;eta&#x27;: Real(low=0.01, high=1, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;gamma&#x27;: Real(low=0, high=7, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;max_depth&#x27;: Integer(low=1, high=20, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;n_estimators&#x27;: Integer(low=10, high=1000, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;reg_lambda&#x27;: Real(low=0, high=10, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;)},\n",
       "              verbose=True)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "BayesSearchCV(cv=5,\n",
       "              estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "              search_spaces={'eta': Real(low=0.01, high=1, prior='uniform', transform='normalize'),\n",
       "                             'gamma': Real(low=0, high=7, prior='uniform', transform='normalize'),\n",
       "                             'max_depth': Integer(low=1, high=20, prior='uniform', transform='normalize'),\n",
       "                             'n_estimators': Integer(low=10, high=1000, prior='uniform', transform='normalize'),\n",
       "                             'reg_lambda': Real(low=0, high=10, prior='uniform', transform='normalize')},\n",
       "              verbose=True)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_xgb_yb3 = xgb.XGBRegressor()\n",
    "\n",
    "xgb_bayes_yb3 = BayesSearchCV(reg_xgb_yb3, param_space, n_iter=32,\n",
    "                                 scoring=\"neg_root_mean_squared_error\",\n",
    "                                 verbose=True, cv=5, n_jobs=8, random_state=42)\n",
    "\n",
    "xgb_bayes_yb3.fit(X_train_yb3, yb3_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\data.py:335: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(dtype):\n",
      "c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\data.py:338: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  is_categorical_dtype(dtype) or is_pa_ext_categorical_dtype(dtype)\n",
      "c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\data.py:384: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_categorical_dtype(dtype):\n",
      "c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\data.py:359: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  return is_int or is_bool or is_float or is_categorical_dtype(dtype)\n",
      "c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\data.py:520: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(data):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BayesSearchCV(cv=5,\n",
       "              estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "              search_spaces={&#x27;eta&#x27;: Real(low=0.01, high=1, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;gamma&#x27;: Real(low=0, high=7, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;max_depth&#x27;: Integer(low=1, high=20, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;n_estimators&#x27;: Integer(low=10, high=1000, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;reg_lambda&#x27;: Real(low=0, high=10, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;)},\n",
       "              verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BayesSearchCV</label><div class=\"sk-toggleable__content\"><pre>BayesSearchCV(cv=5,\n",
       "              estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "              search_spaces={&#x27;eta&#x27;: Real(low=0.01, high=1, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;gamma&#x27;: Real(low=0, high=7, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;max_depth&#x27;: Integer(low=1, high=20, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;n_estimators&#x27;: Integer(low=10, high=1000, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;reg_lambda&#x27;: Real(low=0, high=10, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;)},\n",
       "              verbose=True)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "BayesSearchCV(cv=5,\n",
       "              estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "              search_spaces={'eta': Real(low=0.01, high=1, prior='uniform', transform='normalize'),\n",
       "                             'gamma': Real(low=0, high=7, prior='uniform', transform='normalize'),\n",
       "                             'max_depth': Integer(low=1, high=20, prior='uniform', transform='normalize'),\n",
       "                             'n_estimators': Integer(low=10, high=1000, prior='uniform', transform='normalize'),\n",
       "                             'reg_lambda': Real(low=0, high=10, prior='uniform', transform='normalize')},\n",
       "              verbose=True)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_xgb_yb4 = xgb.XGBRegressor()\n",
    "\n",
    "xgb_bayes_yb4 = BayesSearchCV(reg_xgb_yb4, param_space, n_iter=32,\n",
    "                                 scoring=\"neg_root_mean_squared_error\",\n",
    "                                 verbose=True, cv=5, n_jobs=8, random_state=42)\n",
    "\n",
    "xgb_bayes_yb4.fit(X_train_yb4, yb4_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\data.py:335: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(dtype):\n",
      "c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\data.py:338: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  is_categorical_dtype(dtype) or is_pa_ext_categorical_dtype(dtype)\n",
      "c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\data.py:384: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_categorical_dtype(dtype):\n",
      "c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\data.py:359: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  return is_int or is_bool or is_float or is_categorical_dtype(dtype)\n",
      "c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\data.py:520: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(data):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BayesSearchCV(cv=5,\n",
       "              estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "              search_spaces={&#x27;eta&#x27;: Real(low=0.01, high=1, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;gamma&#x27;: Real(low=0, high=7, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;max_depth&#x27;: Integer(low=1, high=20, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;n_estimators&#x27;: Integer(low=10, high=1000, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;reg_lambda&#x27;: Real(low=0, high=10, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;)},\n",
       "              verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BayesSearchCV</label><div class=\"sk-toggleable__content\"><pre>BayesSearchCV(cv=5,\n",
       "              estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "              search_spaces={&#x27;eta&#x27;: Real(low=0.01, high=1, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;gamma&#x27;: Real(low=0, high=7, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;max_depth&#x27;: Integer(low=1, high=20, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;n_estimators&#x27;: Integer(low=10, high=1000, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;reg_lambda&#x27;: Real(low=0, high=10, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;)},\n",
       "              verbose=True)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" ><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "BayesSearchCV(cv=5,\n",
       "              estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "              search_spaces={'eta': Real(low=0.01, high=1, prior='uniform', transform='normalize'),\n",
       "                             'gamma': Real(low=0, high=7, prior='uniform', transform='normalize'),\n",
       "                             'max_depth': Integer(low=1, high=20, prior='uniform', transform='normalize'),\n",
       "                             'n_estimators': Integer(low=10, high=1000, prior='uniform', transform='normalize'),\n",
       "                             'reg_lambda': Real(low=0, high=10, prior='uniform', transform='normalize')},\n",
       "              verbose=True)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_xgb_yc = xgb.XGBRegressor()\n",
    "\n",
    "xgb_bayes_yc = BayesSearchCV(reg_xgb_yc, param_space, n_iter=32,\n",
    "                                 scoring=\"neg_root_mean_squared_error\",\n",
    "                                 verbose=True, cv=5, n_jobs=8, random_state=42)\n",
    "\n",
    "xgb_bayes_yc.fit(X_train_yc, yc_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('eta', 0.6819801039220021), ('gamma', 7.0), ('max_depth', 1), ('n_estimators', 178), ('reg_lambda', 0.7441291807581816)])\n",
      "5.070935799081243\n",
      "OrderedDict([('eta', 0.23795487705752305), ('gamma', 0.396483686417526), ('max_depth', 1), ('n_estimators', 1000), ('reg_lambda', 9.942953172304561)])\n",
      "3.5111916498146747\n",
      "OrderedDict([('eta', 0.0767425263728436), ('gamma', 5.684946091773975), ('max_depth', 18), ('n_estimators', 34), ('reg_lambda', 6.095441348912608)])\n",
      "4.251398255522526\n",
      "OrderedDict([('eta', 0.013594004182195795), ('gamma', 5.724810137646261), ('max_depth', 15), ('n_estimators', 262), ('reg_lambda', 5.786643362283849)])\n",
      "2.484272186331002\n",
      "OrderedDict([('eta', 0.39683716415545056), ('gamma', 7.0), ('max_depth', 1), ('n_estimators', 416), ('reg_lambda', 9.775113804233674)])\n",
      "2.2985392668740716\n",
      "OrderedDict([('eta', 0.01), ('gamma', 7.0), ('max_depth', 20), ('n_estimators', 323), ('reg_lambda', 10.0)])\n",
      "1.5857074556695365\n",
      "OrderedDict([('eta', 0.01), ('gamma', 7.0), ('max_depth', 11), ('n_estimators', 156), ('reg_lambda', 10.0)])\n",
      "3.6921400628130625\n"
     ]
    }
   ],
   "source": [
    "print(xgb_bayes_ya1.best_params_)\n",
    "print(-xgb_bayes_ya1.best_score_)\n",
    "estimator_ya1 = xgb_bayes_ya1.best_estimator_\n",
    "\n",
    "print(xgb_bayes_ya2.best_params_)\n",
    "print(-xgb_bayes_ya2.best_score_)\n",
    "estimator_ya2 = xgb_bayes_ya2.best_estimator_\n",
    "\n",
    "print(xgb_bayes_yb1.best_params_)\n",
    "print(-xgb_bayes_yb1.best_score_)\n",
    "estimator_yb1 = xgb_bayes_yb1.best_estimator_\n",
    "\n",
    "print(xgb_bayes_yb2.best_params_)\n",
    "print(-xgb_bayes_yb2.best_score_)\n",
    "estimator_yb2 = xgb_bayes_yb2.best_estimator_\n",
    "\n",
    "print(xgb_bayes_yb3.best_params_)\n",
    "print(-xgb_bayes_yb3.best_score_)\n",
    "estimator_yb3 = xgb_bayes_yb3.best_estimator_\n",
    "\n",
    "print(xgb_bayes_yb4.best_params_)\n",
    "print(-xgb_bayes_yb4.best_score_)\n",
    "estimator_yb4 = xgb_bayes_yb4.best_estimator_\n",
    "\n",
    "print(xgb_bayes_yc.best_params_)\n",
    "print(-xgb_bayes_yc.best_score_)\n",
    "estimator_yc = xgb_bayes_yc.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.939133634285067\n",
      "3.375217650139085\n",
      "5.350164057834889\n",
      "3.1885227192079357\n",
      "2.012453922553288\n",
      "1.9316194348028335\n",
      "2.4180963299695573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\data.py:335: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(dtype):\n",
      "c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\data.py:338: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  is_categorical_dtype(dtype) or is_pa_ext_categorical_dtype(dtype)\n",
      "c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\data.py:384: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_categorical_dtype(dtype):\n",
      "c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\data.py:359: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  return is_int or is_bool or is_float or is_categorical_dtype(dtype)\n",
      "c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\data.py:335: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(dtype):\n",
      "c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\data.py:338: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  is_categorical_dtype(dtype) or is_pa_ext_categorical_dtype(dtype)\n",
      "c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\data.py:384: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_categorical_dtype(dtype):\n",
      "c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\data.py:359: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  return is_int or is_bool or is_float or is_categorical_dtype(dtype)\n",
      "c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\data.py:335: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(dtype):\n",
      "c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\data.py:338: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  is_categorical_dtype(dtype) or is_pa_ext_categorical_dtype(dtype)\n",
      "c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\data.py:384: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_categorical_dtype(dtype):\n",
      "c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\data.py:359: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  return is_int or is_bool or is_float or is_categorical_dtype(dtype)\n",
      "c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\data.py:335: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(dtype):\n",
      "c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\data.py:338: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  is_categorical_dtype(dtype) or is_pa_ext_categorical_dtype(dtype)\n",
      "c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\data.py:384: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_categorical_dtype(dtype):\n",
      "c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\data.py:359: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  return is_int or is_bool or is_float or is_categorical_dtype(dtype)\n",
      "c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\data.py:335: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(dtype):\n",
      "c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\data.py:338: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  is_categorical_dtype(dtype) or is_pa_ext_categorical_dtype(dtype)\n",
      "c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\data.py:384: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_categorical_dtype(dtype):\n",
      "c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\data.py:359: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  return is_int or is_bool or is_float or is_categorical_dtype(dtype)\n",
      "c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\data.py:335: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(dtype):\n",
      "c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\data.py:338: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  is_categorical_dtype(dtype) or is_pa_ext_categorical_dtype(dtype)\n",
      "c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\data.py:384: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_categorical_dtype(dtype):\n",
      "c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\data.py:359: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  return is_int or is_bool or is_float or is_categorical_dtype(dtype)\n",
      "c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\data.py:335: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(dtype):\n",
      "c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\data.py:338: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  is_categorical_dtype(dtype) or is_pa_ext_categorical_dtype(dtype)\n",
      "c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\data.py:384: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_categorical_dtype(dtype):\n",
      "c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\data.py:359: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  return is_int or is_bool or is_float or is_categorical_dtype(dtype)\n"
     ]
    }
   ],
   "source": [
    "predicoes_ya1 = estimator_ya1.predict(X_test_ya1)\n",
    "print(np.sqrt(mean_squared_error(predicoes_ya1, ya1_test)))\n",
    "\n",
    "predicoes_ya2 = estimator_ya2.predict(X_test_ya2)\n",
    "print(np.sqrt(mean_squared_error(predicoes_ya2, ya2_test)))\n",
    "\n",
    "predicoes_yb1 = estimator_yb1.predict(X_test_yb1)\n",
    "print(np.sqrt(mean_squared_error(predicoes_yb1, yb1_test)))\n",
    "\n",
    "predicoes_yb2 = estimator_yb2.predict(X_test_yb2)\n",
    "print(np.sqrt(mean_squared_error(predicoes_yb2, yb2_test)))\n",
    "\n",
    "predicoes_yb3 = estimator_yb3.predict(X_test_yb3)\n",
    "print(np.sqrt(mean_squared_error(predicoes_yb3, yb3_test)))\n",
    "\n",
    "predicoes_yb4 = estimator_yb4.predict(X_test_yb4)\n",
    "print(np.sqrt(mean_squared_error(predicoes_yb4, yb4_test)))\n",
    "\n",
    "predicoes_yc = estimator_yc.predict(X_test_yc)\n",
    "print(np.sqrt(mean_squared_error(predicoes_yc, yc_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 1.6544214),\n",
       " (8, 7.742039),\n",
       " (0, 2.189793),\n",
       " (8, 2.1524053),\n",
       " (1, 0.9669367),\n",
       " (0, -0.20766462),\n",
       " (11, 4.661025),\n",
       " (0, -0.4518466),\n",
       " (1, -0.35034743),\n",
       " (4, 4.6611633),\n",
       " (1, 3.7931108),\n",
       " (5, 6.0076065),\n",
       " (1, 1.7208542),\n",
       " (3, 3.7942326),\n",
       " (3, 11.790098),\n",
       " (1, 1.6642836),\n",
       " (0, 0.8186923),\n",
       " (0, 2.169525),\n",
       " (0, 1.164871),\n",
       " (46, 5.015874),\n",
       " (0, 3.170341),\n",
       " (0, -0.58087105),\n",
       " (0, 2.189793),\n",
       " (1, 6.102502),\n",
       " (1, 5.490651),\n",
       " (0, 2.5031083),\n",
       " (4, 0.54121786),\n",
       " (0, 1.2558607),\n",
       " (1, 1.0175874),\n",
       " (0, 6.034958),\n",
       " (0, 2.6680322),\n",
       " (0, 1.5127999),\n",
       " (0, 2.1524053),\n",
       " (0, 1.5986435),\n",
       " (0, -0.3879854),\n",
       " (1, 2.5124419),\n",
       " (3, 4.2812314),\n",
       " (0, 2.1524053),\n",
       " (1, 2.1524053),\n",
       " (15, 5.0054884),\n",
       " (0, 2.1524053),\n",
       " (2, 4.0561666),\n",
       " (1, 2.1524053),\n",
       " (0, 1.4611434),\n",
       " (1, -0.20766462),\n",
       " (18, 20.063534),\n",
       " (0, 1.7137239),\n",
       " (0, -0.09987513),\n",
       " (0, 2.716701),\n",
       " (0, -1.1331767),\n",
       " (0, 1.677288),\n",
       " (0, -0.94504267),\n",
       " (0, 0.9688235),\n",
       " (0, 0.45726445),\n",
       " (0, 0.828889),\n",
       " (0, 0.061199486),\n",
       " (0, 0.33460346),\n",
       " (0, 4.113098),\n",
       " (0, 0.33460346),\n",
       " (6, 2.1524053),\n",
       " (0, 0.56908673),\n",
       " (0, 0.45726445),\n",
       " (0, -0.58087105),\n",
       " (1, 1.9968153),\n",
       " (4, 8.627864),\n",
       " (1, 1.0093592),\n",
       " (2, 8.771587),\n",
       " (1, 4.1256413),\n",
       " (0, 0.83047056),\n",
       " (4, 0.6261478),\n",
       " (0, 1.6642836),\n",
       " (2, 1.1382719),\n",
       " (3, 8.283463),\n",
       " (0, 0.6416093),\n",
       " (0, 1.3831347),\n",
       " (0, -1.7182183),\n",
       " (0, -0.8486758),\n",
       " (3, 0.68462545),\n",
       " (7, 2.2285788),\n",
       " (42, 2.6173987),\n",
       " (1, 1.3497618),\n",
       " (0, 0.7859482),\n",
       " (1, 0.4963571),\n",
       " (0, 0.15487027),\n",
       " (0, 1.6642836),\n",
       " (0, 3.170341),\n",
       " (0, 3.821128),\n",
       " (0, 1.6544214),\n",
       " (5, 4.4338365),\n",
       " (1, 1.6642836),\n",
       " (0, 1.6642836),\n",
       " (5, 3.6082833),\n",
       " (3, 2.6822193),\n",
       " (4, 13.3432865),\n",
       " (0, 3.7037935),\n",
       " (0, 1.6642836),\n",
       " (0, 1.0246779),\n",
       " (0, 4.0848603),\n",
       " (49, 8.696653),\n",
       " (0, 0.7350804),\n",
       " (0, 0.11556674),\n",
       " (8, 2.9144237),\n",
       " (0, 0.78062165),\n",
       " (1, 2.6286254),\n",
       " (0, -0.4518466),\n",
       " (0, -1.3418714),\n",
       " (2, 4.4864197),\n",
       " (0, 0.9669367),\n",
       " (0, 1.3497618),\n",
       " (0, 0.9669367),\n",
       " (0, 1.2310334),\n",
       " (0, -0.053253055),\n",
       " (0, -1.1053907),\n",
       " (0, 0.34363833),\n",
       " (0, 1.5416225),\n",
       " (0, 1.7515444),\n",
       " (0, -1.7388207),\n",
       " (0, 0.3604607),\n",
       " (0, 0.83985627),\n",
       " (0, -0.06857305),\n",
       " (1, 1.7492291),\n",
       " (2, 5.7688975),\n",
       " (3, 3.170341),\n",
       " (0, 1.7910103),\n",
       " (6, 2.189793),\n",
       " (0, 1.0861579),\n",
       " (1, 2.9197505),\n",
       " (0, -2.4791527),\n",
       " (2, 2.1524053),\n",
       " (4, 2.169525),\n",
       " (5, 4.4864197),\n",
       " (0, 1.1585542),\n",
       " (0, 4.2135415),\n",
       " (4, 3.96091),\n",
       " (2, 2.1524053),\n",
       " (2, 1.0290188),\n",
       " (3, 1.0093592),\n",
       " (0, -0.087675124),\n",
       " (0, 2.2750664),\n",
       " (0, 1.6440841),\n",
       " (0, 1.0680484),\n",
       " (0, 0.33460346),\n",
       " (1, 6.478668),\n",
       " (1, 0.33460346),\n",
       " (2, 1.3483678),\n",
       " (2, 2.1524053),\n",
       " (4, 5.9938974),\n",
       " (0, 1.6642836),\n",
       " (0, 8.485573),\n",
       " (0, -0.58087105),\n",
       " (5, 3.415894),\n",
       " (0, 2.3377852),\n",
       " (0, -0.7004433),\n",
       " (0, 6.0312853),\n",
       " (0, 2.2750664),\n",
       " (6, 0.87050486),\n",
       " (0, 1.4995552),\n",
       " (0, 0.46441984),\n",
       " (31, 5.4846845),\n",
       " (0, 2.1524053),\n",
       " (14, 1.6642836),\n",
       " (4, 10.49544),\n",
       " (0, 4.500247),\n",
       " (0, 2.6822193),\n",
       " (0, 1.1402485),\n",
       " (1, 3.1226401),\n",
       " (4, 8.349358),\n",
       " (0, 4.6558366),\n",
       " (0, 0.51904184),\n",
       " (0, 0.76773846),\n",
       " (6, 1.4653019),\n",
       " (1, 1.6683491),\n",
       " (0, 0.6261478),\n",
       " (6, 12.100518),\n",
       " (0, 4.6671867),\n",
       " (0, 1.9968153),\n",
       " (0, 2.2650106),\n",
       " (0, 1.6642836),\n",
       " (6, 3.5967395),\n",
       " (0, 1.6642836),\n",
       " (0, -0.029567925),\n",
       " (13, 4.500247),\n",
       " (1, 2.3377852),\n",
       " (0, 0.33460346),\n",
       " (2, 2.03749),\n",
       " (0, 0.571266),\n",
       " (0, 1.4286741),\n",
       " (0, 1.5416225),\n",
       " (4, 1.3438684),\n",
       " (1, 1.0861579),\n",
       " (2, 4.0935564),\n",
       " (1, 1.5469493),\n",
       " (1, -0.0024778638),\n",
       " (3, 3.170341),\n",
       " (0, -1.6197718),\n",
       " (5, 4.4490314),\n",
       " (0, -2.2422533),\n",
       " (13, 20.063534),\n",
       " (0, 2.1524053),\n",
       " (0, 2.1524053),\n",
       " (0, 0.33460346),\n",
       " (3, 11.827263),\n",
       " (0, -1.6365101),\n",
       " (0, 0.1413487),\n",
       " (4, 6.359698),\n",
       " (1, 2.9144237),\n",
       " (0, 1.0861579),\n",
       " (3, 2.1524053),\n",
       " (18, 5.742351),\n",
       " (2, 1.1846093),\n",
       " (0, 1.6642836),\n",
       " (2, 1.4348027),\n",
       " (0, 1.4820129),\n",
       " (3, 1.6080985),\n",
       " (0, -0.55722404),\n",
       " (6, 2.6674812),\n",
       " (28, 16.954645),\n",
       " (1, 1.7515444),\n",
       " (0, -1.7078614),\n",
       " (9, 6.629075),\n",
       " (0, 0.33460346),\n",
       " (0, 3.170341),\n",
       " (34, 10.65103),\n",
       " (0, 0.48550785),\n",
       " (2, 1.9968153),\n",
       " (0, 2.230687),\n",
       " (2, 1.5416225),\n",
       " (2, 2.03749),\n",
       " (0, 1.5469493),\n",
       " (0, 2.1524053),\n",
       " (1, 1.1827778),\n",
       " (0, 3.6082833),\n",
       " (0, 2.1524053),\n",
       " (5, 2.782935),\n",
       " (0, 1.5416225),\n",
       " (0, 1.6642836),\n",
       " (0, -0.009666393),\n",
       " (7, 10.65103),\n",
       " (0, 0.88669825),\n",
       " (2, 3.7931108),\n",
       " (0, -1.4973478),\n",
       " (5, 0.45726445),\n",
       " (0, -0.2184872),\n",
       " (0, -1.1367973),\n",
       " (0, -0.087675124),\n",
       " (1, 1.7515444),\n",
       " (6, 4.75021),\n",
       " (0, -0.89801294),\n",
       " (1, 0.68462545),\n",
       " (0, 0.57582444),\n",
       " (0, 1.6642836),\n",
       " (5, 20.063534),\n",
       " (8, 3.9613535),\n",
       " (1, 1.1193439),\n",
       " (2, 2.3700995),\n",
       " (0, 1.7910103),\n",
       " (2, 2.716701),\n",
       " (0, 0.94229263),\n",
       " (0, 1.2298073),\n",
       " (0, 1.8726515),\n",
       " (26, 17.07198),\n",
       " (0, 8.771587),\n",
       " (6, 1.7515444),\n",
       " (0, 3.170341),\n",
       " (2, 2.6099334),\n",
       " (0, 1.5469493),\n",
       " (4, 1.5416225),\n",
       " (1, 0.5445252),\n",
       " (6, 7.008869),\n",
       " (0, 0.9989572),\n",
       " (0, 4.1807203),\n",
       " (8, 3.574456),\n",
       " (0, 2.6680322),\n",
       " (0, -0.3710204),\n",
       " (0, 0.053394616),\n",
       " (1, 0.37902272),\n",
       " (22, 7.173384),\n",
       " (3, 5.5745516),\n",
       " (1, 1.6449004),\n",
       " (30, 17.560102),\n",
       " (3, 6.432703),\n",
       " (0, 1.6683491),\n",
       " (0, 2.220263),\n",
       " (0, 1.5416225),\n",
       " (0, 1.5144945),\n",
       " (3, 0.6351823),\n",
       " (4, 6.027165),\n",
       " (1, 3.6417058),\n",
       " (0, 0.33460346),\n",
       " (0, 0.27499354),\n",
       " (0, -1.0639731),\n",
       " (0, 0.83047056),\n",
       " (0, 0.83985627),\n",
       " (5, 2.782935),\n",
       " (2, 4.500247),\n",
       " (4, 1.8236204),\n",
       " (12, 5.0668473),\n",
       " (12, 1.2611071),\n",
       " (2, 1.5469493),\n",
       " (2, 5.5426135),\n",
       " (0, 1.0680484),\n",
       " (0, 1.3497618),\n",
       " (0, 0.7656534),\n",
       " (0, 2.6173987),\n",
       " (3, 1.2934214),\n",
       " (2, 2.6822193),\n",
       " (0, 0.45726445),\n",
       " (1, 1.7542337),\n",
       " (0, -0.09987513),\n",
       " (7, 5.1709123),\n",
       " (1, 2.1524053),\n",
       " (0, -0.11801803),\n",
       " (1, 1.5469493),\n",
       " (6, 8.283463),\n",
       " (0, 3.170341),\n",
       " (0, 3.2541811),\n",
       " (11, 11.527143),\n",
       " (2, 2.1524053),\n",
       " (9, 8.760597),\n",
       " (0, 0.9669367),\n",
       " (0, 2.1524053),\n",
       " (16, 8.367759),\n",
       " (1, 1.6642836),\n",
       " (0, 0.33460346),\n",
       " (1, 2.1524053),\n",
       " (8, 2.6822193),\n",
       " (0, 1.6683491),\n",
       " (0, 13.880086),\n",
       " (0, 2.782935),\n",
       " (0, 1.0246779),\n",
       " (0, 2.4263022),\n",
       " (2, 1.9624748),\n",
       " (4, 2.716701),\n",
       " (13, 2.1524053),\n",
       " (0, 0.94229263),\n",
       " (0, 7.431051),\n",
       " (0, 1.5317606),\n",
       " (0, -0.17551781),\n",
       " (1, 1.6642836),\n",
       " (2, 3.188059),\n",
       " (0, 1.111318),\n",
       " (2, 1.2661115),\n",
       " (2, 5.0475073),\n",
       " (0, 1.3914045),\n",
       " (6, 4.4792585),\n",
       " (0, -1.1102556),\n",
       " (37, 5.735208),\n",
       " (0, 1.9064803),\n",
       " (8, 6.2518578),\n",
       " (0, 1.492154),\n",
       " (3, 2.6437523),\n",
       " (3, 0.8113464),\n",
       " (0, 0.9669367),\n",
       " (0, 0.7551722),\n",
       " (0, 1.2812153),\n",
       " (1, 1.138446),\n",
       " (44, 13.724496),\n",
       " (2, 0.26197618),\n",
       " (0, 1.6642836),\n",
       " (0, 1.4475337),\n",
       " (3, 3.7931108),\n",
       " (0, 2.0125573),\n",
       " (0, -0.19765943),\n",
       " (0, 0.33150938),\n",
       " (1, 2.1524053),\n",
       " (0, 1.6683491),\n",
       " (0, -0.94504267),\n",
       " (5, 2.0521905),\n",
       " (7, 3.9613535),\n",
       " (1, 0.9669367),\n",
       " (0, 5.5470967),\n",
       " (6, 8.771587),\n",
       " (0, 3.7472212),\n",
       " (19, 19.841534),\n",
       " (0, 1.5416225),\n",
       " (0, 2.1524053),\n",
       " (0, 1.3497618),\n",
       " (0, 1.5469493),\n",
       " (1, 4.6558366),\n",
       " (16, 4.6558366),\n",
       " (0, 0.86163974),\n",
       " (4, 1.4995552),\n",
       " (0, 1.8285236),\n",
       " (4, 3.5967395),\n",
       " (6, 4.4490314),\n",
       " (0, 2.6410203),\n",
       " (1, -0.042652458),\n",
       " (0, 1.3471416),\n",
       " (0, 2.47793),\n",
       " (2, 1.0246779),\n",
       " (3, 3.1254177),\n",
       " (4, 2.1524053),\n",
       " (11, 6.027165),\n",
       " (0, 1.0000664),\n",
       " (1, 1.6642836),\n",
       " (5, 1.3304137),\n",
       " (2, 2.6173987),\n",
       " (22, 2.637296),\n",
       " (0, 2.5595582),\n",
       " (0, 2.208953),\n",
       " (0, 1.3324264),\n",
       " (0, 1.5416225),\n",
       " (0, 1.1723881),\n",
       " (4, 11.1194315),\n",
       " (4, 1.4820129),\n",
       " (13, 7.4861217),\n",
       " (2, 1.3008765),\n",
       " (0, 1.9420996),\n",
       " (0, 3.6976058),\n",
       " (0, -0.28510013),\n",
       " (0, 0.8988991),\n",
       " (0, 0.7171953),\n",
       " (0, 1.1434506),\n",
       " (23, 6.3695908),\n",
       " (2, 5.5426135),\n",
       " (0, 4.802867),\n",
       " (0, 1.1837856),\n",
       " (0, 1.3515857),\n",
       " (0, 0.06378028),\n",
       " (1, 3.170341),\n",
       " (0, -0.4518466),\n",
       " (0, 0.83047056),\n",
       " (27, 3.170341),\n",
       " (2, 4.500247),\n",
       " (0, 0.98447907),\n",
       " (0, 2.03749),\n",
       " (3, 1.1402485),\n",
       " (0, -0.7239824),\n",
       " (0, 3.170341),\n",
       " (0, 1.2661115),\n",
       " (3, 5.064366),\n",
       " (0, 1.1193439),\n",
       " (0, 3.170341),\n",
       " (0, 3.428899),\n",
       " (0, 1.6642836),\n",
       " (0, 0.73897874),\n",
       " (0, -1.5999662),\n",
       " (0, 2.6822193),\n",
       " (10, 1.6642836),\n",
       " (0, 2.1524053),\n",
       " (0, 0.73897874),\n",
       " (1, 0.69648695),\n",
       " (0, 1.7542337),\n",
       " (0, 2.6674812),\n",
       " (0, 0.94229263),\n",
       " (1, 2.9144237),\n",
       " (0, 1.5416225),\n",
       " (2, 1.2558607),\n",
       " (0, 1.0093592),\n",
       " (1, 2.8061206),\n",
       " (2, 1.2349888),\n",
       " (1, 0.88669825),\n",
       " (0, 0.46629938),\n",
       " (0, 0.49420464),\n",
       " (3, 4.2576647),\n",
       " (7, 3.4740784),\n",
       " (0, 1.472423),\n",
       " (0, 2.6576467),\n",
       " (0, -0.48584718),\n",
       " (0, 0.9793322),\n",
       " (6, 3.170341),\n",
       " (0, 3.9221218),\n",
       " (4, 6.084483),\n",
       " (1, 3.188059),\n",
       " (1, 2.2192268),\n",
       " (0, 2.603018),\n",
       " (0, -0.58087105),\n",
       " (0, 1.1802275),\n",
       " (0, -0.549892),\n",
       " (9, 2.1524053),\n",
       " (3, 0.8113464),\n",
       " (3, 0.67023253),\n",
       " (13, 4.4490314),\n",
       " (0, -0.94504267),\n",
       " (0, 1.317068),\n",
       " (0, 1.4974815),\n",
       " (0, 2.1940086),\n",
       " (0, 0.86163974),\n",
       " (0, 1.6642836),\n",
       " (0, -0.91607636),\n",
       " (0, 3.6704497),\n",
       " (44, 3.5374637),\n",
       " (2, 2.9485683),\n",
       " (0, 2.6174412),\n",
       " (0, 1.6326439),\n",
       " (0, 0.83047056),\n",
       " (0, -0.18572046),\n",
       " (3, 1.6642836),\n",
       " (1, 1.7542337),\n",
       " (0, 2.1524053),\n",
       " (10, 5.413317),\n",
       " (2, 1.6642836),\n",
       " (4, 1.6642836),\n",
       " (0, 5.904504),\n",
       " (2, 4.500247),\n",
       " (0, 13.880086),\n",
       " (0, 0.86163974),\n",
       " (2, 8.349358),\n",
       " (0, 5.1895084),\n",
       " (1, 2.6173987),\n",
       " (0, 2.1524053),\n",
       " (31, 6.0621724),\n",
       " (0, 5.0589747),\n",
       " (3, 3.231777),\n",
       " (26, 6.8404174),\n",
       " (0, -1.4501946),\n",
       " (14, 6.201898),\n",
       " (0, 3.170341),\n",
       " (0, 1.5469493),\n",
       " (0, 0.94229263),\n",
       " (0, 6.13773),\n",
       " (0, 3.1646488),\n",
       " (0, 1.011336),\n",
       " (2, 0.6261478),\n",
       " (1, 0.4963571),\n",
       " (0, 2.1524053),\n",
       " (0, 0.7350804),\n",
       " (1, 2.189793),\n",
       " (0, -0.58087105),\n",
       " (1, 2.189793),\n",
       " (0, 0.88669825),\n",
       " (0, 2.716701),\n",
       " (0, 0.6251506),\n",
       " (0, 1.1199768),\n",
       " (1, 1.6642836),\n",
       " (2, 4.592787),\n",
       " (1, 2.1434462),\n",
       " (1, -0.56031847),\n",
       " (7, 1.6642836),\n",
       " (1, 2.7906933),\n",
       " (2, 1.2611071),\n",
       " (1, -0.58087105),\n",
       " (0, 0.50598645),\n",
       " (0, -1.7753398),\n",
       " (3, 5.8647227),\n",
       " (0, 1.5469493),\n",
       " (1, 0.45726445),\n",
       " (0, 3.170341),\n",
       " (0, 7.139246),\n",
       " (0, -2.1138701),\n",
       " (16, 17.560102),\n",
       " (0, -12.192975),\n",
       " (0, 1.4994587),\n",
       " (3, 8.341741),\n",
       " (1, 17.560102),\n",
       " (1, 1.2329761),\n",
       " (4, 13.880086),\n",
       " (0, 0.33460346),\n",
       " (1, 3.8372352),\n",
       " (0, 1.041674),\n",
       " (3, 0.25996375),\n",
       " (3, 1.9968153),\n",
       " (5, 6.7241035),\n",
       " (2, 0.9793322),\n",
       " (0, 0.83047056),\n",
       " (0, 1.6598061),\n",
       " (1, 2.189793),\n",
       " (1, 2.3089678),\n",
       " (0, 1.3471416),\n",
       " (0, 4.1346254),\n",
       " (14, 5.9938974),\n",
       " (0, 2.1524053),\n",
       " (0, 1.2661115),\n",
       " (10, 7.861236),\n",
       " (0, 0.4963571),\n",
       " (2, 0.5528981),\n",
       " (0, 0.83985627),\n",
       " (0, 0.45726445),\n",
       " (0, 0.5445252),\n",
       " (1, 2.2750664),\n",
       " (0, -2.8861434),\n",
       " (0, 0.86160225),\n",
       " (15, 6.3601685),\n",
       " (0, 0.42186427),\n",
       " (2, 11.612395),\n",
       " (0, 1.856398),\n",
       " (0, 1.011336),\n",
       " (1, 1.7492291),\n",
       " (0, 1.2812153),\n",
       " (0, 1.6642836),\n",
       " (0, 2.1524053),\n",
       " (0, 1.5348696),\n",
       " (0, 1.6642836),\n",
       " (0, 0.98447907),\n",
       " (0, 2.4263022),\n",
       " (0, 0.27499354),\n",
       " (2, 1.8718902),\n",
       " (0, 2.03749),\n",
       " (0, 0.7859482),\n",
       " (2, 3.4159708),\n",
       " (0, 0.061199486),\n",
       " (17, 2.1969392),\n",
       " (0, 0.72252184),\n",
       " (0, 0.9973154),\n",
       " (18, 2.6822193),\n",
       " (0, -1.2544895),\n",
       " (6, 5.286366),\n",
       " (0, -0.50286233),\n",
       " (5, 17.560102),\n",
       " (0, 1.6642836),\n",
       " (0, -0.58087105),\n",
       " (14, 8.561125),\n",
       " (0, 1.6440841),\n",
       " (3, 7.894941),\n",
       " (0, 2.1524053),\n",
       " (1, 1.9968153),\n",
       " (0, 0.02595686),\n",
       " (8, 4.500247),\n",
       " (16, 11.012066),\n",
       " (0, 1.164871),\n",
       " (1, 2.6302164),\n",
       " (3, 1.7542337),\n",
       " (0, 0.9793322),\n",
       " (0, -0.056696013),\n",
       " (0, 2.5491812),\n",
       " (0, -0.27154076),\n",
       " (0, 2.6822193),\n",
       " (6, 2.716701),\n",
       " (3, 6.13773),\n",
       " (0, -0.58087105),\n",
       " (4, 5.0762706),\n",
       " (4, 3.2909007),\n",
       " (0, 1.041674),\n",
       " (0, -0.74259907),\n",
       " (0, 2.1524053),\n",
       " (0, -0.7882489),\n",
       " (0, 0.42186427),\n",
       " (2, 2.3902347),\n",
       " (0, 0.07384247),\n",
       " (0, 0.8113464),\n",
       " (0, 0.100248106),\n",
       " (2, 2.1524053),\n",
       " (0, 1.5416225),\n",
       " (0, -0.39567244),\n",
       " (1, 2.189793),\n",
       " (0, 1.203037),\n",
       " (1, -0.025503721),\n",
       " (2, 1.5416225),\n",
       " (1, 2.637296),\n",
       " (3, 0.07289339),\n",
       " (1, 2.6822193),\n",
       " (0, 1.3554794),\n",
       " (6, 5.389723),\n",
       " (0, 1.9777932),\n",
       " (3, 2.189793),\n",
       " (0, 2.5595582),\n",
       " (0, 1.128379),\n",
       " (0, -0.24661632),\n",
       " (0, -2.0297203),\n",
       " (71, 8.771587),\n",
       " (2, 2.189793),\n",
       " (0, 1.1846093),\n",
       " (0, 3.170341),\n",
       " (2, 1.1503233),\n",
       " (7, 3.4197044),\n",
       " (13, 3.6984668),\n",
       " (17, 1.5416225),\n",
       " (0, 0.09958375),\n",
       " (0, 3.1727226),\n",
       " (2, 3.4159708),\n",
       " (2, 2.1524053),\n",
       " (0, -0.94504267),\n",
       " (1, 2.4263022),\n",
       " (10, 3.4457262),\n",
       " (1, -0.07562977),\n",
       " (0, 1.8447818),\n",
       " (0, 9.2221985),\n",
       " (0, 25.944698),\n",
       " (4, 2.47793),\n",
       " (3, 12.100518),\n",
       " (1, 0.07289339),\n",
       " (8, 2.637296),\n",
       " (1, 1.6642836),\n",
       " (0, 0.8853372),\n",
       " (1, 2.9014194),\n",
       " (1, 4.500247),\n",
       " (0, 2.4535842),\n",
       " (1, 3.2260861),\n",
       " (0, 1.6642836),\n",
       " (0, 2.782935),\n",
       " (0, 0.33460346),\n",
       " (0, 5.0762706),\n",
       " (9, 14.395163)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_list = list(predicoes_ya1)\n",
    "test_list = list(ya1_test)\n",
    "complist = []\n",
    "for i in range(len(test_list)):\n",
    "    complist.append((test_list[i], pred_list[i]))\n",
    "complist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 0.3754376),\n",
       " (4, 3.960713),\n",
       " (2, 0.8912915),\n",
       " (3, 1.8856685),\n",
       " (0, 0.91466457),\n",
       " (0, -0.15808249),\n",
       " (9, 2.412734),\n",
       " (0, 0.050864726),\n",
       " (0, 0.76828074),\n",
       " (0, 3.7035556),\n",
       " (0, 3.5765655),\n",
       " (3, 2.5659642),\n",
       " (1, 0.40382892),\n",
       " (2, 2.1043515),\n",
       " (5, 8.5441475),\n",
       " (0, 1.5465772),\n",
       " (0, 1.3629595),\n",
       " (6, 1.5465772),\n",
       " (0, 1.3299563),\n",
       " (14, 3.910461),\n",
       " (0, 1.3541044),\n",
       " (1, -0.51117694),\n",
       " (0, 1.5247695),\n",
       " (2, 4.4269595),\n",
       " (2, 5.3409266),\n",
       " (2, 2.492778),\n",
       " (4, 0.848662),\n",
       " (2, 0.8505134),\n",
       " (0, 1.5002146),\n",
       " (0, 2.7486184),\n",
       " (0, 1.8856685),\n",
       " (0, 1.8856685),\n",
       " (2, 1.8856685),\n",
       " (0, 1.500721),\n",
       " (1, -0.28929603),\n",
       " (0, 1.0228771),\n",
       " (5, 3.9620216),\n",
       " (2, 1.532574),\n",
       " (5, 2.0964077),\n",
       " (4, 3.8517795),\n",
       " (0, 1.8856685),\n",
       " (1, 2.1868234),\n",
       " (8, 1.8856685),\n",
       " (0, 1.0718005),\n",
       " (0, -0.15808249),\n",
       " (2, 7.6842136),\n",
       " (0, -0.53207463),\n",
       " (0, -0.70136726),\n",
       " (0, 3.209096),\n",
       " (0, -1.3296324),\n",
       " (1, 0.3412611),\n",
       " (0, -0.072298236),\n",
       " (1, 1.3963557),\n",
       " (0, 0.8146434),\n",
       " (0, 0.9847631),\n",
       " (0, -0.53207463),\n",
       " (0, 0.2205848),\n",
       " (6, 6.6647935),\n",
       " (0, 0.76828074),\n",
       " (1, 1.4895635),\n",
       " (2, 0.6161337),\n",
       " (0, 0.26694715),\n",
       " (0, -0.072298236),\n",
       " (1, 1.6944537),\n",
       " (0, 4.839797),\n",
       " (0, 1.2460492),\n",
       " (0, 5.749548),\n",
       " (0, 3.2803507),\n",
       " (0, 0.069023),\n",
       " (0, 0.5738539),\n",
       " (2, 1.6323617),\n",
       " (2, 1.0225201),\n",
       " (4, 5.4104533),\n",
       " (0, 0.92313385),\n",
       " (0, 0.97142255),\n",
       " (0, -1.3390863),\n",
       " (0, -0.4970602),\n",
       " (1, 1.154476),\n",
       " (5, 2.870004),\n",
       " (35, 1.2702417),\n",
       " (3, 1.8856685),\n",
       " (0, 0.7825707),\n",
       " (0, 0.83688694),\n",
       " (0, 0.9525206),\n",
       " (4, 1.5465772),\n",
       " (0, 1.3077418),\n",
       " (7, 3.6534135),\n",
       " (0, 0.3754376),\n",
       " (5, 1.864719),\n",
       " (1, 1.4344374),\n",
       " (4, 1.5130292),\n",
       " (9, 6.4757457),\n",
       " (1, 0.9686497),\n",
       " (6, 8.402519),\n",
       " (2, 3.6352556),\n",
       " (2, 1.5465772),\n",
       " (2, 1.348653),\n",
       " (1, 3.94863),\n",
       " (7, 5.1317034),\n",
       " (0, 0.56185),\n",
       " (0, 0.78280103),\n",
       " (11, 3.0709805),\n",
       " (0, 0.95229006),\n",
       " (0, 5.2646213),\n",
       " (0, 0.13664916),\n",
       " (0, -0.7060074),\n",
       " (1, 4.0496364),\n",
       " (0, 0.91466457),\n",
       " (1, 1.8856685),\n",
       " (0, 0.91466457),\n",
       " (1, 0.6161337),\n",
       " (0, -1.5260583),\n",
       " (0, -1.5089036),\n",
       " (0, 0.26694715),\n",
       " (3, 1.1168959),\n",
       " (0, 0.96102697),\n",
       " (0, -0.15808249),\n",
       " (0, 0.70705146),\n",
       " (0, -0.1940434),\n",
       " (0, 0.13813603),\n",
       " (2, 1.80322),\n",
       " (1, 2.1496572),\n",
       " (0, 1.3077418),\n",
       " (0, 1.7341081),\n",
       " (1, 1.5247695),\n",
       " (0, 1.414514),\n",
       " (3, 2.8548982),\n",
       " (0, -0.8677731),\n",
       " (1, 1.8856685),\n",
       " (3, 1.5465772),\n",
       " (3, 4.0496364),\n",
       " (1, 0.3754376),\n",
       " (0, 4.2796264),\n",
       " (15, 4.157237),\n",
       " (0, 1.9714528),\n",
       " (3, 1.6944537),\n",
       " (4, 1.0481249),\n",
       " (0, 0.050864726),\n",
       " (0, 1.9320312),\n",
       " (0, -0.0040759593),\n",
       " (0, 0.45943257),\n",
       " (0, 0.2205848),\n",
       " (0, 3.1737196),\n",
       " (0, 0.2205848),\n",
       " (2, 0.83221614),\n",
       " (2, 1.8856685),\n",
       " (1, 3.1217723),\n",
       " (0, 0.8009593),\n",
       " (3, 3.7415504),\n",
       " (0, -0.15808249),\n",
       " (6, 2.816503),\n",
       " (4, 3.81409),\n",
       " (0, -0.51329154),\n",
       " (1, 2.675089),\n",
       " (0, 1.1913679),\n",
       " (0, 1.5465772),\n",
       " (0, 1.8132552),\n",
       " (0, 1.0299667),\n",
       " (5, 5.103433),\n",
       " (0, 1.9320312),\n",
       " (8, 1.5465772),\n",
       " (1, 5.915679),\n",
       " (0, 2.6325068),\n",
       " (2, 0.9686497),\n",
       " (0, 1.5465772),\n",
       " (1, 1.4389851),\n",
       " (9, 6.1516376),\n",
       " (4, 3.6899004),\n",
       " (0, 0.99888265),\n",
       " (0, 0.51142144),\n",
       " (12, 1.8856685),\n",
       " (0, 1.8856685),\n",
       " (0, 0.5738539),\n",
       " (0, 6.848938),\n",
       " (0, 3.7180266),\n",
       " (0, 1.85883),\n",
       " (0, -0.9837635),\n",
       " (0, 1.1791159),\n",
       " (4, 3.4116118),\n",
       " (0, 1.5465772),\n",
       " (0, 0.2205848),\n",
       " (0, 3.683036),\n",
       " (1, 4.0120134),\n",
       " (0, 0.26694715),\n",
       " (1, 1.5465772),\n",
       " (0, 0.56185),\n",
       " (1, 3.2482378),\n",
       " (0, 1.5002146),\n",
       " (2, 0.77326703),\n",
       " (0, 0.8668203),\n",
       " (0, 1.74014),\n",
       " (0, 1.494871),\n",
       " (0, -0.21224101),\n",
       " (0, 1.3077418),\n",
       " (0, -0.65882576),\n",
       " (3, 4.4963303),\n",
       " (0, -1.3390863),\n",
       " (10, 7.730576),\n",
       " (2, 1.8856685),\n",
       " (0, 1.8089732),\n",
       " (0, 0.76828074),\n",
       " (0, 4.8585978),\n",
       " (0, -1.249293),\n",
       " (0, 0.10027961),\n",
       " (0, 1.0228771),\n",
       " (0, 3.024618),\n",
       " (0, 1.414514),\n",
       " (2, 1.8856685),\n",
       " (9, 5.184003),\n",
       " (3, 1.8856685),\n",
       " (0, 1.5465772),\n",
       " (0, 1.5323322),\n",
       " (0, 1.5519407),\n",
       " (8, 4.1248817),\n",
       " (0, -0.039256394),\n",
       " (0, 2.6087286),\n",
       " (2, 4.9717126),\n",
       " (1, 0.96102697),\n",
       " (0, -1.367489),\n",
       " (3, 5.9404516),\n",
       " (0, 0.2205848),\n",
       " (0, 1.3077418),\n",
       " (13, 6.1068964),\n",
       " (0, 0.6952337),\n",
       " (3, 1.5247335),\n",
       " (0, 2.2547598),\n",
       " (0, 1.585999),\n",
       " (0, 1.348653),\n",
       " (0, 1.1607746),\n",
       " (0, 1.8856685),\n",
       " (4, 0.8685854),\n",
       " (2, 6.2778206),\n",
       " (1, 1.4895635),\n",
       " (1, 1.3293611),\n",
       " (0, 1.6645908),\n",
       " (0, 1.348653),\n",
       " (0, 0.33986455),\n",
       " (9, 6.1068964),\n",
       " (0, 1.1996865),\n",
       " (9, 3.5765655),\n",
       " (0, -1.3296324),\n",
       " (0, 0.26694715),\n",
       " (0, -0.7006784),\n",
       " (0, 0.050864726),\n",
       " (0, 0.050864726),\n",
       " (0, 0.76310307),\n",
       " (3, 4.0496364),\n",
       " (0, -0.38006735),\n",
       " (0, 0.33545446),\n",
       " (1, 2.2368178),\n",
       " (0, 1.7109535),\n",
       " (9, 7.6842136),\n",
       " (2, 2.5733478),\n",
       " (1, 0.78280103),\n",
       " (6, 3.6954753),\n",
       " (0, 1.9320312),\n",
       " (6, 3.209096),\n",
       " (0, 0.4160242),\n",
       " (0, 1.1085104),\n",
       " (0, 1.2170007),\n",
       " (6, 4.989871),\n",
       " (5, 5.749548),\n",
       " (3, 0.96102697),\n",
       " (0, 1.3077418),\n",
       " (10, 2.558639),\n",
       " (1, 0.97142255),\n",
       " (0, 1.1041095),\n",
       " (0, 0.22909097),\n",
       " (1, 4.3788486),\n",
       " (0, 4.771086),\n",
       " (0, 2.498585),\n",
       " (4, 1.8954041),\n",
       " (0, 1.9320312),\n",
       " (1, -0.07121139),\n",
       " (0, 0.050864726),\n",
       " (3, 0.6208047),\n",
       " (14, 3.0541244),\n",
       " (9, 4.6033397),\n",
       " (2, 2.5229442),\n",
       " (0, 5.52689),\n",
       " (4, 5.914739),\n",
       " (0, 1.8856685),\n",
       " (5, 2.492778),\n",
       " (0, 1.585999),\n",
       " (0, 1.2937849),\n",
       " (1, 0.5738539),\n",
       " (6, 1.348653),\n",
       " (0, 3.2262094),\n",
       " (0, 0.2205848),\n",
       " (0, 0.6573773),\n",
       " (0, -1.2686232),\n",
       " (0, 0.26694715),\n",
       " (0, 0.55157673),\n",
       " (2, 1.3293611),\n",
       " (1, 3.1802025),\n",
       " (9, 1.4389851),\n",
       " (0, 3.8198485),\n",
       " (9, 1.4177661),\n",
       " (1, 1.3304948),\n",
       " (5, 3.012648),\n",
       " (0, 0.45943257),\n",
       " (0, 1.8856685),\n",
       " (0, 1.3379765),\n",
       " (0, 1.4389851),\n",
       " (0, 1.1012267),\n",
       " (2, 0.9686497),\n",
       " (0, 0.4555697),\n",
       " (0, 1.6919358),\n",
       " (0, -0.70136726),\n",
       " (5, 4.1645513),\n",
       " (4, 1.9320312),\n",
       " (0, 0.33545446),\n",
       " (6, 1.3304948),\n",
       " (1, 5.212528),\n",
       " (0, 1.3077418),\n",
       " (0, 2.0369284),\n",
       " (17, 9.455228),\n",
       " (0, 1.7169251),\n",
       " (1, 4.795078),\n",
       " (0, 0.91466457),\n",
       " (0, 1.8856685),\n",
       " (12, 3.6630595),\n",
       " (1, 1.1875043),\n",
       " (0, 0.2205848),\n",
       " (0, 1.8856685),\n",
       " (2, 0.9686497),\n",
       " (2, 1.8856685),\n",
       " (0, 6.965965),\n",
       " (0, 1.3293611),\n",
       " (0, 1.5465772),\n",
       " (1, 2.6855273),\n",
       " (4, 1.1384571),\n",
       " (8, 3.209096),\n",
       " (1, 1.4895635),\n",
       " (1, 0.24630418),\n",
       " (0, 3.134694),\n",
       " (0, 0.32907504),\n",
       " (0, -1.1004605),\n",
       " (0, 1.6323617),\n",
       " (6, 2.492778),\n",
       " (0, 1.1649737),\n",
       " (1, 1.3528445),\n",
       " (1, 0.33545446),\n",
       " (0, 0.79005194),\n",
       " (6, 5.37214),\n",
       " (0, 0.050864726),\n",
       " (21, 5.8410745),\n",
       " (1, 1.9750202),\n",
       " (8, 5.1217065),\n",
       " (1, 4.9800334),\n",
       " (9, 4.731993),\n",
       " (1, 0.051872052),\n",
       " (0, 0.91466457),\n",
       " (0, 0.8685854),\n",
       " (0, 0.3754376),\n",
       " (0, 1.4177661),\n",
       " (20, 6.774747),\n",
       " (1, 0.6596383),\n",
       " (0, 1.5465772),\n",
       " (0, 0.4160242),\n",
       " (3, 3.5765655),\n",
       " (0, 2.222416),\n",
       " (0, 0.514115),\n",
       " (0, -0.51712775),\n",
       " (1, 1.7161314),\n",
       " (0, 1.8856685),\n",
       " (0, -0.15808249),\n",
       " (2, 1.3304948),\n",
       " (6, 2.5733478),\n",
       " (0, 0.91466457),\n",
       " (0, 4.86311),\n",
       " (4, 5.749548),\n",
       " (0, 1.2306066),\n",
       " (15, 5.7455683),\n",
       " (0, 1.5002146),\n",
       " (0, 1.4219021),\n",
       " (4, 1.8856685),\n",
       " (1, 1.494871),\n",
       " (4, 3.8033652),\n",
       " (8, 4.0893617),\n",
       " (0, 1.5465772),\n",
       " (2, 1.6506267),\n",
       " (0, 1.1807295),\n",
       " (3, 3.6095362),\n",
       " (27, 4.5426927),\n",
       " (0, 2.083339),\n",
       " (1, 0.78280103),\n",
       " (1, 1.1266686),\n",
       " (4, 2.5733478),\n",
       " (4, 1.5465772),\n",
       " (1, 1.8856685),\n",
       " (0, 1.8856685),\n",
       " (1, 1.5465772),\n",
       " (0, 0.15935525),\n",
       " (0, 1.4344374),\n",
       " (0, 1.3158221),\n",
       " (2, 1.4389851),\n",
       " (12, 1.5465772),\n",
       " (0, 0.9222871),\n",
       " (0, 2.6615195),\n",
       " (0, 0.6823444),\n",
       " (0, 1.6645908),\n",
       " (0, 0.6994542),\n",
       " (0, 7.774336),\n",
       " (0, 1.5519407),\n",
       " (5, 5.6775913),\n",
       " (5, 1.0102509),\n",
       " (2, 1.2937849),\n",
       " (0, 3.8517795),\n",
       " (0, -0.11086563),\n",
       " (0, 1.5440118),\n",
       " (0, 0.5052141),\n",
       " (0, 1.3064818),\n",
       " (13, 5.9758306),\n",
       " (5, 3.012648),\n",
       " (0, 4.3468714),\n",
       " (0, 1.8719066),\n",
       " (0, 2.4525719),\n",
       " (0, 0.050864726),\n",
       " (1, 1.3077418),\n",
       " (0, 0.050864726),\n",
       " (0, 0.069023),\n",
       " (1, 1.3077418),\n",
       " (2, 3.683036),\n",
       " (0, 1.1759781),\n",
       " (5, 1.348653),\n",
       " (11, 1.5465772),\n",
       " (0, -0.050003096),\n",
       " (0, 1.3077418),\n",
       " (0, 1.1549202),\n",
       " (0, 1.5480443),\n",
       " (0, 1.3304948),\n",
       " (0, 1.3077418),\n",
       " (1, 1.4468108),\n",
       " (0, 1.3770401),\n",
       " (0, 1.5002146),\n",
       " (0, -0.4586109),\n",
       " (0, 0.7707256),\n",
       " (0, 1.1799096),\n",
       " (0, 1.7169251),\n",
       " (0, 1.5002146),\n",
       " (3, 1.348653),\n",
       " (0, 1.6919358),\n",
       " (0, 2.6087286),\n",
       " (1, -0.32464224),\n",
       " (8, 3.0709805),\n",
       " (0, 0.9525206),\n",
       " (3, 0.896876),\n",
       " (1, 1.0481249),\n",
       " (1, 2.5733478),\n",
       " (1, 0.5738539),\n",
       " (0, 1.1996865),\n",
       " (0, 0.069023),\n",
       " (0, -0.0061612204),\n",
       " (0, 3.8492622),\n",
       " (13, 3.6095362),\n",
       " (3, 1.9320312),\n",
       " (0, 1.8856685),\n",
       " (0, -0.1428679),\n",
       " (2, 1.348653),\n",
       " (3, 1.3077418),\n",
       " (2, 3.976322),\n",
       " (0, 2.885717),\n",
       " (2, 2.492778),\n",
       " (0, 1.2452524),\n",
       " (1, 1.766885),\n",
       " (0, -0.15808249),\n",
       " (2, 1.348653),\n",
       " (0, -0.19479325),\n",
       " (5, 1.8856685),\n",
       " (0, 0.7234488),\n",
       " (1, 0.91043264),\n",
       " (1, 4.4963303),\n",
       " (0, -0.5171551),\n",
       " (3, 0.52296036),\n",
       " (0, 1.5851405),\n",
       " (0, 2.0545573),\n",
       " (0, 1.5465772),\n",
       " (3, 1.7109535),\n",
       " (0, -0.19479325),\n",
       " (0, 3.5765655),\n",
       " (1, 1.7665931),\n",
       " (3, 4.199545),\n",
       " (0, 1.8854176),\n",
       " (0, 1.1467612),\n",
       " (0, 0.069023),\n",
       " (0, -0.19479325),\n",
       " (12, 1.5465772),\n",
       " (1, 1.6919358),\n",
       " (1, 1.8856685),\n",
       " (5, 4.39757),\n",
       " (4, 1.6323617),\n",
       " (5, 1.4344374),\n",
       " (0, 1.5002146),\n",
       " (3, 4.0161552),\n",
       " (4, 6.965965),\n",
       " (0, 1.348653),\n",
       " (2, 6.1516376),\n",
       " (1, 3.6682873),\n",
       " (2, 1.4389851),\n",
       " (0, 1.8856685),\n",
       " (19, 5.5003867),\n",
       " (0, 4.5240145),\n",
       " (2, 3.683743),\n",
       " (11, 5.550784),\n",
       " (0, -1.2869192),\n",
       " (14, 5.9623055),\n",
       " (1, 1.3077418),\n",
       " (0, 1.1609577),\n",
       " (0, 0.4160242),\n",
       " (2, 2.4470148),\n",
       " (0, 0.314852),\n",
       " (1, 1.0990424),\n",
       " (6, 1.1215473),\n",
       " (0, 0.83688694),\n",
       " (4, 1.8856685),\n",
       " (0, 0.56185),\n",
       " (0, 1.0858907),\n",
       " (0, -0.15808249),\n",
       " (0, 1.4389851),\n",
       " (0, 1.1996865),\n",
       " (1, 3.209096),\n",
       " (0, 0.19403999),\n",
       " (1, 3.785789),\n",
       " (1, 1.6323617),\n",
       " (0, 4.7461367),\n",
       " (0, 2.5229442),\n",
       " (0, -0.77696794),\n",
       " (3, 1.6323617),\n",
       " (1, 1.9320312),\n",
       " (0, 1.4177661),\n",
       " (0, -0.51117694),\n",
       " (0, 0.23503666),\n",
       " (0, -0.29831702),\n",
       " (0, 4.3296967),\n",
       " (1, 1.2537994),\n",
       " (0, 0.069023),\n",
       " (0, 1.3077418),\n",
       " (0, 4.6819887),\n",
       " (0, -0.15808249),\n",
       " (4, 5.52689),\n",
       " (0, -1.1665475),\n",
       " (0, 1.636058),\n",
       " (4, 5.087884),\n",
       " (0, 5.52689),\n",
       " (0, 0.5738539),\n",
       " (1, 6.965965),\n",
       " (0, 0.2205848),\n",
       " (0, 0.8009593),\n",
       " (0, 0.92951024),\n",
       " (0, 0.95280445),\n",
       " (0, 1.0228771),\n",
       " (1, 4.5386424),\n",
       " (0, 1.5465772),\n",
       " (0, 0.26694715),\n",
       " (0, 1.4389851),\n",
       " (8, 1.4389851),\n",
       " (6, 2.469445),\n",
       " (0, 1.1266686),\n",
       " (5, 1.2089849),\n",
       " (6, 3.1217723),\n",
       " (0, 1.7169251),\n",
       " (0, 1.1549202),\n",
       " (6, 5.812544),\n",
       " (0, 0.83688694),\n",
       " (0, 0.89227426),\n",
       " (0, 0.35365152),\n",
       " (0, 0.069023),\n",
       " (0, 0.031166492),\n",
       " (1, 1.762311),\n",
       " (0, -2.0487785),\n",
       " (0, 0.917254),\n",
       " (3, 4.5075293),\n",
       " (0, 0.1827284),\n",
       " (4, 6.3119187),\n",
       " (2, 0.891061),\n",
       " (0, 1.0990424),\n",
       " (1, 1.80322),\n",
       " (0, 0.17751351),\n",
       " (0, 0.99888265),\n",
       " (0, 1.9714528),\n",
       " (3, 1.1384571),\n",
       " (0, 1.3770401),\n",
       " (0, 1.1759781),\n",
       " (0, 2.6855273),\n",
       " (0, 0.8200057),\n",
       " (1, 1.80322),\n",
       " (0, 1.5465772),\n",
       " (1, 0.7825707),\n",
       " (1, 3.3934538),\n",
       " (0, -0.7206972),\n",
       " (6, 2.470188),\n",
       " (0, 0.33549327),\n",
       " (0, 3.7394264),\n",
       " (18, 0.9686497),\n",
       " (1, 0.050864726),\n",
       " (4, 3.5330503),\n",
       " (0, -0.41677815),\n",
       " (3, 5.52689),\n",
       " (1, 1.4344374),\n",
       " (0, -0.51117694),\n",
       " (14, 5.8072534),\n",
       " (2, -0.0040759593),\n",
       " (8, 6.157638),\n",
       " (2, 1.9714528),\n",
       " (1, 1.6944537),\n",
       " (0, -0.15808249),\n",
       " (5, 3.3441553),\n",
       " (2, 8.817951),\n",
       " (2, 1.3299563),\n",
       " (0, 0.069023),\n",
       " (0, 1.7382984),\n",
       " (1, 1.5465772),\n",
       " (0, 0.014153948),\n",
       " (1, 1.5381914),\n",
       " (1, 2.3073559),\n",
       " (0, 0.9686497),\n",
       " (6, 3.2554586),\n",
       " (1, 2.4470148),\n",
       " (0, 0.0062934863),\n",
       " (21, 5.2881565),\n",
       " (4, 3.9044225),\n",
       " (0, 0.92951024),\n",
       " (0, 0.29803205),\n",
       " (0, 1.7161314),\n",
       " (0, -1.2869192),\n",
       " (0, 0.1827284),\n",
       " (6, 2.492778),\n",
       " (0, -0.5976971),\n",
       " (0, 0.27935523),\n",
       " (0, 0.48227274),\n",
       " (2, 1.8089732),\n",
       " (0, 0.4887541),\n",
       " (0, -0.45257983),\n",
       " (3, 1.5247695),\n",
       " (2, 1.6944537),\n",
       " (3, 0.4160242),\n",
       " (1, 1.585999),\n",
       " (0, 1.5465772),\n",
       " (2, -0.73601073),\n",
       " (0, 0.7707256),\n",
       " (0, -0.026618965),\n",
       " (11, 7.502514),\n",
       " (0, 1.4389851),\n",
       " (1, 1.4389851),\n",
       " (0, 0.9222871),\n",
       " (0, 0.78280103),\n",
       " (0, 0.09642763),\n",
       " (0, -2.36479),\n",
       " (31, 5.749548),\n",
       " (0, 1.5247695),\n",
       " (4, 1.8856685),\n",
       " (0, 1.3077418),\n",
       " (0, 0.7460902),\n",
       " (1, 1.2412026),\n",
       " (14, 3.8049757),\n",
       " (8, 1.5002146),\n",
       " (0, -0.46132797),\n",
       " (0, 2.3603153),\n",
       " (4, 3.3934538),\n",
       " (3, 1.8856685),\n",
       " (0, -0.15808249),\n",
       " (3, 2.487603),\n",
       " (3, 2.5733478),\n",
       " (0, -0.15808249),\n",
       " (0, 2.6615195),\n",
       " (0, 5.7995033),\n",
       " (1, 1.0205935),\n",
       " (9, 2.5733478),\n",
       " (4, 6.8953004),\n",
       " (0, -0.73601073),\n",
       " (1, 1.5465772),\n",
       " (2, 1.7109535),\n",
       " (0, 0.050864726),\n",
       " (0, 4.812563),\n",
       " (0, 3.910461),\n",
       " (5, 1.5247695),\n",
       " (0, 1.632069),\n",
       " (0, 1.3770401),\n",
       " (0, 1.3293611),\n",
       " (0, 0.2205848),\n",
       " (0, 5.2881565),\n",
       " (4, 7.6032414)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_list = list(predicoes_ya2)\n",
    "test_list = list(ya2_test)\n",
    "complist = []\n",
    "for i in range(len(test_list)):\n",
    "    complist.append((test_list[i], pred_list[i]))\n",
    "complist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.27145958),\n",
       " (7, 0.6519885),\n",
       " (0, 0.7205555),\n",
       " (1, 1.3723118),\n",
       " (0, 0.66657203),\n",
       " (0, 0.23549947),\n",
       " (6, 2.5315666),\n",
       " (0, 0.22211653),\n",
       " (0, 0.29010534),\n",
       " (0, 1.0012683),\n",
       " (1, 3.7577221),\n",
       " (0, 0.6900773),\n",
       " (0, 0.8930736),\n",
       " (0, 1.3788916),\n",
       " (3, 1.1051788),\n",
       " (1, 5.7627754),\n",
       " (0, 0.8018064),\n",
       " (0, 0.95534575),\n",
       " (0, 0.60691404),\n",
       " (3, 1.5779246),\n",
       " (0, 0.73096704),\n",
       " (1, 0.22211653),\n",
       " (14, 2.7583807),\n",
       " (0, 1.5779246),\n",
       " (5, 1.7291154),\n",
       " (0, 1.5779246),\n",
       " (9, 0.67121243),\n",
       " (3, 3.673317),\n",
       " (1, 1.084197),\n",
       " (0, 1.5130695),\n",
       " (2, 1.1601341),\n",
       " (2, 1.1710583),\n",
       " (0, 1.1601341),\n",
       " (0, 0.83180714),\n",
       " (1, 0.67121243),\n",
       " (1, 0.83180714),\n",
       " (9, 5.608441),\n",
       " (0, 1.1052563),\n",
       " (21, 36.766426),\n",
       " (1, 1.2189316),\n",
       " (2, 1.3723118),\n",
       " (0, 1.1601341),\n",
       " (1, 6.8561473),\n",
       " (2, 0.4940416),\n",
       " (0, 0.22211653),\n",
       " (0, 1.0594339),\n",
       " (0, 0.6339479),\n",
       " (0, 0.24135172),\n",
       " (3, 1.5423143),\n",
       " (0, 0.27145958),\n",
       " (37, 2.0821571),\n",
       " (0, 0.8709474),\n",
       " (0, 0.811098),\n",
       " (0, 1.0768529),\n",
       " (0, 0.83180714),\n",
       " (0, 0.6012102),\n",
       " (0, 0.27145958),\n",
       " (0, 1.1526284),\n",
       " (1, 0.29010534),\n",
       " (4, 1.1601341),\n",
       " (0, 0.60427153),\n",
       " (0, 0.27145958),\n",
       " (0, 0.8709474),\n",
       " (0, 0.80112636),\n",
       " (0, 1.1586326),\n",
       " (0, 0.89477104),\n",
       " (0, 1.4467415),\n",
       " (11, 2.8705945),\n",
       " (0, 0.27145958),\n",
       " (0, 0.67121243),\n",
       " (4, 2.7167294),\n",
       " (6, 1.3723118),\n",
       " (0, 0.9693185),\n",
       " (0, 0.30010483),\n",
       " (3, 0.811098),\n",
       " (0, 0.20861402),\n",
       " (1, 0.26067573),\n",
       " (1, 0.773101),\n",
       " (0, 1.1253481),\n",
       " (0, 0.8067999),\n",
       " (7, 1.3723118),\n",
       " (0, 3.2481),\n",
       " (0, 0.95534575),\n",
       " (3, 0.7831607),\n",
       " (8, 1.7826091),\n",
       " (1, 0.79574424),\n",
       " (3, 1.2601136),\n",
       " (2, 0.27145958),\n",
       " (2, 1.552526),\n",
       " (0, 1.9493983),\n",
       " (15, 13.963074),\n",
       " (1, 3.4199405),\n",
       " (1, 0.6582493),\n",
       " (4, 1.1726054),\n",
       " (0, 1.1695164),\n",
       " (2, 0.95534575),\n",
       " (1, 0.81834114),\n",
       " (0, 1.6937275),\n",
       " (11, 2.927374),\n",
       " (0, 0.27035022),\n",
       " (0, 0.67121243),\n",
       " (13, 11.282069),\n",
       " (0, 1.4479792),\n",
       " (0, 1.0876777),\n",
       " (0, 0.8709474),\n",
       " (0, 0.29469308),\n",
       " (2, 1.0480773),\n",
       " (0, 0.66657203),\n",
       " (12, 1.3723118),\n",
       " (6, 2.1669295),\n",
       " (1, 0.60427153),\n",
       " (0, 0.23761252),\n",
       " (0, 0.20267001),\n",
       " (0, 0.27145958),\n",
       " (1, 3.9602852),\n",
       " (1, 2.7597458),\n",
       " (1, 0.22211653),\n",
       " (0, 0.30010483),\n",
       " (0, 0.84436876),\n",
       " (0, 0.27145958),\n",
       " (0, 1.0652897),\n",
       " (0, 1.3723118),\n",
       " (0, 0.79574424),\n",
       " (1, 1.2601136),\n",
       " (0, 2.7583807),\n",
       " (0, 0.95534575),\n",
       " (10, 11.282069),\n",
       " (0, 0.23549947),\n",
       " (11, 1.9414947),\n",
       " (7, 0.95534575),\n",
       " (1, 1.0480773),\n",
       " (0, 0.27145958),\n",
       " (0, 1.1526284),\n",
       " (3, 1.5838983),\n",
       " (7, 3.165539),\n",
       " (3, 0.83180714),\n",
       " (3, 0.89477104),\n",
       " (0, 0.22211653),\n",
       " (0, 1.2601136),\n",
       " (0, 0.5825772),\n",
       " (0, 0.4100255),\n",
       " (0, 0.27145958),\n",
       " (0, 0.52715564),\n",
       " (0, 0.27145958),\n",
       " (1, 0.64039046),\n",
       " (2, 1.1601341),\n",
       " (0, 1.3723118),\n",
       " (0, 0.84436876),\n",
       " (0, 4.2773104),\n",
       " (0, 0.22211653),\n",
       " (1, 1.3730596),\n",
       " (0, 0.95534575),\n",
       " (0, 0.22211653),\n",
       " (0, 0.8067999),\n",
       " (0, 1.2601136),\n",
       " (1, 0.97818196),\n",
       " (0, 1.7324874),\n",
       " (0, 0.8798702),\n",
       " (16, 2.0025282),\n",
       " (1, 1.0914512),\n",
       " (1, 0.95534575),\n",
       " (0, 0.83180714),\n",
       " (0, 1.018393),\n",
       " (2, 0.6582493),\n",
       " (0, 1.3060621),\n",
       " (1, 0.8067999),\n",
       " (3, 1.1601341),\n",
       " (5, 1.0045562),\n",
       " (2, 0.7831607),\n",
       " (1, 1.0416194),\n",
       " (5, 1.1601341),\n",
       " (0, 1.1601341),\n",
       " (2, 1.0434608),\n",
       " (2, 1.1601341),\n",
       " (0, 1.5227034),\n",
       " (0, 40.325397),\n",
       " (0, 0.724111),\n",
       " (0, 0.95534575),\n",
       " (0, 1.2916415),\n",
       " (0, 0.95534575),\n",
       " (0, 0.27145958),\n",
       " (0, 1.2189316),\n",
       " (3, 0.95534575),\n",
       " (0, 0.27145958),\n",
       " (1, 1.0717463),\n",
       " (0, 0.27035022),\n",
       " (0, 0.67121243),\n",
       " (0, 0.8018064),\n",
       " (0, 0.83180714),\n",
       " (0, 0.84436876),\n",
       " (0, 0.8067999),\n",
       " (9, 15.23665),\n",
       " (0, 0.801949),\n",
       " (0, 0.79574424),\n",
       " (0, 0.25807664),\n",
       " (1, 1.788687),\n",
       " (0, 0.20861402),\n",
       " (0, 0.99075115),\n",
       " (0, 1.3723118),\n",
       " (0, 1.2693439),\n",
       " (0, 0.29010534),\n",
       " (0, 1.7628721),\n",
       " (0, 0.24865091),\n",
       " (0, 0.27035022),\n",
       " (2, 1.5682416),\n",
       " (17, 6.4451284),\n",
       " (1, 0.8647485),\n",
       " (2, 1.0824558),\n",
       " (7, 2.0025282),\n",
       " (0, 1.1601341),\n",
       " (9, 5.7627754),\n",
       " (0, 1.1695164),\n",
       " (0, 0.7252573),\n",
       " (0, 1.3723118),\n",
       " (0, 0.20267001),\n",
       " (0, 3.165539),\n",
       " (0, 0.811098),\n",
       " (25, 3.6975245),\n",
       " (0, 0.27035022),\n",
       " (11, 2.9279323),\n",
       " (0, 0.27145958),\n",
       " (0, 0.79574424),\n",
       " (0, 1.3723118),\n",
       " (0, 0.27145958),\n",
       " (2, 0.83180714),\n",
       " (0, 0.773101),\n",
       " (1, 2.8905652),\n",
       " (12, 3.285446),\n",
       " (0, 0.811098),\n",
       " (0, 1.598584),\n",
       " (0, 1.9493983),\n",
       " (0, 3.4199405),\n",
       " (1, 1.1601341),\n",
       " (0, 1.3723118),\n",
       " (5, 6.2172465),\n",
       " (0, 1.5526129),\n",
       " (0, 0.20267001),\n",
       " (0, 1.3723118),\n",
       " (0, 0.80831033),\n",
       " (3, 3.7577221),\n",
       " (0, 0.27145958),\n",
       " (0, 0.27145958),\n",
       " (0, 0.23761252),\n",
       " (0, 0.22211653),\n",
       " (0, 0.22211653),\n",
       " (0, 0.6948687),\n",
       " (3, 1.0480773),\n",
       " (0, 0.20135796),\n",
       " (0, 0.773101),\n",
       " (2, 1.6459833),\n",
       " (21, 3.6836689),\n",
       " (0, 1.1002345),\n",
       " (0, 1.5779246),\n",
       " (1, 0.67121243),\n",
       " (0, 0.8067999),\n",
       " (1, 1.2601136),\n",
       " (2, 1.5423143),\n",
       " (0, 0.773101),\n",
       " (0, 0.7061982),\n",
       " (0, 0.7019001),\n",
       " (0, 0.95534575),\n",
       " (1, 1.4467415),\n",
       " (36, 2.7597458),\n",
       " (0, 0.73096704),\n",
       " (4, 1.6797138),\n",
       " (0, 0.811098),\n",
       " (1, 0.8018064),\n",
       " (0, 0.27035022),\n",
       " (19, 2.267257),\n",
       " (0, 0.9363573),\n",
       " (0, 2.0821571),\n",
       " (25, 1.4394747),\n",
       " (0, 1.0914512),\n",
       " (0, 0.27145958),\n",
       " (0, 0.32842952),\n",
       " (1, 0.811098),\n",
       " (3, 1.372238),\n",
       " (2, 2.9279323),\n",
       " (1, 1.6619165),\n",
       " (0, 1.2730007),\n",
       " (6, 2.307817),\n",
       " (0, 1.1601341),\n",
       " (0, 1.5779246),\n",
       " (5, 2.8905652),\n",
       " (0, 0.6198627),\n",
       " (2, 2.0738394),\n",
       " (2, 1.8418416),\n",
       " (0, 0.99075115),\n",
       " (0, 0.27145958),\n",
       " (1, 0.27035022),\n",
       " (0, 0.27144518),\n",
       " (0, 0.27145958),\n",
       " (0, 0.95534575),\n",
       " (1, 1.3723118),\n",
       " (2, 1.4537488),\n",
       " (4, 0.82963604),\n",
       " (0, 1.3723118),\n",
       " (0, 0.9008675),\n",
       " (6, 1.2361944),\n",
       " (0, 2.5403461),\n",
       " (0, 0.4100255),\n",
       " (0, 1.3723118),\n",
       " (1, 1.0932312),\n",
       " (1, 5.5108476),\n",
       " (0, 0.8067999),\n",
       " (0, 0.6582493),\n",
       " (0, 0.77503276),\n",
       " (2, 1.1601341),\n",
       " (0, 0.24135172),\n",
       " (2, 1.0182005),\n",
       " (0, 1.0914512),\n",
       " (0, 0.773101),\n",
       " (3, 1.2361944),\n",
       " (1, 0.9693185),\n",
       " (0, 0.79574424),\n",
       " (0, 0.20861402),\n",
       " (2, 1.6619165),\n",
       " (0, 1.1601341),\n",
       " (2, 0.67121243),\n",
       " (0, 0.9239667),\n",
       " (0, 1.3723118),\n",
       " (4, 1.3053359),\n",
       " (0, 0.95534575),\n",
       " (0, 0.27145958),\n",
       " (5, 1.598584),\n",
       " (0, 0.6582493),\n",
       " (1, 1.1601341),\n",
       " (0, 3.1178167),\n",
       " (0, 1.1601341),\n",
       " (0, 0.81834114),\n",
       " (0, 2.9924784),\n",
       " (5, 0.8755721),\n",
       " (3, 1.5423143),\n",
       " (2, 1.1601341),\n",
       " (0, 0.7974171),\n",
       " (0, 1.372238),\n",
       " (1, 0.27145958),\n",
       " (0, 0.20861402),\n",
       " (1, 2.7167294),\n",
       " (3, 1.5779246),\n",
       " (0, 0.60427153),\n",
       " (3, 0.95534575),\n",
       " (0, 1.5095354),\n",
       " (0, 4.12885),\n",
       " (4, 1.6619165),\n",
       " (0, 0.25807664),\n",
       " (0, 1.39524),\n",
       " (2, 1.5278267),\n",
       " (3, 2.4933066),\n",
       " (0, 0.9723174),\n",
       " (3, 1.5779246),\n",
       " (42, 4.5085683),\n",
       " (0, 0.666552),\n",
       " (1, 1.888277),\n",
       " (0, 0.27145958),\n",
       " (0, 0.77564484),\n",
       " (9, 2.789489),\n",
       " (0, 2.691363),\n",
       " (0, 1.8865482),\n",
       " (0, 0.773101),\n",
       " (14, 3.7577221),\n",
       " (23, 1.5605673),\n",
       " (0, 0.38243654),\n",
       " (0, 0.74842715),\n",
       " (6, 1.1601341),\n",
       " (1, 1.1601341),\n",
       " (0, 0.22211653),\n",
       " (0, 0.811098),\n",
       " (0, 1.5779246),\n",
       " (0, 2.1669295),\n",
       " (0, 1.3723118),\n",
       " (1, 1.1741068),\n",
       " (0, 1.0086913),\n",
       " (0, 1.552526),\n",
       " (6, 0.8018064),\n",
       " (0, 1.1601341),\n",
       " (2, 1.1601341),\n",
       " (11, 15.23665),\n",
       " (1, 1.0594339),\n",
       " (0, 0.99075115),\n",
       " (1, 0.95534575),\n",
       " (0, 1.2231994),\n",
       " (0, 1.8836324),\n",
       " (0, 1.5227034),\n",
       " (6, 1.7200041),\n",
       " (0, 1.3243743),\n",
       " (0, 0.7071725),\n",
       " (0, 0.79134774),\n",
       " (1, 1.5779246),\n",
       " (0, 0.81834114),\n",
       " (2, 3.2500963),\n",
       " (3, 1.3723118),\n",
       " (2, 1.8418416),\n",
       " (0, 0.27145958),\n",
       " (7, 1.9493983),\n",
       " (1, 3.9299212),\n",
       " (1, 1.1790482),\n",
       " (8, 2.4003778),\n",
       " (1, 0.6554783),\n",
       " (0, 0.35875255),\n",
       " (0, 0.6845954),\n",
       " (4, 2.8148253),\n",
       " (0, 0.83180714),\n",
       " (0, 1.5860871),\n",
       " (6, 2.1669295),\n",
       " (4, 11.282069),\n",
       " (4, 0.74036324),\n",
       " (6, 5.5997214),\n",
       " (1, 1.5779246),\n",
       " (0, 0.27145958),\n",
       " (0, 0.3760896),\n",
       " (0, 0.8018064),\n",
       " (0, 0.8018064),\n",
       " (1, 1.5779246),\n",
       " (1, 2.5403461),\n",
       " (0, 0.74036324),\n",
       " (0, 0.23083591),\n",
       " (0, 0.2230359),\n",
       " (0, 0.22211653),\n",
       " (3, 0.73096704),\n",
       " (0, 0.25807664),\n",
       " (0, 0.27145958),\n",
       " (0, 0.73096704),\n",
       " (3, 1.5779246),\n",
       " (0, 1.4428828),\n",
       " (0, 3.285446),\n",
       " (13, 1.3060621),\n",
       " (0, 0.69400316),\n",
       " (0, 0.79574424),\n",
       " (0, 0.95534575),\n",
       " (0, 1.552526),\n",
       " (1, 1.2361944),\n",
       " (0, 0.79574424),\n",
       " (0, 2.2021377),\n",
       " (0, 0.95534575),\n",
       " (0, 0.9096597),\n",
       " (0, 0.23549947),\n",
       " (0, 0.6522579),\n",
       " (0, 0.95534575),\n",
       " (1, 1.1601341),\n",
       " (1, 0.9096597),\n",
       " (0, 0.95534575),\n",
       " (0, 1.3723118),\n",
       " (0, 3.165539),\n",
       " (1, 1.7848811),\n",
       " (5, 11.282069),\n",
       " (0, 0.7831607),\n",
       " (12, 3.673317),\n",
       " (2, 0.8647485),\n",
       " (1, 1.4311674),\n",
       " (0, 1.4663014),\n",
       " (0, 0.76954836),\n",
       " (0, 0.27145958),\n",
       " (0, 0.4963903),\n",
       " (4, 1.1995456),\n",
       " (0, 1.4614954),\n",
       " (0, 1.2601136),\n",
       " (0, 1.1601341),\n",
       " (0, 0.22211653),\n",
       " (1, 0.95534575),\n",
       " (2, 0.79574424),\n",
       " (0, 1.6797138),\n",
       " (0, 1.5579605),\n",
       " (0, 1.1989735),\n",
       " (0, 0.89395714),\n",
       " (0, 1.3796146),\n",
       " (0, 0.22211653),\n",
       " (1, 0.95534575),\n",
       " (0, 0.22211653),\n",
       " (40, 1.1601341),\n",
       " (0, 0.667098),\n",
       " (0, 0.95534575),\n",
       " (5, 1.949584),\n",
       " (0, 0.6147127),\n",
       " (0, 0.4940416),\n",
       " (0, 1.2709626),\n",
       " (0, 1.5779246),\n",
       " (0, 0.95534575),\n",
       " (25, 12.438658),\n",
       " (0, 0.9406311),\n",
       " (0, 5.407771),\n",
       " (0, 1.4394747),\n",
       " (0, 1.2601136),\n",
       " (0, 1.3773861),\n",
       " (4, 0.9201407),\n",
       " (0, 0.27145958),\n",
       " (0, 0.22211653),\n",
       " (2, 0.95534575),\n",
       " (0, 1.1601341),\n",
       " (0, 1.2946335),\n",
       " (4, 1.1721567),\n",
       " (5, 2.7167294),\n",
       " (2, 1.9493983),\n",
       " (0, 3.3327017),\n",
       " (98, 26.672853),\n",
       " (0, 3.1178167),\n",
       " (1, 0.95534575),\n",
       " (0, 1.3723118),\n",
       " (0, 1.2601136),\n",
       " (3, 0.8067999),\n",
       " (4, 6.8561473),\n",
       " (2, 1.6619165),\n",
       " (0, 2.0966735),\n",
       " (5, 1.3226309),\n",
       " (4, 1.5779246),\n",
       " (0, 0.27035022),\n",
       " (0, 1.1995456),\n",
       " (0, 0.73096704),\n",
       " (0, 0.811098),\n",
       " (0, 0.7974171),\n",
       " (0, 1.6265548),\n",
       " (0, 0.22211653),\n",
       " (0, 0.95534575),\n",
       " (1, 1.2361944),\n",
       " (0, 0.95534575),\n",
       " (1, 6.8561473),\n",
       " (0, 0.27035022),\n",
       " (0, 0.8067999),\n",
       " (0, 0.22211653),\n",
       " (0, 0.8067999),\n",
       " (2, 0.76954836),\n",
       " (3, 1.3301365),\n",
       " (0, 0.6885773),\n",
       " (0, 0.95534575),\n",
       " (0, 2.7167294),\n",
       " (2, 2.1041837),\n",
       " (0, 1.6619165),\n",
       " (0, 0.4963903),\n",
       " (1, 2.7167294),\n",
       " (0, 1.2601136),\n",
       " (0, 0.9008675),\n",
       " (0, 0.22211653),\n",
       " (0, 0.8067999),\n",
       " (0, 0.22211653),\n",
       " (0, 1.0455815),\n",
       " (1, 0.811098),\n",
       " (0, 0.27145958),\n",
       " (0, 0.79574424),\n",
       " (0, 0.773101),\n",
       " (1, 0.22211653),\n",
       " (0, 1.2730007),\n",
       " (0, 0.20861402),\n",
       " (0, 1.1601341),\n",
       " (0, 1.5779246),\n",
       " (0, 1.2730007),\n",
       " (2, 1.4663014),\n",
       " (0, 3.1178167),\n",
       " (0, 0.27145958),\n",
       " (3, 1.6836162),\n",
       " (0, 0.8755721),\n",
       " (0, 0.811098),\n",
       " (0, 0.80112636),\n",
       " (0, 1.1586326),\n",
       " (0, 0.95534575),\n",
       " (0, 0.27145958),\n",
       " (1, 0.82963604),\n",
       " (2, 5.5108476),\n",
       " (5, 4.1350064),\n",
       " (0, 0.79134774),\n",
       " (1, 0.8280025),\n",
       " (9, 1.3723118),\n",
       " (0, 1.1601341),\n",
       " (0, 0.9519059),\n",
       " (0, 0.95534575),\n",
       " (0, 0.95534575),\n",
       " (6, 0.811098),\n",
       " (0, 0.95534575),\n",
       " (0, 0.27145958),\n",
       " (0, 0.27035022),\n",
       " (0, 1.2601136),\n",
       " (0, 0.20861402),\n",
       " (1, 1.3243743),\n",
       " (5, 1.5779246),\n",
       " (0, 0.27035022),\n",
       " (0, 0.95534575),\n",
       " (0, 3.2438018),\n",
       " (0, 0.95534575),\n",
       " (0, 1.0652897),\n",
       " (0, 0.27145958),\n",
       " (0, 0.84436876),\n",
       " (7, 3.165539),\n",
       " (1, 0.8755721),\n",
       " (0, 0.95534575),\n",
       " (0, 1.4428828),\n",
       " (11, 2.9924784),\n",
       " (0, 0.27035022),\n",
       " (0, 1.2056354),\n",
       " (0, 1.0717463),\n",
       " (1, 3.2481),\n",
       " (0, 0.93380266),\n",
       " (0, 0.23872188),\n",
       " (13, 1.0557531),\n",
       " (0, 0.811098),\n",
       " (0, 0.8018064),\n",
       " (1, 0.6582493),\n",
       " (0, 0.22211653),\n",
       " (2, 0.99075115),\n",
       " (0, 0.20135796),\n",
       " (0, 1.2730007),\n",
       " (1, 1.9493983),\n",
       " (0, 0.22211653),\n",
       " (3, 1.2542574),\n",
       " (0, 0.5825772),\n",
       " (6, 1.0840104),\n",
       " (4, 3.165539),\n",
       " (0, 0.83180714),\n",
       " (0, 0.22211653),\n",
       " (1, 1.5779246),\n",
       " (6, 1.3723118),\n",
       " (0, 0.60691404),\n",
       " (4, 0.47740048),\n",
       " (2, 1.0914512),\n",
       " (0, 0.95534575),\n",
       " (0, 5.876444),\n",
       " (4, 3.220622),\n",
       " (0, 0.22211653),\n",
       " (2, 0.6582493),\n",
       " (2, 1.2614536),\n",
       " (0, 1.6265548),\n",
       " (4, 2.4283614),\n",
       " (0, 1.3723118),\n",
       " (2, 0.8067999),\n",
       " (0, 0.8755721),\n",
       " (0, 0.36200202),\n",
       " (0, 1.3723118),\n",
       " (0, 0.27035022),\n",
       " (0, 0.27035022),\n",
       " (0, 1.5779246),\n",
       " (0, 0.724111),\n",
       " (9, 2.9189708),\n",
       " (0, 0.73998463),\n",
       " (3, 2.4780009),\n",
       " (0, 0.7831905),\n",
       " (0, 1.7164285),\n",
       " (0, 2.7583807),\n",
       " (0, 0.83180714),\n",
       " (3, 0.7974171),\n",
       " (4, 2.8905652),\n",
       " (2, 2.4003778),\n",
       " (0, 0.22211653),\n",
       " (0, 0.6582493),\n",
       " (0, 0.7544275),\n",
       " (6, 1.1152918),\n",
       " (3, 0.7492007),\n",
       " (2, 0.8067999),\n",
       " (0, 0.6554783),\n",
       " (1, 1.9658349),\n",
       " (2, 0.7183193),\n",
       " (3, 0.26707655),\n",
       " (7, 1.4467415),\n",
       " (1, 2.7583807),\n",
       " (0, 1.1601341),\n",
       " (1, 0.79574424),\n",
       " (4, 6.3336406),\n",
       " (5, 1.552526),\n",
       " (3, 1.3723118),\n",
       " (0, 0.8018064),\n",
       " (0, 0.74036324),\n",
       " (0, 1.0635666),\n",
       " (0, 0.88382787),\n",
       " (1, 1.1601341),\n",
       " (0, 0.22211653),\n",
       " (3, 4.1350064),\n",
       " (32, 1.5779246),\n",
       " (0, 0.22211653),\n",
       " (1, 0.27301064),\n",
       " (0, 2.9358377),\n",
       " (0, 0.7974171),\n",
       " (0, 1.5779246),\n",
       " (0, 1.0914512),\n",
       " (0, 0.22211653),\n",
       " (3, 2.4003778),\n",
       " (29, 3.6836689),\n",
       " (1, 0.25807664),\n",
       " (0, 1.5779246),\n",
       " (3, 1.1989735),\n",
       " (3, 2.7583807),\n",
       " (1, 0.8647485),\n",
       " (0, 0.95534575),\n",
       " (0, 1.3723118),\n",
       " (4, 0.27145958),\n",
       " (0, 1.3723118),\n",
       " (0, 3.6195989)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_list = list(predicoes_yb1)\n",
    "test_list = list(yb1_test)\n",
    "complist = []\n",
    "for i in range(len(test_list)):\n",
    "    complist.append((test_list[i], pred_list[i]))\n",
    "complist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.3080121),\n",
       " (0, 0.77247417),\n",
       " (5, 0.6890715),\n",
       " (0, 0.81774443),\n",
       " (0, 0.4006054),\n",
       " (0, 0.3037108),\n",
       " (3, 4.013461),\n",
       " (0, 0.2903435),\n",
       " (0, 0.25301144),\n",
       " (0, 0.8418446),\n",
       " (2, 3.7718432),\n",
       " (0, 0.6612491),\n",
       " (1, 3.4605267),\n",
       " (4, 0.61599815),\n",
       " (8, 0.97944564),\n",
       " (3, 1.3219881),\n",
       " (2, 0.92117405),\n",
       " (0, 0.8168411),\n",
       " (0, 0.36316624),\n",
       " (1, 1.8655862),\n",
       " (1, 0.92450094),\n",
       " (0, 0.3037108),\n",
       " (5, 2.3077445),\n",
       " (1, 1.2215021),\n",
       " (4, 1.9969674),\n",
       " (3, 1.4520954),\n",
       " (8, 1.2867467),\n",
       " (4, 3.943832),\n",
       " (0, 0.92117405),\n",
       " (0, 1.8161957),\n",
       " (1, 1.0076436),\n",
       " (1, 0.94613606),\n",
       " (2, 1.0076436),\n",
       " (0, 0.76410985),\n",
       " (0, 0.6547131),\n",
       " (0, 0.911894),\n",
       " (11, 8.160089),\n",
       " (0, 0.7933142),\n",
       " (3, 3.655504),\n",
       " (0, 1.2724022),\n",
       " (0, 1.0076436),\n",
       " (3, 1.0076436),\n",
       " (0, 4.0303845),\n",
       " (1, 0.22983178),\n",
       " (1, 0.3037108),\n",
       " (2, 0.5201057),\n",
       " (0, 0.20307928),\n",
       " (0, 0.20307928),\n",
       " (1, 1.0076436),\n",
       " (0, 0.20307928),\n",
       " (8, 0.70379627),\n",
       " (0, 0.4371537),\n",
       " (1, 1.3194852),\n",
       " (2, 0.52191854),\n",
       " (0, 0.5145752),\n",
       " (0, 0.20307928),\n",
       " (0, 0.25301144),\n",
       " (0, 0.911894),\n",
       " (0, 0.37712377),\n",
       " (2, 1.0076436),\n",
       " (0, 0.77278763),\n",
       " (0, 0.3080121),\n",
       " (0, 0.4371537),\n",
       " (0, 0.7822238),\n",
       " (0, 0.83882666),\n",
       " (0, 0.9761748),\n",
       " (1, 1.0076436),\n",
       " (19, 1.012901),\n",
       " (0, 0.3080121),\n",
       " (1, 0.6547131),\n",
       " (3, 1.907366),\n",
       " (8, 1.0076436),\n",
       " (0, 0.9761748),\n",
       " (0, 0.2846177),\n",
       " (0, 0.67807794),\n",
       " (0, 0.20307928),\n",
       " (1, 0.3372287),\n",
       " (0, 0.46639118),\n",
       " (0, 1.1486666),\n",
       " (0, 0.6612491),\n",
       " (5, 1.0703988),\n",
       " (0, 2.5476468),\n",
       " (0, 0.78909236),\n",
       " (0, 0.92117405),\n",
       " (2, 2.6167865),\n",
       " (1, 0.92450094),\n",
       " (9, 2.1325338),\n",
       " (3, 0.3080121),\n",
       " (3, 0.6612491),\n",
       " (1, 1.7978292),\n",
       " (4, 1.2373579),\n",
       " (0, 0.9855035),\n",
       " (0, 0.8930325),\n",
       " (2, 0.83882666),\n",
       " (0, 2.1229553),\n",
       " (5, 0.96859306),\n",
       " (2, 0.92387784),\n",
       " (0, 1.6496089),\n",
       " (7, 1.0220516),\n",
       " (0, 0.24302296),\n",
       " (0, 0.60946214),\n",
       " (12, 10.108543),\n",
       " (0, 1.7186953),\n",
       " (0, 0.80959827),\n",
       " (1, 0.4371537),\n",
       " (2, 0.3372287),\n",
       " (2, 1.1403896),\n",
       " (0, 0.4006054),\n",
       " (7, 1.0703988),\n",
       " (0, 1.4642763),\n",
       " (0, 0.77914315),\n",
       " (0, 0.22981542),\n",
       " (0, 0.20431823),\n",
       " (0, 0.3080121),\n",
       " (0, 1.040983),\n",
       " (2, 1.4642763),\n",
       " (0, 0.3037108),\n",
       " (0, 0.28031638),\n",
       " (0, 0.7444327),\n",
       " (0, 0.2941679),\n",
       " (0, 0.95533365),\n",
       " (1, 1.0076436),\n",
       " (0, 0.92450094),\n",
       " (1, 0.98413587),\n",
       " (0, 2.3077445),\n",
       " (1, 1.3891244),\n",
       " (14, 7.9890623),\n",
       " (0, 0.29953957),\n",
       " (17, 5.0313954),\n",
       " (0, 0.8168411),\n",
       " (1, 1.1403896),\n",
       " (0, 0.33153325),\n",
       " (3, 2.0698628),\n",
       " (2, 1.5926298),\n",
       " (16, 1.2527945),\n",
       " (1, 0.78980553),\n",
       " (6, 0.97214675),\n",
       " (0, 0.3037108),\n",
       " (0, 1.0076436),\n",
       " (0, 0.57861704),\n",
       " (1, 0.27811047),\n",
       " (0, 0.46062505),\n",
       " (0, 0.20307928),\n",
       " (0, 0.25301144),\n",
       " (0, 0.8736092),\n",
       " (0, 0.81774443),\n",
       " (4, 1.0076436),\n",
       " (0, 0.99699646),\n",
       " (0, 3.5660448),\n",
       " (0, 0.3037108),\n",
       " (1, 0.9761748),\n",
       " (0, 0.97214675),\n",
       " (0, 0.22981542),\n",
       " (1, 0.6612491),\n",
       " (1, 0.9462733),\n",
       " (2, 0.9761748),\n",
       " (0, 0.8373896),\n",
       " (0, 0.8975052),\n",
       " (5, 1.5881673),\n",
       " (0, 1.0076436),\n",
       " (0, 0.9761748),\n",
       " (2, 0.68482864),\n",
       " (0, 0.9703996),\n",
       " (0, 0.8930325),\n",
       " (2, 0.9761748),\n",
       " (1, 0.54103684),\n",
       " (0, 1.0076436),\n",
       " (0, 0.8148106),\n",
       " (1, 0.92117405),\n",
       " (1, 3.5248199),\n",
       " (3, 1.0076436),\n",
       " (1, 0.98037213),\n",
       " (0, 0.53567386),\n",
       " (0, 1.0076436),\n",
       " (0, 1.5846767),\n",
       " (0, 11.598891),\n",
       " (0, 0.30666617),\n",
       " (0, 0.9838184),\n",
       " (2, 1.5250652),\n",
       " (0, 0.96859306),\n",
       " (0, 0.25301144),\n",
       " (0, 1.4393034),\n",
       " (0, 0.9761748),\n",
       " (0, 0.25301144),\n",
       " (0, 1.3033675),\n",
       " (0, 0.24302296),\n",
       " (1, 0.6547131),\n",
       " (0, 0.92117405),\n",
       " (0, 0.9204292),\n",
       " (0, 1.3774527),\n",
       " (0, 0.6612491),\n",
       " (3, 1.2373579),\n",
       " (0, 0.46639118),\n",
       " (0, 0.92450094),\n",
       " (0, 0.29953957),\n",
       " (5, 1.6496089),\n",
       " (0, 0.20307928),\n",
       " (0, 0.5201057),\n",
       " (2, 1.0076436),\n",
       " (2, 2.4789531),\n",
       " (0, 0.25301144),\n",
       " (0, 0.46639118),\n",
       " (0, 0.20307928),\n",
       " (0, 0.22746307),\n",
       " (0, 2.7795987),\n",
       " (16, 5.634775),\n",
       " (0, 1.3618802),\n",
       " (1, 1.000062),\n",
       " (1, 1.949752),\n",
       " (0, 1.0076436),\n",
       " (0, 1.3219881),\n",
       " (0, 0.9723852),\n",
       " (0, 0.4006054),\n",
       " (1, 1.0076436),\n",
       " (0, 0.20431823),\n",
       " (0, 1.2527945),\n",
       " (1, 0.5321403),\n",
       " (14, 1.4642763),\n",
       " (0, 0.25192085),\n",
       " (11, 1.0690558),\n",
       " (0, 0.25301144),\n",
       " (1, 0.92450094),\n",
       " (0, 1.0076436),\n",
       " (0, 0.45497677),\n",
       " (2, 0.68482864),\n",
       " (0, 1.2986478),\n",
       " (4, 1.2449231),\n",
       " (3, 1.3081807),\n",
       " (0, 0.67807794),\n",
       " (2, 1.1319064),\n",
       " (0, 2.3077445),\n",
       " (0, 0.9659032),\n",
       " (0, 1.0076436),\n",
       " (0, 1.0076436),\n",
       " (0, 1.040983),\n",
       " (0, 2.1728187),\n",
       " (0, 0.20431823),\n",
       " (2, 1.0076436),\n",
       " (0, 0.92117405),\n",
       " (2, 2.169111),\n",
       " (3, 0.20307928),\n",
       " (0, 0.3080121),\n",
       " (0, 0.22981542),\n",
       " (0, 0.3037108),\n",
       " (0, 0.3037108),\n",
       " (0, 0.92360646),\n",
       " (3, 1.1403896),\n",
       " (0, 0.23342755),\n",
       " (0, 0.46639118),\n",
       " (0, 0.67807794),\n",
       " (6, 1.040983),\n",
       " (0, 0.5201057),\n",
       " (1, 1.5830867),\n",
       " (0, 0.68253547),\n",
       " (2, 0.6612491),\n",
       " (0, 0.98037213),\n",
       " (0, 1.0076436),\n",
       " (0, 0.46639118),\n",
       " (0, 0.7543571),\n",
       " (0, 0.4590326),\n",
       " (0, 0.5477127),\n",
       " (0, 1.0076436),\n",
       " (17, 1.4642763),\n",
       " (0, 0.92450094),\n",
       " (1, 1.2215021),\n",
       " (0, 0.9565742),\n",
       " (0, 0.92117405),\n",
       " (0, 0.24302296),\n",
       " (11, 3.89473),\n",
       " (1, 0.3037108),\n",
       " (0, 0.70379627),\n",
       " (16, 0.670518),\n",
       " (0, 1.0076436),\n",
       " (0, 0.3080121),\n",
       " (0, 0.27248213),\n",
       " (0, 0.5332657),\n",
       " (7, 5.5527215),\n",
       " (9, 1.0220516),\n",
       " (0, 1.0076436),\n",
       " (1, 0.5618485),\n",
       " (4, 1.8059686),\n",
       " (0, 0.98037213),\n",
       " (0, 1.2215021),\n",
       " (0, 1.2449231),\n",
       " (2, 0.39355937),\n",
       " (0, 1.0664095),\n",
       " (12, 1.8010672),\n",
       " (2, 0.98364455),\n",
       " (0, 0.25301144),\n",
       " (0, 0.22981542),\n",
       " (0, 0.20307928),\n",
       " (3, 0.3080121),\n",
       " (0, 0.7444327),\n",
       " (2, 1.0076436),\n",
       " (2, 0.97944564),\n",
       " (1, 0.6612491),\n",
       " (1, 1.0076436),\n",
       " (0, 0.9238652),\n",
       " (11, 2.1698008),\n",
       " (0, 1.0076436),\n",
       " (0, 0.27811047),\n",
       " (2, 1.0703988),\n",
       " (0, 1.0076436),\n",
       " (0, 2.5625453),\n",
       " (1, 0.6119575),\n",
       " (0, 0.8930325),\n",
       " (0, 0.3080121),\n",
       " (1, 1.2944185),\n",
       " (0, 0.20307928),\n",
       " (0, 0.8148106),\n",
       " (3, 2.3635988),\n",
       " (0, 1.2855144),\n",
       " (7, 2.1728187),\n",
       " (0, 0.97214675),\n",
       " (0, 0.92450094),\n",
       " (0, 0.20307928),\n",
       " (0, 1.0076436),\n",
       " (0, 1.0076436),\n",
       " (0, 0.6547131),\n",
       " (0, 0.4006054),\n",
       " (0, 0.81774443),\n",
       " (4, 6.1974673),\n",
       " (0, 0.9838184),\n",
       " (0, 0.3633499),\n",
       " (2, 1.1319064),\n",
       " (1, 0.8930325),\n",
       " (1, 0.98037213),\n",
       " (0, 1.0076436),\n",
       " (0, 1.0076436),\n",
       " (2, 0.92387784),\n",
       " (2, 5.4023466),\n",
       " (6, 0.8806764),\n",
       " (6, 1.0076436),\n",
       " (3, 1.0076436),\n",
       " (0, 0.5244523),\n",
       " (0, 5.9143057),\n",
       " (1, 0.25301144),\n",
       " (0, 0.1936201),\n",
       " (1, 1.907366),\n",
       " (4, 1.7555784),\n",
       " (0, 0.7432928),\n",
       " (1, 1.0063533),\n",
       " (3, 3.202483),\n",
       " (0, 2.1940975),\n",
       " (6, 2.0522797),\n",
       " (1, 0.3037108),\n",
       " (0, 0.97944564),\n",
       " (4, 1.424599),\n",
       " (1, 1.4493188),\n",
       " (0, 0.3037108),\n",
       " (6, 1.2439953),\n",
       " (8, 1.4642763),\n",
       " (1, 0.9276345),\n",
       " (2, 2.3077445),\n",
       " (0, 0.33153325),\n",
       " (3, 0.9238652),\n",
       " (5, 0.68482864),\n",
       " (0, 2.3077445),\n",
       " (3, 2.401426),\n",
       " (0, 0.31447825),\n",
       " (5, 3.7718432),\n",
       " (10, 1.0076436),\n",
       " (0, 0.3080121),\n",
       " (0, 0.5154934),\n",
       " (4, 1.0076436),\n",
       " (0, 0.98037213),\n",
       " (0, 0.3037108),\n",
       " (0, 0.5685225),\n",
       " (2, 1.5830867),\n",
       " (0, 1.4642763),\n",
       " (0, 1.0076436),\n",
       " (0, 1.0076436),\n",
       " (1, 0.67807794),\n",
       " (9, 0.28278738),\n",
       " (1, 0.92117405),\n",
       " (0, 1.0076436),\n",
       " (2, 1.0703988),\n",
       " (1, 1.2373579),\n",
       " (1, 0.98364455),\n",
       " (0, 0.97606283),\n",
       " (1, 1.1989774),\n",
       " (0, 0.7416405),\n",
       " (0, 1.1338699),\n",
       " (3, 1.5926298),\n",
       " (6, 1.6496089),\n",
       " (0, 1.52748),\n",
       " (0, 0.6547131),\n",
       " (0, 0.7699296),\n",
       " (4, 1.2215021),\n",
       " (1, 0.92387784),\n",
       " (2, 1.2016047),\n",
       " (1, 0.81774443),\n",
       " (0, 1.7934235),\n",
       " (0, 0.3037108),\n",
       " (9, 1.7978292),\n",
       " (0, 2.3077445),\n",
       " (0, 0.54220986),\n",
       " (11, 1.0540003),\n",
       " (0, 0.83803177),\n",
       " (0, 0.3037108),\n",
       " (2, 0.6612491),\n",
       " (2, 1.040983),\n",
       " (0, 0.4553183),\n",
       " (0, 1.4541048),\n",
       " (3, 1.4642763),\n",
       " (3, 7.9890623),\n",
       " (1, 0.46639118),\n",
       " (4, 1.330942),\n",
       " (1, 2.0734978),\n",
       " (0, 0.2237643),\n",
       " (0, 0.25301144),\n",
       " (0, 0.68943197),\n",
       " (0, 0.951352),\n",
       " (1, 5.02866),\n",
       " (5, 1.0076436),\n",
       " (0, 1.2144116),\n",
       " (0, 1.0398238),\n",
       " (1, 0.3037108),\n",
       " (0, 0.3037108),\n",
       " (0, 0.92450094),\n",
       " (0, 0.3037108),\n",
       " (0, 0.3080121),\n",
       " (0, 0.92450094),\n",
       " (8, 1.4493188),\n",
       " (0, 0.8373896),\n",
       " (0, 1.3081807),\n",
       " (14, 0.9761748),\n",
       " (0, 0.46362993),\n",
       " (0, 0.92450094),\n",
       " (1, 1.013997),\n",
       " (4, 0.6612491),\n",
       " (0, 2.1698008),\n",
       " (0, 0.92450094),\n",
       " (0, 0.46639118),\n",
       " (0, 0.9838184),\n",
       " (0, 1.1439766),\n",
       " (0, 0.3037108),\n",
       " (0, 0.8774602),\n",
       " (0, 0.97214675),\n",
       " (1, 1.0076436),\n",
       " (0, 1.1439766),\n",
       " (1, 0.9838184),\n",
       " (0, 1.0977281),\n",
       " (0, 1.2527945),\n",
       " (2, 1.0134957),\n",
       " (6, 10.108543),\n",
       " (0, 0.92117405),\n",
       " (6, 3.943832),\n",
       " (0, 0.9565742),\n",
       " (0, 1.5168117),\n",
       " (0, 0.73253804),\n",
       " (0, 0.92117405),\n",
       " (0, 0.3080121),\n",
       " (0, 0.3522176),\n",
       " (0, 1.062926),\n",
       " (3, 1.537629),\n",
       " (3, 1.0703988),\n",
       " (0, 0.82751745),\n",
       " (0, 0.3037108),\n",
       " (0, 1.0724361),\n",
       " (0, 0.92450094),\n",
       " (5, 1.8655862),\n",
       " (0, 1.180029),\n",
       " (0, 1.2436445),\n",
       " (3, 0.67583513),\n",
       " (1, 1.1123658),\n",
       " (0, 0.33153325),\n",
       " (0, 0.9838184),\n",
       " (0, 0.24302296),\n",
       " (11, 1.0076436),\n",
       " (2, 0.4006054),\n",
       " (0, 0.9838184),\n",
       " (3, 1.6496089),\n",
       " (1, 0.3037108),\n",
       " (0, 0.35913822),\n",
       " (0, 1.0076436),\n",
       " (2, 1.2215021),\n",
       " (0, 1.1989774),\n",
       " (4, 1.040983),\n",
       " (1, 0.48729467),\n",
       " (0, 7.4087315),\n",
       " (0, 0.6119575),\n",
       " (1, 0.9996298),\n",
       " (1, 1.5830867),\n",
       " (0, 0.68482864),\n",
       " (0, 0.3080121),\n",
       " (0, 0.22981542),\n",
       " (0, 0.9761748),\n",
       " (2, 1.2944185),\n",
       " (0, 1.000062),\n",
       " (3, 1.1483427),\n",
       " (1, 1.907366),\n",
       " (0, 1.7978292),\n",
       " (1, 1.7384228),\n",
       " (32, 3.0602996),\n",
       " (0, 1.0076436),\n",
       " (1, 1.1949494),\n",
       " (0, 1.0076436),\n",
       " (0, 0.9879577),\n",
       " (0, 0.6612491),\n",
       " (0, 9.482788),\n",
       " (0, 1.0076436),\n",
       " (0, 0.9761748),\n",
       " (0, 0.911894),\n",
       " (9, 1.5830867),\n",
       " (0, 0.22981542),\n",
       " (13, 2.2130427),\n",
       " (0, 0.92450094),\n",
       " (2, 0.69175273),\n",
       " (9, 1.1794188),\n",
       " (0, 1.3947409),\n",
       " (0, 0.3037108),\n",
       " (0, 0.9838184),\n",
       " (2, 2.1698008),\n",
       " (0, 0.80592114),\n",
       " (3, 9.482788),\n",
       " (0, 0.24302296),\n",
       " (0, 0.5455464),\n",
       " (0, 0.3037108),\n",
       " (0, 0.6612491),\n",
       " (3, 0.92117405),\n",
       " (0, 1.0076436),\n",
       " (0, 0.42279097),\n",
       " (0, 0.9761748),\n",
       " (0, 1.907366),\n",
       " (7, 0.98364455),\n",
       " (0, 1.0076436),\n",
       " (0, 0.3522176),\n",
       " (5, 1.907366),\n",
       " (0, 1.0076436),\n",
       " (0, 0.9238652),\n",
       " (0, 0.3037108),\n",
       " (0, 0.43655372),\n",
       " (0, 0.3037108),\n",
       " (1, 0.83882666),\n",
       " (0, 1.0771155),\n",
       " (1, 0.33153325),\n",
       " (0, 0.92450094),\n",
       " (0, 0.46639118),\n",
       " (0, 0.32367766),\n",
       " (2, 0.5618485),\n",
       " (0, 0.19890805),\n",
       " (0, 1.0076436),\n",
       " (0, 1.4493188),\n",
       " (0, 0.5618485),\n",
       " (1, 0.73253804),\n",
       " (0, 1.0076436),\n",
       " (0, 0.25301144),\n",
       " (0, 0.97214675),\n",
       " (1, 0.8806764),\n",
       " (0, 0.67807794),\n",
       " (0, 0.9043123),\n",
       " (1, 0.83882666),\n",
       " (0, 1.0841078),\n",
       " (0, 0.3080121),\n",
       " (0, 0.6612491),\n",
       " (1, 2.5625453),\n",
       " (3, 3.9895928),\n",
       " (0, 0.7699296),\n",
       " (0, 0.6019819),\n",
       " (1, 1.0076436),\n",
       " (0, 1.0076436),\n",
       " (0, 0.98675287),\n",
       " (0, 0.9761748),\n",
       " (0, 0.80592114),\n",
       " (2, 0.69175273),\n",
       " (0, 0.7444327),\n",
       " (1, 0.3080121),\n",
       " (0, 0.22981542),\n",
       " (0, 0.99198574),\n",
       " (0, 0.19890805),\n",
       " (0, 1.52748),\n",
       " (3, 1.5830867),\n",
       " (0, 0.24302296),\n",
       " (0, 0.9838184),\n",
       " (1, 2.5278),\n",
       " (0, 0.97214675),\n",
       " (0, 0.95533365),\n",
       " (0, 0.33153325),\n",
       " (0, 0.9761748),\n",
       " (15, 1.2527945),\n",
       " (0, 0.8806764),\n",
       " (0, 0.9838184),\n",
       " (1, 0.8373896),\n",
       " (32, 3.2828655),\n",
       " (0, 0.22981542),\n",
       " (0, 0.95533365),\n",
       " (1, 1.3033675),\n",
       " (0, 2.554002),\n",
       " (1, 1.1403896),\n",
       " (0, 0.20307928),\n",
       " (4, 0.68482864),\n",
       " (0, 0.4533826),\n",
       " (0, 0.92117405),\n",
       " (2, 0.8930325),\n",
       " (2, 0.32367766),\n",
       " (0, 0.98364455),\n",
       " (0, 0.20431823),\n",
       " (0, 0.5618485),\n",
       " (2, 1.7978292),\n",
       " (0, 0.3037108),\n",
       " (9, 0.97944564),\n",
       " (0, 0.57861704),\n",
       " (0, 0.9703996),\n",
       " (3, 1.2527945),\n",
       " (0, 0.68482864),\n",
       " (0, 0.38153577),\n",
       " (1, 1.6014892),\n",
       " (1, 1.0076436),\n",
       " (0, 0.36316624),\n",
       " (1, 0.3080121),\n",
       " (0, 1.2944185),\n",
       " (0, 1.076464),\n",
       " (0, 0.48729467),\n",
       " (3, 2.6062112),\n",
       " (0, 0.3037108),\n",
       " (0, 0.8930325),\n",
       " (0, 1.0076436),\n",
       " (0, 1.3947409),\n",
       " (1, 0.9419988),\n",
       " (2, 1.084815),\n",
       " (1, 0.6612491),\n",
       " (0, 0.8806764),\n",
       " (0, 0.3037108),\n",
       " (0, 1.0076436),\n",
       " (0, 0.22981542),\n",
       " (0, 0.24302296),\n",
       " (0, 1.2090744),\n",
       " (0, 0.46362993),\n",
       " (4, 1.3759248),\n",
       " (0, 0.8741404),\n",
       " (0, 2.4789531),\n",
       " (0, 0.92117405),\n",
       " (0, 0.38502914),\n",
       " (1, 2.3077445),\n",
       " (0, 0.68482864),\n",
       " (0, 0.5244523),\n",
       " (1, 1.2449231),\n",
       " (0, 1.0540003),\n",
       " (0, 0.3037108),\n",
       " (0, 0.8930325),\n",
       " (0, 1.8809613),\n",
       " (0, 1.9262938),\n",
       " (2, 0.61599815),\n",
       " (1, 0.6612491),\n",
       " (0, 0.83803177),\n",
       " (2, 1.0664095),\n",
       " (0, 0.91036093),\n",
       " (0, 0.20307928),\n",
       " (1, 1.0076436),\n",
       " (0, 2.3077445),\n",
       " (0, 1.0076436),\n",
       " (0, 0.92450094),\n",
       " (8, 1.3165348),\n",
       " (2, 0.6612491),\n",
       " (17, 2.1522193),\n",
       " (2, 0.92117405),\n",
       " (0, 0.46639118),\n",
       " (0, 0.7359672),\n",
       " (0, 1.1338536),\n",
       " (4, 2.3635988),\n",
       " (0, 0.3037108),\n",
       " (15, 3.9895928),\n",
       " (6, 1.5830867),\n",
       " (0, 0.27248213),\n",
       " (0, 0.3037108),\n",
       " (0, 1.1900285),\n",
       " (0, 0.5244523),\n",
       " (0, 1.5830867),\n",
       " (0, 1.0076436),\n",
       " (0, 0.3037108),\n",
       " (2, 1.0540003),\n",
       " (3, 1.040983),\n",
       " (1, 0.38153577),\n",
       " (0, 1.5585757),\n",
       " (8, 1.2436445),\n",
       " (0, 2.3077445),\n",
       " (0, 0.9565742),\n",
       " (1, 0.9761748),\n",
       " (0, 1.0076436),\n",
       " (0, 0.25301144),\n",
       " (1, 1.084815),\n",
       " (4, 1.0076436)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_list = list(predicoes_yb2)\n",
    "test_list = list(yb2_test)\n",
    "complist = []\n",
    "for i in range(len(test_list)):\n",
    "    complist.append((test_list[i], pred_list[i]))\n",
    "complist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.31590325),\n",
       " (2, 1.1978548),\n",
       " (0, 0.46143058),\n",
       " (0, 0.7979511),\n",
       " (0, 0.5043288),\n",
       " (0, 0.31590325),\n",
       " (5, 1.3421016),\n",
       " (0, -0.10761082),\n",
       " (0, 0.5781252),\n",
       " (0, 1.3105289),\n",
       " (2, 0.5210029),\n",
       " (0, 0.5210029),\n",
       " (1, 0.5210029),\n",
       " (1, 0.40832862),\n",
       " (3, 1.3605589),\n",
       " (1, 0.5210029),\n",
       " (0, 0.5210029),\n",
       " (0, 0.5210029),\n",
       " (0, 0.5043288),\n",
       " (1, 1.5843982),\n",
       " (0, 0.7479211),\n",
       " (0, -0.10761082),\n",
       " (1, 0.866967),\n",
       " (1, 1.1669137),\n",
       " (0, 0.95202),\n",
       " (2, 1.6303735),\n",
       " (5, 0.34875652),\n",
       " (0, 0.7479211),\n",
       " (0, 0.5710329),\n",
       " (0, 1.1669137),\n",
       " (2, 0.7479211),\n",
       " (1, 0.7979511),\n",
       " (2, 0.7479211),\n",
       " (0, 0.7979511),\n",
       " (0, 0.34875652),\n",
       " (0, 0.7979511),\n",
       " (2, 0.7479211),\n",
       " (1, 0.7479211),\n",
       " (6, 2.6951747),\n",
       " (0, 1.3605589),\n",
       " (3, 0.7979511),\n",
       " (0, 0.7979511),\n",
       " (0, 0.7979511),\n",
       " (0, 0.70466936),\n",
       " (0, 0.20322923),\n",
       " (0, 1.3605589),\n",
       " (0, -0.078979746),\n",
       " (0, 0.19553183),\n",
       " (0, 1.9720318),\n",
       " (0, -0.13855185),\n",
       " (0, 2.55156),\n",
       " (0, 0.2383533),\n",
       " (3, 0.5210029),\n",
       " (2, 0.064635366),\n",
       " (0, 0.7979511),\n",
       " (0, -0.078979746),\n",
       " (0, 0.005063529),\n",
       " (0, 0.7979511),\n",
       " (0, 0.064635366),\n",
       " (4, 0.7979511),\n",
       " (0, 0.45429865),\n",
       " (0, 0.005063529),\n",
       " (0, 0.2383533),\n",
       " (0, 0.7979511),\n",
       " (0, 1.1978548),\n",
       " (0, 0.5210029),\n",
       " (1, 0.7979511),\n",
       " (0, 1.0217903),\n",
       " (1, 0.31590325),\n",
       " (0, 0.34875652),\n",
       " (0, 0.866967),\n",
       " (5, 0.7979511),\n",
       " (0, 0.5210029),\n",
       " (0, 0.064635366),\n",
       " (1, 0.5210029),\n",
       " (0, -0.078979746),\n",
       " (0, 1.1339347),\n",
       " (0, 0.6043059),\n",
       " (0, 1.6950837),\n",
       " (0, 0.5210029),\n",
       " (6, 3.0856032),\n",
       " (0, 1.7625481),\n",
       " (0, 0.5210029),\n",
       " (0, 0.5114607),\n",
       " (0, 0.5210029),\n",
       " (0, 0.7979511),\n",
       " (0, 0.7479211),\n",
       " (0, 0.31590325),\n",
       " (2, 0.40832862),\n",
       " (2, 0.866967),\n",
       " (0, 2.4682567),\n",
       " (0, 0.5210029),\n",
       " (0, 0.5210029),\n",
       " (4, 1.1978548),\n",
       " (1, 0.7479211),\n",
       " (0, 0.5210029),\n",
       " (5, 0.5210029),\n",
       " (1, 5.204334),\n",
       " (0, 1.1669137),\n",
       " (0, 0.24830194),\n",
       " (0, 0.34875652),\n",
       " (1, 0.7479211),\n",
       " (0, 1.8125781),\n",
       " (0, 0.6043059),\n",
       " (1, 0.2383533),\n",
       " (4, 1.1339347),\n",
       " (2, 4.986957),\n",
       " (0, 0.5043288),\n",
       " (3, 3.0856032),\n",
       " (0, 0.5043288),\n",
       " (0, 0.57498014),\n",
       " (0, -0.025002278),\n",
       " (0, -0.025002278),\n",
       " (0, 0.31590325),\n",
       " (0, 2.4086845),\n",
       " (0, 0.57498014),\n",
       " (0, -0.10761082),\n",
       " (0, 0.064635366),\n",
       " (0, 0.46143058),\n",
       " (0, 0.005063529),\n",
       " (2, 0.7479211),\n",
       " (2, 0.7979511),\n",
       " (0, 0.7979511),\n",
       " (0, 0.7479211),\n",
       " (0, 0.866967),\n",
       " (1, 0.5210029),\n",
       " (6, 0.7479211),\n",
       " (0, -0.10761082),\n",
       " (3, 0.7479211),\n",
       " (2, 0.5210029),\n",
       " (3, 4.986957),\n",
       " (0, 0.005063529),\n",
       " (0, 0.7979511),\n",
       " (5, 4.986957),\n",
       " (3, 1.1439149),\n",
       " (1, 0.7979511),\n",
       " (1, 0.5210029),\n",
       " (0, -0.10761082),\n",
       " (0, 0.7479211),\n",
       " (0, 0.34875652),\n",
       " (0, 0.10047978),\n",
       " (0, 0.055093378),\n",
       " (0, -0.078979746),\n",
       " (0, 0.055093378),\n",
       " (0, 0.57498014),\n",
       " (0, 0.7479211),\n",
       " (0, 0.7979511),\n",
       " (0, 0.46143058),\n",
       " (0, 1.3605589),\n",
       " (0, -0.10761082),\n",
       " (0, 0.5210029),\n",
       " (0, 0.5210029),\n",
       " (0, -0.071766414),\n",
       " (2, 0.5210029),\n",
       " (0, 0.55684733),\n",
       " (1, 0.5210029),\n",
       " (1, 0.7979511),\n",
       " (0, 0.5210029),\n",
       " (3, 5.632868),\n",
       " (0, 0.7479211),\n",
       " (1, 0.5210029),\n",
       " (1, 0.7979511),\n",
       " (0, 1.3009868),\n",
       " (0, 0.5210029),\n",
       " (3, 0.5210029),\n",
       " (0, 0.5210029),\n",
       " (1, 0.7479211),\n",
       " (3, 1.3105289),\n",
       " (0, 0.46143058),\n",
       " (0, 0.5210029),\n",
       " (4, 0.7979511),\n",
       " (2, 0.7479211),\n",
       " (1, 0.34875652),\n",
       " (0, 0.7479211),\n",
       " (0, 4.9273853),\n",
       " (0, 2.7452047),\n",
       " (0, 0.3178155),\n",
       " (0, 0.5210029),\n",
       " (0, 4.9273853),\n",
       " (0, 0.5210029),\n",
       " (0, 0.055093378),\n",
       " (0, 1.3605589),\n",
       " (0, 0.5210029),\n",
       " (0, 0.005063529),\n",
       " (0, 0.8318429),\n",
       " (0, 0.24830194),\n",
       " (0, 0.34875652),\n",
       " (0, 0.5210029),\n",
       " (1, 0.7979511),\n",
       " (0, 0.46143058),\n",
       " (0, 0.5210029),\n",
       " (1, 2.4682567),\n",
       " (0, 0.5447338),\n",
       " (0, 0.7979511),\n",
       " (0, -0.10761082),\n",
       " (6, 5.2138753),\n",
       " (0, -0.078979746),\n",
       " (0, 1.3105289),\n",
       " (0, 0.7979511),\n",
       " (0, 0.7479211),\n",
       " (0, 0.064635366),\n",
       " (0, 1.2718792),\n",
       " (0, 1.4370773),\n",
       " (0, 0.11861266),\n",
       " (1, 0.7979511),\n",
       " (2, 0.7979511),\n",
       " (0, 0.5210029),\n",
       " (0, 0.7979511),\n",
       " (6, 5.632868),\n",
       " (2, 0.7479211),\n",
       " (0, 0.5210029),\n",
       " (0, 0.7479211),\n",
       " (0, 0.5043288),\n",
       " (1, 0.58305705),\n",
       " (0, 0.04796146),\n",
       " (0, 1.1439149),\n",
       " (0, 0.5210029),\n",
       " (1, 0.57498014),\n",
       " (0, -0.14568378),\n",
       " (2, 1.5843982),\n",
       " (0, 0.055093378),\n",
       " (0, 0.7979511),\n",
       " (1, 0.7979511),\n",
       " (0, 0.055093378),\n",
       " (2, 0.7979511),\n",
       " (0, 0.6043059),\n",
       " (1, 0.866967),\n",
       " (0, 0.8318429),\n",
       " (0, 0.5210029),\n",
       " (0, 0.7479211),\n",
       " (0, 0.6947208),\n",
       " (1, 0.5210029),\n",
       " (0, 0.7979511),\n",
       " (0, 0.7979511),\n",
       " (0, 2.4682567),\n",
       " (0, 0.5210029),\n",
       " (0, 0.24830194),\n",
       " (0, 0.7979511),\n",
       " (0, 0.5710329),\n",
       " (0, 0.5210029),\n",
       " (0, -0.13855185),\n",
       " (0, 0.005063529),\n",
       " (0, -0.14568378),\n",
       " (0, 0.35584888),\n",
       " (0, -0.10761082),\n",
       " (0, 0.57498014),\n",
       " (9, 4.986957),\n",
       " (0, -0.10761082),\n",
       " (0, 0.6043059),\n",
       " (0, 1.9712312),\n",
       " (3, 2.4682567),\n",
       " (0, 1.3605589),\n",
       " (4, 1.1669137),\n",
       " (0, 0.34875652),\n",
       " (0, 0.5210029),\n",
       " (0, 0.7479211),\n",
       " (0, 1.9720318),\n",
       " (0, 0.6043059),\n",
       " (0, 0.5210029),\n",
       " (0, 0.5210029),\n",
       " (0, 0.5210029),\n",
       " (0, 0.7979511),\n",
       " (1, 0.57498014),\n",
       " (0, 0.7479211),\n",
       " (3, 1.1669137),\n",
       " (1, 0.5210029),\n",
       " (0, 0.5210029),\n",
       " (0, 0.11861266),\n",
       " (28, 1.9047095),\n",
       " (0, -0.10761082),\n",
       " (0, 3.114168),\n",
       " (8, 0.40832862),\n",
       " (0, 0.7479211),\n",
       " (0, 0.005063529),\n",
       " (0, -0.10761082),\n",
       " (0, 0.5210029),\n",
       " (0, 1.1669137),\n",
       " (0, 1.1669137),\n",
       " (0, 0.7979511),\n",
       " (0, 0.7979511),\n",
       " (10, 5.7669415),\n",
       " (0, 0.7479211),\n",
       " (1, 1.1669137),\n",
       " (1, 0.916997),\n",
       " (0, 0.70466936),\n",
       " (0, 0.65959674),\n",
       " (4, 0.5210029),\n",
       " (2, 1.3105289),\n",
       " (0, 0.005063529),\n",
       " (0, 0.04796146),\n",
       " (0, 1.1029938),\n",
       " (0, 0.31590325),\n",
       " (0, 0.5210029),\n",
       " (0, 0.7979511),\n",
       " (1, 1.3605589),\n",
       " (0, 0.5210029),\n",
       " (0, 0.7979511),\n",
       " (0, 0.5210029),\n",
       " (1, 0.5210029),\n",
       " (0, 0.7479211),\n",
       " (0, 0.10047978),\n",
       " (0, 3.0856032),\n",
       " (0, 0.738379),\n",
       " (0, 0.5210029),\n",
       " (0, 0.5210029),\n",
       " (0, 0.5210029),\n",
       " (0, 0.064635366),\n",
       " (0, 0.7979511),\n",
       " (0, -0.078979746),\n",
       " (1, 1.3605589),\n",
       " (0, 0.7479211),\n",
       " (0, 2.8919585),\n",
       " (0, 0.5210029),\n",
       " (0, 0.5210029),\n",
       " (0, 0.7979511),\n",
       " (0, -0.078979746),\n",
       " (2, 0.7979511),\n",
       " (0, 0.7479211),\n",
       " (0, 0.34875652),\n",
       " (0, 0.5043288),\n",
       " (0, 0.7979511),\n",
       " (4, 1.1669137),\n",
       " (0, 0.5210029),\n",
       " (0, 0.005063529),\n",
       " (1, 0.7479211),\n",
       " (9, 0.5210029),\n",
       " (0, 0.7979511),\n",
       " (0, 1.4154943),\n",
       " (0, 0.7979511),\n",
       " (2, 0.5210029),\n",
       " (0, 0.5210029),\n",
       " (0, 0.5210029),\n",
       " (0, 1.9720318),\n",
       " (2, 0.7979511),\n",
       " (0, 0.8788176),\n",
       " (0, 1.4414253),\n",
       " (0, 0.31590325),\n",
       " (0, -0.078979746),\n",
       " (2, 0.866967),\n",
       " (3, 1.1669137),\n",
       " (0, 0.70466936),\n",
       " (0, 0.5210029),\n",
       " (0, 0.6043059),\n",
       " (2, 1.9799242),\n",
       " (1, 0.7979511),\n",
       " (0, -0.10761082),\n",
       " (1, 2.5346386),\n",
       " (4, 2.0394962),\n",
       " (1, 1.3605589),\n",
       " (0, -0.10761082),\n",
       " (1, 0.95202),\n",
       " (1, 0.5043288),\n",
       " (0, 0.45429865),\n",
       " (0, 0.6947208),\n",
       " (0, 0.005063529),\n",
       " (0, 0.5210029),\n",
       " (5, 1.4655243),\n",
       " (0, 0.6947208),\n",
       " (8, 0.5210029),\n",
       " (0, 0.6043059),\n",
       " (4, 0.5210029),\n",
       " (1, 0.7979511),\n",
       " (0, 0.064635366),\n",
       " (0, 0.5923273),\n",
       " (0, 0.7479211),\n",
       " (8, 0.7479211),\n",
       " (0, -0.10761082),\n",
       " (0, 0.5210029),\n",
       " (0, 1.4414253),\n",
       " (0, 0.5043288),\n",
       " (1, 0.7979511),\n",
       " (0, 0.7479211),\n",
       " (0, 0.40832862),\n",
       " (1, 0.40832862),\n",
       " (0, 0.5210029),\n",
       " (0, 0.7979511),\n",
       " (2, 3.0355732),\n",
       " (0, 2.4682567),\n",
       " (0, 1.3105289),\n",
       " (1, 1.3105289),\n",
       " (1, 2.8086548),\n",
       " (0, 0.7979511),\n",
       " (0, 0.3773876),\n",
       " (6, 4.9273853),\n",
       " (7, 5.2138753),\n",
       " (0, 0.6043059),\n",
       " (0, 0.34875652),\n",
       " (0, 0.5210029),\n",
       " (0, 1.1669137),\n",
       " (0, 0.5210029),\n",
       " (0, 0.7979511),\n",
       " (0, 0.7979511),\n",
       " (2, 0.5210029),\n",
       " (0, 0.005063529),\n",
       " (0, 0.866967),\n",
       " (0, 0.866967),\n",
       " (1, 0.5210029),\n",
       " (15, 0.5210029),\n",
       " (0, 0.5710329),\n",
       " (4, 4.358343),\n",
       " (0, 0.46143058),\n",
       " (0, 2.4682567),\n",
       " (1, 0.7979511),\n",
       " (1, 1.5843982),\n",
       " (0, 0.5043288),\n",
       " (0, 1.1978548),\n",
       " (1, 0.6043059),\n",
       " (0, 0.70466936),\n",
       " (0, 3.6482112),\n",
       " (0, 0.055093378),\n",
       " (0, 1.2291741),\n",
       " (0, 0.5210029),\n",
       " (0, 0.5210029),\n",
       " (1, 1.1669137),\n",
       " (0, 0.7479211),\n",
       " (0, 0.6043059),\n",
       " (0, -0.10761082),\n",
       " (0, 4.358343),\n",
       " (0, -0.10761082),\n",
       " (0, 0.7979511),\n",
       " (0, -0.10761082),\n",
       " (0, 0.31590325),\n",
       " (1, 0.7479211),\n",
       " (1, 1.3605589),\n",
       " (0, 0.7979511),\n",
       " (0, 0.8318429),\n",
       " (9, 0.5210029),\n",
       " (0, 0.3773876),\n",
       " (0, 0.7979511),\n",
       " (0, 0.5210029),\n",
       " (0, 0.40832862),\n",
       " (2, 0.5210029),\n",
       " (0, 0.7979511),\n",
       " (0, 0.6043059),\n",
       " (0, 0.5210029),\n",
       " (0, 2.8586848),\n",
       " (0, -0.10761082),\n",
       " (0, 0.5210029),\n",
       " (0, 0.5210029),\n",
       " (0, 0.7479211),\n",
       " (1, 2.8586848),\n",
       " (0, 0.5210029),\n",
       " (0, 0.7979511),\n",
       " (0, 1.1439149),\n",
       " (1, 0.68774384),\n",
       " (1, 0.7479211),\n",
       " (0, 0.5114607),\n",
       " (1, 0.7479211),\n",
       " (0, 0.5210029),\n",
       " (1, 1.4414253),\n",
       " (3, 0.34875652),\n",
       " (0, 0.5210029),\n",
       " (0, 0.31590325),\n",
       " (0, 0.7281682),\n",
       " (0, 1.3605589),\n",
       " (8, 4.9273853),\n",
       " (1, 3.0355732),\n",
       " (0, 0.7479211),\n",
       " (0, -0.10761082),\n",
       " (0, 0.9844628),\n",
       " (0, 0.7979511),\n",
       " (0, 1.5843982),\n",
       " (0, 1.1669137),\n",
       " (0, 1.1669137),\n",
       " (0, 0.5210029),\n",
       " (0, 1.1669137),\n",
       " (0, -0.10761082),\n",
       " (0, 0.5210029),\n",
       " (0, 0.07605572),\n",
       " (7, 0.7979511),\n",
       " (0, 0.5043288),\n",
       " (1, 0.5210029),\n",
       " (11, 5.2639055),\n",
       " (0, -0.10761082),\n",
       " (0, 0.57498014),\n",
       " (0, 0.7979511),\n",
       " (10, 1.1669137),\n",
       " (0, 2.8086548),\n",
       " (13, 2.4682567),\n",
       " (1, 0.07605572),\n",
       " (0, 0.5210029),\n",
       " (0, 0.40832862),\n",
       " (0, 0.7479211),\n",
       " (0, 1.3818532),\n",
       " (0, 0.738379),\n",
       " (0, 0.31590325),\n",
       " (0, 0.07605572),\n",
       " (0, 0.5210029),\n",
       " (1, 0.7979511),\n",
       " (0, 0.7979511),\n",
       " (0, 4.8742833),\n",
       " (2, 0.866967),\n",
       " (0, 0.866967),\n",
       " (0, 0.5710329),\n",
       " (5, 3.3078127),\n",
       " (0, 1.4154943),\n",
       " (2, 2.8086548),\n",
       " (0, 0.7979511),\n",
       " (0, 0.7479211),\n",
       " (1, 0.5210029),\n",
       " (0, 0.7979511),\n",
       " (3, 0.7979511),\n",
       " (0, 0.5210029),\n",
       " (0, 1.9720318),\n",
       " (0, 1.4414253),\n",
       " (0, 0.12882783),\n",
       " (0, 1.3605589),\n",
       " (0, 0.7979511),\n",
       " (1, 0.5210029),\n",
       " (0, 0.6043059),\n",
       " (0, 0.7479211),\n",
       " (0, -0.10761082),\n",
       " (0, 0.5210029),\n",
       " (0, 0.5210029),\n",
       " (0, 0.5210029),\n",
       " (1, 0.7979511),\n",
       " (0, 0.24830194),\n",
       " (0, 0.5210029),\n",
       " (3, -0.10761082),\n",
       " (0, 0.5210029),\n",
       " (0, 0.5210029),\n",
       " (0, 1.9220018),\n",
       " (0, 0.8788176),\n",
       " (0, 0.30610862),\n",
       " (3, 0.866967),\n",
       " (5, 1.3605589),\n",
       " (0, 0.7979511),\n",
       " (0, 0.31068343),\n",
       " (0, 0.866967),\n",
       " (0, 0.7479211),\n",
       " (0, 0.5210029),\n",
       " (0, -0.10761082),\n",
       " (0, 0.5210029),\n",
       " (0, -0.10761082),\n",
       " (0, 1.1978548),\n",
       " (0, 0.5210029),\n",
       " (0, 0.005063529),\n",
       " (0, 0.7979511),\n",
       " (0, 0.6043059),\n",
       " (0, 2.1800413),\n",
       " (0, 0.7979511),\n",
       " (0, 0.23452795),\n",
       " (0, 0.7479211),\n",
       " (0, 1.3605589),\n",
       " (0, 0.7979511),\n",
       " (1, 0.34875652),\n",
       " (2, 1.4154943),\n",
       " (0, 0.055093378),\n",
       " (1, 0.46143058),\n",
       " (0, 0.5210029),\n",
       " (0, 0.5210029),\n",
       " (0, 0.7979511),\n",
       " (0, 1.1978548),\n",
       " (0, 0.9844628),\n",
       " (0, 0.31590325),\n",
       " (0, 0.5210029),\n",
       " (0, 0.5210029),\n",
       " (0, 0.5210029),\n",
       " (0, 0.5210029),\n",
       " (1, 0.40832862),\n",
       " (2, 0.7979511),\n",
       " (0, 0.7979511),\n",
       " (0, 0.5210029),\n",
       " (0, 0.5210029),\n",
       " (0, 0.5210029),\n",
       " (2, 0.5210029),\n",
       " (0, 0.5210029),\n",
       " (0, 0.005063529),\n",
       " (2, 0.11861266),\n",
       " (0, 0.7479211),\n",
       " (0, -0.078979746),\n",
       " (0, 0.6043059),\n",
       " (0, 1.4414253),\n",
       " (0, 0.11861266),\n",
       " (0, 0.5210029),\n",
       " (2, 1.7625481),\n",
       " (0, 0.5210029),\n",
       " (0, 0.7479211),\n",
       " (0, 0.005063529),\n",
       " (0, 0.46143058),\n",
       " (4, 1.093885),\n",
       " (0, 0.5210029),\n",
       " (0, 0.5210029),\n",
       " (1, 0.7979511),\n",
       " (3, 0.5210029),\n",
       " (0, 0.04796146),\n",
       " (0, 0.7479211),\n",
       " (1, 0.8318429),\n",
       " (2, 1.7625481),\n",
       " (0, 4.8147116),\n",
       " (0, -0.13855185),\n",
       " (0, 1.9124599),\n",
       " (0, 0.5210029),\n",
       " (0, 0.3561386),\n",
       " (3, 0.5210029),\n",
       " (0, 2.1800413),\n",
       " (8, 1.3105289),\n",
       " (0, 0.07605572),\n",
       " (0, 0.7979511),\n",
       " (1, 0.866967),\n",
       " (0, -0.10761082),\n",
       " (1, 1.3605589),\n",
       " (0, 0.34875652),\n",
       " (1, 1.3605589),\n",
       " (0, 1.1439149),\n",
       " (0, 0.7979511),\n",
       " (0, -0.10761082),\n",
       " (3, 1.5843982),\n",
       " (0, 0.7979511),\n",
       " (0, 0.5043288),\n",
       " (0, 0.005063529),\n",
       " (0, 0.7479211),\n",
       " (1, 0.9844628),\n",
       " (0, 0.07605572),\n",
       " (1, 1.1669137),\n",
       " (0, -0.10761082),\n",
       " (2, 0.5210029),\n",
       " (0, 1.9220018),\n",
       " (2, 0.7479211),\n",
       " (1, 1.8396444),\n",
       " (0, 0.7979511),\n",
       " (0, 0.5210029),\n",
       " (0, 0.5210029),\n",
       " (0, 0.064635366),\n",
       " (1, 0.7979511),\n",
       " (0, 0.24950908),\n",
       " (0, 0.11861266),\n",
       " (0, 1.1669137),\n",
       " (0, 0.3178155),\n",
       " (1, 0.7281682),\n",
       " (0, 0.34875652),\n",
       " (0, 0.7979511),\n",
       " (0, 0.5114607),\n",
       " (0, 0.27180046),\n",
       " (1, 0.866967),\n",
       " (0, 0.7979511),\n",
       " (1, 0.8788176),\n",
       " (0, 0.916997),\n",
       " (2, 0.5210029),\n",
       " (0, -0.10761082),\n",
       " (0, 0.5210029),\n",
       " (0, 0.43136474),\n",
       " (0, 1.4414253),\n",
       " (4, 0.5210029),\n",
       " (2, 0.5210029),\n",
       " (0, 0.5710329),\n",
       " (1, 0.65959674),\n",
       " (0, 0.6518994),\n",
       " (0, -0.13855185),\n",
       " (2, 0.7979511),\n",
       " (0, 0.866967),\n",
       " (0, 0.7479211),\n",
       " (0, 0.7979511),\n",
       " (0, 0.53242314),\n",
       " (2, 0.40832862),\n",
       " (6, 0.7979511),\n",
       " (2, 0.5210029),\n",
       " (1, 0.6043059),\n",
       " (0, 0.7979511),\n",
       " (0, 4.8147116),\n",
       " (2, 0.7979511),\n",
       " (0, -0.10761082),\n",
       " (3, 0.5210029),\n",
       " (3, 1.1669137),\n",
       " (0, -0.10761082),\n",
       " (2, 4.358343),\n",
       " (0, 1.1669137),\n",
       " (0, 0.8788176),\n",
       " (1, 1.4414253),\n",
       " (0, 0.7479211),\n",
       " (0, -0.10761082),\n",
       " (10, 0.5210029),\n",
       " (14, 2.4682567),\n",
       " (0, -0.10761082),\n",
       " (0, 0.95202),\n",
       " (1, 1.5843982),\n",
       " (0, 0.866967),\n",
       " (0, 0.5210029),\n",
       " (1, 0.5210029),\n",
       " (0, 0.7979511),\n",
       " (0, 0.055093378),\n",
       " (0, 0.7979511),\n",
       " (0, 1.4655243)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_list = list(predicoes_yb3)\n",
    "test_list = list(yb3_test)\n",
    "complist = []\n",
    "for i in range(len(test_list)):\n",
    "    complist.append((test_list[i], pred_list[i]))\n",
    "complist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.2187954),\n",
       " (0, 0.3952857),\n",
       " (0, 0.3474573),\n",
       " (0, 0.990039),\n",
       " (3, 0.5865002),\n",
       " (0, 0.2187954),\n",
       " (0, 0.9201729),\n",
       " (0, 0.46053895),\n",
       " (0, 0.23324159),\n",
       " (4, 0.4064731),\n",
       " (3, 0.36915997),\n",
       " (0, 0.3474573),\n",
       " (0, 0.3474573),\n",
       " (0, 0.3362699),\n",
       " (1, 1.6723902),\n",
       " (0, 0.36915997),\n",
       " (0, 0.36915997),\n",
       " (5, 0.36915997),\n",
       " (0, 0.3982599),\n",
       " (13, 0.8382749),\n",
       " (0, 0.42221588),\n",
       " (0, 0.2187954),\n",
       " (0, 0.3362699),\n",
       " (7, 0.7884308),\n",
       " (0, 0.79429656),\n",
       " (0, 0.7884308),\n",
       " (3, 0.3362699),\n",
       " (0, 0.42221588),\n",
       " (0, 0.36915997),\n",
       " (0, 0.79429656),\n",
       " (0, 0.42221588),\n",
       " (0, 0.49531367),\n",
       " (0, 0.42221588),\n",
       " (0, 0.52076805),\n",
       " (0, 0.3362699),\n",
       " (0, 0.52076805),\n",
       " (1, 0.42221588),\n",
       " (0, 0.42221588),\n",
       " (1, 1.0891188),\n",
       " (0, 0.8382749),\n",
       " (0, 0.49531367),\n",
       " (0, 0.42221588),\n",
       " (0, 9.514479),\n",
       " (0, 0.4064731),\n",
       " (0, 0.2187954),\n",
       " (0, 0.5896965),\n",
       " (0, 0.23910733),\n",
       " (0, 0.2187954),\n",
       " (6, 1.7221359),\n",
       " (0, 0.2187954),\n",
       " (2, 0.6128405),\n",
       " (0, 0.2187954),\n",
       " (1, 0.36190343),\n",
       " (0, 0.2187954),\n",
       " (0, 0.42980567),\n",
       " (0, 0.23087253),\n",
       " (0, 0.2187954),\n",
       " (0, 0.52076805),\n",
       " (0, 0.23324159),\n",
       " (3, 0.42221588),\n",
       " (0, 0.30897808),\n",
       " (0, 0.2187954),\n",
       " (0, 0.2187954),\n",
       " (0, 0.52076805),\n",
       " (0, 0.3952857),\n",
       " (0, 0.36915997),\n",
       " (0, 1.1603942),\n",
       " (1, 0.42980567),\n",
       " (0, 0.2187954),\n",
       " (0, 0.3362699),\n",
       " (0, 0.36915997),\n",
       " (0, 0.49531367),\n",
       " (0, 0.37211043),\n",
       " (0, 0.2187954),\n",
       " (0, 0.36190343),\n",
       " (0, 0.23087253),\n",
       " (0, 0.2187954),\n",
       " (0, 0.42980567),\n",
       " (0, 1.054054),\n",
       " (0, 0.3474573),\n",
       " (0, 0.42221588),\n",
       " (0, 0.36190343),\n",
       " (0, 0.35471383),\n",
       " (0, 0.36915997),\n",
       " (3, 1.7314268),\n",
       " (0, 0.49531367),\n",
       " (4, 0.42221588),\n",
       " (0, 0.2187954),\n",
       " (32, 0.3362699),\n",
       " (0, 0.36915997),\n",
       " (2, 1.0326757),\n",
       " (0, 0.36915997),\n",
       " (0, 0.36915997),\n",
       " (1, 0.78113014),\n",
       " (4, 0.41495934),\n",
       " (0, 0.36915997),\n",
       " (1, 0.36915997),\n",
       " (2, 2.2838116),\n",
       " (0, 0.7860617),\n",
       " (0, 0.2778113),\n",
       " (0, 0.3362699),\n",
       " (1, 0.42221588),\n",
       " (0, 0.36915997),\n",
       " (0, 0.42980567),\n",
       " (0, 0.2187954),\n",
       " (0, 0.2187954),\n",
       " (0, 0.7313742),\n",
       " (4, 0.5865002),\n",
       " (0, 0.49531367),\n",
       " (1, 0.31623462),\n",
       " (0, 0.30897808),\n",
       " (0, 0.5865002),\n",
       " (0, 0.18031621),\n",
       " (0, 0.23324159),\n",
       " (0, 1.0399324),\n",
       " (0, 0.31623462),\n",
       " (0, 0.2187954),\n",
       " (0, 0.2187954),\n",
       " (0, 0.36915997),\n",
       " (0, 0.2187954),\n",
       " (0, 0.42221588),\n",
       " (0, 0.42221588),\n",
       " (0, 0.42221588),\n",
       " (0, 0.42221588),\n",
       " (0, 0.3362699),\n",
       " (0, 0.36915997),\n",
       " (4, 0.41495934),\n",
       " (0, 0.2187954),\n",
       " (5, 4.3078313),\n",
       " (6, 0.36915997),\n",
       " (2, 0.7313742),\n",
       " (0, 0.2187954),\n",
       " (0, 0.52076805),\n",
       " (0, 1.6836377),\n",
       " (1, 0.42221588),\n",
       " (0, 0.52076805),\n",
       " (0, 0.36915997),\n",
       " (0, 0.2187954),\n",
       " (0, 1.2867005),\n",
       " (0, 0.3362699),\n",
       " (0, 0.2862975),\n",
       " (0, 0.23324159),\n",
       " (0, 0.233823),\n",
       " (0, 0.23324159),\n",
       " (1, 0.31623462),\n",
       " (0, 0.990039),\n",
       " (0, 0.42221588),\n",
       " (0, 0.36915997),\n",
       " (0, 1.6046603),\n",
       " (0, 0.2187954),\n",
       " (0, 0.36915997),\n",
       " (0, 0.36915997),\n",
       " (0, 0.5670262),\n",
       " (0, 0.3362699),\n",
       " (0, 0.42221588),\n",
       " (0, 0.36915997),\n",
       " (0, 0.54228365),\n",
       " (0, 0.35071602),\n",
       " (0, 1.4499481),\n",
       " (0, 0.42221588),\n",
       " (0, 2.298588),\n",
       " (0, 0.42980567),\n",
       " (0, 0.7739407),\n",
       " (0, 0.36915997),\n",
       " (0, 0.36915997),\n",
       " (0, 0.3474573),\n",
       " (2, 0.42221588),\n",
       " (3, 0.41372964),\n",
       " (0, 0.36915997),\n",
       " (0, 0.36915997),\n",
       " (1, 0.42221588),\n",
       " (0, 0.42221588),\n",
       " (0, 1.145837),\n",
       " (0, 0.42221588),\n",
       " (0, 2.11437),\n",
       " (0, 0.6152096),\n",
       " (0, 0.41062224),\n",
       " (0, 0.36915997),\n",
       " (5, 1.2755969),\n",
       " (0, 0.36915997),\n",
       " (0, 0.2187954),\n",
       " (0, 0.8382749),\n",
       " (0, 0.36915997),\n",
       " (0, 0.2187954),\n",
       " (0, 0.43893692),\n",
       " (0, 0.2778113),\n",
       " (1, 0.3362699),\n",
       " (0, 0.36915997),\n",
       " (0, 1.7212079),\n",
       " (0, 0.36915997),\n",
       " (0, 0.3474573),\n",
       " (0, 1.0326757),\n",
       " (0, 0.42980567),\n",
       " (0, 0.49531367),\n",
       " (0, 0.2187954),\n",
       " (1, 1.7462597),\n",
       " (0, 0.23087253),\n",
       " (0, 0.41372964),\n",
       " (1, 0.42221588),\n",
       " (0, 0.76300615),\n",
       " (0, 0.23324159),\n",
       " (0, 0.4274366),\n",
       " (0, 0.23324159),\n",
       " (0, 0.18031621),\n",
       " (1, 0.52076805),\n",
       " (0, 0.49531367),\n",
       " (1, 0.36190343),\n",
       " (0, 0.42221588),\n",
       " (4, 1.4499481),\n",
       " (0, 0.42221588),\n",
       " (0, 0.36915997),\n",
       " (0, 0.41495934),\n",
       " (3, 0.5865002),\n",
       " (0, 0.49531367),\n",
       " (0, 0.18031621),\n",
       " (0, 0.54228365),\n",
       " (0, 0.36190343),\n",
       " (0, 0.31623462),\n",
       " (0, 0.18031621),\n",
       " (1, 0.8382749),\n",
       " (0, 0.2187954),\n",
       " (2, 0.42221588),\n",
       " (1, 0.42221588),\n",
       " (0, 0.2187954),\n",
       " (0, 0.52076805),\n",
       " (0, 0.4356714),\n",
       " (0, 0.36915997),\n",
       " (0, 0.43893692),\n",
       " (0, 0.36190343),\n",
       " (0, 0.42221588),\n",
       " (0, 0.3474573),\n",
       " (0, 0.36190343),\n",
       " (0, 0.42221588),\n",
       " (0, 0.42221588),\n",
       " (0, 1.0399324),\n",
       " (0, 2.3699293),\n",
       " (0, 0.2778113),\n",
       " (0, 0.49531367),\n",
       " (3, 0.4422578),\n",
       " (1, 0.36915997),\n",
       " (0, 0.23324159),\n",
       " (0, 0.2187954),\n",
       " (0, 0.5865002),\n",
       " (0, 0.2187954),\n",
       " (0, 0.2187954),\n",
       " (0, 0.31623462),\n",
       " (1, 0.7313742),\n",
       " (0, 0.2187954),\n",
       " (0, 0.42980567),\n",
       " (0, 0.35071602),\n",
       " (0, 1.0399324),\n",
       " (0, 0.5896965),\n",
       " (2, 0.8382749),\n",
       " (0, 0.3362699),\n",
       " (0, 0.3362699),\n",
       " (0, 0.42221588),\n",
       " (0, 1.4353654),\n",
       " (0, 0.42980567),\n",
       " (0, 0.36190343),\n",
       " (0, 0.3474573),\n",
       " (0, 0.36915997),\n",
       " (0, 0.49148124),\n",
       " (0, 0.31623462),\n",
       " (0, 0.42221588),\n",
       " (2, 0.79429656),\n",
       " (0, 0.36190343),\n",
       " (0, 0.36915997),\n",
       " (0, 0.18031621),\n",
       " (5, 1.2631351),\n",
       " (0, 0.2187954),\n",
       " (0, 0.9596815),\n",
       " (1, 0.3362699),\n",
       " (0, 0.42221588),\n",
       " (0, 0.23324159),\n",
       " (0, 0.2187954),\n",
       " (0, 0.36190343),\n",
       " (3, 1.3140973),\n",
       " (0, 0.7884308),\n",
       " (0, 0.54228365),\n",
       " (0, 0.49531367),\n",
       " (6, 2.219324),\n",
       " (1, 0.42221588),\n",
       " (0, 0.7884308),\n",
       " (2, 0.36915997),\n",
       " (0, 0.5865002),\n",
       " (0, 0.40604684),\n",
       " (0, 0.36915997),\n",
       " (0, 0.41372964),\n",
       " (0, 0.23324159),\n",
       " (0, 0.5865002),\n",
       " (0, 0.23087253),\n",
       " (0, 0.2187954),\n",
       " (0, 0.36915997),\n",
       " (0, 0.42221588),\n",
       " (0, 0.7739407),\n",
       " (6, 0.3474573),\n",
       " (0, 0.49531367),\n",
       " (0, 0.36915997),\n",
       " (12, 2.3699293),\n",
       " (0, 0.42221588),\n",
       " (3, 0.2862975),\n",
       " (0, 0.49531367),\n",
       " (1, 0.5230656),\n",
       " (1, 0.3474573),\n",
       " (0, 0.3362699),\n",
       " (0, 0.36915997),\n",
       " (0, 0.23324159),\n",
       " (2, 0.42221588),\n",
       " (0, 0.2187954),\n",
       " (0, 0.7739407),\n",
       " (0, 0.42221588),\n",
       " (0, 0.42980567),\n",
       " (1, 2.3699293),\n",
       " (0, 0.37211043),\n",
       " (0, 0.49531367),\n",
       " (0, 0.23087253),\n",
       " (0, 0.54228365),\n",
       " (0, 0.42221588),\n",
       " (0, 0.3362699),\n",
       " (0, 0.5865002),\n",
       " (0, 0.6408185),\n",
       " (2, 1.3052405),\n",
       " (0, 0.36915997),\n",
       " (0, 0.2187954),\n",
       " (0, 0.42221588),\n",
       " (1, 0.36915997),\n",
       " (0, 0.42221588),\n",
       " (1, 0.42221588),\n",
       " (0, 0.42221588),\n",
       " (3, 0.36915997),\n",
       " (0, 0.36915997),\n",
       " (0, 0.3474573),\n",
       " (1, 1.7221359),\n",
       " (0, 0.42221588),\n",
       " (0, 0.42980567),\n",
       " (0, 1.3639412),\n",
       " (0, 0.2187954),\n",
       " (0, 0.6203538),\n",
       " (0, 0.36915997),\n",
       " (0, 0.79429656),\n",
       " (0, 0.4064731),\n",
       " (0, 0.36915997),\n",
       " (0, 0.42980567),\n",
       " (0, 0.42221588),\n",
       " (1, 0.54228365),\n",
       " (0, 0.2187954),\n",
       " (0, 1.841586),\n",
       " (0, 0.52076805),\n",
       " (0, 0.8382749),\n",
       " (0, 0.2187954),\n",
       " (1, 0.7884308),\n",
       " (8, 0.36937657),\n",
       " (0, 0.31623462),\n",
       " (0, 0.3362699),\n",
       " (0, 0.2187954),\n",
       " (0, 0.36915997),\n",
       " (1, 0.52076805),\n",
       " (0, 0.3362699),\n",
       " (5, 1.7314268),\n",
       " (0, 0.42980567),\n",
       " (0, 0.36915997),\n",
       " (0, 0.54228365),\n",
       " (0, 0.23324159),\n",
       " (0, 0.41299132),\n",
       " (0, 0.42221588),\n",
       " (0, 0.42221588),\n",
       " (0, 0.2187954),\n",
       " (0, 0.36190343),\n",
       " (0, 0.8382749),\n",
       " (0, 0.31623462),\n",
       " (0, 0.49531367),\n",
       " (0, 0.49148124),\n",
       " (0, 0.35071602),\n",
       " (2, 0.3362699),\n",
       " (0, 0.36915997),\n",
       " (1, 0.42221588),\n",
       " (0, 0.42221588),\n",
       " (2, 1.0326757),\n",
       " (0, 0.41372964),\n",
       " (0, 0.41372964),\n",
       " (0, 0.36915997),\n",
       " (1, 0.52076805),\n",
       " (0, 0.41062224),\n",
       " (12, 2.1203399),\n",
       " (6, 1.7462597),\n",
       " (0, 0.4274366),\n",
       " (1, 0.3362699),\n",
       " (0, 0.36915997),\n",
       " (0, 0.7884308),\n",
       " (0, 0.36915997),\n",
       " (0, 0.49531367),\n",
       " (0, 0.6408185),\n",
       " (0, 0.36915997),\n",
       " (0, 0.2187954),\n",
       " (1, 0.36915997),\n",
       " (0, 0.3362699),\n",
       " (0, 1.1570244),\n",
       " (1, 0.36915997),\n",
       " (0, 0.4422578),\n",
       " (0, 0.7044675),\n",
       " (0, 0.3362699),\n",
       " (1, 1.0399324),\n",
       " (0, 0.52076805),\n",
       " (0, 1.2549119),\n",
       " (1, 0.3982599),\n",
       " (0, 0.3952857),\n",
       " (1, 0.4274366),\n",
       " (0, 0.4064731),\n",
       " (0, 0.8382749),\n",
       " (0, 0.23324159),\n",
       " (0, 0.4370252),\n",
       " (0, 0.36915997),\n",
       " (0, 0.36915997),\n",
       " (0, 0.8382749),\n",
       " (0, 0.42221588),\n",
       " (1, 0.4274366),\n",
       " (0, 0.2187954),\n",
       " (0, 1.1052667),\n",
       " (0, 0.2187954),\n",
       " (0, 0.42221588),\n",
       " (0, 0.2187954),\n",
       " (0, 0.2187954),\n",
       " (1, 0.42221588),\n",
       " (1, 0.8382749),\n",
       " (0, 0.49531367),\n",
       " (0, 0.43893692),\n",
       " (1, 0.36915997),\n",
       " (0, 0.41299132),\n",
       " (0, 0.42221588),\n",
       " (0, 0.36915997),\n",
       " (0, 0.3362699),\n",
       " (3, 2.3699293),\n",
       " (0, 0.49531367),\n",
       " (0, 0.4274366),\n",
       " (0, 0.36915997),\n",
       " (0, 0.4422578),\n",
       " (0, 0.2187954),\n",
       " (0, 0.36190343),\n",
       " (0, 0.36915997),\n",
       " (0, 0.42221588),\n",
       " (1, 0.4422578),\n",
       " (0, 0.36915997),\n",
       " (0, 0.49531367),\n",
       " (1, 0.54228365),\n",
       " (2, 1.1994647),\n",
       " (0, 0.42221588),\n",
       " (0, 0.36915997),\n",
       " (0, 0.42221588),\n",
       " (0, 0.36190343),\n",
       " (0, 0.8382749),\n",
       " (0, 0.3362699),\n",
       " (0, 0.36915997),\n",
       " (0, 0.2187954),\n",
       " (0, 0.36937657),\n",
       " (0, 1.00584),\n",
       " (0, 2.1203399),\n",
       " (0, 0.42221588),\n",
       " (0, 0.42221588),\n",
       " (0, 0.2187954),\n",
       " (0, 0.36915997),\n",
       " (0, 0.49531367),\n",
       " (0, 0.8382749),\n",
       " (0, 0.7860617),\n",
       " (0, 0.7383125),\n",
       " (0, 0.3474573),\n",
       " (0, 0.7860617),\n",
       " (0, 0.2187954),\n",
       " (0, 0.36915997),\n",
       " (0, 0.2778113),\n",
       " (1, 0.42221588),\n",
       " (0, 0.5865002),\n",
       " (0, 0.36915997),\n",
       " (0, 1.7462597),\n",
       " (0, 0.2187954),\n",
       " (0, 0.30897808),\n",
       " (0, 0.49531367),\n",
       " (1, 0.7884308),\n",
       " (3, 0.36915997),\n",
       " (1, 1.0399324),\n",
       " (0, 0.2778113),\n",
       " (0, 0.36915997),\n",
       " (0, 0.3362699),\n",
       " (0, 0.42221588),\n",
       " (8, 0.8382749),\n",
       " (0, 0.62161815),\n",
       " (0, 0.2187954),\n",
       " (1, 0.5865002),\n",
       " (0, 0.36915997),\n",
       " (0, 0.42221588),\n",
       " (0, 0.42221588),\n",
       " (0, 0.73734397),\n",
       " (0, 0.36915997),\n",
       " (0, 0.36190343),\n",
       " (0, 0.36915997),\n",
       " (1, 1.0118945),\n",
       " (0, 0.42221588),\n",
       " (1, 0.36915997),\n",
       " (3, 0.42221588),\n",
       " (0, 0.42221588),\n",
       " (2, 0.3474573),\n",
       " (3, 9.514479),\n",
       " (4, 0.54228365),\n",
       " (3, 0.42255947),\n",
       " (8, 1.7221359),\n",
       " (7, 0.8382749),\n",
       " (0, 0.5865002),\n",
       " (0, 0.5896965),\n",
       " (0, 0.42221588),\n",
       " (0, 0.36190343),\n",
       " (0, 0.42980567),\n",
       " (0, 0.6931698),\n",
       " (0, 0.2187954),\n",
       " (0, 0.46376476),\n",
       " (0, 2.3699293),\n",
       " (0, 0.36915997),\n",
       " (0, 9.514479),\n",
       " (0, 0.2778113),\n",
       " (0, 0.3474573),\n",
       " (0, 0.2187954),\n",
       " (0, 0.3362699),\n",
       " (0, 0.36915997),\n",
       " (0, 1.4353654),\n",
       " (0, 0.42980567),\n",
       " (0, 0.36915997),\n",
       " (0, 0.36915997),\n",
       " (11, 1.095876),\n",
       " (0, 0.54228365),\n",
       " (0, 0.36937657),\n",
       " (1, 0.36915997),\n",
       " (2, 0.42221588),\n",
       " (0, 0.36915997),\n",
       " (0, 0.2187954),\n",
       " (0, 0.3362699),\n",
       " (0, 0.2187954),\n",
       " (1, 0.3952857),\n",
       " (0, 0.7026938),\n",
       " (0, 0.2187954),\n",
       " (0, 0.49531367),\n",
       " (0, 0.42980567),\n",
       " (0, 0.2187954),\n",
       " (0, 0.49531367),\n",
       " (0, 0.23087253),\n",
       " (1, 0.8453864),\n",
       " (1, 0.8382749),\n",
       " (0, 0.49531367),\n",
       " (0, 0.3362699),\n",
       " (0, 0.42221588),\n",
       " (0, 0.2187954),\n",
       " (0, 0.36915997),\n",
       " (0, 0.3362699),\n",
       " (0, 0.35071602),\n",
       " (0, 0.52076805),\n",
       " (1, 0.3952857),\n",
       " (0, 0.36915997),\n",
       " (0, 0.2187954),\n",
       " (0, 0.3474573),\n",
       " (0, 0.3474573),\n",
       " (0, 0.36190343),\n",
       " (0, 0.36915997),\n",
       " (0, 0.35071602),\n",
       " (0, 0.42221588),\n",
       " (0, 0.42221588),\n",
       " (0, 0.36190343),\n",
       " (0, 0.36915997),\n",
       " (0, 0.36915997),\n",
       " (3, 0.36190343),\n",
       " (0, 0.36915997),\n",
       " (0, 0.2187954),\n",
       " (0, 0.5865002),\n",
       " (0, 0.42221588),\n",
       " (0, 0.23087253),\n",
       " (0, 0.4274366),\n",
       " (0, 0.8382749),\n",
       " (0, 0.18031621),\n",
       " (0, 0.36915997),\n",
       " (1, 0.3474573),\n",
       " (1, 0.46376476),\n",
       " (2, 0.42221588),\n",
       " (0, 0.2187954),\n",
       " (0, 0.36915997),\n",
       " (2, 0.42221588),\n",
       " (0, 0.3362699),\n",
       " (0, 0.36915997),\n",
       " (0, 0.49531367),\n",
       " (2, 0.36915997),\n",
       " (0, 0.5865002),\n",
       " (0, 0.42221588),\n",
       " (4, 0.43893692),\n",
       " (0, 0.36190343),\n",
       " (0, 0.7313742),\n",
       " (0, 0.2187954),\n",
       " (0, 1.652302),\n",
       " (0, 0.36190343),\n",
       " (0, 0.36915997),\n",
       " (1, 0.36915997),\n",
       " (0, 0.2187954),\n",
       " (0, 0.41372964),\n",
       " (0, 0.2778113),\n",
       " (0, 0.42221588),\n",
       " (3, 0.36190343),\n",
       " (0, 0.2187954),\n",
       " (2, 0.7739407),\n",
       " (0, 0.3362699),\n",
       " (1, 0.7739407),\n",
       " (0, 0.49531367),\n",
       " (1, 0.52076805),\n",
       " (0, 0.2187954),\n",
       " (1, 0.8382749),\n",
       " (0, 0.49531367),\n",
       " (0, 0.3982599),\n",
       " (0, 0.2187954),\n",
       " (0, 0.42221588),\n",
       " (0, 0.36915997),\n",
       " (0, 0.2778113),\n",
       " (2, 0.7884308),\n",
       " (2, 0.2187954),\n",
       " (0, 0.36915997),\n",
       " (2, 1.4353654),\n",
       " (0, 0.6931698),\n",
       " (0, 0.4215025),\n",
       " (2, 0.49531367),\n",
       " (1, 0.3474573),\n",
       " (0, 0.3362699),\n",
       " (0, 0.2187954),\n",
       " (0, 0.49531367),\n",
       " (0, 0.5865002),\n",
       " (0, 0.18031621),\n",
       " (7, 0.79429656),\n",
       " (0, 0.41299132),\n",
       " (1, 0.36937657),\n",
       " (0, 0.3362699),\n",
       " (3, 0.76300615),\n",
       " (0, 0.36915997),\n",
       " (0, 0.18031621),\n",
       " (0, 0.3362699),\n",
       " (0, 0.42980567),\n",
       " (1, 0.42980567),\n",
       " (0, 0.36915997),\n",
       " (1, 0.36915997),\n",
       " (0, 0.2187954),\n",
       " (0, 0.36915997),\n",
       " (0, 0.6252182),\n",
       " (0, 0.8382749),\n",
       " (4, 0.3474573),\n",
       " (0, 0.3362699),\n",
       " (0, 0.36915997),\n",
       " (0, 0.41723424),\n",
       " (0, 0.41299132),\n",
       " (0, 0.23910733),\n",
       " (1, 0.49148124),\n",
       " (1, 0.3362699),\n",
       " (1, 0.42221588),\n",
       " (0, 0.49531367),\n",
       " (0, 0.4064731),\n",
       " (1, 0.3362699),\n",
       " (3, 0.42221588),\n",
       " (0, 0.36915997),\n",
       " (0, 0.4274366),\n",
       " (0, 0.52076805),\n",
       " (0, 0.7313742),\n",
       " (0, 0.42221588),\n",
       " (0, 0.2187954),\n",
       " (1, 0.36915997),\n",
       " (0, 0.8382749),\n",
       " (0, 0.2187954),\n",
       " (0, 1.1052667),\n",
       " (0, 1.2525429),\n",
       " (0, 0.42980567),\n",
       " (0, 0.8382749),\n",
       " (0, 0.42221588),\n",
       " (0, 0.2187954),\n",
       " (0, 0.36915997),\n",
       " (1, 1.0399324),\n",
       " (0, 0.2187954),\n",
       " (0, 0.7884308),\n",
       " (0, 0.7383125),\n",
       " (0, 0.3474573),\n",
       " (0, 0.36190343),\n",
       " (0, 0.36915997),\n",
       " (0, 0.49531367),\n",
       " (0, 0.2187954),\n",
       " (0, 0.42221588),\n",
       " (0, 0.54228365)]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_list = list(predicoes_yb4)\n",
    "test_list = list(yb4_test)\n",
    "complist = []\n",
    "for i in range(len(test_list)):\n",
    "    complist.append((test_list[i], pred_list[i]))\n",
    "complist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.37555546),\n",
       " (0, 0.79886574),\n",
       " (0, 0.64915556),\n",
       " (0, 0.65919656),\n",
       " (1, 0.9946021),\n",
       " (0, 0.36574942),\n",
       " (0, 1.7350303),\n",
       " (0, 0.36574942),\n",
       " (0, 0.37555546),\n",
       " (0, 0.80867165),\n",
       " (0, 1.0314583),\n",
       " (1, 0.64915556),\n",
       " (0, 0.64915556),\n",
       " (3, 0.63934964),\n",
       " (0, 1.637487),\n",
       " (0, 0.65919656),\n",
       " (0, 0.65919656),\n",
       " (1, 0.65919656),\n",
       " (3, 0.84821296),\n",
       " (2, 0.89702636),\n",
       " (0, 0.65919656),\n",
       " (0, 0.36574942),\n",
       " (4, 0.64915556),\n",
       " (0, 0.85174423),\n",
       " (3, 0.85174423),\n",
       " (0, 0.85174423),\n",
       " (5, 0.63934964),\n",
       " (0, 0.65919656),\n",
       " (2, 0.65919656),\n",
       " (4, 1.0433902),\n",
       " (1, 0.65919656),\n",
       " (0, 0.65919656),\n",
       " (0, 0.65919656),\n",
       " (0, 0.65919656),\n",
       " (0, 0.63934964),\n",
       " (0, 0.65919656),\n",
       " (5, 1.0314583),\n",
       " (0, 0.65919656),\n",
       " (9, 5.009901),\n",
       " (0, 0.89702636),\n",
       " (0, 0.65919656),\n",
       " (0, 0.65919656),\n",
       " (1, 0.78790027),\n",
       " (0, 0.7729654),\n",
       " (0, 0.36574942),\n",
       " (0, 0.89702636),\n",
       " (0, 0.37555546),\n",
       " (0, 0.37555546),\n",
       " (0, 0.65919656),\n",
       " (0, 0.37555546),\n",
       " (8, 4.435337),\n",
       " (0, 0.36574942),\n",
       " (0, 0.64915556),\n",
       " (0, 0.37555546),\n",
       " (0, 0.65919656),\n",
       " (0, 0.37555546),\n",
       " (0, 0.6154955),\n",
       " (0, 0.65919656),\n",
       " (0, 0.37555546),\n",
       " (37, 5.465328),\n",
       " (0, 0.80451924),\n",
       " (0, 0.37555546),\n",
       " (0, 0.36574942),\n",
       " (0, 0.65919656),\n",
       " (0, 0.79886574),\n",
       " (1, 0.65919656),\n",
       " (0, 0.66227823),\n",
       " (1, 1.0314583),\n",
       " (0, 0.37555546),\n",
       " (0, 0.63934964),\n",
       " (1, 0.65919656),\n",
       " (2, 0.65919656),\n",
       " (0, 0.38247874),\n",
       " (0, 0.37555546),\n",
       " (1, 0.64915556),\n",
       " (0, 0.37555546),\n",
       " (0, 0.36574942),\n",
       " (0, 0.65919656),\n",
       " (0, 0.65919656),\n",
       " (2, 0.64915556),\n",
       " (0, 0.65919656),\n",
       " (0, 0.64915556),\n",
       " (0, 0.65919656),\n",
       " (1, 0.65919656),\n",
       " (1, 0.78790027),\n",
       " (0, 0.65919656),\n",
       " (0, 0.65919656),\n",
       " (0, 0.37555546),\n",
       " (2, 0.63934964),\n",
       " (2, 0.65919656),\n",
       " (2, 4.8406096),\n",
       " (0, 0.65919656),\n",
       " (0, 0.65919656),\n",
       " (1, 0.38247874),\n",
       " (0, 0.64915556),\n",
       " (8, 0.65919656),\n",
       " (0, 0.65919656),\n",
       " (12, 2.8842626),\n",
       " (4, 1.2240059),\n",
       " (0, 0.3872956),\n",
       " (0, 0.63934964),\n",
       " (2, 0.65919656),\n",
       " (0, 0.65919656),\n",
       " (0, 0.65919656),\n",
       " (0, 0.37555546),\n",
       " (0, 0.36574942),\n",
       " (0, 0.68228066),\n",
       " (0, 0.9946021),\n",
       " (0, 0.65919656),\n",
       " (4, 0.89287394),\n",
       " (0, 0.80451924),\n",
       " (0, 0.40080494),\n",
       " (0, 0.35761794),\n",
       " (0, 0.37555546),\n",
       " (3, 0.6952085),\n",
       " (0, 0.81456023),\n",
       " (0, 0.36574942),\n",
       " (0, 0.37555546),\n",
       " (0, 0.65919656),\n",
       " (0, 0.37555546),\n",
       " (3, 0.65919656),\n",
       " (1, 0.65919656),\n",
       " (0, 0.65919656),\n",
       " (0, 0.65919656),\n",
       " (0, 0.64915556),\n",
       " (0, 0.65919656),\n",
       " (2, 0.64915556),\n",
       " (0, 0.36574942),\n",
       " (0, 0.78790027),\n",
       " (0, 0.65919656),\n",
       " (2, 0.68228066),\n",
       " (1, 0.37555546),\n",
       " (0, 0.65919656),\n",
       " (4, 2.498775),\n",
       " (1, 0.65919656),\n",
       " (0, 0.65919656),\n",
       " (0, 0.65919656),\n",
       " (0, 0.36574942),\n",
       " (0, 0.65919656),\n",
       " (0, 0.63934964),\n",
       " (0, 0.37555546),\n",
       " (0, 0.37555546),\n",
       " (0, 3.517925),\n",
       " (0, 0.37555546),\n",
       " (0, 0.81456023),\n",
       " (0, 0.65919656),\n",
       " (1, 0.65919656),\n",
       " (0, 0.81812364),\n",
       " (0, 0.9059834),\n",
       " (0, 0.36574942),\n",
       " (0, 0.67055476),\n",
       " (1, 0.65919656),\n",
       " (0, 0.37925875),\n",
       " (0, 0.63934964),\n",
       " (0, 0.65919656),\n",
       " (0, 0.65919656),\n",
       " (0, 0.65919656),\n",
       " (1, 0.64915556),\n",
       " (0, 2.4868298),\n",
       " (0, 0.65919656),\n",
       " (0, 0.65919656),\n",
       " (0, 0.65919656),\n",
       " (1, 0.89702636),\n",
       " (0, 0.65919656),\n",
       " (3, 0.65919656),\n",
       " (0, 0.64915556),\n",
       " (1, 0.65919656),\n",
       " (1, 1.0433902),\n",
       " (0, 0.65919656),\n",
       " (0, 0.65919656),\n",
       " (4, 2.6144762),\n",
       " (0, 0.65919656),\n",
       " (0, 0.63934964),\n",
       " (0, 0.65919656),\n",
       " (0, 2.2280853),\n",
       " (0, 5.5968575),\n",
       " (0, 0.65919656),\n",
       " (0, 0.65919656),\n",
       " (2, 1.5562413),\n",
       " (0, 0.65919656),\n",
       " (0, 0.37555546),\n",
       " (0, 0.89702636),\n",
       " (0, 0.65919656),\n",
       " (0, 0.45058972),\n",
       " (0, 1.4269724),\n",
       " (0, 0.3872956),\n",
       " (0, 0.63934964),\n",
       " (0, 0.65919656),\n",
       " (0, 0.65919656),\n",
       " (0, 0.65919656),\n",
       " (0, 0.64915556),\n",
       " (4, 4.8406096),\n",
       " (0, 1.9969583),\n",
       " (0, 0.65919656),\n",
       " (0, 0.37555546),\n",
       " (1, 2.4207976),\n",
       " (0, 0.37555546),\n",
       " (0, 0.81871265),\n",
       " (0, 0.65919656),\n",
       " (0, 5.366849),\n",
       " (0, 0.37555546),\n",
       " (0, 0.65919656),\n",
       " (0, 0.37555546),\n",
       " (0, 0.3872956),\n",
       " (0, 0.65919656),\n",
       " (0, 0.65919656),\n",
       " (0, 0.64915556),\n",
       " (5, 0.65919656),\n",
       " (1, 2.4868298),\n",
       " (0, 0.65919656),\n",
       " (6, 0.65919656),\n",
       " (0, 0.64915556),\n",
       " (0, 0.9946021),\n",
       " (1, 0.65919656),\n",
       " (0, 0.35761794),\n",
       " (0, 0.65919656),\n",
       " (0, 0.64915556),\n",
       " (0, 0.81456023),\n",
       " (0, 0.3872956),\n",
       " (2, 1.2692877),\n",
       " (0, 0.37555546),\n",
       " (0, 0.65919656),\n",
       " (1, 0.65919656),\n",
       " (0, 0.37555546),\n",
       " (0, 0.65919656),\n",
       " (0, 0.65919656),\n",
       " (2, 0.65919656),\n",
       " (1, 1.6813252),\n",
       " (0, 0.64915556),\n",
       " (0, 0.65919656),\n",
       " (0, 0.64915556),\n",
       " (0, 0.64915556),\n",
       " (0, 5.465328),\n",
       " (0, 0.65919656),\n",
       " (1, 3.8820078),\n",
       " (0, 0.78790027),\n",
       " (0, 0.35761794),\n",
       " (2, 0.65919656),\n",
       " (0, 0.65919656),\n",
       " (3, 1.0314583),\n",
       " (0, 0.37555546),\n",
       " (0, 0.6154955),\n",
       " (0, 0.40080494),\n",
       " (0, 0.36574942),\n",
       " (0, 0.36574942),\n",
       " (1, 0.81456023),\n",
       " (1, 0.7318174),\n",
       " (0, 0.3478119),\n",
       " (1, 0.65919656),\n",
       " (0, 0.64915556),\n",
       " (0, 3.8820078),\n",
       " (0, 0.89702636),\n",
       " (4, 0.85174423),\n",
       " (0, 0.63934964),\n",
       " (0, 0.63934964),\n",
       " (1, 0.65919656),\n",
       " (1, 0.65919656),\n",
       " (0, 0.65919656),\n",
       " (0, 0.622726),\n",
       " (0, 0.622726),\n",
       " (0, 0.65919656),\n",
       " (0, 0.66227823),\n",
       " (1, 0.81456023),\n",
       " (0, 0.65919656),\n",
       " (1, 0.85174423),\n",
       " (0, 0.64915556),\n",
       " (2, 5.465328),\n",
       " (0, 0.3872956),\n",
       " (4, 1.8355654),\n",
       " (0, 0.36574942),\n",
       " (0, 4.435337),\n",
       " (1, 0.63934964),\n",
       " (0, 0.65919656),\n",
       " (1, 0.5442108),\n",
       " (0, 0.37555546),\n",
       " (0, 0.64915556),\n",
       " (1, 0.86070126),\n",
       " (0, 1.2240059),\n",
       " (0, 0.65919656),\n",
       " (0, 0.65919656),\n",
       " (5, 2.894081),\n",
       " (0, 0.65919656),\n",
       " (0, 0.85174423),\n",
       " (2, 0.65919656),\n",
       " (2, 0.9103998),\n",
       " (0, 0.8223065),\n",
       " (0, 0.65919656),\n",
       " (0, 0.81871265),\n",
       " (0, 0.37555546),\n",
       " (0, 0.40080494),\n",
       " (0, 0.37555546),\n",
       " (0, 0.37555546),\n",
       " (0, 0.65919656),\n",
       " (0, 0.65919656),\n",
       " (5, 0.89702636),\n",
       " (0, 0.64915556),\n",
       " (0, 0.65919656),\n",
       " (0, 0.65919656),\n",
       " (3, 0.7778593),\n",
       " (0, 0.65919656),\n",
       " (0, 0.37555546),\n",
       " (0, 0.65919656),\n",
       " (1, 0.65919656),\n",
       " (1, 0.64915556),\n",
       " (0, 0.63934964),\n",
       " (0, 0.65919656),\n",
       " (0, 0.37555546),\n",
       " (0, 0.65919656),\n",
       " (0, 0.37555546),\n",
       " (0, 1.0433902),\n",
       " (2, 0.65919656),\n",
       " (0, 0.65919656),\n",
       " (0, 0.7778593),\n",
       " (0, 0.38247874),\n",
       " (0, 0.65919656),\n",
       " (0, 0.37555546),\n",
       " (0, 0.65919656),\n",
       " (0, 0.65919656),\n",
       " (0, 0.63934964),\n",
       " (0, 0.9946021),\n",
       " (0, 0.65919656),\n",
       " (1, 0.86070126),\n",
       " (0, 0.65919656),\n",
       " (0, 0.37555546),\n",
       " (1, 0.65919656),\n",
       " (2, 0.65919656),\n",
       " (0, 0.65919656),\n",
       " (2, 0.65919656),\n",
       " (0, 0.65919656),\n",
       " (0, 0.65919656),\n",
       " (0, 0.65919656),\n",
       " (2, 0.64915556),\n",
       " (0, 0.65919656),\n",
       " (42, 5.465328),\n",
       " (0, 0.65919656),\n",
       " (0, 0.86070126),\n",
       " (0, 0.37555546),\n",
       " (0, 0.37555546),\n",
       " (0, 0.65919656),\n",
       " (2, 0.85174423),\n",
       " (0, 0.80867165),\n",
       " (5, 0.65919656),\n",
       " (0, 0.65919656),\n",
       " (0, 0.65919656),\n",
       " (0, 0.65919656),\n",
       " (0, 0.37555546),\n",
       " (0, 0.89702636),\n",
       " (0, 0.65919656),\n",
       " (0, 0.90838456),\n",
       " (0, 0.37555546),\n",
       " (1, 0.85174423),\n",
       " (11, 0.89287394),\n",
       " (0, 0.81456023),\n",
       " (1, 0.63934964),\n",
       " (0, 0.37555546),\n",
       " (3, 0.65919656),\n",
       " (1, 0.65919656),\n",
       " (0, 0.63934964),\n",
       " (0, 0.78790027),\n",
       " (0, 0.65919656),\n",
       " (2, 1.0314583),\n",
       " (1, 0.65919656),\n",
       " (2, 0.37555546),\n",
       " (0, 0.81812364),\n",
       " (0, 0.65919656),\n",
       " (0, 0.65919656),\n",
       " (0, 0.36574942),\n",
       " (0, 0.64915556),\n",
       " (0, 0.85174423),\n",
       " (0, 0.89287394),\n",
       " (0, 0.65919656),\n",
       " (0, 0.38247874),\n",
       " (1, 0.63934964),\n",
       " (0, 0.63934964),\n",
       " (0, 0.65919656),\n",
       " (0, 0.65919656),\n",
       " (0, 0.65919656),\n",
       " (1, 4.8406096),\n",
       " (0, 0.81871265),\n",
       " (0, 0.81871265),\n",
       " (0, 0.65919656),\n",
       " (3, 0.65919656),\n",
       " (0, 0.65919656),\n",
       " (1, 2.9060266),\n",
       " (2, 2.4207976),\n",
       " (0, 0.65919656),\n",
       " (0, 0.64915556),\n",
       " (0, 0.632767),\n",
       " (0, 0.85174423),\n",
       " (2, 0.65919656),\n",
       " (2, 0.65919656),\n",
       " (0, 0.65919656),\n",
       " (2, 0.65919656),\n",
       " (0, 0.37555546),\n",
       " (0, 0.65919656),\n",
       " (0, 0.63934964),\n",
       " (0, 0.64915556),\n",
       " (2, 0.65919656),\n",
       " (0, 0.65919656),\n",
       " (3, 0.654829),\n",
       " (0, 0.63934964),\n",
       " (0, 3.5974722),\n",
       " (2, 0.65919656),\n",
       " (0, 1.4164177),\n",
       " (3, 0.89287394),\n",
       " (1, 0.79886574),\n",
       " (0, 0.65919656),\n",
       " (0, 0.853046),\n",
       " (0, 0.89702636),\n",
       " (4, 0.5442108),\n",
       " (0, 0.37555546),\n",
       " (0, 0.65919656),\n",
       " (0, 0.65919656),\n",
       " (0, 0.85174423),\n",
       " (1, 0.65919656),\n",
       " (0, 0.65919656),\n",
       " (0, 0.46604103),\n",
       " (0, 0.6338967),\n",
       " (0, 0.36574942),\n",
       " (1, 0.65919656),\n",
       " (0, 0.37555546),\n",
       " (0, 0.37555546),\n",
       " (2, 0.65919656),\n",
       " (3, 0.89702636),\n",
       " (0, 0.65919656),\n",
       " (1, 1.6813252),\n",
       " (3, 0.65919656),\n",
       " (0, 0.65919656),\n",
       " (0, 0.65919656),\n",
       " (0, 0.65919656),\n",
       " (0, 0.63934964),\n",
       " (0, 0.7778593),\n",
       " (0, 0.65919656),\n",
       " (2, 0.67055476),\n",
       " (0, 0.65919656),\n",
       " (0, 0.65919656),\n",
       " (0, 0.36574942),\n",
       " (3, 0.64915556),\n",
       " (0, 0.65919656),\n",
       " (0, 0.65919656),\n",
       " (0, 0.65919656),\n",
       " (0, 0.65919656),\n",
       " (0, 0.65919656),\n",
       " (0, 0.65919656),\n",
       " (2, 0.76961),\n",
       " (0, 0.65919656),\n",
       " (0, 0.65919656),\n",
       " (0, 0.65919656),\n",
       " (0, 0.64915556),\n",
       " (1, 0.85174423),\n",
       " (1, 0.63934964),\n",
       " (3, 0.65919656),\n",
       " (0, 0.37555546),\n",
       " (0, 0.80293083),\n",
       " (2, 0.89702636),\n",
       " (1, 2.8280492),\n",
       " (0, 0.65919656),\n",
       " (0, 0.65919656),\n",
       " (0, 0.36574942),\n",
       " (0, 0.65919656),\n",
       " (0, 0.65919656),\n",
       " (0, 0.89702636),\n",
       " (0, 0.85174423),\n",
       " (0, 0.9351821),\n",
       " (1, 0.64915556),\n",
       " (0, 0.85174423),\n",
       " (0, 0.36574942),\n",
       " (0, 0.65919656),\n",
       " (0, 0.37748957),\n",
       " (0, 0.65919656),\n",
       " (0, 0.9763118),\n",
       " (0, 0.65919656),\n",
       " (0, 2.477011),\n",
       " (0, 0.36574942),\n",
       " (0, 0.76881295),\n",
       " (0, 0.65919656),\n",
       " (0, 0.85174423),\n",
       " (0, 0.65919656),\n",
       " (1, 3.8820078),\n",
       " (0, 0.41933557),\n",
       " (0, 1.0314583),\n",
       " (0, 0.63934964),\n",
       " (0, 0.65919656),\n",
       " (0, 1.0677499),\n",
       " (0, 0.65919656),\n",
       " (0, 0.37555546),\n",
       " (0, 0.3909989),\n",
       " (1, 0.65919656),\n",
       " (0, 0.65919656),\n",
       " (0, 0.65919656),\n",
       " (1, 1.1318482),\n",
       " (2, 0.65919656),\n",
       " (0, 0.64915556),\n",
       " (0, 0.65919656),\n",
       " (1, 5.5968575),\n",
       " (0, 0.65919656),\n",
       " (2, 0.65919656),\n",
       " (0, 0.65919656),\n",
       " (2, 0.65919656),\n",
       " (2, 0.64915556),\n",
       " (0, 0.78790027),\n",
       " (1, 0.65919656),\n",
       " (0, 0.65919656),\n",
       " (5, 0.65919656),\n",
       " (4, 0.85174423),\n",
       " (0, 0.40080494),\n",
       " (0, 0.89702636),\n",
       " (0, 0.65919656),\n",
       " (0, 0.64915556),\n",
       " (0, 0.65919656),\n",
       " (0, 0.65919656),\n",
       " (0, 0.36574942),\n",
       " (0, 0.65919656),\n",
       " (0, 0.76805335),\n",
       " (0, 0.65919656),\n",
       " (1, 0.78790027),\n",
       " (0, 0.3872956),\n",
       " (0, 0.64915556),\n",
       " (0, 0.36574942),\n",
       " (0, 0.64915556),\n",
       " (1, 0.65919656),\n",
       " (2, 0.65919656),\n",
       " (0, 0.632767),\n",
       " (0, 0.65919656),\n",
       " (0, 0.65919656),\n",
       " (12, 0.89702636),\n",
       " (0, 0.65919656),\n",
       " (0, 0.80293083),\n",
       " (3, 0.65919656),\n",
       " (0, 0.65919656),\n",
       " (0, 0.65919656),\n",
       " (0, 0.36574942),\n",
       " (0, 0.63934964),\n",
       " (1, 0.50348634),\n",
       " (0, 0.79886574),\n",
       " (1, 1.1453363),\n",
       " (0, 0.37555546),\n",
       " (0, 0.65919656),\n",
       " (0, 0.65919656),\n",
       " (0, 0.36574942),\n",
       " (0, 0.65919656),\n",
       " (0, 0.37555546),\n",
       " (0, 0.65919656),\n",
       " (0, 0.89702636),\n",
       " (0, 0.65919656),\n",
       " (0, 0.63934964),\n",
       " (0, 0.65919656),\n",
       " (0, 0.6154955),\n",
       " (0, 0.65919656),\n",
       " (0, 0.63934964),\n",
       " (0, 0.63934964),\n",
       " (2, 0.65919656),\n",
       " (0, 0.79886574),\n",
       " (0, 0.65919656),\n",
       " (0, 0.37555546),\n",
       " (0, 0.64915556),\n",
       " (0, 0.64915556),\n",
       " (0, 0.64915556),\n",
       " (0, 0.632767),\n",
       " (0, 0.63934964),\n",
       " (1, 0.65919656),\n",
       " (0, 0.65919656),\n",
       " (0, 0.64915556),\n",
       " (0, 0.65919656),\n",
       " (0, 0.65919656),\n",
       " (0, 0.64915556),\n",
       " (0, 0.65919656),\n",
       " (0, 0.6154955),\n",
       " (0, 0.40080494),\n",
       " (0, 0.65919656),\n",
       " (1, 0.37555546),\n",
       " (0, 0.65919656),\n",
       " (2, 0.85174423),\n",
       " (0, 0.3872956),\n",
       " (0, 0.65919656),\n",
       " (0, 0.64915556),\n",
       " (0, 0.65919656),\n",
       " (1, 0.65919656),\n",
       " (0, 0.37555546),\n",
       " (0, 0.65919656),\n",
       " (1, 0.65919656),\n",
       " (0, 0.64915556),\n",
       " (0, 0.65919656),\n",
       " (1, 0.65919656),\n",
       " (0, 0.65919656),\n",
       " (0, 0.40080494),\n",
       " (0, 0.65919656),\n",
       " (1, 1.4269724),\n",
       " (0, 0.64915556),\n",
       " (0, 0.68228066),\n",
       " (0, 0.37555546),\n",
       " (0, 0.65919656),\n",
       " (1, 0.64915556),\n",
       " (0, 0.65919656),\n",
       " (0, 0.65919656),\n",
       " (0, 0.36574942),\n",
       " (2, 0.81871265),\n",
       " (0, 0.3478119),\n",
       " (0, 0.65919656),\n",
       " (1, 0.64915556),\n",
       " (0, 0.36574942),\n",
       " (1, 0.89702636),\n",
       " (0, 0.63934964),\n",
       " (0, 0.89702636),\n",
       " (1, 0.65919656),\n",
       " (1, 0.65919656),\n",
       " (0, 0.36574942),\n",
       " (2, 0.85174423),\n",
       " (1, 0.65919656),\n",
       " (0, 0.84821296),\n",
       " (0, 0.37555546),\n",
       " (2, 0.65919656),\n",
       " (0, 0.65919656),\n",
       " (0, 0.4291416),\n",
       " (0, 0.85174423),\n",
       " (0, 0.36574942),\n",
       " (0, 0.65919656),\n",
       " (0, 0.65919656),\n",
       " (0, 0.65919656),\n",
       " (3, 0.8787479),\n",
       " (0, 0.65919656),\n",
       " (0, 0.64915556),\n",
       " (0, 0.63934964),\n",
       " (0, 0.37555546),\n",
       " (0, 0.65919656),\n",
       " (0, 0.40080494),\n",
       " (0, 0.3872956),\n",
       " (0, 0.85174423),\n",
       " (0, 0.65919656),\n",
       " (1, 0.8475918),\n",
       " (2, 0.63934964),\n",
       " (0, 7.3232374),\n",
       " (0, 0.65919656),\n",
       " (0, 0.4291416),\n",
       " (0, 0.64915556),\n",
       " (0, 0.65919656),\n",
       " (0, 0.65919656),\n",
       " (3, 0.65919656),\n",
       " (1, 0.65919656),\n",
       " (0, 0.36574942),\n",
       " (0, 0.65919656),\n",
       " (0, 0.8475918),\n",
       " (0, 0.85174423),\n",
       " (0, 0.64915556),\n",
       " (0, 0.64915556),\n",
       " (0, 0.65919656),\n",
       " (1, 0.83211243),\n",
       " (0, 0.65919656),\n",
       " (0, 0.37555546),\n",
       " (1, 0.66227823),\n",
       " (0, 0.64915556),\n",
       " (0, 0.65919656),\n",
       " (0, 0.65919656),\n",
       " (2, 0.853046),\n",
       " (0, 0.63934964),\n",
       " (3, 0.65919656),\n",
       " (0, 0.65919656),\n",
       " (1, 0.65919656),\n",
       " (0, 0.65919656),\n",
       " (1, 0.68228066),\n",
       " (0, 0.65919656),\n",
       " (0, 0.36574942),\n",
       " (2, 0.65919656),\n",
       " (19, 0.85174423),\n",
       " (0, 0.36574942),\n",
       " (0, 0.6338967),\n",
       " (0, 3.517925),\n",
       " (0, 0.65919656),\n",
       " (1, 0.85174423),\n",
       " (0, 0.65919656),\n",
       " (0, 0.36574942),\n",
       " (0, 0.65919656),\n",
       " (1, 3.8820078),\n",
       " (0, 0.37555546),\n",
       " (0, 0.85174423),\n",
       " (0, 0.9804642),\n",
       " (3, 0.64915556),\n",
       " (0, 0.64915556),\n",
       " (0, 0.65919656),\n",
       " (0, 0.65919656),\n",
       " (0, 0.37555546),\n",
       " (1, 0.65919656),\n",
       " (0, 0.65919656)]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_list = list(predicoes_yc)\n",
    "test_list = list(yc_test)\n",
    "complist = []\n",
    "for i in range(len(test_list)):\n",
    "    complist.append((test_list[i], pred_list[i]))\n",
    "complist"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
