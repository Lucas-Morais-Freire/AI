{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning para Previsão de Taxas de Qualis de Professores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliotecas Importadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import warnings as wrn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importação de Bibliotecas de Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import balanced_accuracy_score, roc_auc_score, make_scorer\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importação de Bibliotecas de Otimização de Hiperparâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Integer, Categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leitura e Seleção de Colunas do Arquivo CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>siape</th>\n",
       "      <th>sexo</th>\n",
       "      <th>formacao</th>\n",
       "      <th>tipo_jornada_trabalho</th>\n",
       "      <th>vinculo</th>\n",
       "      <th>lotacao</th>\n",
       "      <th>admissao</th>\n",
       "      <th>categoria</th>\n",
       "      <th>classe_funcional</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1543339</td>\n",
       "      <td>F</td>\n",
       "      <td>MESTRADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Ativo Permanente</td>\n",
       "      <td>NÚCLEO DE EDUCAÇÃO DA INFÂNCIA</td>\n",
       "      <td>2006/07/24 00:00:00.000000000</td>\n",
       "      <td>PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO</td>\n",
       "      <td>DIV                                           ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1554468</td>\n",
       "      <td>M</td>\n",
       "      <td>DOUTORADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Ativo Permanente</td>\n",
       "      <td>ESCOLA AGRÍCOLA DE JUNDIAÍ</td>\n",
       "      <td>2008/09/12 00:00:00.000000000</td>\n",
       "      <td>PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO</td>\n",
       "      <td>DV                                            ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1177821</td>\n",
       "      <td>M</td>\n",
       "      <td>MESTRADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Ativo Permanente</td>\n",
       "      <td>ESCOLA DE MÚSICA</td>\n",
       "      <td>1998/04/28 00:00:00.000000000</td>\n",
       "      <td>PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO</td>\n",
       "      <td>DIV                                           ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2360824</td>\n",
       "      <td>M</td>\n",
       "      <td>MESTRADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Ativo Permanente</td>\n",
       "      <td>ESCOLA AGRÍCOLA DE JUNDIAÍ</td>\n",
       "      <td>2017/01/25 00:00:00.000000000</td>\n",
       "      <td>PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO</td>\n",
       "      <td>DIII                                          ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2364334</td>\n",
       "      <td>F</td>\n",
       "      <td>DOUTORADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Ativo Permanente</td>\n",
       "      <td>ESCOLA AGRÍCOLA DE JUNDIAÍ</td>\n",
       "      <td>2009/10/13 00:00:00.000000000</td>\n",
       "      <td>PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO</td>\n",
       "      <td>DIV                                           ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2765</th>\n",
       "      <td>4246363</td>\n",
       "      <td>M</td>\n",
       "      <td>DOUTORADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Professor Visitante</td>\n",
       "      <td>INSTITUTO DE POLÍTICAS PÚBLICAS</td>\n",
       "      <td>2023/05/23 00:00:00.000000000</td>\n",
       "      <td>PROFESSOR MAGISTERIO SUPERIOR - VISITANTE</td>\n",
       "      <td>Adjunto                                       ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2766</th>\n",
       "      <td>3304576</td>\n",
       "      <td>M</td>\n",
       "      <td>DOUTORADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Professor Visitante</td>\n",
       "      <td>ESCOLA DE CIÊNCIAS E TECNOLOGIA</td>\n",
       "      <td>2022/08/12 00:00:00.000000000</td>\n",
       "      <td>PROFESSOR MAGISTERIO SUPERIOR - VISITANTE</td>\n",
       "      <td>Titular                                       ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2767</th>\n",
       "      <td>1056188</td>\n",
       "      <td>M</td>\n",
       "      <td>DOUTORADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Professor Visitante</td>\n",
       "      <td>DEPARTAMENTO DE BIOLOGIA CELULAR E GENÉTICA</td>\n",
       "      <td>2022/10/03 00:00:00.000000000</td>\n",
       "      <td>PROFESSOR MAGISTERIO SUPERIOR - VISITANTE</td>\n",
       "      <td>A                                             ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2768</th>\n",
       "      <td>3330361</td>\n",
       "      <td>F</td>\n",
       "      <td>DOUTORADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Professor Visitante</td>\n",
       "      <td>INSTITUTO METROPOLE DIGITAL</td>\n",
       "      <td>2023/02/15 00:00:00.000000000</td>\n",
       "      <td>PROFESSOR MAGISTERIO SUPERIOR - VISITANTE</td>\n",
       "      <td>A                                             ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2769</th>\n",
       "      <td>3309092</td>\n",
       "      <td>M</td>\n",
       "      <td>DOUTORADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Professor Visitante</td>\n",
       "      <td>DEPARTAMENTO DE GEOFÍSICA</td>\n",
       "      <td>2022/09/06 00:00:00.000000000</td>\n",
       "      <td>PROFESSOR MAGISTERIO SUPERIOR - VISITANTE</td>\n",
       "      <td>Titular                                       ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2770 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        siape sexo   formacao           tipo_jornada_trabalho  \\\n",
       "0     1543339    F   MESTRADO  Dedicação exclusiva              \n",
       "1     1554468    M  DOUTORADO  Dedicação exclusiva              \n",
       "2     1177821    M   MESTRADO  Dedicação exclusiva              \n",
       "3     2360824    M   MESTRADO  Dedicação exclusiva              \n",
       "4     2364334    F  DOUTORADO  Dedicação exclusiva              \n",
       "...       ...  ...        ...                             ...   \n",
       "2765  4246363    M  DOUTORADO  Dedicação exclusiva              \n",
       "2766  3304576    M  DOUTORADO  Dedicação exclusiva              \n",
       "2767  1056188    M  DOUTORADO  Dedicação exclusiva              \n",
       "2768  3330361    F  DOUTORADO  Dedicação exclusiva              \n",
       "2769  3309092    M  DOUTORADO  Dedicação exclusiva              \n",
       "\n",
       "                  vinculo                                      lotacao  \\\n",
       "0        Ativo Permanente               NÚCLEO DE EDUCAÇÃO DA INFÂNCIA   \n",
       "1        Ativo Permanente                   ESCOLA AGRÍCOLA DE JUNDIAÍ   \n",
       "2        Ativo Permanente                             ESCOLA DE MÚSICA   \n",
       "3        Ativo Permanente                   ESCOLA AGRÍCOLA DE JUNDIAÍ   \n",
       "4        Ativo Permanente                   ESCOLA AGRÍCOLA DE JUNDIAÍ   \n",
       "...                   ...                                          ...   \n",
       "2765  Professor Visitante              INSTITUTO DE POLÍTICAS PÚBLICAS   \n",
       "2766  Professor Visitante              ESCOLA DE CIÊNCIAS E TECNOLOGIA   \n",
       "2767  Professor Visitante  DEPARTAMENTO DE BIOLOGIA CELULAR E GENÉTICA   \n",
       "2768  Professor Visitante                  INSTITUTO METROPOLE DIGITAL   \n",
       "2769  Professor Visitante                    DEPARTAMENTO DE GEOFÍSICA   \n",
       "\n",
       "                           admissao  \\\n",
       "0     2006/07/24 00:00:00.000000000   \n",
       "1     2008/09/12 00:00:00.000000000   \n",
       "2     1998/04/28 00:00:00.000000000   \n",
       "3     2017/01/25 00:00:00.000000000   \n",
       "4     2009/10/13 00:00:00.000000000   \n",
       "...                             ...   \n",
       "2765  2023/05/23 00:00:00.000000000   \n",
       "2766  2022/08/12 00:00:00.000000000   \n",
       "2767  2022/10/03 00:00:00.000000000   \n",
       "2768  2023/02/15 00:00:00.000000000   \n",
       "2769  2022/09/06 00:00:00.000000000   \n",
       "\n",
       "                                             categoria  \\\n",
       "0     PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO   \n",
       "1     PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO   \n",
       "2     PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO   \n",
       "3     PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO   \n",
       "4     PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO   \n",
       "...                                                ...   \n",
       "2765         PROFESSOR MAGISTERIO SUPERIOR - VISITANTE   \n",
       "2766         PROFESSOR MAGISTERIO SUPERIOR - VISITANTE   \n",
       "2767         PROFESSOR MAGISTERIO SUPERIOR - VISITANTE   \n",
       "2768         PROFESSOR MAGISTERIO SUPERIOR - VISITANTE   \n",
       "2769         PROFESSOR MAGISTERIO SUPERIOR - VISITANTE   \n",
       "\n",
       "                                       classe_funcional  \n",
       "0     DIV                                           ...  \n",
       "1     DV                                            ...  \n",
       "2     DIV                                           ...  \n",
       "3     DIII                                          ...  \n",
       "4     DIV                                           ...  \n",
       "...                                                 ...  \n",
       "2765  Adjunto                                       ...  \n",
       "2766  Titular                                       ...  \n",
       "2767  A                                             ...  \n",
       "2768  A                                             ...  \n",
       "2769  Titular                                       ...  \n",
       "\n",
       "[2770 rows x 9 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# selecionar atributos dos professores que sao de interesse\n",
    "\n",
    "tp_cols = [\"siape\", \"sexo\", \"formacao\", \"tipo_jornada_trabalho\",\n",
    "           \"vinculo\", \"lotacao\", \"admissao\", \"categoria\",\n",
    "           \"classe_funcional\"]\n",
    "\n",
    "tp_df = pd.read_csv(\"./perfis/docentes.csv\", sep=\";\")\n",
    "tp_df = tp_df[tp_cols]\n",
    "\n",
    "tp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tipos de Dados das Colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "siape                     int64\n",
       "sexo                     object\n",
       "formacao                 object\n",
       "tipo_jornada_trabalho    object\n",
       "vinculo                  object\n",
       "lotacao                  object\n",
       "admissao                 object\n",
       "categoria                object\n",
       "classe_funcional         object\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resumo Estatístico do DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>siape</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.770000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.114588e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.142222e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.274600e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.297595e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.810985e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.722937e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.350807e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              siape\n",
       "count  2.770000e+03\n",
       "mean   2.114588e+06\n",
       "std    1.142222e+06\n",
       "min    1.274600e+04\n",
       "25%    1.297595e+06\n",
       "50%    1.810985e+06\n",
       "75%    2.722937e+06\n",
       "max    9.350807e+06"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparação dos Dados de Qualis das Revistas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>siape</th>\n",
       "      <th>revista_a1</th>\n",
       "      <th>revista_a2</th>\n",
       "      <th>revista_b1</th>\n",
       "      <th>revista_b2</th>\n",
       "      <th>revista_b3</th>\n",
       "      <th>revista_b4</th>\n",
       "      <th>revista_b5</th>\n",
       "      <th>revista_c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.756000e+03</td>\n",
       "      <td>2756.000000</td>\n",
       "      <td>2756.000000</td>\n",
       "      <td>2756.000000</td>\n",
       "      <td>2756.000000</td>\n",
       "      <td>2756.000000</td>\n",
       "      <td>2756.000000</td>\n",
       "      <td>2756.000000</td>\n",
       "      <td>2756.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.112227e+06</td>\n",
       "      <td>2.634978</td>\n",
       "      <td>1.933599</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>1.269231</td>\n",
       "      <td>0.818215</td>\n",
       "      <td>0.568578</td>\n",
       "      <td>0.054790</td>\n",
       "      <td>0.889332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.137681e+06</td>\n",
       "      <td>6.073799</td>\n",
       "      <td>3.917333</td>\n",
       "      <td>5.375914</td>\n",
       "      <td>2.891393</td>\n",
       "      <td>2.413658</td>\n",
       "      <td>1.778480</td>\n",
       "      <td>0.330389</td>\n",
       "      <td>3.855806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.274600e+04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.296285e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.808676e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.721404e+06</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.350807e+06</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>124.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              siape   revista_a1   revista_a2   revista_b1   revista_b2  \\\n",
       "count  2.756000e+03  2756.000000  2756.000000  2756.000000  2756.000000   \n",
       "mean   2.112227e+06     2.634978     1.933599     1.750000     1.269231   \n",
       "std    1.137681e+06     6.073799     3.917333     5.375914     2.891393   \n",
       "min    1.274600e+04     0.000000     0.000000     0.000000     0.000000   \n",
       "25%    1.296285e+06     0.000000     0.000000     0.000000     0.000000   \n",
       "50%    1.808676e+06     0.000000     0.000000     0.000000     0.000000   \n",
       "75%    2.721404e+06     3.000000     2.000000     2.000000     1.000000   \n",
       "max    9.350807e+06    71.000000    51.000000    99.000000    46.000000   \n",
       "\n",
       "        revista_b3   revista_b4   revista_b5    revista_c  \n",
       "count  2756.000000  2756.000000  2756.000000  2756.000000  \n",
       "mean      0.818215     0.568578     0.054790     0.889332  \n",
       "std       2.413658     1.778480     0.330389     3.855806  \n",
       "min       0.000000     0.000000     0.000000     0.000000  \n",
       "25%       0.000000     0.000000     0.000000     0.000000  \n",
       "50%       0.000000     0.000000     0.000000     0.000000  \n",
       "75%       1.000000     0.000000     0.000000     1.000000  \n",
       "max      41.000000    32.000000     8.000000   124.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# selecionar atributos que desejamos prever. o siape é incluso para unir as tabelas.\n",
    "\n",
    "qualis = [\"siape\", \"revista_a1\", \"revista_a2\", \"revista_b1\",\n",
    "          \"revista_b2\", \"revista_b3\", \"revista_b4\", \"revista_b5\", \"revista_c\"]\n",
    "\n",
    "ti_df_list = []\n",
    "for year in range(2010, 2021):\n",
    "    ti_df_y = pd.read_csv(\n",
    "        \"./indicadores/indicadores-pesquisa-\" + str(year) + \".csv\", sep=\";\")\n",
    "    ti_df_y = ti_df_y[qualis]\n",
    "    ti_df_list.append(ti_df_y)\n",
    "\n",
    "ti_df = pd.concat(ti_df_list)\n",
    "ti_df = ti_df.groupby(\"siape\", as_index=False).sum()\n",
    "ti_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fusão de Dados e Remoção da Coluna \"siape\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sexo</th>\n",
       "      <th>formacao</th>\n",
       "      <th>tipo_jornada_trabalho</th>\n",
       "      <th>vinculo</th>\n",
       "      <th>lotacao</th>\n",
       "      <th>admissao</th>\n",
       "      <th>categoria</th>\n",
       "      <th>classe_funcional</th>\n",
       "      <th>revista_a1</th>\n",
       "      <th>revista_a2</th>\n",
       "      <th>revista_b1</th>\n",
       "      <th>revista_b2</th>\n",
       "      <th>revista_b3</th>\n",
       "      <th>revista_b4</th>\n",
       "      <th>revista_b5</th>\n",
       "      <th>revista_c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F</td>\n",
       "      <td>MESTRADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Ativo Permanente</td>\n",
       "      <td>NÚCLEO DE EDUCAÇÃO DA INFÂNCIA</td>\n",
       "      <td>2006/07/24 00:00:00.000000000</td>\n",
       "      <td>PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO</td>\n",
       "      <td>DIV                                           ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>DOUTORADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Ativo Permanente</td>\n",
       "      <td>ESCOLA AGRÍCOLA DE JUNDIAÍ</td>\n",
       "      <td>2008/09/12 00:00:00.000000000</td>\n",
       "      <td>PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO</td>\n",
       "      <td>DV                                            ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "      <td>MESTRADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Ativo Permanente</td>\n",
       "      <td>ESCOLA DE MÚSICA</td>\n",
       "      <td>1998/04/28 00:00:00.000000000</td>\n",
       "      <td>PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO</td>\n",
       "      <td>DIV                                           ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>MESTRADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Ativo Permanente</td>\n",
       "      <td>ESCOLA AGRÍCOLA DE JUNDIAÍ</td>\n",
       "      <td>2017/01/25 00:00:00.000000000</td>\n",
       "      <td>PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO</td>\n",
       "      <td>DIII                                          ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F</td>\n",
       "      <td>DOUTORADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Ativo Permanente</td>\n",
       "      <td>ESCOLA AGRÍCOLA DE JUNDIAÍ</td>\n",
       "      <td>2009/10/13 00:00:00.000000000</td>\n",
       "      <td>PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO</td>\n",
       "      <td>DIV                                           ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2748</th>\n",
       "      <td>M</td>\n",
       "      <td>DOUTORADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Professor Visitante</td>\n",
       "      <td>INSTITUTO DE POLÍTICAS PÚBLICAS</td>\n",
       "      <td>2023/05/23 00:00:00.000000000</td>\n",
       "      <td>PROFESSOR MAGISTERIO SUPERIOR - VISITANTE</td>\n",
       "      <td>Adjunto                                       ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2749</th>\n",
       "      <td>M</td>\n",
       "      <td>DOUTORADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Professor Visitante</td>\n",
       "      <td>ESCOLA DE CIÊNCIAS E TECNOLOGIA</td>\n",
       "      <td>2022/08/12 00:00:00.000000000</td>\n",
       "      <td>PROFESSOR MAGISTERIO SUPERIOR - VISITANTE</td>\n",
       "      <td>Titular                                       ...</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2750</th>\n",
       "      <td>M</td>\n",
       "      <td>DOUTORADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Professor Visitante</td>\n",
       "      <td>DEPARTAMENTO DE BIOLOGIA CELULAR E GENÉTICA</td>\n",
       "      <td>2022/10/03 00:00:00.000000000</td>\n",
       "      <td>PROFESSOR MAGISTERIO SUPERIOR - VISITANTE</td>\n",
       "      <td>A                                             ...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2751</th>\n",
       "      <td>F</td>\n",
       "      <td>DOUTORADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Professor Visitante</td>\n",
       "      <td>INSTITUTO METROPOLE DIGITAL</td>\n",
       "      <td>2023/02/15 00:00:00.000000000</td>\n",
       "      <td>PROFESSOR MAGISTERIO SUPERIOR - VISITANTE</td>\n",
       "      <td>A                                             ...</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2752</th>\n",
       "      <td>M</td>\n",
       "      <td>DOUTORADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Professor Visitante</td>\n",
       "      <td>DEPARTAMENTO DE GEOFÍSICA</td>\n",
       "      <td>2022/09/06 00:00:00.000000000</td>\n",
       "      <td>PROFESSOR MAGISTERIO SUPERIOR - VISITANTE</td>\n",
       "      <td>Titular                                       ...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2753 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sexo   formacao           tipo_jornada_trabalho              vinculo  \\\n",
       "0       F   MESTRADO  Dedicação exclusiva                Ativo Permanente   \n",
       "1       M  DOUTORADO  Dedicação exclusiva                Ativo Permanente   \n",
       "2       M   MESTRADO  Dedicação exclusiva                Ativo Permanente   \n",
       "3       M   MESTRADO  Dedicação exclusiva                Ativo Permanente   \n",
       "4       F  DOUTORADO  Dedicação exclusiva                Ativo Permanente   \n",
       "...   ...        ...                             ...                  ...   \n",
       "2748    M  DOUTORADO  Dedicação exclusiva             Professor Visitante   \n",
       "2749    M  DOUTORADO  Dedicação exclusiva             Professor Visitante   \n",
       "2750    M  DOUTORADO  Dedicação exclusiva             Professor Visitante   \n",
       "2751    F  DOUTORADO  Dedicação exclusiva             Professor Visitante   \n",
       "2752    M  DOUTORADO  Dedicação exclusiva             Professor Visitante   \n",
       "\n",
       "                                          lotacao  \\\n",
       "0                  NÚCLEO DE EDUCAÇÃO DA INFÂNCIA   \n",
       "1                      ESCOLA AGRÍCOLA DE JUNDIAÍ   \n",
       "2                                ESCOLA DE MÚSICA   \n",
       "3                      ESCOLA AGRÍCOLA DE JUNDIAÍ   \n",
       "4                      ESCOLA AGRÍCOLA DE JUNDIAÍ   \n",
       "...                                           ...   \n",
       "2748              INSTITUTO DE POLÍTICAS PÚBLICAS   \n",
       "2749              ESCOLA DE CIÊNCIAS E TECNOLOGIA   \n",
       "2750  DEPARTAMENTO DE BIOLOGIA CELULAR E GENÉTICA   \n",
       "2751                  INSTITUTO METROPOLE DIGITAL   \n",
       "2752                    DEPARTAMENTO DE GEOFÍSICA   \n",
       "\n",
       "                           admissao  \\\n",
       "0     2006/07/24 00:00:00.000000000   \n",
       "1     2008/09/12 00:00:00.000000000   \n",
       "2     1998/04/28 00:00:00.000000000   \n",
       "3     2017/01/25 00:00:00.000000000   \n",
       "4     2009/10/13 00:00:00.000000000   \n",
       "...                             ...   \n",
       "2748  2023/05/23 00:00:00.000000000   \n",
       "2749  2022/08/12 00:00:00.000000000   \n",
       "2750  2022/10/03 00:00:00.000000000   \n",
       "2751  2023/02/15 00:00:00.000000000   \n",
       "2752  2022/09/06 00:00:00.000000000   \n",
       "\n",
       "                                             categoria  \\\n",
       "0     PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO   \n",
       "1     PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO   \n",
       "2     PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO   \n",
       "3     PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO   \n",
       "4     PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO   \n",
       "...                                                ...   \n",
       "2748         PROFESSOR MAGISTERIO SUPERIOR - VISITANTE   \n",
       "2749         PROFESSOR MAGISTERIO SUPERIOR - VISITANTE   \n",
       "2750         PROFESSOR MAGISTERIO SUPERIOR - VISITANTE   \n",
       "2751         PROFESSOR MAGISTERIO SUPERIOR - VISITANTE   \n",
       "2752         PROFESSOR MAGISTERIO SUPERIOR - VISITANTE   \n",
       "\n",
       "                                       classe_funcional  revista_a1  \\\n",
       "0     DIV                                           ...           0   \n",
       "1     DV                                            ...           1   \n",
       "2     DIV                                           ...           0   \n",
       "3     DIII                                          ...           0   \n",
       "4     DIV                                           ...           0   \n",
       "...                                                 ...         ...   \n",
       "2748  Adjunto                                       ...           0   \n",
       "2749  Titular                                       ...           8   \n",
       "2750  A                                             ...           4   \n",
       "2751  A                                             ...          44   \n",
       "2752  Titular                                       ...           4   \n",
       "\n",
       "      revista_a2  revista_b1  revista_b2  revista_b3  revista_b4  revista_b5  \\\n",
       "0              0           0           0           0           0           0   \n",
       "1              1           5           0           0           4           0   \n",
       "2              0           0           0           0           0           0   \n",
       "3              0           0           0           0           0           0   \n",
       "4              0           0           1           0           0           0   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "2748           0           0           1           0           0           0   \n",
       "2749           4           7           0           2           0           0   \n",
       "2750           2           5           0           0           0           0   \n",
       "2751           1           0           0           0           0           0   \n",
       "2752           0           0           0           0           0           0   \n",
       "\n",
       "      revista_c  \n",
       "0             0  \n",
       "1             0  \n",
       "2             0  \n",
       "3             0  \n",
       "4             0  \n",
       "...         ...  \n",
       "2748          1  \n",
       "2749          0  \n",
       "2750          0  \n",
       "2751          0  \n",
       "2752          0  \n",
       "\n",
       "[2753 rows x 16 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unir ambas as tabelas e manter apenas as entradas que possuem siapes em comum\n",
    "\n",
    "df = tp_df.merge(ti_df, on=\"siape\", how=\"inner\")\n",
    "del df[\"siape\"]\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OPA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mappingSex = {\"F\": 0, \"M\": 1}\n",
    "df[\"sexo\"] = df[\"sexo\"].replace(mappingSex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 1269\n",
      "1: 1484\n"
     ]
    }
   ],
   "source": [
    "for sexo in df[\"sexo\"].unique():\n",
    "    print(sexo, \": \", len(df[df[\"sexo\"] == sexo]), sep=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cálculo dos Semestres na Universidade e Seleção de Colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sexo</th>\n",
       "      <th>formacao</th>\n",
       "      <th>tipo_jornada_trabalho</th>\n",
       "      <th>vinculo</th>\n",
       "      <th>categoria</th>\n",
       "      <th>classe_funcional</th>\n",
       "      <th>lotacao</th>\n",
       "      <th>num_semestres</th>\n",
       "      <th>revista_a1</th>\n",
       "      <th>revista_a2</th>\n",
       "      <th>revista_b1</th>\n",
       "      <th>revista_b2</th>\n",
       "      <th>revista_b3</th>\n",
       "      <th>revista_b4</th>\n",
       "      <th>revista_c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>MESTRADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Ativo Permanente</td>\n",
       "      <td>PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO</td>\n",
       "      <td>DIV                                           ...</td>\n",
       "      <td>NÚCLEO DE EDUCAÇÃO DA INFÂNCIA</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>DOUTORADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Ativo Permanente</td>\n",
       "      <td>PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO</td>\n",
       "      <td>DV                                            ...</td>\n",
       "      <td>ESCOLA AGRÍCOLA DE JUNDIAÍ</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>MESTRADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Ativo Permanente</td>\n",
       "      <td>PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO</td>\n",
       "      <td>DIV                                           ...</td>\n",
       "      <td>ESCOLA DE MÚSICA</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>MESTRADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Ativo Permanente</td>\n",
       "      <td>PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO</td>\n",
       "      <td>DIII                                          ...</td>\n",
       "      <td>ESCOLA AGRÍCOLA DE JUNDIAÍ</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>DOUTORADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Ativo Permanente</td>\n",
       "      <td>PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO</td>\n",
       "      <td>DIV                                           ...</td>\n",
       "      <td>ESCOLA AGRÍCOLA DE JUNDIAÍ</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2748</th>\n",
       "      <td>1</td>\n",
       "      <td>DOUTORADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Professor Visitante</td>\n",
       "      <td>PROFESSOR MAGISTERIO SUPERIOR - VISITANTE</td>\n",
       "      <td>Adjunto                                       ...</td>\n",
       "      <td>INSTITUTO DE POLÍTICAS PÚBLICAS</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2749</th>\n",
       "      <td>1</td>\n",
       "      <td>DOUTORADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Professor Visitante</td>\n",
       "      <td>PROFESSOR MAGISTERIO SUPERIOR - VISITANTE</td>\n",
       "      <td>Titular                                       ...</td>\n",
       "      <td>ESCOLA DE CIÊNCIAS E TECNOLOGIA</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2750</th>\n",
       "      <td>1</td>\n",
       "      <td>DOUTORADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Professor Visitante</td>\n",
       "      <td>PROFESSOR MAGISTERIO SUPERIOR - VISITANTE</td>\n",
       "      <td>A                                             ...</td>\n",
       "      <td>DEPARTAMENTO DE BIOLOGIA CELULAR E GENÉTICA</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2751</th>\n",
       "      <td>0</td>\n",
       "      <td>DOUTORADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Professor Visitante</td>\n",
       "      <td>PROFESSOR MAGISTERIO SUPERIOR - VISITANTE</td>\n",
       "      <td>A                                             ...</td>\n",
       "      <td>INSTITUTO METROPOLE DIGITAL</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2752</th>\n",
       "      <td>1</td>\n",
       "      <td>DOUTORADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Professor Visitante</td>\n",
       "      <td>PROFESSOR MAGISTERIO SUPERIOR - VISITANTE</td>\n",
       "      <td>Titular                                       ...</td>\n",
       "      <td>DEPARTAMENTO DE GEOFÍSICA</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2753 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sexo   formacao           tipo_jornada_trabalho              vinculo  \\\n",
       "0        0   MESTRADO  Dedicação exclusiva                Ativo Permanente   \n",
       "1        1  DOUTORADO  Dedicação exclusiva                Ativo Permanente   \n",
       "2        1   MESTRADO  Dedicação exclusiva                Ativo Permanente   \n",
       "3        1   MESTRADO  Dedicação exclusiva                Ativo Permanente   \n",
       "4        0  DOUTORADO  Dedicação exclusiva                Ativo Permanente   \n",
       "...    ...        ...                             ...                  ...   \n",
       "2748     1  DOUTORADO  Dedicação exclusiva             Professor Visitante   \n",
       "2749     1  DOUTORADO  Dedicação exclusiva             Professor Visitante   \n",
       "2750     1  DOUTORADO  Dedicação exclusiva             Professor Visitante   \n",
       "2751     0  DOUTORADO  Dedicação exclusiva             Professor Visitante   \n",
       "2752     1  DOUTORADO  Dedicação exclusiva             Professor Visitante   \n",
       "\n",
       "                                             categoria  \\\n",
       "0     PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO   \n",
       "1     PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO   \n",
       "2     PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO   \n",
       "3     PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO   \n",
       "4     PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO   \n",
       "...                                                ...   \n",
       "2748         PROFESSOR MAGISTERIO SUPERIOR - VISITANTE   \n",
       "2749         PROFESSOR MAGISTERIO SUPERIOR - VISITANTE   \n",
       "2750         PROFESSOR MAGISTERIO SUPERIOR - VISITANTE   \n",
       "2751         PROFESSOR MAGISTERIO SUPERIOR - VISITANTE   \n",
       "2752         PROFESSOR MAGISTERIO SUPERIOR - VISITANTE   \n",
       "\n",
       "                                       classe_funcional  \\\n",
       "0     DIV                                           ...   \n",
       "1     DV                                            ...   \n",
       "2     DIV                                           ...   \n",
       "3     DIII                                          ...   \n",
       "4     DIV                                           ...   \n",
       "...                                                 ...   \n",
       "2748  Adjunto                                       ...   \n",
       "2749  Titular                                       ...   \n",
       "2750  A                                             ...   \n",
       "2751  A                                             ...   \n",
       "2752  Titular                                       ...   \n",
       "\n",
       "                                          lotacao  num_semestres  revista_a1  \\\n",
       "0                  NÚCLEO DE EDUCAÇÃO DA INFÂNCIA             34           0   \n",
       "1                      ESCOLA AGRÍCOLA DE JUNDIAÍ             30           1   \n",
       "2                                ESCOLA DE MÚSICA             51           0   \n",
       "3                      ESCOLA AGRÍCOLA DE JUNDIAÍ             13           0   \n",
       "4                      ESCOLA AGRÍCOLA DE JUNDIAÍ             28           0   \n",
       "...                                           ...            ...         ...   \n",
       "2748              INSTITUTO DE POLÍTICAS PÚBLICAS              1           0   \n",
       "2749              ESCOLA DE CIÊNCIAS E TECNOLOGIA              2           8   \n",
       "2750  DEPARTAMENTO DE BIOLOGIA CELULAR E GENÉTICA              2           4   \n",
       "2751                  INSTITUTO METROPOLE DIGITAL              1          44   \n",
       "2752                    DEPARTAMENTO DE GEOFÍSICA              2           4   \n",
       "\n",
       "      revista_a2  revista_b1  revista_b2  revista_b3  revista_b4  revista_c  \n",
       "0              0           0           0           0           0          0  \n",
       "1              1           5           0           0           4          0  \n",
       "2              0           0           0           0           0          0  \n",
       "3              0           0           0           0           0          0  \n",
       "4              0           0           1           0           0          0  \n",
       "...          ...         ...         ...         ...         ...        ...  \n",
       "2748           0           0           1           0           0          1  \n",
       "2749           4           7           0           2           0          0  \n",
       "2750           2           5           0           0           0          0  \n",
       "2751           1           0           0           0           0          0  \n",
       "2752           0           0           0           0           0          0  \n",
       "\n",
       "[2753 rows x 15 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converter a data de admissao para quantos semestres o professor está na universidade.\n",
    "\n",
    "def num_semestres(data: str, data_atual: str):\n",
    "    data = data[:10]\n",
    "    anos = int(data_atual[6:]) - int(data[:4])\n",
    "    if int(data_atual[3:5]) < 7 and int(data[5:7]) < 7 or int(data_atual[3:5]) >= 7 and int(data[5:7]) >= 7:\n",
    "        return 2*anos\n",
    "    elif int(data_atual[3:5]) < 7 and int(data[5:7]) > 7:\n",
    "        return 2*anos - 1\n",
    "    else:\n",
    "        return 2*anos + 1\n",
    "\n",
    "data_atual = \"18/10/2023\"\n",
    "\n",
    "df['num_semestres'] = df['admissao'].apply(lambda x: num_semestres(x, data_atual))\n",
    "df = df[[\"sexo\", \"formacao\", \"tipo_jornada_trabalho\", \"vinculo\", \"categoria\",\"classe_funcional\", \"lotacao\", \"num_semestres\", \"revista_a1\",\n",
    "         \"revista_a2\", \"revista_b1\", \"revista_b2\", \"revista_b3\", \"revista_b4\", \"revista_c\"]]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tipos de Dados das Colunas do DataFrame Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sexo                      int64\n",
       "formacao                 object\n",
       "tipo_jornada_trabalho    object\n",
       "vinculo                  object\n",
       "categoria                object\n",
       "classe_funcional         object\n",
       "lotacao                  object\n",
       "num_semestres             int64\n",
       "revista_a1                int64\n",
       "revista_a2                int64\n",
       "revista_b1                int64\n",
       "revista_b2                int64\n",
       "revista_b3                int64\n",
       "revista_b4                int64\n",
       "revista_c                 int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise de Dados no DataFrame Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "existem 2753 entradas diferentes;\n",
      "existem 6 formacoes diferentes;\n",
      "existem 3 tipos de jornada de trabalho diferentes;\n",
      "existem 8 tipos de vinculo diferentes;\n",
      "existem 18 classes funcionais diferentes;\n",
      "existem 7 categorias diferentes;\n",
      "existem 135 lotacoes diferentes;\n",
      "existem 89 datas de admissao diferentes;\n"
     ]
    }
   ],
   "source": [
    "print(\"existem\", len(df), \"entradas diferentes;\")\n",
    "print(\"existem\", len(df[\"formacao\"].unique()), \"formacoes diferentes;\")\n",
    "print(\"existem\", len(df[\"tipo_jornada_trabalho\"].unique()),\n",
    "      \"tipos de jornada de trabalho diferentes;\")\n",
    "print(\"existem\", len(df[\"vinculo\"].unique()), \"tipos de vinculo diferentes;\")\n",
    "print(\"existem\", len(df[\"classe_funcional\"].unique()),\"classes funcionais diferentes;\")\n",
    "print(\"existem\", len(df[\"categoria\"].unique()),\"categorias diferentes;\")\n",
    "print(\"existem\", len(df[\"lotacao\"].unique()), \"lotacoes diferentes;\")\n",
    "print(\"existem\", len(df[\"num_semestres\"].unique()),\"datas de admissao diferentes;\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contagem de Professores por Formação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MESTRADO: 431\n",
      "DOUTORADO: 2189\n",
      "ESPECIALIZAÇÃO: 120\n",
      "GRADUAÇÃO: 11\n",
      "PÓS-DOUTORADO: 1\n",
      "DESCONHECIDA: 1\n"
     ]
    }
   ],
   "source": [
    "for formacao in df[\"formacao\"].unique():\n",
    "    print(formacao, \": \", len(df[df[\"formacao\"] == formacao]), sep=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remoção de Professores com Formação Desconhecida e Contagem por Formação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MESTRADO: 431\n",
      "DOUTORADO: 2189\n",
      "ESPECIALIZAÇÃO: 120\n",
      "GRADUAÇÃO: 11\n",
      "PÓS-DOUTORADO: 1\n"
     ]
    }
   ],
   "source": [
    "# retirar professores de formação desconhecida.\n",
    "\n",
    "df = df[df[\"formacao\"] != \"DESCONHECIDA\"]\n",
    "for formacao in df[\"formacao\"].unique():\n",
    "    print(formacao, \": \", len(df[df[\"formacao\"] == formacao]), sep=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classificação por Nível de Formação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3: 431\n",
      "4: 2189\n",
      "2: 120\n",
      "1: 11\n",
      "5: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mathe\\AppData\\Local\\Temp\\ipykernel_9992\\852662980.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"formacao\"].replace(nivel_formacao, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# colocar uma ordem de classificacao. pos-doc > doc > mestrado > esp > grad\n",
    "\n",
    "nivel_formacao = {\"GRADUAÇÃO\":1, \"ESPECIALIZAÇÃO\":2, \"MESTRADO\":3,\"DOUTORADO\":4,\"PÓS-DOUTORADO\":5}\n",
    "\n",
    "df[\"formacao\"].replace(nivel_formacao, inplace=True)\n",
    "for formacao in df[\"formacao\"].unique():\n",
    "    print(formacao, \": \", len(df[df[\"formacao\"] == formacao]), sep=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contagem de Professores por Tipo de Jornada de Trabalho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dedicação exclusiva           : 2155\n",
      "20 horas semanais             : 307\n",
      "40 horas semanais             : 290\n"
     ]
    }
   ],
   "source": [
    "for tipo_jornada_trabalho in df[\"tipo_jornada_trabalho\"].unique():\n",
    "    print(tipo_jornada_trabalho, \": \", len(\n",
    "        df[df[\"tipo_jornada_trabalho\"] == tipo_jornada_trabalho]), sep=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contagem de Professores por Tipo de Vínculo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ativo Permanente: 2376\n",
      "Celetista: 1\n",
      "Colaborador PCCTAE e Magistério Federal: 2\n",
      "Excedente de lotação: 3\n",
      "Exercicio provisorio: 18\n",
      "Professor Substituto: 260\n",
      "Professor Temporario: 50\n",
      "Professor Visitante: 42\n"
     ]
    }
   ],
   "source": [
    "for vinculo in df[\"vinculo\"].unique():\n",
    "    print(vinculo, \": \", len(df[df[\"vinculo\"] == vinculo]), sep=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remoção de Vínculos com Poucas Entradas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ativo Permanente: 2376\n",
      "Exercicio provisorio: 18\n",
      "Professor Substituto: 260\n",
      "Professor Temporario: 50\n",
      "Professor Visitante: 42\n"
     ]
    }
   ],
   "source": [
    "# há poucas pessoas com esses atributos:\n",
    "\n",
    "df = df[df[\"vinculo\"] != \"Celetista\"]\n",
    "df = df[df[\"vinculo\"] != \"Colaborador PCCTAE e Magistério Federal\"]\n",
    "df = df[df[\"vinculo\"] != \"Excedente de lotação\"]\n",
    "for vinculo in df[\"vinculo\"].unique():\n",
    "    print(vinculo, \": \", len(df[df[\"vinculo\"] == vinculo]), sep=\"\")\n",
    "\n",
    "# então decidi retirá-los"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contagem de Professores por Categoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO: 215\n",
      "PROFESSOR DO MAGISTERIO SUPERIOR: 2178\n",
      "PROFESSOR 3 GRAU                        : 1\n",
      "PROF ENS BAS TEC TECNOLOGICO-SUBSTITUTO: 29\n",
      "PROFESSOR DO MAGISTERIO SUPERIOR - SUBSTITUTO: 231\n",
      "PROFESSOR DO MAGISTERIO SUPERIOR - TEMPORARIO: 50\n",
      "PROFESSOR MAGISTERIO SUPERIOR - VISITANTE: 42\n"
     ]
    }
   ],
   "source": [
    "for categoria in df[\"categoria\"].unique():\n",
    "    print(categoria, \": \", len(df[df[\"categoria\"] == categoria]), sep=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veja que a informação de \"SUBSTITUTO\", \"TEMPORARIO\" e \"VISITANTE\" já está informada na coluna \"vínculo\". Então, irei retirá-la dos dados, assim como o único professor de terceiro grau."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Atualização e Simplificação de Categorias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO: 244\n",
      "PROFESSOR DO MAGISTERIO SUPERIOR: 2501\n"
     ]
    }
   ],
   "source": [
    "retirar_vinculo = {\"PROF ENS BAS TEC TECNOLOGICO-SUBSTITUTO\":\"PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO\",\n",
    "                   \"PROFESSOR DO MAGISTERIO SUPERIOR - SUBSTITUTO\":\"PROFESSOR DO MAGISTERIO SUPERIOR\",\n",
    "                   \"PROFESSOR DO MAGISTERIO SUPERIOR - TEMPORARIO\":\"PROFESSOR DO MAGISTERIO SUPERIOR\",\n",
    "                   \"PROFESSOR MAGISTERIO SUPERIOR - VISITANTE\":\"PROFESSOR DO MAGISTERIO SUPERIOR\"}\n",
    "\n",
    "df = df[df[\"categoria\"] != \"PROFESSOR 3 GRAU                        \"]\n",
    "\n",
    "df[\"categoria\"].replace(retirar_vinculo, inplace=True)\n",
    "\n",
    "for categoria in df[\"categoria\"].unique():\n",
    "    print(categoria, \": \", len(df[df[\"categoria\"] == categoria]), sep=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verifique que a soma de elementos de uma mesma categoria se manteve. Agora, iremos ranquear os professores com base em sua classe funcional:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classificação de Professores por Classe Funcional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DIV                                                                                                 : 75\n",
      "DV                                                                                                  : 32\n",
      "DIII                                                                                                : 78\n",
      "DI                                                                                                  : 47\n",
      "D                                                                                                   : 7\n",
      "DII                                                                                                 : 4\n",
      "Classe A - Adjunto A                                                                                : 141\n",
      "Classe C - Adjunto                                                                                  : 757\n",
      "Classe A - Auxiliar                                                                                 : 46\n",
      "Classe E - Titular                                                                                  : 307\n",
      "Classe D - Associado                                                                                : 834\n",
      "Classe B - Assistente                                                                               : 59\n",
      "Classe A - Assistente A                                                                             : 22\n",
      "Não Informada                                                                                       : 16\n",
      "Auxiliar                                                                                            : 278\n",
      "A                                                                                                   : 20\n",
      "Titular                                                                                             : 13\n",
      "Adjunto                                                                                             : 9\n"
     ]
    }
   ],
   "source": [
    "for classe_funcional in df[\"classe_funcional\"].unique():\n",
    "    print(classe_funcional, \": \", len(df[df[\"classe_funcional\"] == classe_funcional]), sep=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver, há 17 professores com classes não-informadas, e algmas estão repetidas e com outros nomes. Ainda, há 20 professores de classe A sem uma subclasse. O mapeamento, segundo a [PROGESP](https://progesp.ufrn.br/secao/carreira), se dá da seguinte maneira:\n",
    "\n",
    "| Original | Mapeamento |\n",
    "|-|-|\n",
    "|DV|1|\n",
    "|DIV|2|\n",
    "|DIII|3|\n",
    "|DII|4|\n",
    "|DI|5|\n",
    "|Classe E - Titular<br>Titular|6|\n",
    "|Classe D - Associado<br>D|7|\n",
    "|Classe C - Adjunto<br>Adjunto|8|\n",
    "|Classe B - Assistente|9|\n",
    "|Classe A - Auxiliar<br>Auxiliar|10|\n",
    "|Classe A - Assistente A<br>A|11|\n",
    "|Classe A - Adjunto A|12|\n",
    "\n",
    "É importante notar também que iremos retirar professores sem categoria. E professores classe A sem denominação específica serão tratados como Assistentes, pois têm o valor médio da classe A."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapeamento e Classificação das Classes Funcionais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapear_class_func = {\n",
    "    \"DV                                                                                                  \":1,\n",
    "    \"DIV                                                                                                 \":2,\n",
    "    \"DIII                                                                                                \":3,\n",
    "    \"DII                                                                                                 \":4,\n",
    "    \"DI                                                                                                  \":5,\n",
    "    \"Classe E - Titular                                                                                  \":6,\n",
    "    \"Titular                                                                                             \":6,\n",
    "    \"Classe D - Associado                                                                                \":7,\n",
    "    \"D                                                                                                   \":7,\n",
    "    \"Classe C - Adjunto                                                                                  \":8,\n",
    "    \"Adjunto                                                                                             \":8,\n",
    "    \"Classe B - Assistente                                                                               \":9,\n",
    "    \"Classe A - Auxiliar                                                                                 \":10,\n",
    "    \"Auxiliar                                                                                            \":10,\n",
    "    \"Classe A - Assistente A                                                                             \":11,\n",
    "    \"A                                                                                                   \":11,\n",
    "    \"Classe A - Adjunto A                                                                                \":12,\n",
    "}\n",
    "\n",
    "df = df[df[\"classe_funcional\"] != \"Não Informada                                                                                       \"]\n",
    "\n",
    "df[\"classe_funcional\"].replace(mapear_class_func, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contagem de Professores por Classe Funcional Após Classificação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2: 75\n",
      "1: 32\n",
      "3: 78\n",
      "5: 47\n",
      "7: 841\n",
      "4: 4\n",
      "12: 141\n",
      "8: 766\n",
      "10: 324\n",
      "6: 320\n",
      "9: 59\n",
      "11: 42\n"
     ]
    }
   ],
   "source": [
    "for classe_funcional in df[\"classe_funcional\"].unique():\n",
    "    print(classe_funcional, \": \", len(df[df[\"classe_funcional\"] == classe_funcional]), sep=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reset do Índice e Resumo Estatístico do DataFrame Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sexo</th>\n",
       "      <th>formacao</th>\n",
       "      <th>classe_funcional</th>\n",
       "      <th>num_semestres</th>\n",
       "      <th>revista_a1</th>\n",
       "      <th>revista_a2</th>\n",
       "      <th>revista_b1</th>\n",
       "      <th>revista_b2</th>\n",
       "      <th>revista_b3</th>\n",
       "      <th>revista_b4</th>\n",
       "      <th>revista_c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2729.000000</td>\n",
       "      <td>2729.000000</td>\n",
       "      <td>2729.000000</td>\n",
       "      <td>2729.000000</td>\n",
       "      <td>2729.000000</td>\n",
       "      <td>2729.000000</td>\n",
       "      <td>2729.000000</td>\n",
       "      <td>2729.000000</td>\n",
       "      <td>2729.000000</td>\n",
       "      <td>2729.000000</td>\n",
       "      <td>2729.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.540857</td>\n",
       "      <td>3.744229</td>\n",
       "      <td>7.521803</td>\n",
       "      <td>25.477831</td>\n",
       "      <td>2.646757</td>\n",
       "      <td>1.939538</td>\n",
       "      <td>1.755955</td>\n",
       "      <td>1.270429</td>\n",
       "      <td>0.814584</td>\n",
       "      <td>0.569073</td>\n",
       "      <td>0.890070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.498419</td>\n",
       "      <td>0.548749</td>\n",
       "      <td>2.113959</td>\n",
       "      <td>20.856943</td>\n",
       "      <td>6.095930</td>\n",
       "      <td>3.929876</td>\n",
       "      <td>5.398132</td>\n",
       "      <td>2.900249</td>\n",
       "      <td>2.394411</td>\n",
       "      <td>1.780601</td>\n",
       "      <td>3.868675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>124.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              sexo     formacao  classe_funcional  num_semestres   revista_a1  \\\n",
       "count  2729.000000  2729.000000       2729.000000    2729.000000  2729.000000   \n",
       "mean      0.540857     3.744229          7.521803      25.477831     2.646757   \n",
       "std       0.498419     0.548749          2.113959      20.856943     6.095930   \n",
       "min       0.000000     1.000000          1.000000       0.000000     0.000000   \n",
       "25%       0.000000     4.000000          7.000000      10.000000     0.000000   \n",
       "50%       1.000000     4.000000          7.000000      24.000000     0.000000   \n",
       "75%       1.000000     4.000000          8.000000      30.000000     3.000000   \n",
       "max       1.000000     5.000000         12.000000      97.000000    71.000000   \n",
       "\n",
       "        revista_a2   revista_b1   revista_b2   revista_b3   revista_b4  \\\n",
       "count  2729.000000  2729.000000  2729.000000  2729.000000  2729.000000   \n",
       "mean      1.939538     1.755955     1.270429     0.814584     0.569073   \n",
       "std       3.929876     5.398132     2.900249     2.394411     1.780601   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       2.000000     2.000000     1.000000     1.000000     0.000000   \n",
       "max      51.000000    99.000000    46.000000    41.000000    32.000000   \n",
       "\n",
       "         revista_c  \n",
       "count  2729.000000  \n",
       "mean      0.890070  \n",
       "std       3.868675  \n",
       "min       0.000000  \n",
       "25%       0.000000  \n",
       "50%       0.000000  \n",
       "75%       1.000000  \n",
       "max     124.000000  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.reset_index(drop=True, inplace=True)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resumo Estatístico das Colunas de Texto no DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tipo_jornada_trabalho</th>\n",
       "      <th>vinculo</th>\n",
       "      <th>categoria</th>\n",
       "      <th>lotacao</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2729</td>\n",
       "      <td>2729</td>\n",
       "      <td>2729</td>\n",
       "      <td>2729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Ativo Permanente</td>\n",
       "      <td>PROFESSOR DO MAGISTERIO SUPERIOR</td>\n",
       "      <td>ESCOLA AGRÍCOLA DE JUNDIAÍ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>2133</td>\n",
       "      <td>2376</td>\n",
       "      <td>2486</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 tipo_jornada_trabalho           vinculo  \\\n",
       "count                             2729              2729   \n",
       "unique                               3                 5   \n",
       "top     Dedicação exclusiva             Ativo Permanente   \n",
       "freq                              2133              2376   \n",
       "\n",
       "                               categoria                     lotacao  \n",
       "count                               2729                        2729  \n",
       "unique                                 2                         134  \n",
       "top     PROFESSOR DO MAGISTERIO SUPERIOR  ESCOLA AGRÍCOLA DE JUNDIAÍ  \n",
       "freq                                2486                         119  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include=\"object\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparação dos Dados para Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep = ['revista_a1',\n",
    "        'revista_a2',\n",
    "        'revista_b1',\n",
    "        'revista_b2',\n",
    "        'revista_b3',\n",
    "        'revista_b4',\n",
    "        'revista_c']\n",
    "\n",
    "X = df.drop(keep, axis=1).copy()\n",
    "\n",
    "[ya1,\n",
    " ya2,\n",
    " yb1,\n",
    " yb2,\n",
    " yb3,\n",
    " yb4,\n",
    " yc] = [df[col].copy() for col in keep]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Codificação de Variáveis Categóricas em Dados Numéricos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sexo</th>\n",
       "      <th>formacao</th>\n",
       "      <th>classe_funcional</th>\n",
       "      <th>num_semestres</th>\n",
       "      <th>tipo_jornada_trabalho_20 horas semanais</th>\n",
       "      <th>tipo_jornada_trabalho_40 horas semanais</th>\n",
       "      <th>tipo_jornada_trabalho_Dedicação exclusiva</th>\n",
       "      <th>vinculo_Ativo Permanente</th>\n",
       "      <th>vinculo_Exercicio provisorio</th>\n",
       "      <th>vinculo_Professor Substituto</th>\n",
       "      <th>...</th>\n",
       "      <th>lotacao_SECRETARIA DE EDUCAÇÃO BÁSICA, TÉCNICA E TECNOLÓGICA DA UFRN</th>\n",
       "      <th>lotacao_SECRETARIA DE GESTÃO DE PROJETOS</th>\n",
       "      <th>lotacao_SECRETARIA DE GOVERNANÇA INSTITUCIONAL</th>\n",
       "      <th>lotacao_SECRETARIA DE INCLUSÃO E ACESSIBILIDADE- SIA</th>\n",
       "      <th>lotacao_SECRETARIA DE RELAÇOES INTERNACIONAIS</th>\n",
       "      <th>lotacao_SUPERINTENDENCIA DE COMUNICACAO</th>\n",
       "      <th>lotacao_SUPERINTENDÊNCIA DE INFRAESTRUTURA</th>\n",
       "      <th>lotacao_SUPERINTENDÊNCIA DE TECNOLOGIA DA INFORMAÇÃO</th>\n",
       "      <th>lotacao_SUPERINTENDÊNCIA DO HUOL - EBSERH</th>\n",
       "      <th>lotacao_UNIVERSIDADE FEDERAL DO RIO GRANDE DO NORTE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>51</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2724</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2725</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2726</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2727</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2728</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2729 rows × 148 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sexo  formacao  classe_funcional  num_semestres  \\\n",
       "0        0         3                 2             34   \n",
       "1        1         4                 1             30   \n",
       "2        1         3                 2             51   \n",
       "3        1         3                 3             13   \n",
       "4        0         4                 2             28   \n",
       "...    ...       ...               ...            ...   \n",
       "2724     1         4                 8              1   \n",
       "2725     1         4                 6              2   \n",
       "2726     1         4                11              2   \n",
       "2727     0         4                11              1   \n",
       "2728     1         4                 6              2   \n",
       "\n",
       "      tipo_jornada_trabalho_20 horas semanais               \\\n",
       "0                                                 False      \n",
       "1                                                 False      \n",
       "2                                                 False      \n",
       "3                                                 False      \n",
       "4                                                 False      \n",
       "...                                                 ...      \n",
       "2724                                              False      \n",
       "2725                                              False      \n",
       "2726                                              False      \n",
       "2727                                              False      \n",
       "2728                                              False      \n",
       "\n",
       "      tipo_jornada_trabalho_40 horas semanais               \\\n",
       "0                                                 False      \n",
       "1                                                 False      \n",
       "2                                                 False      \n",
       "3                                                 False      \n",
       "4                                                 False      \n",
       "...                                                 ...      \n",
       "2724                                              False      \n",
       "2725                                              False      \n",
       "2726                                              False      \n",
       "2727                                              False      \n",
       "2728                                              False      \n",
       "\n",
       "      tipo_jornada_trabalho_Dedicação exclusiva             \\\n",
       "0                                                  True      \n",
       "1                                                  True      \n",
       "2                                                  True      \n",
       "3                                                  True      \n",
       "4                                                  True      \n",
       "...                                                 ...      \n",
       "2724                                               True      \n",
       "2725                                               True      \n",
       "2726                                               True      \n",
       "2727                                               True      \n",
       "2728                                               True      \n",
       "\n",
       "      vinculo_Ativo Permanente  vinculo_Exercicio provisorio  \\\n",
       "0                         True                         False   \n",
       "1                         True                         False   \n",
       "2                         True                         False   \n",
       "3                         True                         False   \n",
       "4                         True                         False   \n",
       "...                        ...                           ...   \n",
       "2724                     False                         False   \n",
       "2725                     False                         False   \n",
       "2726                     False                         False   \n",
       "2727                     False                         False   \n",
       "2728                     False                         False   \n",
       "\n",
       "      vinculo_Professor Substituto  ...  \\\n",
       "0                            False  ...   \n",
       "1                            False  ...   \n",
       "2                            False  ...   \n",
       "3                            False  ...   \n",
       "4                            False  ...   \n",
       "...                            ...  ...   \n",
       "2724                         False  ...   \n",
       "2725                         False  ...   \n",
       "2726                         False  ...   \n",
       "2727                         False  ...   \n",
       "2728                         False  ...   \n",
       "\n",
       "      lotacao_SECRETARIA DE EDUCAÇÃO BÁSICA, TÉCNICA E TECNOLÓGICA DA UFRN  \\\n",
       "0                                                 False                      \n",
       "1                                                 False                      \n",
       "2                                                 False                      \n",
       "3                                                 False                      \n",
       "4                                                 False                      \n",
       "...                                                 ...                      \n",
       "2724                                              False                      \n",
       "2725                                              False                      \n",
       "2726                                              False                      \n",
       "2727                                              False                      \n",
       "2728                                              False                      \n",
       "\n",
       "      lotacao_SECRETARIA DE GESTÃO DE PROJETOS  \\\n",
       "0                                        False   \n",
       "1                                        False   \n",
       "2                                        False   \n",
       "3                                        False   \n",
       "4                                        False   \n",
       "...                                        ...   \n",
       "2724                                     False   \n",
       "2725                                     False   \n",
       "2726                                     False   \n",
       "2727                                     False   \n",
       "2728                                     False   \n",
       "\n",
       "      lotacao_SECRETARIA DE GOVERNANÇA INSTITUCIONAL  \\\n",
       "0                                              False   \n",
       "1                                              False   \n",
       "2                                              False   \n",
       "3                                              False   \n",
       "4                                              False   \n",
       "...                                              ...   \n",
       "2724                                           False   \n",
       "2725                                           False   \n",
       "2726                                           False   \n",
       "2727                                           False   \n",
       "2728                                           False   \n",
       "\n",
       "      lotacao_SECRETARIA DE INCLUSÃO E ACESSIBILIDADE- SIA  \\\n",
       "0                                                 False      \n",
       "1                                                 False      \n",
       "2                                                 False      \n",
       "3                                                 False      \n",
       "4                                                 False      \n",
       "...                                                 ...      \n",
       "2724                                              False      \n",
       "2725                                              False      \n",
       "2726                                              False      \n",
       "2727                                              False      \n",
       "2728                                              False      \n",
       "\n",
       "      lotacao_SECRETARIA DE RELAÇOES INTERNACIONAIS  \\\n",
       "0                                             False   \n",
       "1                                             False   \n",
       "2                                             False   \n",
       "3                                             False   \n",
       "4                                             False   \n",
       "...                                             ...   \n",
       "2724                                          False   \n",
       "2725                                          False   \n",
       "2726                                          False   \n",
       "2727                                          False   \n",
       "2728                                          False   \n",
       "\n",
       "      lotacao_SUPERINTENDENCIA DE COMUNICACAO  \\\n",
       "0                                       False   \n",
       "1                                       False   \n",
       "2                                       False   \n",
       "3                                       False   \n",
       "4                                       False   \n",
       "...                                       ...   \n",
       "2724                                    False   \n",
       "2725                                    False   \n",
       "2726                                    False   \n",
       "2727                                    False   \n",
       "2728                                    False   \n",
       "\n",
       "      lotacao_SUPERINTENDÊNCIA DE INFRAESTRUTURA  \\\n",
       "0                                          False   \n",
       "1                                          False   \n",
       "2                                          False   \n",
       "3                                          False   \n",
       "4                                          False   \n",
       "...                                          ...   \n",
       "2724                                       False   \n",
       "2725                                       False   \n",
       "2726                                       False   \n",
       "2727                                       False   \n",
       "2728                                       False   \n",
       "\n",
       "      lotacao_SUPERINTENDÊNCIA DE TECNOLOGIA DA INFORMAÇÃO  \\\n",
       "0                                                 False      \n",
       "1                                                 False      \n",
       "2                                                 False      \n",
       "3                                                 False      \n",
       "4                                                 False      \n",
       "...                                                 ...      \n",
       "2724                                              False      \n",
       "2725                                              False      \n",
       "2726                                              False      \n",
       "2727                                              False      \n",
       "2728                                              False      \n",
       "\n",
       "      lotacao_SUPERINTENDÊNCIA DO HUOL - EBSERH  \\\n",
       "0                                         False   \n",
       "1                                         False   \n",
       "2                                         False   \n",
       "3                                         False   \n",
       "4                                         False   \n",
       "...                                         ...   \n",
       "2724                                      False   \n",
       "2725                                      False   \n",
       "2726                                      False   \n",
       "2727                                      False   \n",
       "2728                                      False   \n",
       "\n",
       "      lotacao_UNIVERSIDADE FEDERAL DO RIO GRANDE DO NORTE  \n",
       "0                                                 False    \n",
       "1                                                 False    \n",
       "2                                                 False    \n",
       "3                                                 False    \n",
       "4                                                 False    \n",
       "...                                                 ...    \n",
       "2724                                              False    \n",
       "2725                                              False    \n",
       "2726                                              False    \n",
       "2727                                              False    \n",
       "2728                                              False    \n",
       "\n",
       "[2729 rows x 148 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_encoded = pd.get_dummies(X, columns=[\"tipo_jornada_trabalho\",\n",
    "                                       \"vinculo\",\n",
    "                                       \"categoria\",\n",
    "                                       \"lotacao\"])\n",
    "\n",
    "X_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cálculo das Médias das Taxas por Categoria de Revista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ya1': 2.646757053865885,\n",
       " 'ya2': 1.939538292414804,\n",
       " 'yb1': 1.7559545621106631,\n",
       " 'yb2': 1.2704287284719677,\n",
       " 'yb3': 0.8145840967387321,\n",
       " 'yb4': 0.5690729204836936,\n",
       " 'yc': 0.8900696225723709}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\"ya1\": (sum(ya1) / len(ya1)),\n",
    " \"ya2\": (sum(ya2) / len(ya2)),\n",
    " \"yb1\": (sum(yb1) / len(yb1)),\n",
    " \"yb2\": (sum(yb2) / len(yb2)),\n",
    " \"yb3\": (sum(yb3) / len(yb3)),\n",
    " \"yb4\": (sum(yb4) / len(yb4)),\n",
    " \"yc\": (sum(yc) / len(yc))}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparação dos Conjuntos de Treinamento e Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_vars = [(ya1, \"ya1\"),\n",
    "               (ya2, \"ya2\"),\n",
    "               (yb1, \"yb1\"),\n",
    "               (yb2, \"yb2\"),\n",
    "               (yb3, \"yb3\"),\n",
    "               (yb4, \"yb4\"),\n",
    "               (yc, \"yc\")]\n",
    "\n",
    "train_test_sets = {}\n",
    "\n",
    "for var, var_name in target_vars:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_encoded, var, random_state=42)\n",
    "    train_test_sets[var_name] = (X_train, X_test, y_train, y_test)\n",
    "\n",
    "# Agora, você pode acessar os conjuntos de treinamento e teste usando o nome da variável alvo desejada\n",
    "X_train_ya1, X_test_ya1, ya1_train, ya1_test = train_test_sets[\"ya1\"]\n",
    "X_train_ya2, X_test_ya2, ya2_train, ya2_test = train_test_sets[\"ya2\"]\n",
    "X_train_yb1, X_test_yb1, yb1_train, yb1_test = train_test_sets[\"yb1\"]\n",
    "X_train_yb2, X_test_yb2, yb2_train, yb2_test = train_test_sets[\"yb2\"]\n",
    "X_train_yb3, X_test_yb3, yb3_train, yb3_test = train_test_sets[\"yb3\"]\n",
    "X_train_yb4, X_test_yb4, yb4_train, yb4_test = train_test_sets[\"yb4\"]\n",
    "X_train_yc, X_test_yc, yc_train, yc_test = train_test_sets[\"yc\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Médias das Taxas nas Partições de Treinamento e Teste por Categoria de Revista (TRAIN & TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ya1': (2.639784946236559, 2.6676427525622253),\n",
       " 'ya2': (1.9472140762463344, 1.916544655929722),\n",
       " 'yb1': (1.6715542521994136, 2.0087847730600292),\n",
       " 'yb2': (1.1901270772238515, 1.5109809663250366),\n",
       " 'yb3': (0.8093841642228738, 0.8301610541727672),\n",
       " 'yb4': (0.5650048875855328, 0.5812591508052709),\n",
       " 'yc': (0.9496578690127078, 0.7115666178623719)}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test_pairs = {\n",
    "    \"ya1\": (sum(ya1_train) / len(ya1_train), sum(ya1_test) / len(ya1_test)),\n",
    "    \"ya2\": (sum(ya2_train) / len(ya2_train), sum(ya2_test) / len(ya2_test)),\n",
    "    \"yb1\": (sum(yb1_train) / len(yb1_train), sum(yb1_test) / len(yb1_test)),\n",
    "    \"yb2\": (sum(yb2_train) / len(yb2_train), sum(yb2_test) / len(yb2_test)),\n",
    "    \"yb3\": (sum(yb3_train) / len(yb3_train), sum(yb3_test) / len(yb3_test)),\n",
    "    \"yb4\": (sum(yb4_train) / len(yb4_train), sum(yb4_test) / len(yb4_test)),\n",
    "    \"yc\" : (sum(yc_train) / len(yc_train), sum(yc_test) / len(yc_test))\n",
    "}\n",
    "\n",
    "train_test_pairs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Espaço de Parâmetros para Otimização do Modelo XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_space = {\n",
    "    \"max_depth\": Integer(1,20),\n",
    "    \"n_estimators\": Integer(10,1000),\n",
    "    \"reg_lambda\": Real(0, 10),\n",
    "    \"eta\": Real(0.01, 1),\n",
    "    \"gamma\": Real(0,7)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinamento e Otimização do Modelo XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo XGBoost para \"ya1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BayesSearchCV(cv=5,\n",
       "              estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "              search_spaces={&#x27;eta&#x27;: Real(low=0.01, high=1, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;gamma&#x27;: Real(low=0, high=7, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;max_depth&#x27;: Integer(low=1, high=20, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;n_estimators&#x27;: Integer(low=10, high=1000, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;reg_lambda&#x27;: Real(low=0, high=10, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;)},\n",
       "              verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BayesSearchCV</label><div class=\"sk-toggleable__content\"><pre>BayesSearchCV(cv=5,\n",
       "              estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "              search_spaces={&#x27;eta&#x27;: Real(low=0.01, high=1, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;gamma&#x27;: Real(low=0, high=7, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;max_depth&#x27;: Integer(low=1, high=20, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;n_estimators&#x27;: Integer(low=10, high=1000, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;reg_lambda&#x27;: Real(low=0, high=10, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;)},\n",
       "              verbose=True)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "BayesSearchCV(cv=5,\n",
       "              estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "              search_spaces={'eta': Real(low=0.01, high=1, prior='uniform', transform='normalize'),\n",
       "                             'gamma': Real(low=0, high=7, prior='uniform', transform='normalize'),\n",
       "                             'max_depth': Integer(low=1, high=20, prior='uniform', transform='normalize'),\n",
       "                             'n_estimators': Integer(low=10, high=1000, prior='uniform', transform='normalize'),\n",
       "                             'reg_lambda': Real(low=0, high=10, prior='uniform', transform='normalize')},\n",
       "              verbose=True)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrn.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "reg_xgb_ya1 = xgb.XGBRegressor()\n",
    "\n",
    "xgb_bayes_ya1 = BayesSearchCV(reg_xgb_ya1,\n",
    "                              param_space,\n",
    "                              n_iter=32,\n",
    "                              scoring=\"neg_root_mean_squared_error\",\n",
    "                              verbose=True,\n",
    "                              cv=5,\n",
    "                              n_jobs=8,\n",
    "                              random_state=42)\n",
    "\n",
    "xgb_bayes_ya1.fit(X_train_ya1, ya1_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo XGBoost para \"ya2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BayesSearchCV(cv=5,\n",
       "              estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "              search_spaces={&#x27;eta&#x27;: Real(low=0.01, high=1, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;gamma&#x27;: Real(low=0, high=7, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;max_depth&#x27;: Integer(low=1, high=20, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;n_estimators&#x27;: Integer(low=10, high=1000, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;reg_lambda&#x27;: Real(low=0, high=10, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;)},\n",
       "              verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BayesSearchCV</label><div class=\"sk-toggleable__content\"><pre>BayesSearchCV(cv=5,\n",
       "              estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "              search_spaces={&#x27;eta&#x27;: Real(low=0.01, high=1, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;gamma&#x27;: Real(low=0, high=7, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;max_depth&#x27;: Integer(low=1, high=20, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;n_estimators&#x27;: Integer(low=10, high=1000, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;reg_lambda&#x27;: Real(low=0, high=10, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;)},\n",
       "              verbose=True)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "BayesSearchCV(cv=5,\n",
       "              estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "              search_spaces={'eta': Real(low=0.01, high=1, prior='uniform', transform='normalize'),\n",
       "                             'gamma': Real(low=0, high=7, prior='uniform', transform='normalize'),\n",
       "                             'max_depth': Integer(low=1, high=20, prior='uniform', transform='normalize'),\n",
       "                             'n_estimators': Integer(low=10, high=1000, prior='uniform', transform='normalize'),\n",
       "                             'reg_lambda': Real(low=0, high=10, prior='uniform', transform='normalize')},\n",
       "              verbose=True)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrn.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "reg_xgb_ya2 = xgb.XGBRegressor()\n",
    "\n",
    "xgb_bayes_ya2 = BayesSearchCV(reg_xgb_ya2,\n",
    "                              param_space,\n",
    "                              n_iter=32,\n",
    "                              scoring=\"neg_root_mean_squared_error\",\n",
    "                              verbose=True,\n",
    "                              cv=5,\n",
    "                              n_jobs=8,\n",
    "                              random_state=42)\n",
    "\n",
    "xgb_bayes_ya2.fit(X_train_ya2, ya2_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo XGBoost para \"yb1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BayesSearchCV(cv=5,\n",
       "              estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "              search_spaces={&#x27;eta&#x27;: Real(low=0.01, high=1, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;gamma&#x27;: Real(low=0, high=7, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;max_depth&#x27;: Integer(low=1, high=20, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;n_estimators&#x27;: Integer(low=10, high=1000, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;reg_lambda&#x27;: Real(low=0, high=10, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;)},\n",
       "              verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BayesSearchCV</label><div class=\"sk-toggleable__content\"><pre>BayesSearchCV(cv=5,\n",
       "              estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "              search_spaces={&#x27;eta&#x27;: Real(low=0.01, high=1, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;gamma&#x27;: Real(low=0, high=7, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;max_depth&#x27;: Integer(low=1, high=20, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;n_estimators&#x27;: Integer(low=10, high=1000, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;reg_lambda&#x27;: Real(low=0, high=10, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;)},\n",
       "              verbose=True)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "BayesSearchCV(cv=5,\n",
       "              estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "              search_spaces={'eta': Real(low=0.01, high=1, prior='uniform', transform='normalize'),\n",
       "                             'gamma': Real(low=0, high=7, prior='uniform', transform='normalize'),\n",
       "                             'max_depth': Integer(low=1, high=20, prior='uniform', transform='normalize'),\n",
       "                             'n_estimators': Integer(low=10, high=1000, prior='uniform', transform='normalize'),\n",
       "                             'reg_lambda': Real(low=0, high=10, prior='uniform', transform='normalize')},\n",
       "              verbose=True)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrn.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "reg_xgb_yb1 = xgb.XGBRegressor()\n",
    "\n",
    "xgb_bayes_yb1 = BayesSearchCV(reg_xgb_yb1,\n",
    "                              param_space,\n",
    "                              n_iter=32,\n",
    "                              scoring=\"neg_root_mean_squared_error\",\n",
    "                              verbose=True,\n",
    "                              cv=5,\n",
    "                              n_jobs=8,\n",
    "                              random_state=42)\n",
    "\n",
    "xgb_bayes_yb1.fit(X_train_yb1, yb1_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo XGBoost para \"yb2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BayesSearchCV(cv=5,\n",
       "              estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "              search_spaces={&#x27;eta&#x27;: Real(low=0.01, high=1, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;gamma&#x27;: Real(low=0, high=7, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;max_depth&#x27;: Integer(low=1, high=20, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;n_estimators&#x27;: Integer(low=10, high=1000, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;reg_lambda&#x27;: Real(low=0, high=10, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;)},\n",
       "              verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BayesSearchCV</label><div class=\"sk-toggleable__content\"><pre>BayesSearchCV(cv=5,\n",
       "              estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "              search_spaces={&#x27;eta&#x27;: Real(low=0.01, high=1, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;gamma&#x27;: Real(low=0, high=7, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;max_depth&#x27;: Integer(low=1, high=20, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;n_estimators&#x27;: Integer(low=10, high=1000, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;reg_lambda&#x27;: Real(low=0, high=10, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;)},\n",
       "              verbose=True)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "BayesSearchCV(cv=5,\n",
       "              estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "              search_spaces={'eta': Real(low=0.01, high=1, prior='uniform', transform='normalize'),\n",
       "                             'gamma': Real(low=0, high=7, prior='uniform', transform='normalize'),\n",
       "                             'max_depth': Integer(low=1, high=20, prior='uniform', transform='normalize'),\n",
       "                             'n_estimators': Integer(low=10, high=1000, prior='uniform', transform='normalize'),\n",
       "                             'reg_lambda': Real(low=0, high=10, prior='uniform', transform='normalize')},\n",
       "              verbose=True)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrn.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "reg_xgb_yb2 = xgb.XGBRegressor()\n",
    "\n",
    "xgb_bayes_yb2 = BayesSearchCV(reg_xgb_yb2,\n",
    "                              param_space,\n",
    "                              n_iter=32,\n",
    "                              scoring=\"neg_root_mean_squared_error\",\n",
    "                              verbose=True,\n",
    "                              cv=5,\n",
    "                              n_jobs=8,\n",
    "                              random_state=42)\n",
    "\n",
    "xgb_bayes_yb2.fit(X_train_yb2, yb2_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo XGBoost para \"yb3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BayesSearchCV(cv=5,\n",
       "              estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "              search_spaces={&#x27;eta&#x27;: Real(low=0.01, high=1, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;gamma&#x27;: Real(low=0, high=7, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;max_depth&#x27;: Integer(low=1, high=20, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;n_estimators&#x27;: Integer(low=10, high=1000, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;reg_lambda&#x27;: Real(low=0, high=10, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;)},\n",
       "              verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BayesSearchCV</label><div class=\"sk-toggleable__content\"><pre>BayesSearchCV(cv=5,\n",
       "              estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "              search_spaces={&#x27;eta&#x27;: Real(low=0.01, high=1, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;gamma&#x27;: Real(low=0, high=7, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;max_depth&#x27;: Integer(low=1, high=20, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;n_estimators&#x27;: Integer(low=10, high=1000, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;reg_lambda&#x27;: Real(low=0, high=10, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;)},\n",
       "              verbose=True)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "BayesSearchCV(cv=5,\n",
       "              estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "              search_spaces={'eta': Real(low=0.01, high=1, prior='uniform', transform='normalize'),\n",
       "                             'gamma': Real(low=0, high=7, prior='uniform', transform='normalize'),\n",
       "                             'max_depth': Integer(low=1, high=20, prior='uniform', transform='normalize'),\n",
       "                             'n_estimators': Integer(low=10, high=1000, prior='uniform', transform='normalize'),\n",
       "                             'reg_lambda': Real(low=0, high=10, prior='uniform', transform='normalize')},\n",
       "              verbose=True)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrn.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "reg_xgb_yb3 = xgb.XGBRegressor()\n",
    "\n",
    "xgb_bayes_yb3 = BayesSearchCV(reg_xgb_yb3,\n",
    "                              param_space,\n",
    "                              n_iter=32,\n",
    "                              scoring=\"neg_root_mean_squared_error\",\n",
    "                              verbose=True,\n",
    "                              cv=5,\n",
    "                              n_jobs=8,\n",
    "                              random_state=42)\n",
    "\n",
    "xgb_bayes_yb3.fit(X_train_yb3, yb3_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo XGBoost para \"yb4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BayesSearchCV(cv=5,\n",
       "              estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "              search_spaces={&#x27;eta&#x27;: Real(low=0.01, high=1, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;gamma&#x27;: Real(low=0, high=7, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;max_depth&#x27;: Integer(low=1, high=20, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;n_estimators&#x27;: Integer(low=10, high=1000, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;reg_lambda&#x27;: Real(low=0, high=10, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;)},\n",
       "              verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BayesSearchCV</label><div class=\"sk-toggleable__content\"><pre>BayesSearchCV(cv=5,\n",
       "              estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "              search_spaces={&#x27;eta&#x27;: Real(low=0.01, high=1, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;gamma&#x27;: Real(low=0, high=7, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;max_depth&#x27;: Integer(low=1, high=20, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;n_estimators&#x27;: Integer(low=10, high=1000, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;reg_lambda&#x27;: Real(low=0, high=10, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;)},\n",
       "              verbose=True)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "BayesSearchCV(cv=5,\n",
       "              estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "              search_spaces={'eta': Real(low=0.01, high=1, prior='uniform', transform='normalize'),\n",
       "                             'gamma': Real(low=0, high=7, prior='uniform', transform='normalize'),\n",
       "                             'max_depth': Integer(low=1, high=20, prior='uniform', transform='normalize'),\n",
       "                             'n_estimators': Integer(low=10, high=1000, prior='uniform', transform='normalize'),\n",
       "                             'reg_lambda': Real(low=0, high=10, prior='uniform', transform='normalize')},\n",
       "              verbose=True)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrn.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "reg_xgb_yb4 = xgb.XGBRegressor()\n",
    "\n",
    "xgb_bayes_yb4 = BayesSearchCV(reg_xgb_yb4,\n",
    "                              param_space,\n",
    "                              n_iter=32,\n",
    "                              scoring=\"neg_root_mean_squared_error\",\n",
    "                              verbose=True,\n",
    "                              cv=5,\n",
    "                              n_jobs=8,\n",
    "                              random_state=42)\n",
    "\n",
    "xgb_bayes_yb4.fit(X_train_yb4, yb4_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo XGBoost para \"yc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BayesSearchCV(cv=5,\n",
       "              estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "              search_spaces={&#x27;eta&#x27;: Real(low=0.01, high=1, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;gamma&#x27;: Real(low=0, high=7, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;max_depth&#x27;: Integer(low=1, high=20, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;n_estimators&#x27;: Integer(low=10, high=1000, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;reg_lambda&#x27;: Real(low=0, high=10, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;)},\n",
       "              verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BayesSearchCV</label><div class=\"sk-toggleable__content\"><pre>BayesSearchCV(cv=5,\n",
       "              estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "              search_spaces={&#x27;eta&#x27;: Real(low=0.01, high=1, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;gamma&#x27;: Real(low=0, high=7, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;max_depth&#x27;: Integer(low=1, high=20, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;n_estimators&#x27;: Integer(low=10, high=1000, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;reg_lambda&#x27;: Real(low=0, high=10, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;)},\n",
       "              verbose=True)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" ><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "BayesSearchCV(cv=5,\n",
       "              estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "              search_spaces={'eta': Real(low=0.01, high=1, prior='uniform', transform='normalize'),\n",
       "                             'gamma': Real(low=0, high=7, prior='uniform', transform='normalize'),\n",
       "                             'max_depth': Integer(low=1, high=20, prior='uniform', transform='normalize'),\n",
       "                             'n_estimators': Integer(low=10, high=1000, prior='uniform', transform='normalize'),\n",
       "                             'reg_lambda': Real(low=0, high=10, prior='uniform', transform='normalize')},\n",
       "              verbose=True)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrn.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "reg_xgb_yc = xgb.XGBRegressor()\n",
    "\n",
    "xgb_bayes_yc = BayesSearchCV(reg_xgb_yc,\n",
    "                             param_space,\n",
    "                             n_iter=32,\n",
    "                             scoring=\"neg_root_mean_squared_error\",\n",
    "                             verbose=True,\n",
    "                             cv=5,\n",
    "                             n_jobs=8,\n",
    "                             random_state=42)\n",
    "\n",
    "xgb_bayes_yc.fit(X_train_yc, yc_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lista de Variáveis Alvo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = [\"ya1\",\n",
    "             \"ya2\",\n",
    "             \"yb1\",\n",
    "             \"yb2\",\n",
    "             \"yb3\",\n",
    "             \"yb4\",\n",
    "             \"yc\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Melhores Parâmetros e Pontuações dos Modelos XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ya1 params: OrderedDict([('eta', 0.8422271191727188), ('gamma', 7.0), ('max_depth', 1), ('n_estimators', 755), ('reg_lambda', 10.0)])\n",
      "    score : 5.0707014362325324\n",
      "\n",
      "ya2 params: OrderedDict([('eta', 1.0), ('gamma', 7.0), ('max_depth', 1), ('n_estimators', 1000), ('reg_lambda', 10.0)])\n",
      "    score : 3.5101206371420117\n",
      "\n",
      "yb1 params: OrderedDict([('eta', 0.21403491181724588), ('gamma', 5.755764629309848), ('max_depth', 2), ('n_estimators', 10), ('reg_lambda', 5.01675508536886)])\n",
      "    score : 4.183589006180328\n",
      "\n",
      "yb2 params: OrderedDict([('eta', 0.01), ('gamma', 5.414098945296594), ('max_depth', 16), ('n_estimators', 237), ('reg_lambda', 10.0)])\n",
      "    score : 2.4521849223506713\n",
      "\n",
      "yb3 params: OrderedDict([('eta', 0.6473495190743908), ('gamma', 7.0), ('max_depth', 1), ('n_estimators', 225), ('reg_lambda', 10.0)])\n",
      "    score : 2.2996850433449447\n",
      "\n",
      "yb4 params: OrderedDict([('eta', 0.6200383486942431), ('gamma', 6.604105513161855), ('max_depth', 5), ('n_estimators', 1000), ('reg_lambda', 7.7758680599368235)])\n",
      "    score : 1.5979243276476198\n",
      "\n",
      "yc params: OrderedDict([('eta', 0.01), ('gamma', 7.0), ('max_depth', 10), ('n_estimators', 254), ('reg_lambda', 10.0)])\n",
      "    score : 3.7387499145166005\n",
      "\n"
     ]
    }
   ],
   "source": [
    "estimator_ya1 = xgb_bayes_ya1.best_estimator_\n",
    "estimator_ya2 = xgb_bayes_ya2.best_estimator_\n",
    "estimator_yb1 = xgb_bayes_yb1.best_estimator_\n",
    "estimator_yb2 = xgb_bayes_yb2.best_estimator_\n",
    "estimator_yb3 = xgb_bayes_yb3.best_estimator_\n",
    "estimator_yb4 = xgb_bayes_yb4.best_estimator_\n",
    "estimator_yc  = xgb_bayes_yc.best_estimator_\n",
    "\n",
    "bayes_estimators = [xgb_bayes_ya1,\n",
    "                    xgb_bayes_ya2,\n",
    "                    xgb_bayes_yb1,\n",
    "                    xgb_bayes_yb2,\n",
    "                    xgb_bayes_yb3,\n",
    "                    xgb_bayes_yb4,\n",
    "                    xgb_bayes_yc]\n",
    "\n",
    "for var, estimator in zip(variables, bayes_estimators):\n",
    "    best_params = estimator.best_params_\n",
    "    best_score = -estimator.best_score_\n",
    "    print(f\"{var} params: {best_params}\\n    score : {best_score}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaliação das Previsões do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ya1: 5.844634176792734\n",
      "ya2: 3.3811955088508894\n",
      "yb1: 5.0566765120161685\n",
      "yb2: 3.1728301000662547\n",
      "yb3: 2.013742838305503\n",
      "yb4: 1.980233707679643\n",
      "yc: 2.379122836447968\n"
     ]
    }
   ],
   "source": [
    "wrn.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "estimators = [estimator_ya1,\n",
    "              estimator_ya2,\n",
    "              estimator_yb1,\n",
    "              estimator_yb2,\n",
    "              estimator_yb3,\n",
    "              estimator_yb4,\n",
    "              estimator_yc]\n",
    "\n",
    "X_tests = [X_test_ya1,\n",
    "           X_test_ya2,\n",
    "           X_test_yb1,\n",
    "           X_test_yb2,\n",
    "           X_test_yb3,\n",
    "           X_test_yb4,\n",
    "           X_test_yc]\n",
    "\n",
    "y_tests = [ya1_test,\n",
    "           ya2_test,\n",
    "           yb1_test,\n",
    "           yb2_test,\n",
    "           yb3_test,\n",
    "           yb4_test,\n",
    "           yc_test]\n",
    "\n",
    "predict = {}\n",
    "\n",
    "for var, estimator, X_test, y_test in zip(variables, estimators, X_tests, y_tests):\n",
    "    predict[var] = estimator.predict(X_test)\n",
    "    rmse = np.sqrt(mean_squared_error(predict[var], y_test))\n",
    "    print(f\"{var}: {rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listas de Comparação entre Valores Reais e Previsões"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "complist_ya1 = [(true, pred) for true, pred in zip(ya1_test, predict[\"ya1\"])]\n",
    "complist_ya2 = [(true, pred) for true, pred in zip(ya2_test, predict[\"ya2\"])]\n",
    "complist_yb1 = [(true, pred) for true, pred in zip(yb1_test, predict[\"yb1\"])]\n",
    "complist_yb2 = [(true, pred) for true, pred in zip(yb2_test, predict[\"yb2\"])]\n",
    "complist_yb3 = [(true, pred) for true, pred in zip(yb3_test, predict[\"yb3\"])]\n",
    "complist_yb4 = [(true, pred) for true, pred in zip(yb4_test, predict[\"yb4\"])]\n",
    "complist_yc  = [(true, pred) for true, pred in zip(yc_test, predict[\"yc\"])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tabela de Comparação entre Valores Reais e Previsões"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " true_ya1   pred_ya1  true_ya2  pred_ya2  true_yb1  pred_yb1  true_yb2  pred_yb2  true_yb3  pred_yb3  true_yb4  pred_yb4  true_yc   pred_yc\n",
      "        0   1.811096         1  0.872487         0  0.744771         0  0.333761         0  0.321552         0  0.131216        0  0.349370\n",
      "        8   8.070203         4  4.222690         7  1.458642         0  0.759879         2  1.184288         0  0.708671        0  0.750607\n",
      "        0   1.476912         2  0.940053         0  1.458642         5  0.670103         0  0.511971         0  0.291825        0  0.602581\n",
      "        8   2.470807         3  2.245958         1  1.458642         0  0.968734         0  0.755697         0  0.432399        0  0.614912\n",
      "        1   0.593630         0  0.759945         0  1.458642         0  0.493076         0  0.365731         3  0.704413        1  0.987071\n",
      "        0  -0.049184         0  0.055298         0  0.744771         0  0.328381         0  0.321552         0  0.131216        0  0.296717\n",
      "       11   4.368906         9  2.245958         6  1.458642         3  6.272408         5  1.240715         0  1.074137        0  1.776863\n",
      "        0  -0.420557         0 -0.107712         0  0.744771         0  0.328381         0 -0.155307         0  0.131216        0  0.268690\n",
      "        1  -0.372746         0  0.472676         0  0.744771         0  0.299408         0  0.454738         0  0.271790        0  0.321343\n",
      "        4   5.424440         0  4.556251         0  1.458642         0  0.848441         0  1.354989         4  0.708671        0  0.799665\n",
      "        1   3.591777         0  3.445281         1  1.996623         2  3.847970         2  0.511971         3  0.432399        0  1.001132\n",
      "        5   5.693425         3  2.678733         0  1.458642         0  0.679963         0  0.511971         0  0.291825        1  0.602581\n",
      "        1   1.728229         1  0.605407         0  1.458642         1  3.155192         1  0.511971         0  0.291825        0  0.602581\n",
      "        3   3.356764         2  2.061918         0  1.458642         4  0.626184         1  0.341270         0  0.291825        3  0.553523\n",
      "        3  12.124845         5  8.719717         3  1.458642         8  0.969727         3  1.354989         1  1.795460        0  1.852512\n",
      "        1   2.124682         0  1.908543         1  1.458642         3  1.265826         1  0.511971         0  0.432399        0  0.614912\n",
      "        0   1.176550         0  1.908543         0  1.458642         2  1.000464         0  0.511971         0  0.432399        0  0.614912\n",
      "        0   2.002298         6  1.381378         0  1.458642         0  0.851245         0  0.511971         5  0.432399        1  0.614912\n",
      "        0   1.550942         0  1.268194         0  1.458642         0  0.479549         0  0.365731         0  0.604256        3  0.693882\n",
      "       46   5.043502        14  4.380067         3  1.458642         1  1.585133         1  2.039686        13  1.127564        2  0.953395\n",
      "        0   3.371780         0  1.449458         0  1.458642         1  0.913043         0  0.755697         0  0.432399        0  0.614912\n",
      "        0  -0.382448         1 -0.631912         1  0.744771         0  0.328381         0 -0.155307         0  0.131216        0  0.268690\n",
      "        0   2.541738         0  1.995308        14  1.829701         5  2.219221         1  1.057391         0  0.291825        4  0.602581\n",
      "        1   6.474222         2  5.010977         0  1.458642         1  1.239365         1  1.193471         7  1.127564        0  0.860790\n",
      "        1   5.964104         2  4.752981         5  1.458642         4  2.148392         0  0.833401         0  1.127564        3  0.860790\n",
      "        0   2.228456         2  2.530589         0  1.458642         3  1.351226         2  1.632815         0  0.802609        0  0.860790\n",
      "        4   0.504246         4  1.197319         9  1.458642         8  0.836547         5  0.341270         3  0.291825        5  0.553523\n",
      "        0   1.183418         2  0.856057         3  1.458642         4  3.182080         0  0.755697         0  0.432399        0  0.614912\n",
      "        1   1.279844         0  1.777707         1  1.458642         0  1.000464         0  0.511971         0  0.432399        2  0.614912\n",
      "        0   6.696104         0  2.717166         0  1.458642         0  2.056961         0  1.193471         0  1.127564        4  1.428594\n",
      "        0   2.470807         0  2.245958         2  1.458642         1  1.001226         2  0.755697         0  0.432399        1  0.614912\n",
      "        0   1.600735         0  2.245958         2  1.458642         1  1.010992         1  0.755697         0  0.525767        0  0.614912\n",
      "        0   1.937234         2  1.718793         0  1.458642         2  0.973077         2  0.755697         0  0.432399        0  0.614912\n",
      "        0   1.879084         0  1.508489         0  1.458642         0  0.890299         0  0.755697         0  0.525767        0  0.608483\n",
      "        0  -0.193707         1 -0.085583         1  1.458642         0  0.688726         0  0.341270         0  0.291825        0  0.553523\n",
      "        1   2.348659         0  1.625583         1  1.458642         0  0.907739         0  0.755697         0  0.525767        0  0.608483\n",
      "        3   3.937902         5  3.913532         9  1.996623        11  6.774187         2  0.755697         1  0.432399        5  1.001132\n",
      "        0   2.470807         2  1.558748         0  1.458642         0  0.880293         1  0.755697         0  0.432399        0  0.614912\n",
      "        1   1.937234         5  1.849629        21 32.035645         3  3.020112         6  2.803238         1  0.921858        9  5.741332\n",
      "       15   5.454690         4  4.380067         1  1.458642         0  1.322285         0  1.354989         0  1.127564        0  0.953395\n",
      "        0   2.470807         0  2.245958         2  1.458642         0  1.030074         3  0.755697         0  0.525767        0  0.614912\n",
      "        2   4.067372         1  2.245958         0  1.458642         3  1.030074         0  0.755697         0  0.432399        0  0.614912\n",
      "        1   1.527939         8  1.718793         1  1.458642         0  1.874422         0  0.755697         0 10.956652        1  0.726381\n",
      "        0   1.890861         0  1.331538         2  1.458642         1  0.368995         0  0.778579         0  0.708671        0  0.626804\n",
      "        1  -0.582758         0 -0.471867         0  0.744771         1  0.328381         0  0.150851         0  0.131216        0  0.296717\n",
      "       18  20.255373         2  7.890120         0  1.458642         2  0.589278         0  1.354989         0  0.708671        0  0.953395\n",
      "        0   2.389814         0 -0.741387         0  0.744771         0  0.302566         0 -0.146124         0  0.059444        0  0.314914\n",
      "        0  -0.899060         0 -1.078120         0  0.744771         0  0.293357         0  0.205623         0  0.059444        0  0.314914\n",
      "        0   1.937234         0  2.690820         3  1.458642         1  0.973077         0  2.041846         6  1.855717        0  0.614912\n",
      "        0  -1.376982         0 -1.079044         0  0.744771         0  0.293357         0 -0.146124         0  0.059444        0  0.314914\n",
      "        0   1.315695         1 -0.064711        37 32.035645         8  1.235205         0  2.641720         2  0.802881        8  4.476591\n",
      "        0  -0.916021         0 -0.471867         0  1.115831         0  0.361301         0  0.390113         0  0.131216        0  0.268690\n",
      "        0   0.975807         1  1.198243         0  1.458642         1  0.799580         3  0.511971         1  0.432399        0  0.602581\n",
      "        0   0.584577         0  0.603512         0  0.744771         2  0.398916         2  0.015394         0  0.131216        0  0.321343\n",
      "        0   1.047417         0  1.034640         0  1.458642         0  0.646589         0  0.755697         0  0.313421        0  0.608483\n",
      "        0   0.343084         0 -0.741387         0  0.744771         0  0.302566         0 -0.146124         0  0.059444        0  0.314914\n",
      "        0   0.328107         0  0.471751         0  0.744771         0  0.299408         0  0.015394         0  0.131216        0  0.561282\n",
      "        0   3.810028         6  6.437601         0  1.458642         0  0.936588         0  0.755697         0  0.525767        0  0.614912\n",
      "        0   0.859360         0  0.999841         1  0.744771         0  0.318670         0  0.015394         0  0.271790        0  0.321343\n",
      "        6   2.470807         1  2.245958         4  1.458642         2  1.030074         4  0.755697         3  0.432399       37  7.716683\n",
      "        0   1.217735         2  0.799154         0  1.458642         0  0.764847         0  0.365731         0  0.185364        0  0.732764\n",
      "        0   0.586897         0  0.602588         0  0.744771         0  0.334868         0  0.015394         0  0.131216        0  0.321343\n",
      "        0  -0.916021         0 -0.471867         0  1.115831         0  0.361301         0  0.390113         0  0.131216        0  0.268690\n",
      "        1   2.348659         1  2.017477         0  1.458642         0  0.876466         0  0.755697         0  0.525767        0  0.608483\n",
      "        4   8.765801         0  5.150026         0  1.458642         0  0.832012         0  1.184288         0  0.708671        0  0.750607\n",
      "        1   0.743687         0  0.901987         0  1.458642         0  0.997110         0  0.511971         0  0.432399        1  0.614912\n",
      "        2   8.366865         0  5.458375         0  1.458642         1  0.973077         1  0.755697         0  1.193665        0  0.727508\n",
      "        1   3.155292         0  2.515452        11  1.996623        19  0.835777         0  1.440393         1  0.313421        1  0.994703\n",
      "        0   0.386587         0 -0.107712         0  0.744771         0  0.328270         1  0.321552         0  0.131216        0  0.349370\n",
      "        4   0.090512         0  0.305998         0  1.458642         1  0.635620         0  0.341270         0  0.291825        0  0.553523\n",
      "        0   1.591109         2  1.381378         4  1.829701         3  1.806483         0  1.057391         0  0.432399        1  0.614912\n",
      "        2   1.119443         2  0.800046         6  1.458642         8  0.973077         5  0.755697         0  0.525767        2  0.614912\n",
      "        3   8.020734         4  5.120960         0  1.458642         0  0.997110         0  0.511971         0  0.404334        0  0.229318\n",
      "        0   1.139014         0  1.400576         0  0.744771         0  0.326867         0  0.015394         0  0.131216        0  0.321343\n",
      "        0   1.403351         0  0.661189         3  1.458642         0  0.649663         1  0.511971         0  0.432399        1  0.602581\n",
      "        0  -1.205588         0 -0.783663         0  0.744771         0  0.293357         0 -0.146124         0  0.059444        0  0.314914\n",
      "        0  -1.129437         0 -0.827131         1  0.744771         1  0.407677         0  1.029487         0  0.131216        0  0.268690\n",
      "        3   0.765717         1  0.695163         1  1.458642         0  0.539025         0  0.594179         0  0.313421        0  0.608483\n",
      "        7   1.591109         5  2.353405         0  1.458642         0  0.960820         0  1.798118         0  1.049549        0  0.614912\n",
      "       42   3.015619        35  1.458587         0  1.458642         0  0.679963         0  0.511971         0  0.291825        2  0.602581\n",
      "        1   1.642940         3  2.245958         7  1.458642         5  1.023004         6  3.133467         0  0.432399        0  0.614912\n",
      "        0   1.415803         0  1.005989         0  1.458642         0  3.781966         0  1.696764         0  0.432399        0  0.602581\n",
      "        1   0.823440         0  0.925706         0  1.458642         0  0.844122         0  0.511971         0  0.291825        0  0.614912\n",
      "        0  -0.478293         0  0.722452         3  1.458642         0  0.931958         0  0.511971         0  0.432399        1  0.614912\n",
      "        0   1.715387         4  1.908543         8  1.458642         2  5.237871         0  0.511971         3  1.613378        1  0.941194\n",
      "        0   2.838208         0  0.791456         1  1.458642         1  0.908197         0  0.755697         0  0.525767        0  0.614912\n",
      "        0   3.989039         7  3.496810         3  1.458642         9  1.910401         0  0.755697         4  0.432399        0  0.614912\n",
      "        0   1.811096         0  0.872487         2  0.744771         3  0.326867         0  0.321552         0  0.131216        0  0.349370\n",
      "        5   4.760408         5  2.589083         2  1.458642         3  0.688726         2  0.341270        32  0.291825        2  0.553523\n",
      "        1   1.591109         1  1.198243         0  1.829701         1  1.775829         2  1.057391         0  0.432399        2  0.614912\n",
      "        0   1.591109         4  1.198243        15  9.224761         4  1.230827         0  2.559512         2  0.921858        2  5.791870\n",
      "        5   3.782010         9  6.468126         1  1.458642         0  1.033671         0  0.511971         0  0.432399        0  0.614912\n",
      "        3   3.025656         1  0.981206         1  1.458642         0  0.910890         0  0.511971         0  0.432399        0  0.614912\n",
      "        4  13.598861         6  8.889608         4  1.458642         2  0.832012         4  1.184288         1  0.680607        1  0.229318\n",
      "        0   3.989039         2  3.496810         0  1.458642         0  1.910401         1  0.755697         4  0.432399        0  0.602581\n",
      "        0   1.591109         2  1.381378         2  1.458642         5  0.950517         0  0.511971         0  0.432399        8  0.614912\n",
      "        0   0.721036         2  1.198243         1  1.458642         2  0.941082         5  0.511971         1  0.432399        0  0.614912\n",
      "        0   4.532873         1  4.305781         0  1.458642         0  1.646566         1  5.300229         2  2.858531       12  3.725250\n",
      "       49  10.850116         7  5.468280        11  1.996623         7  0.835777         0  1.193471         0  0.648010        4  1.247010\n",
      "        0   1.053632         0  0.417010         0  0.744771         0  0.323375         0  0.282003         0  0.223108        0  0.376602\n",
      "        0  -0.284097         0  0.670154         0  1.458642         0  0.626184         0  0.341270         0  0.291825        0  0.553523\n",
      "        8   3.065784        11  3.183933        13  3.644618        12  6.419558         1  0.755697         1  0.432399        2  0.614912\n",
      "        0   1.157013         0  1.058287         0  1.458642         0  4.372991         0  1.696764         0  0.432399        0  0.614912\n",
      "        1   1.889472         0  4.727581         0  1.458642         0  0.628868         0  0.594179         0  0.313421        0  0.608483\n",
      "        0  -0.420557         0 -0.107712         0  1.115831         1  0.361301         1  0.144716         0  0.131216        0  0.317748\n",
      "        0  -1.624900         0 -1.191287         0  0.744771         2  0.407677         4  0.784090         0  0.131216        0  0.268690\n",
      "        2   4.601485         1  4.056055         2  1.458642         2  1.116104         2  5.056503         0  0.672521        0  0.665502\n",
      "        0   0.593630         0  0.759945         0  1.458642         0  0.493076         0  0.365731         4  0.704413        0  0.987071\n",
      "        0   1.109367         1  1.718793        12  1.458642         7  0.966007         3  3.133467         0  0.525767        0  0.614912\n",
      "        0   1.002926         0  0.759945         6  2.684085         0  1.430117         0  0.365731         1  0.185364        4  0.886495\n",
      "        0   1.217735         1  0.799154         1  1.458642         0  0.776216         0  0.563829         0  0.185364        0  0.732764\n",
      "        0  -0.235991         0 -1.314195         0  0.744771         0  0.321638         0 -0.094266         0  0.467187        0  0.347990\n",
      "        0  -1.743573         0 -1.959219         0  0.744771         0  0.321446         0 -0.094266         0  0.024756        0  0.241680\n",
      "        0   0.661370         0  0.602588         0  0.744771         0  0.333761         0  0.321552         0  0.271790        0  0.349370\n",
      "        0   0.801066         3  0.722452         1  6.665905         0  1.122557         0  2.559512         0  0.921858        3  1.021724\n",
      "        0   1.261715         0  0.890781         1  2.684085         2  1.430117         0  0.563829         0  0.185364        0  0.737690\n",
      "        0  -1.598353         0 -0.471867         1  0.744771         0  0.328381         0 -0.155307         0  0.131216        0  0.268690\n",
      "        0   0.417683         0  0.690277         0  0.744771         0  0.328381         0  0.015394         0  0.131216        0  0.317748\n",
      "        0   0.768604         0  0.143208         0  1.458642         0  0.788321         0  0.511971         0  0.432399        0  0.614912\n",
      "        0  -0.249446         0  0.166929         0  0.744771         0  0.333761         0  0.015394         0  0.131216        0  0.321343\n",
      "        1   1.893254         2  1.941136         0  1.458642         0  0.978714         2  0.755697         0  0.432399        3  0.614912\n",
      "        2   4.772635         1  1.718793         0  1.458642         1  0.973077         2  0.755697         0  0.432399        1  0.614912\n",
      "        3   3.371780         0  1.318621         0  1.458642         0  0.913043         0  0.755697         0  0.432399        0  0.614912\n",
      "        0   2.182323         0  2.193660         1  1.458642         1  1.027768         0  0.755697         0  0.432399        0  0.614912\n",
      "        6   2.541738         1  1.995308         0  1.829701         0  2.219221         0  1.057391         0  0.291825        0  0.602581\n",
      "        0   0.975807         0  1.198243         0  1.458642         1  1.051233         1  0.511971         0  0.432399        0  0.614912\n",
      "        1   3.324573         3  3.000799        10  3.644618        14  5.068421         6  0.755697         4  0.432399        2  0.602581\n",
      "        0  -1.683688         0 -0.927539         0  0.744771         0  0.328381         0 -0.400704         0  0.131216        0  0.268690\n",
      "        2   1.527939         1  1.718793        11  1.458642        17  1.771148         3  0.755697         5  5.045707        0  0.726381\n",
      "        4   2.535871         3  1.908543         7  1.458642         0  0.908818         2  0.511971         6  0.432399        0  0.614912\n",
      "        5   4.601485         3  4.056055         1  1.458642         1  1.116104         3  5.056503         2  0.672521        2  0.665502\n",
      "        0   1.219043         1  0.872487         0  0.744771         0  0.377312         0  0.015394         0  0.131216        1  0.321343\n",
      "        0   4.259812         0  3.920694         0  1.458642         3  1.912708         0  0.755697         0  0.525767        0  0.614912\n",
      "        4   4.184431        15  3.969290         3  1.458642         2  1.621568         5  5.056503         0  1.778384        4  1.961799\n",
      "        2   2.470807         0  2.245958         7  1.829701        16  1.247932         3  1.301117         1  0.432399        1  0.614912\n",
      "        2   1.769031         3  2.017477         3  1.458642         1  0.876466         1  0.755697         0  0.525767        0  0.608483\n",
      "        3   1.277261         4  1.246017         3  1.458642         6  1.033617         1  0.511971         0  0.432399        0  0.614912\n",
      "        0  -0.420557         0 -0.107712         0  0.744771         0  0.328381         0 -0.155307         0  0.131216        0  0.268690\n",
      "        0   2.196024         0  1.849629         0  1.458642         0  1.009367         0  0.755697         0  2.093698        0  0.614912\n",
      "        0   0.991485         0 -0.621339         0  1.458642         0  0.584554         0  0.341270         0  0.291825        0  0.553523\n",
      "        0   0.672300         0  0.212538         0  0.744771         1  0.329019         0 -0.079747         0  0.271790        0  0.321343\n",
      "        0  -0.205466         0 -0.055414         0  0.744771         0  0.377312         0  0.015394         0  0.271790        0  0.321343\n",
      "        1   6.667450         0  2.955920         0  0.744771         0  0.293357         0 -0.146124         0  0.727341        0  5.488215\n",
      "        1   0.328107         0  0.471751         0  0.744771         0  0.299408         0  0.015394         0  0.271790        0  0.321343\n",
      "        2   1.217735         2  0.982289         1  1.458642         0  0.886134         0  0.563829         1  0.185364        0  0.703154\n",
      "        2   2.470807         2  2.245958         2  1.458642         0  0.968734         0  0.755697         0  0.432399        0  0.614912\n",
      "        4   5.771241         1  2.700039         0  1.458642         4  0.973077         0  0.755697         0  0.432399        1  0.614912\n",
      "        0   1.593429         0  1.197319         0  1.458642         0  1.033617         0  0.511971         0  0.432399        0  0.757815\n",
      "        0   8.429053         3  3.949796         0  1.458642         0  3.351725         0  1.354989         0  2.187438        0  0.988347\n",
      "        0  -0.382448         0  0.055298         0  0.744771         0  0.328381         0 -0.155307         0  0.131216        0  0.268690\n",
      "        5   3.232576         6  2.330674         1  1.458642         1  0.950517         0  0.511971         0  0.432399        0  0.655120\n",
      "        0   2.124682         4  3.721480         0  1.458642         0  1.033617         0  0.511971         0  0.432399        1  0.614912\n",
      "        0  -0.704020         0 -0.335676         0  0.744771         0  0.321638         0 -0.250447         0  0.457150        0  0.352987\n",
      "        0   5.842172         1  2.449390         0  1.458642         1  0.621173         2  0.511971         0  0.291825        0  0.553523\n",
      "        0   1.678832         0  0.990404         0  1.458642         1  1.009367         0  0.416830         0  0.432399        0  0.614912\n",
      "        6   1.442350         0  1.908543         1  1.458642         2  1.027922         1  0.511971         0  0.432399        0  0.614912\n",
      "        0   1.851022         0  1.634707         0  1.458642         0  0.853423         1  0.755697         0  0.525767        0  0.614912\n",
      "        0   0.803380         0  1.246017         0  1.458642         0  0.892280         0  0.511971         0  0.432399        1  0.602581\n",
      "       31   6.053883         5  5.645665        16  1.458642         5  1.516909         3  5.738002         0  1.513790        0  2.502246\n",
      "        0   1.937234         0  1.849629         1  1.458642         0  0.973077         0  0.755697         0  0.432399        0  0.614912\n",
      "       14   2.124682         8  1.908543         1  1.458642         0  1.027922         1  0.511971         0  2.093698        0  0.614912\n",
      "        4   9.779175         1  5.062486         0  1.458642         2  0.704520         1  0.755697         0  0.313421        0  0.608483\n",
      "        0   4.512249         0  3.460084         0  1.458642         0  0.979147         0  1.354989         0  1.127564        1  0.953395\n",
      "        0   3.025656         2  0.981206         2  1.458642         0  0.910890         0  0.511971         0  0.432399        0  0.614912\n",
      "        0   1.005061         0  1.381378         0  1.458642         2  0.960820         3  0.511971         0  0.432399        3  0.614912\n",
      "        1   2.893234         1  1.468143         1  1.458642         1  0.552133         0  0.511971         0  0.291825        0  0.602581\n",
      "        4   8.294546         9  6.458946         3  1.458642         0  1.030074         1  0.755697         2  0.432399        1  0.614912\n",
      "        0   5.165650         4  3.921338         5  1.458642         0  0.881530         3  1.354989         3  0.708671        1  1.328440\n",
      "        0  -0.478293         0  0.853288         2  1.458642         1  0.931958         0  0.511971         0  0.432399        0  0.614912\n",
      "        0   1.370866         0  1.045807         1  1.458642         1  3.230771         0  0.511971         0  0.432399        0  0.614912\n",
      "        6   1.247354        12  1.718793         5  1.458642         3  0.973077         4  0.755697         1  0.432399        4  2.846090\n",
      "        1   1.923533         0  2.245958         0  1.458642         1  1.030074         2  0.755697         0  0.432399        0  0.614912\n",
      "        0   0.624084         0  0.833164         2  1.458642         0  0.627385         1  0.341270         0  0.291825        0  0.553523\n",
      "        6  11.888734         0  6.603739         2  1.458642         0  1.030074         0  0.755697         0  0.432399        0  0.614912\n",
      "        0   5.077686         0  4.238266         0  1.458642         0  1.646018         0  5.056503         0  2.239916        0  2.816071\n",
      "        0   1.815086         0  1.490312         0 32.035645         0  8.712127         0  2.803238         0  0.802881        0  8.045871\n",
      "        0   4.193608         0 -1.008667         0  1.458642         0  0.398067         0  0.350452         0  0.313421        0  0.608483\n",
      "        0   1.591109         0  1.198243         0  1.458642         0  0.950517         0  0.511971         0  0.432399        0  0.614912\n",
      "        6   4.186750         4  3.785232         0  1.458642         2  1.650108         0  5.056503         5  1.415201        2  2.093334\n",
      "        0   1.591109         0  1.381378         0  1.458642         0  0.997110         0  0.511971         0  0.432399        0  0.614912\n",
      "        0   0.328107         0  0.471751         0  0.744771         0  0.299408         0  0.015394         0  0.131216        0  0.321343\n",
      "       13   5.043502         0  3.843347         0  1.458642         0  1.422193         0  1.354989         0  1.127564        0  0.953395\n",
      "        1   2.124682         1  3.904614         3  1.458642         0  1.034816         0  0.511971         0  0.432399        0  0.614912\n",
      "        0   0.328107         0  0.602588         0  0.744771         0  0.299408         0  0.015394         0  0.131216        0  0.276118\n",
      "        2   1.924372         1  1.381378         1  1.458642         0  1.329061         0  0.818128         0  0.432399        0  1.353004\n",
      "        0   0.865874         0  0.417010         0  0.744771         0  0.323375         0  0.282003         0  0.223108        0  0.376602\n",
      "        0   1.119548         1  3.193391         0  1.458642         1  0.688726         0  0.341270         1  0.291825        0  0.553523\n",
      "        0   1.332319         0  1.250541         0  1.458642         0  0.931958         0  0.511971         0  0.432399        0  0.614912\n",
      "        4   1.751861         2  1.625583         0  1.458642         0  0.954392         1  0.755697         0  1.100050        0  0.608483\n",
      "        1   0.444554         0  0.670154         0  1.458642         0  1.048927         0  0.511971         0  0.432399        0  0.614912\n",
      "        2   4.138302         0  1.995308         0  1.458642         0  0.679963         0  0.511971         0  0.291825        0  0.602581\n",
      "        1   1.591109         0  1.198243         9  9.224761         3  1.230827         1  2.559512         0  0.921858        4  5.791870\n",
      "        1  -0.455415         0  0.167073         0  1.458642         0  0.539025         0  0.594179         0  0.313421        0  2.014801\n",
      "        3   3.371780         0  1.318621         0  1.458642         0  0.913043         0  0.755697         0  0.525767        0  0.614912\n",
      "        0  -1.188225         0 -0.563384         0  0.744771         0  0.328381         0 -0.155307         0  0.131216        0  0.317748\n",
      "        5   4.530554         3  4.306705         1  1.458642         5  1.661984         6  5.300229         1  1.778384        1  1.895777\n",
      "        0  -1.791636         0 -0.783663         0  0.744771         0  0.293357         0 -0.146124         0  0.059444        0  0.314914\n",
      "       13  20.255373        10  8.020956         0  1.458642         0  0.589278         0  1.354989         0  0.708671        0  0.770055\n",
      "        0   1.937234         2  1.718793         0  1.458642         2  0.973077         0  0.755697         1  0.432399        0  0.614912\n",
      "        0   1.937234         0  1.718793         0  1.458642         2  1.662252         0  0.755697         0  0.756001        0  6.147016\n",
      "        0   0.859360         0  0.999841         0  0.744771         0  0.299408         0  0.015394         0  0.271790        0  0.321343\n",
      "        3  11.476800         0  4.955270         0  1.458642         0  0.533658         0  1.174796         0  0.313421        0  0.608483\n",
      "        0  -1.074367         0 -1.270375         0  0.744771         0  0.293357         0  1.390417         0  0.059444        0  0.314914\n",
      "        0   0.211203         0  0.204423         0  0.744771         0  0.323375         0  0.067252         0  0.024756        0  0.285867\n",
      "        4   6.100527         0  1.098418         2  1.458642         0  2.879361         1  0.755697         1  0.525767        0  0.608483\n",
      "        1   2.532211         0  2.525932        17  3.644618        16  5.880745         2  0.755697         0  0.525767        0  0.614912\n",
      "        0   0.975807         0  1.198243         1  1.458642         0  0.969597         0  0.511971         1  0.432399        0  0.602581\n",
      "        3   1.937234         2  1.718793         2  1.458642         1  0.973077         0  0.755697         0  0.432399        5  0.614912\n",
      "       18   6.000551         9  5.118500         7  1.458642         1  1.828136         6  5.738002         4  1.188835        1  2.554521\n",
      "        2   1.357607         3  1.718793         0  1.458642         0  0.973077         2  0.755697         0  0.432399        0  0.614912\n",
      "        0   1.591109         0  1.381378         9  1.458642         0  1.187017         0  0.511971         0  0.432399        6  0.614912\n",
      "        2   2.040254         0  2.193660         0  1.458642         0  0.948438         0  0.755697         0  0.432399        0  0.602581\n",
      "        0   1.656765         0  1.658697         0  1.458642         0  0.514638         0  0.365731         3  1.286743        0  0.987071\n",
      "        3   1.738807         8  3.594562         0  1.458642         1  1.030074         1  0.395627         0  0.525767        1  0.614912\n",
      "        0   0.014847         0  0.118742         0  0.744771         0  0.321446         0 -0.130846         0  0.024756        0  0.241680\n",
      "        6   2.618691         0  2.090378         0  1.829701         0  1.244712         0  1.301117         0  0.525767        0  0.614912\n",
      "       28  17.214409         2  5.006978         0  1.458642         1  0.574660         0  0.511971         0  0.432399        0  0.602581\n",
      "        1   1.261715         1  0.890781        25  2.684085        14  1.466408         1  0.563829         0  0.185364        0  0.737690\n",
      "        0  -1.708696         0 -1.568716         0  0.744771         0  0.322713         0 -0.292364         0  0.024756        0  0.326666\n",
      "        9   6.510598         3  5.916807        11  1.996623        11  0.835777         2  2.039686         1  0.802609        2  1.339616\n",
      "        0   0.328107         0  0.471751         0  0.744771         0  0.299408         0  0.015394         0  0.131216        0  0.321343\n",
      "        0   2.838208         0  0.791456         0  1.458642         1  0.908197         0  0.755697         2  0.432399        0  0.614912\n",
      "       34   9.901322        13  5.290967         0  1.458642         0  0.973077         1  0.755697         1  0.432399        1  0.614912\n",
      "        0   0.857670         0  0.843338         0  0.744771         0  0.377312         0  0.015394         0  0.131216        0  0.321343\n",
      "        2   1.815086         3  1.490312         2  1.458642         2  0.704520         2  0.755697         0  0.525767        0  0.608483\n",
      "        0   2.025161         0  1.998313         0  1.458642         0  1.652212         0  0.594179         0  0.313421        0  0.608483\n",
      "        2   1.332319         0  1.250541         1  1.829701         4  1.244712         1  1.057391         0  0.432399        2  0.614912\n",
      "        2   2.457945         0  1.725409        12  1.458642         3  1.365568         0  0.818128         0  0.432399        1  1.414115\n",
      "        0   1.591109         0  1.198243         0  1.458642         0  0.649663         0  0.511971         0  0.432399        0  0.602581\n",
      "        0   1.937234         0  1.718793         0  1.458642         2  1.138931         0  0.755697         0  0.432399        0  0.614912\n",
      "        1   1.059856         4  0.670154         0  1.829701         0  2.241141         0  0.641293         0  0.291825        0  0.602581\n",
      "        0   3.248437         2  5.757827         0  1.458642         0  0.874630         1  0.511971         0  0.432399        0  0.602581\n",
      "        0   1.937234         1  1.718793         1  1.458642         0  0.973077         0  0.755697         0  0.432399        0  6.587885\n",
      "        5   1.937234         1  1.042260         0  1.458642         0  1.017408         0  0.755697         0  0.432399        0  0.614912\n",
      "        0   1.332319         0  1.250541         5  9.224761         0  1.122557         0  2.559512         0  0.921858        1  4.586046\n",
      "        0   1.181813         0  1.198243         0  1.458642         0  1.767039         0  0.511971         0  2.468283        0  0.846228\n",
      "        0   0.064632         0  0.026507         0  0.744771         0  0.321446         0  0.282003         0  0.223108        0  0.241680\n",
      "        7   9.901322         9  5.290967         0  1.458642         2  0.973077         0  0.755697         0  0.525767        2  0.614912\n",
      "        0   1.018471         0  1.298315         0  1.458642         0  1.000464         0  0.511971         3  0.525767        0  0.614912\n",
      "        2   3.591777         9  3.445281         3  1.996623         2  1.990706         0  0.511971         1  0.432399        3  1.001132\n",
      "        0  -1.910555         0 -1.606210         0  0.744771         3  0.293357         0 -0.146124         0  0.059444        0  0.314914\n",
      "        5   0.053324         0  0.075422         0  0.744771         0  0.328270         0  0.015394         0  0.131216        0  0.561282\n",
      "        0  -0.052576         0 -0.694927         0  0.744771         0  0.321638         0 -0.292364         0  0.467187        0  0.347990\n",
      "        0  -0.585518         0  0.419453         0  0.744771         0  0.328381         0  0.284037         0  0.131216        0  0.268690\n",
      "        0   0.113016         0  0.419453         0  0.744771         0  0.328381         0 -0.155307         0  0.131216        0  0.268690\n",
      "        1   1.261715         0  0.707647         0  1.458642         0  0.870194         0  0.563829         0  0.185364        1  0.703154\n",
      "        6   4.887608         3  4.056055         3  1.458642         3  1.116104         9  5.056503         1  0.672521        1  0.744898\n",
      "        0  -0.897566         0 -0.335205         0  0.744771         0  0.320808         0 -0.155307         0  0.131216        0  0.192622\n",
      "        1   0.232145         0  0.167997         0  1.458642         0  0.537474         0  0.594179         0  0.313421        1  0.608483\n",
      "        0   0.618514         1  1.946102         2  1.458642         0  0.649663         0  1.871648         0  0.432399        0  0.602581\n",
      "        0   1.591109         0  1.381378        21  9.224761         6  1.122557         3  2.559512         0  0.921858        0  4.586046\n",
      "        5  20.255373         9  7.890120         0  1.458642         0  0.589278         0  1.354989         0  0.708671        0  0.953395\n",
      "        8   3.407230         2  2.530589         0  1.458642         1  1.478176         4  1.193471         2  0.802609        4  0.860790\n",
      "        1   1.119548         1  1.197319         1  1.458642         0  0.737656         0  0.341270         0  0.291825        0  0.553523\n",
      "        2   2.046275         6  3.627224         0  1.458642         2  0.679963         0  0.511971         0  0.291825        0  0.553523\n",
      "        0   1.648749         0  1.849629         1  1.458642         0  0.973077         0  0.755697         0  0.432399        1  0.614912\n",
      "        2   1.937234         6  2.690820         2  1.458642         0  0.973077         0  2.041846         0  1.762349        1  0.614912\n",
      "        0   1.245959         0  0.695163         0  1.458642         0  0.539025         0  0.594179         0  0.313421        0  0.608483\n",
      "        0   1.609563         0  1.334906         0  1.458642         0  0.810683         0  0.511971         0  0.432399        0  0.526513\n",
      "        0   2.026619         0  1.604805         0  1.458642         0  0.557836         0  0.511971         0  0.291825        0  0.526513\n",
      "       26  17.214409         6  5.006978         0  1.458642         0  0.653991         0  0.511971         0  0.432399        0  0.614912\n",
      "        0   8.900437         5  5.985540         1  1.458642         0  1.030074         0  0.755697         0  0.404334        0  0.666994\n",
      "        6   1.261715         3  0.890781        36  2.684085        17  1.430117         1  0.563829         0  0.185364        1  0.737690\n",
      "        0   2.838208         0  0.791456         0  1.458642         0  0.908197         0  0.755697         0  0.432399        0  0.614912\n",
      "        2   2.311687        10  2.530589         4  1.458642         1  1.237813         3  1.193471         2  0.802609        1  0.860790\n",
      "        0   1.591109         1  0.661189         0  1.458642         0  0.868880         1  0.511971         0  0.432399        0  0.602581\n",
      "        4   1.332319         0  1.250541         1  1.458642         0  0.931958         0  0.511971         0  0.432399        2  6.587885\n",
      "        1   0.255183         0  0.112916         0  0.744771         0  0.323375         0  0.067252         0  0.024756        0  0.285867\n",
      "        6   6.408030         1  3.852903        19  1.458642        11  1.246527        28  1.840007         5  1.350978        4  2.025692\n",
      "        0   0.741308         0  4.087716         0  0.744771         1  0.328381         0 -0.155307         0  0.131216        0  0.268690\n",
      "        0   4.010538         0  2.297881         0 32.035645         0  1.235205         0  3.241012         0  1.292068        0  4.476591\n",
      "        8   4.264946         4  2.224928        25  1.458642        16  0.688726         8  0.341270         1  0.291825        1  0.553523\n",
      "        0   2.470807         0  2.376794         0  1.458642         0  1.001226         0  0.755697         0  0.432399        0  0.614912\n",
      "        0  -0.394510         1 -0.107712         0  0.744771         0  0.328270         0  0.015394         0  0.271790        1  0.580523\n",
      "        0  -0.009369         0 -0.107712         0  0.744771         0  0.328381         0 -0.400704         0  0.131216        0  0.317748\n",
      "        1   0.823440         3  0.742572         1  1.458642         0  0.589071         0  0.511971         0  0.432399        0  0.602581\n",
      "       22   7.379682        14  3.546542         3  1.458642         7  4.163841         0  1.193471         3  1.501969        1  0.895742\n",
      "        3   5.941471         9  5.121657         2  1.996623         9  0.835777         0  1.193471         0  1.127564        0  1.247010\n",
      "        1   1.872904         2  2.617544         1  1.458642         0  1.030074         0  0.755697         0  0.525767        0  0.614912\n",
      "       30  17.560534         0  5.527528         0  1.458642         1  0.650448         0  0.755697         0  0.525767        0  0.614912\n",
      "        3   7.105570         4  6.439890         6  1.458642         4  1.699737        10  5.899521         6  3.134804        5  3.833365\n",
      "        0   1.389960         0  1.718793         0  1.458642         0  0.973077         0  0.755697         1  0.432399        0  0.614912\n",
      "        0   2.347361         5  2.530589         0  1.458642         0  1.237813         1  1.193471         0  0.802609        0  0.860790\n",
      "        0   1.332319         0  1.250541         5  1.829701         0  1.244712         1  1.057391         2  0.432399        2  0.614912\n",
      "        0   1.176988         0  1.194876         0  1.458642         2  0.493076         0  0.778579         0  0.457150        2  0.878948\n",
      "        3   0.957347         1  0.833164         2  1.458642         0  1.078563         0  0.647428         0  0.291825        0  1.045664\n",
      "        4   5.876551         6  1.198243         2  1.458642        12  1.899731         4  0.511971         0  0.432399        0  0.614912\n",
      "        1   4.347858         0  3.820638         0  1.458642         2  0.969727         2  1.354989         0  0.708671        0  0.770055\n",
      "        0  -0.205466         0 -0.055414         0  0.744771         0  0.299408         0  0.015394         0  0.271790        0  0.321343\n",
      "        0   0.650233         0  0.880831         1  0.744771         0  0.321638         0 -0.130846         0  1.286743        0  0.395035\n",
      "        0  -0.897049         0 -1.451841         0  0.744771         0  0.293357         0  1.038669         0  0.059444        0  0.314914\n",
      "        0   0.386587         0  0.075422         0  0.744771         3  0.328270         0  0.321552         0  0.131216        0  0.349370\n",
      "        0   0.766284         0  0.327267         0  1.458642         0  0.784728         0  0.511971         0  0.432399        0  0.614912\n",
      "        5   1.937234         2  1.042260         1  1.458642         2  1.017408         0  0.755697         0  0.432399        0  0.614912\n",
      "        2   4.509930         1  3.461009         2  1.458642         2  0.912730         1  1.354989         0  0.802609        5  0.953395\n",
      "        4   1.799713         9  1.468143         4  1.458642         1  0.621173         0  0.511971         6  0.291825        0  0.602581\n",
      "       12   4.950894         0  3.672016         0  1.458642         1  0.973077         0  0.755697         0  0.525767        0  0.614912\n",
      "       12   1.547129         9  1.472885         0  1.458642         0  0.976561         0  0.511971         0  0.432399        0  0.614912\n",
      "        2   1.715387         1  1.725409         6  1.458642        11  1.586169         1  0.511971        12  1.140069        3  0.907570\n",
      "        2   4.615040         5  2.402217         0  1.458642         0  0.973077         0  0.755697         0  0.432399        0  0.614912\n",
      "        0   0.672300         0  0.212538         0  0.744771         0  0.329019         0 -0.079747         3  0.271790        0  0.321343\n",
      "        0   1.109367         0  1.718793         0  1.458642         2  0.966007         0  3.133467         0  0.525767        0  0.614912\n",
      "        0   0.126622         0  1.190704         1  1.458642         0  0.973077         0  0.755697         1  0.432399        1  0.614912\n",
      "        0   2.482046         0  1.468143         1  1.458642         0  1.967705         0  0.511971         1  0.291825        1  0.602581\n",
      "        3   1.468722         0  1.195494         0  1.458642         1  0.639347         0  0.511971         0  0.291825        0  0.553523\n",
      "        2   3.025656         2  0.981206         0  1.458642         0  0.917785         0  0.511971         0  0.432399        0  0.614912\n",
      "        0   0.584577         0  0.066457         0  0.744771         0  0.337479         0  0.015394         0  0.271790        0  0.321343\n",
      "        1   1.467660         0  1.209805         2  1.458642         1  1.092438         0  0.755697         2  0.432399        0  0.614912\n",
      "        0  -0.365487         0 -0.550955         0  0.744771         0  0.293357         0 -0.146124         0  0.059444        0  0.314914\n",
      "        7   5.695213         5  4.292925         2  1.458642         0  0.881530         1  1.354989         0  1.127564        0  1.521199\n",
      "        1   2.470807         4  2.376794         0  1.458642         3  2.166435         0  0.755697         0  0.432399        2  0.614912\n",
      "        0  -0.062149         0  0.695163         0  1.458642         0  1.412862         0  2.971949         0  0.313421        0  0.608483\n",
      "        1   1.181813         6  1.198243         3  1.458642         7  1.767039         0  0.511971         1  2.468283        0  0.833898\n",
      "        6   8.020734         1  4.937826         1  1.458642         0  0.948210         0  0.511971         0  0.404334        0  0.229318\n",
      "        0   3.371780         0  1.318621         0  1.458642         0  0.913043         0  0.755697         0  0.525767        0  0.614912\n",
      "        0   2.764349         0  1.549069         0  0.744771         0  0.293357         0 -0.146124         0  0.059444        0  0.314914\n",
      "       11  10.885522        17  8.715766         2  1.458642         0  0.973077         2  0.755697         0  0.525767        0  0.614912\n",
      "        2   2.470807         0  1.709237         0  1.458642         0  1.030074         0  0.755697         0  0.432399        0  0.614912\n",
      "        9   8.054597         1  3.878173         2  1.458642         0  0.635620         0  0.341270         0  0.291825        0  0.553523\n",
      "        0   1.127203         0  1.287110         0  1.458642         0  0.514638         0  0.365731         0  1.286743        0  0.987071\n",
      "        0   2.470807         0  2.245958         0  1.458642         0  0.968734         0  0.755697         0  0.525767        0  0.614912\n",
      "       16   8.568498        12  3.893164         4  1.458642         4  4.259791         4  1.193471         2  1.022415        1  0.895742\n",
      "        1   2.124682         1  1.371488         0  1.458642         0  1.035923         0  0.511971         0  0.432399        0  0.614912\n",
      "        0   0.328107         0  0.471751         0  0.744771         0  0.377312         0  0.015394         0  0.131216        0  0.321343\n",
      "        1   1.937234         0  1.718793         5  1.458642         2  1.138931         1  0.755697         0  0.432399        1  0.614912\n",
      "        8   3.025656         2  0.981206         0  1.458642         1  0.910890         9  0.511971         1  0.432399        2  0.614912\n",
      "        0   1.389960         2  1.718793         1  1.458642         1  0.973077         0  0.755697         0  0.432399        0  0.614912\n",
      "        0  13.541750         0  6.738773         0  1.458642         0  1.030074         0  1.336314         1  0.432399        2  0.614912\n",
      "        0   2.470807         0  1.569425         0  1.458642         0  1.030074         0  0.755697         0  0.432399        0  0.614912\n",
      "        0   0.721036         0  1.381378         0  1.458642         2  0.951384         2  0.511971         3  0.432399        0  0.614912\n",
      "        0   2.719659         1  2.715682         0  3.644618         2  5.134838         0  0.511971         0  0.432399        0  0.614912\n",
      "        2   2.168198         4  1.515917         5  1.458642         6  0.863790         0  0.511971         0  0.291825        2  0.602581\n",
      "        4   2.470807         8  3.217985         3  1.458642         6  1.050221         0  2.041846         1  1.855717        0  0.614912\n",
      "       13   2.470807         1  2.245958         2  1.458642         3  1.030074         2  0.755697         0  0.432399       42  7.716683\n",
      "        0   0.712386         1  0.167997         0  1.458642         0  0.577668         0  0.945927         0  0.313421        0  0.608483\n",
      "        0   7.326351         0  3.019377         0  1.458642         0  4.242403         0  1.545219         0  1.177014        0  0.895742\n",
      "        0   1.018734         0  0.214485         1  0.744771         1  0.299408         0  0.321552         0  0.131216        0  0.349370\n",
      "        0  -0.821897         0 -0.783663         0  0.744771         0  0.293357         0 -0.146124         0  0.059444        0  0.314914\n",
      "        1   1.591109         0  1.381378         1  1.829701         1  1.806483         2  1.057391         0  0.432399        0  0.614912\n",
      "        2   3.460562         6  3.057754         3  1.458642         4  1.707728         3  1.193471         0  1.127564        2  0.860790\n",
      "        0   1.542304         0  1.286383         0  1.458642         0  0.764847         0  0.778579         0  0.708671        0  0.799665\n",
      "        2   1.655107         1  1.399555         3  1.458642         1  1.081172         0  0.511971         0  0.432399        5  0.614912\n",
      "        2   4.517587         1  0.167997         0  1.458642         3  2.786708         0  0.594179         0  0.313421        0  0.608483\n",
      "        0   1.230675         0  0.998450         0  1.458642         0  1.764765         2  1.940490         0  0.432399        0  0.614912\n",
      "        6   3.152264         6  2.617544         4  1.458642         6  1.030074         1  0.755697         1  0.525767        0  0.614912\n",
      "        0  -1.166344         0  0.419453         0  0.744771         1  0.328381         0 -0.155307         0  0.131216        0  0.317748\n",
      "       37   5.695213        21  5.952162         0  1.458642         0  0.989874         1  2.641139         0  2.457513        0  0.953395\n",
      "        0   2.291491         1  1.898124         2  1.458642         4  1.635875         4  1.940490         0  0.525767        0  0.614912\n",
      "        8   6.151396         8  4.802198         3  1.458642         1  1.341997         1  1.354989         0  0.802609        0  0.963984\n",
      "        0   1.236770         1  4.451872         0  0.744771         0  0.328381         0 -0.155307         0  0.131216        0  0.317748\n",
      "        3   2.728561         9  4.406358         3  1.458642         6  1.368796         1  0.833401         1  1.127564        1  0.860790\n",
      "        3   0.880777         1  0.139569        42  2.684085         8  1.476289         1  0.365731         8  0.604256       11  0.886495\n",
      "        0   1.002926         0  0.759945         0  1.458642         1  0.880496         0  0.365731         0  0.185364        0  0.703154\n",
      "        0   0.585975         0  0.670154         1  1.829701         2  2.241141         0  0.886690         0  0.291825        1  0.553523\n",
      "        0   0.944260         0  0.345322         0  0.744771         0  0.377312         0  0.015394         0  0.131216        0  0.321343\n",
      "        1   1.288339         0  1.472885         0  1.458642         3  0.983456         0  0.511971         0  0.432399        3  0.614912\n",
      "       44  13.419602        20  6.510291         9  1.458642         5  0.770937         5  1.336314         1  0.525767        1  0.608483\n",
      "        2   0.624084         1  0.833164         0  1.829701         0  2.213537         0  0.641293         0  0.291825        0  0.553523\n",
      "        0   1.715387         0  1.908543         0  1.458642         3  1.596914         8  0.511971         5  1.613378        0  0.919901\n",
      "        0   1.657147         0  0.695163         0  1.458642         0  0.481418         0  0.594179         0  0.313421        0  0.608483\n",
      "        3   3.591777         3  3.445281        14  1.996623         5  3.847970         4  0.511971         0  0.432399        2  1.001132\n",
      "        0   1.771270         0  1.610988        23  1.458642        10  0.973077         1  0.755697         0  0.525767        1  0.614912\n",
      "        0   0.270728         0  0.651286         0  0.744771         0  0.326867         0  0.015394         0  0.271790        2  0.321343\n",
      "        0   0.109792         0 -0.301179         0  1.458642         0  0.595778         0  0.702200         0  0.313421        0  0.751386\n",
      "        1   2.470807         1  2.245958         6  1.458642         4  1.030074         0  0.755697         0  0.432399        0  0.614912\n",
      "        0   1.923533         0  2.245958         1  1.458642         0  1.030074         8  0.755697         0  0.432399        0  0.614912\n",
      "        0  -0.916021         0 -0.471867         0  0.744771         0  0.328381         0 -0.155307         0  0.131216        0  0.268690\n",
      "        5   2.535871         2  1.725409         0  1.458642         0  0.648182         0  0.511971         0  0.432399        0  0.602581\n",
      "        7   3.407230         6  2.530589         0  1.458642         2  1.478176         0  1.545219         0  0.802609        0  0.860790\n",
      "        1   1.002926         0  0.759945         0  2.684085         0  1.430117         0  0.365731         0  0.185364        0  0.886495\n",
      "        0   5.530907         0  5.105854         0  1.458642         0  1.030074         1  0.755697         0  0.525767        0  0.614912\n",
      "        6   8.900437         4  5.985540         1  1.458642         0  1.030074         0  0.755697         0  0.404334        0  0.229318\n",
      "        0   3.374011         0  1.278496         0  1.458642         1  0.702769         0  0.341270         0  0.432399        1  0.553523\n",
      "       19  19.850134        15  5.870653         0  1.458642         9  0.366735         1  0.341270         2  0.291825        0  0.553523\n",
      "        0   1.865893         0  1.777707         6  1.458642         1  1.000464         0  0.511971         0  0.432399        0  0.614912\n",
      "        0   2.470807         0  1.583769         0  1.458642         0  1.030074         0  0.755697         1  0.432399        0  0.614912\n",
      "        0   1.109367         4  1.718793         2  1.458642         2  0.966007         2  3.133467         0  0.432399        0  0.614912\n",
      "        0   1.591109         1  1.198243        11  9.224761         1  1.230827         0  2.559512         2  0.921858        1  5.791870\n",
      "        1   5.165650         4  4.608549         1  1.458642         1  0.969727         0  1.354989         0  0.708671        0  0.770055\n",
      "       16   5.165650         8  4.739385         0  1.458642         0  0.969727         1  1.354989         0  0.708671        0  0.770055\n",
      "        0   0.763242         0  1.381378         1  1.458642         1  0.951228         1  2.889741         0  0.432399        0  0.614912\n",
      "        4   1.699128         2  1.634707         0  1.458642         0  0.759936         0  0.755697         1  0.525767        3  0.614912\n",
      "        0   1.305758         0  0.274177         0  3.644618         0  0.919761         0  0.350452         0  0.313421        0  0.608483\n",
      "        4   4.186750         3  3.968366         0  1.458642         3  1.651308         6  5.056503        12  2.380490        1  3.729303\n",
      "        6   5.064127        27  4.964706         6  1.458642         6  1.646566         7  5.300229         6  1.778384        2  3.672385\n",
      "        0   2.549507         0  1.848925         0  3.644618         0  1.013210         0  0.594179         0  0.313421        0  0.608483\n",
      "        1   0.362926         1  1.197319         0  1.458642         0  0.688726         0  0.341270         1  0.291825        0  0.602581\n",
      "        0   1.609563         1  1.334906         0  1.458642         0  0.890013         0  0.511971         0  0.432399        0  0.535249\n",
      "        0   2.827603         4  2.530589         1  1.458642         4  1.237813         0  1.193471         0  0.802609        0  0.860790\n",
      "        2   0.721036         4  1.381378         0  1.458642         1  0.987675         0  0.511971         0  0.432399        2  0.614912\n",
      "        3   3.211111         1  1.718793         2  1.458642         2  1.151967         0  1.070232         0  0.525767        2  0.614912\n",
      "        4   1.937234         0  1.718793         3  1.458642         1  0.919023         0  0.755697         0  0.525767        0  0.614912\n",
      "       11   5.876551         1  1.381378         2  1.458642         0  1.899731         2  0.511971         0  0.432399        2  0.614912\n",
      "        0   0.756502         0  0.162188         0  0.744771         0  0.328381         0  0.015394         0  0.131216        0  0.317748\n",
      "        1   1.591109         0  1.198243         7  1.829701         9  1.775829         0  1.057391         1  0.432399        0  0.614912\n",
      "        5   1.512702         0  1.103987         1  1.829701         0  2.211738         0  1.057391         0  0.291825        0  0.553523\n",
      "        2   2.482046         2  1.468143         1  1.458642         0  0.569480         1  0.511971         0  0.291825        0  0.602581\n",
      "       22   3.398559        12  1.908543         8  1.458642        11  1.049458        15  0.826505         1  0.432399        2  0.614912\n",
      "        0   2.766866         0  0.850370         1  1.458642         0  0.883432         0  0.511971         0  0.525767        0  0.614912\n",
      "        0   2.706336         0  3.007366         0  0.744771         0  0.328381         4  4.143827         0  0.672521        3  0.834411\n",
      "        0   0.981448         0  0.575898         0  1.458642         2  0.621173         0  0.511971         0  0.291825        0  0.553523\n",
      "        0   1.332319         0  1.250541         4  9.224761         2  1.122557         0  2.559512         1  0.921858        0  4.284052\n",
      "        0   1.523834         0  0.963366         0  1.458642         0  0.574252         1  0.755697         0  0.525767        2  0.608483\n",
      "        4  10.939561         0  7.592485         0  1.458642         0  1.326893         1  2.039686         0  1.470506        0  1.166426\n",
      "        4   1.532489         0  1.131531         6  2.684085         3  1.430117         0  0.365731         1  0.604256        3  0.886495\n",
      "       13   7.764207         5  5.957166         4  3.644618         3  5.068421         0  1.184288         0  0.708671        1  0.750607\n",
      "        2   1.339228         5  1.041786         4  1.458642         1  0.533658         1  0.594179         1  0.313421        0  0.608483\n",
      "        0   2.060164         2  1.194876         6  2.684085         4  1.307801         0  0.778579         0  0.383717        0  0.869458\n",
      "        0   4.215636         0  4.380067         1  1.458642         1  2.130728         0  3.732759         0  1.127564        0  0.953395\n",
      "        0  -0.241875         0  0.243270         0  0.744771         0  0.299408         0  0.015394         0  0.271790        4  0.574094\n",
      "        0  -0.205466         0  0.916614         0  0.744771         0  0.299408         0  1.301542         0  0.888940        0  0.321343\n",
      "        0   1.041068         0  0.723596         0  1.458642         0  0.752862         0  0.511971         0  0.432399        0  0.614912\n",
      "        0   1.396318         0  1.268718         0  1.458642         0  1.053714         0  0.511971         0  0.432399        0  0.614912\n",
      "       23   5.893590        13  5.728923         1  1.458642         1  3.227181         1  1.193471         0  0.802609        0  0.860790\n",
      "        2   5.148613         5  2.929382         1  1.458642         5  1.030074         0  0.755697         0  0.432399        1  0.614912\n",
      "        0   4.440892         0  4.240120         0  1.458642         0  1.018037         0  0.594179         1  0.313421        0  0.608483\n",
      "        0   1.084647         0  1.592036         0  1.282753         0  0.978813         0 -0.155307         0  0.131216        0  0.436028\n",
      "        0   1.677301         0  2.116045         0  0.744771         1  0.328381         0  4.389224         0  1.274627        0  0.531215\n",
      "        0   0.113016         0  0.419453         0  0.744771         0  0.328381         0 -0.155307         0  0.131216        0  0.268690\n",
      "        1   3.371780         1  1.318621         3  1.458642         0  0.913043         0  0.755697         0  0.432399        1  0.614912\n",
      "        0  -0.420557         0 -0.107712         0  0.744771         0  0.328381         0 -0.155307         0  0.131216        0  0.317748\n",
      "        0   0.386587         0 -0.107712         0  0.744771         0  0.328270         0  0.321552         0  0.131216        0  0.349370\n",
      "       27   3.371780         1  1.318621         0  1.458642         0  0.913043         1  0.755697         1  0.432399        2  0.614912\n",
      "        2   5.043502         2  3.843347         3  1.458642         8  1.394019         1  1.354989         1  1.127564        3  0.953395\n",
      "        0   1.169566         0  1.263121         0  1.458642         0  0.853423         0  0.755697         0  0.525767        0  0.614912\n",
      "        0   2.457945         5  1.725409         0  1.458642         0  1.365568         0  0.818128         0  0.432399        1  1.414115\n",
      "        3   1.538634        11  1.908543        13  1.458642        14  1.037863         9  0.511971         1  0.432399        3  0.614912\n",
      "        0  -0.595819         0  0.226911         0  1.458642         0  0.509414         0  0.350452         0  0.313421        0  0.608483\n",
      "        0   2.838208         0  0.791456         0  1.458642         0  0.908197         0  0.755697         0  0.432399        0  0.614912\n",
      "        0   1.121535         0  0.689255         0  1.458642         1  1.003767         0  0.511971         0  0.432399        0  0.614912\n",
      "        3   4.760408         0  1.912550         0  1.458642         4  0.688726         0  0.341270         0  0.291825        0  0.553523\n",
      "        0   1.241505         0  1.725409         1  1.458642         0  1.586169         2  0.511971         3  1.140069        0  0.907570\n",
      "        0   3.371780         0  1.318621         0  1.458642         0  0.913043         0  0.755697         0  0.525767        0  0.614912\n",
      "        0   2.957162         1  0.884586         0  1.458642         0  0.592220         0  0.594179         0  0.313421        2  0.664057\n",
      "        0   2.124682         0  1.908543         0  1.458642         0  1.035923         0  0.511971         0  0.432399        0  0.614912\n",
      "        0   1.038026         0  1.777707         0  1.458642         0  1.001175         0  2.889741         0  0.525767        0  0.614912\n",
      "        0  -1.763442         0 -0.951259         0  0.744771         0  0.328381         0 -0.400704         0  0.131216        0  0.268690\n",
      "        0   2.492083         0  0.270906         0  1.458642         0  0.817815         0  0.511971         0  0.432399        3  0.602581\n",
      "       10   2.124682         0  1.188688         0  1.458642         0  1.033617         0  0.511971         0  0.432399        0  0.614912\n",
      "        0   2.470807         0  1.709237         1  1.458642         1  1.030074         0  0.755697         0  0.432399        0  0.614912\n",
      "        0   1.038026         0  1.777707         1  1.458642         0  1.001175         1  2.889741         1  0.525767        0  0.614912\n",
      "        1   1.545055         3  1.725409         0  1.458642         1  1.035923         0  0.511971         0  0.432399        0  0.614912\n",
      "        0   1.467660         0  1.209805         0  1.458642         0  1.092438         0  0.755697         0  0.525767        0  0.614912\n",
      "        0   2.618691         0  2.090378         0  1.829701         0  1.244712         0  1.301117         1  0.525767        0  0.614912\n",
      "        0   0.319472         1 -0.164063         1  1.458642         2  1.498495         1  0.607060         2  0.467187        2  0.714450\n",
      "        1   3.065784         8  3.183933         5  3.644618         6  6.419558         1  0.755697         0  0.432399        0  0.614912\n",
      "        0   1.334639         0  1.249617         0  1.458642         0  1.000464         0  0.511971         0  0.432399        0  0.614912\n",
      "        2   1.716991         3  1.514058        12  1.458642         6  3.226029         1  0.755697         0  0.432399        0  0.614912\n",
      "        0   0.743687         1  0.718852         2  1.458642         0  0.868880         0  0.511971         0  0.432399        0  0.602581\n",
      "        1   2.537158         1  2.530589         1  1.458642         0  1.466380         1  1.545219         0  0.802609        1  0.860790\n",
      "        2   1.897961         1  0.833164         0  1.458642         0  0.703367         3  0.655805         0  0.291825        1  0.553523\n",
      "        1   1.018471         0  1.298315         0  1.458642         0  1.000464         0  0.511971         0  0.432399        3  0.614912\n",
      "        0   0.386587         0 -0.107712         0  0.744771         0  0.328270         0  0.321552         0  0.131216        0  0.349370\n",
      "        0  -0.294804         0 -0.897802         0  1.458642         0  0.439275         0  1.050427         0  0.604256        0  0.665405\n",
      "        3   4.696076         0  4.099560         4  1.458642         0  1.089088         0  1.354989         0  1.127564        2  0.953395\n",
      "        7   3.927962        13  3.968366         0  1.458642         3  1.616955         8  5.056503         0  2.380490        1  3.672385\n",
      "        0   1.901730         3  2.376794         0  1.458642         3  1.023004         1  3.133467         0  0.432399        0  0.614912\n",
      "        0   2.348423         0  1.718793         0  1.458642         0  0.871444         0  0.755697         0  0.432399        0  0.614912\n",
      "        0  -0.890131         0 -0.616700         0  0.744771         0  0.328381         0 -0.155307         0  0.131216        0  0.268690\n",
      "        0   0.892576         2  1.198243         1  1.458642         0  1.071880         0  0.951315         0  0.432399        0  0.614912\n",
      "        6   3.371780         3  1.318621         2  1.458642         0  0.913043         0  0.755697         0  0.525767        0  0.614912\n",
      "        0   4.428200         2  4.380067         0  1.458642         5  1.613982         0  2.039686         0  1.127564        0  0.953395\n",
      "        4   6.140680         0  2.825046         0  1.458642         0  1.089301         0  1.193471         0  0.648010        0  0.860790\n",
      "        1   3.051266         2  3.057754         0  1.458642         0  1.474324         0  1.193471         0  0.544933        0  0.882192\n",
      "        1   2.012472         0  0.959155         0  1.458642         3  0.653751         0  0.511971         0  0.291825        1  0.602581\n",
      "        0   3.100702         1  2.288326         0  1.458642         1  0.928420         0  1.193471         0  0.648010        0  0.860790\n",
      "        0  -0.382448         0  0.055298         0  0.744771         0  0.377312         0 -0.155307         0  0.131216        0  0.268690\n",
      "        0   1.043835         2  1.198243         1  1.458642         0  0.950517         0  0.511971         0  0.432399        0  0.614912\n",
      "        0  -0.446965         0 -0.475235         0  0.744771         0  0.323375         0  0.111302         0  0.223108        0  0.327544\n",
      "        9   2.470807         5  2.245958        40  1.458642        11  1.030074         7  0.755697         1  0.432399        0  0.614912\n",
      "        3   1.005054         0  1.058629         0  1.458642         2  0.514638         0  0.365731         0  0.467187        0  0.879419\n",
      "        3   2.124682         1  1.725409         0  1.458642         0  1.035923         1  0.511971         0  0.432399        0  0.614912\n",
      "       13   5.064127         1  4.833870         5  1.458642         3  1.646566        11  5.300229         0  2.256425        0  3.725250\n",
      "        0  -0.916021         0 -1.008922         0  0.744771         1  0.337590         0 -0.155307         0  0.131216        0  0.268690\n",
      "        0   0.746596         3  0.317144         0  1.458642         0  0.419337         0  0.563829         0  0.185364        0  0.612292\n",
      "        0   1.089813         0  1.239402         0  1.458642         0  0.973077         0  0.755697         0  0.525767        0  0.614912\n",
      "        0   3.460562         0  3.057754         0  1.458642         2  1.239365        10  1.193471         1  1.127564        0  0.860790\n",
      "        0   1.296815         0  1.908543         0  1.458642         0  1.035528         0  2.889741         3  0.432399        0  0.614912\n",
      "        0   2.124682         3  1.908543        25 13.834241         4  1.122557        13  2.559512         1  0.921858        1  4.759172\n",
      "        0   0.086608         0  0.051930         0  1.970215         1  0.341071         1  0.111302         0  0.548063        0  0.403926\n",
      "        0   3.332988         0  3.445281         0  1.996623         0  6.774187         0  0.511971         0  0.432399        0  1.001132\n",
      "       44   3.153821         1  1.262104         0  1.458642         0  0.635620         0  0.341270         0  0.291825        0  0.553523\n",
      "        2   2.196024         3  3.662566         0  1.458642         1  0.962774         0  0.755697         0  0.432399        0  0.614912\n",
      "        0   2.961716         0  2.529665         0  1.458642         1  1.525897         0  1.545219         8  1.127564        0  1.126073\n",
      "        0   1.817406         0  1.489388         4  1.458642         0  0.770937         0  0.755697         0  0.525767        0  0.608483\n",
      "        0   0.920160         0  0.419453         0  0.744771         0  0.334868         0  0.321552         0  0.131216        0  0.349370\n",
      "        0  -0.322688         0  0.051930         0  0.744771         0  0.321638         0  0.111302         1  0.457150        0  0.348868\n",
      "        3   1.591109        12  1.381378         2  1.458642         0  0.960820         0  0.511971         0  0.432399        1  0.614912\n",
      "        1   1.467660         1  1.209805         0  1.458642         2  1.092438         1  0.755697         0  0.432399        0  0.614912\n",
      "        0   1.937234         1  1.718793         0  1.458642         0  0.973077         0  0.755697         0  0.432399        0  0.614912\n",
      "       10   5.433759         5  4.015777         4  1.458642         3  1.121394         0  4.885802         0  0.813094        1  0.897095\n",
      "        2   1.591109         4  1.381378         5  1.829701         1  1.806483         2  1.057391         0  0.432399        2  0.614912\n",
      "        4   1.591109         5  1.198243         2  1.829701         0  1.775829         0  1.057391         0  0.432399        0  0.602581\n",
      "        0   5.617761         0  1.250541         0  1.458642         1  1.870870         0  0.511971         0  0.432399        0  0.614912\n",
      "        2   5.043502         3  4.380067        98 36.645123        32  5.554734         5  3.402530         1  1.617023        1  5.250843\n",
      "        0  13.541750         4  6.738773         0  1.458642         0  1.030074         0  1.336314         0  0.432399        0  0.614912\n",
      "        0   1.296815         0  1.725409         1  1.458642         1  1.034328         2  2.889741         1  0.432399        2  0.614912\n",
      "        2   7.760974         2  5.931781         0  1.458642         0  0.973077         0  0.755697         3  0.432399        0  0.614912\n",
      "        0   5.209684         1  3.619718         0  1.458642         0  0.960468         0  0.755697         0  0.432399        2  0.614912\n",
      "        1   2.482046         2  1.468143         3  1.458642         0  0.621173         1  0.511971         2  0.291825        2  0.602581\n",
      "        0   2.061511         0  2.245958         4  1.458642         0  7.088585         0  0.755697         3 11.538981        0  0.800054\n",
      "       31   6.212364        19  5.477440         2  1.458642         0  1.030074         3  0.755697         4  0.525767        1  0.614912\n",
      "        0   5.184783         0  4.768439         0  1.458642         0  1.027922         0  0.511971         3  0.432399        0  0.614912\n",
      "        3   2.466797         2  3.062406         5  1.458642         0  0.879590         0  2.041846         8  1.855717        5  0.614912\n",
      "       26   7.000903        11  5.917649         4  1.458642         9  1.480889         0  1.545219         7  1.127564        4  0.860790\n",
      "        0  -1.104177         0 -1.041550         0  0.744771         0  0.321638         0  0.059384         0  0.467187        0  0.347990\n",
      "       14   6.425092        14  5.911699         0  1.458642        13  2.208408         0  1.354989         0  0.708671        0  0.953395\n",
      "        0   2.838208         1  0.791456         0  1.458642         0  0.908197         0  0.755697         0  0.432399        0  0.614912\n",
      "        0   1.591109         0  1.198243         0  1.458642         2  0.651647         1  0.511971         0  0.432399        0  0.602581\n",
      "        0   0.712386         0  0.167997         0  1.458642         9  1.296373         0  0.594179         0  0.313421        0  0.608483\n",
      "        0   5.856354         2  2.207581         0  1.458642         0  1.085575         0  0.755697         0  0.782893        0  0.614912\n",
      "        0   2.414845         0 -0.107712         0  0.744771         0  0.328381         0 -0.155307         0  0.131216        0  0.268690\n",
      "        0   1.527884         1  1.725409         0  1.458642         0  1.035923         0  0.511971         0  1.006681        0  0.614912\n",
      "        2   0.212469         6  0.834088         1  1.458642         2  1.767039         0  0.511971         0  4.519642        0  0.784840\n",
      "        1   0.823440         0  0.925706         0  1.458642         0  0.851270         0  0.511971         0  0.432399        0  0.614912\n",
      "        0   2.061511         4  2.245958         1  1.458642         3  7.088585         1  0.755697         0 11.538981        1  0.800054\n",
      "        0   1.053632         0  0.417010         0  0.744771         0  0.323375         0  0.282003         0  0.223108        0  0.376602\n",
      "        1   2.541738         0  1.308098         0  1.458642         0  0.552506         0  0.511971         0  0.291825        0  0.602581\n",
      "        0  -0.382448         0  0.055298         0  0.744771         0  0.328381         3 -0.155307         0  0.131216        0  0.268690\n",
      "        1   2.008165         0  1.468143         0  1.458642         0  0.621173         0  0.511971         0  0.291825        0  0.602581\n",
      "        0   0.484898         0  0.771150         2  1.458642         3  0.931958         0  0.511971         0  0.432399        1  0.614912\n",
      "        0   1.937234         1  2.690820         3  1.458642         0  0.973077         0  2.041846         0  1.762349        2  0.614912\n",
      "        0   0.730840         0  0.304660         0  1.458642         0  0.546684         0  0.945927         0  0.313421        0  0.535249\n",
      "        0   1.392682         1  3.257148         0  1.458642         0  1.027922         0  0.151901         0  0.432399        0  0.614912\n",
      "        1   2.124682         1  1.908543         0  1.829701         0  1.824711         3  1.057391         0  0.432399        0  0.614912\n",
      "        2   4.698233         0  4.452970         2  1.458642         7  0.912730         5  1.354989        11  0.802609       12  0.953395\n",
      "        1   2.032644         0  2.090378         0  1.458642         0  0.973077         0  0.755697         0  0.525767        0  0.614912\n",
      "        1  -0.203468         0 -0.654188         0  1.458642         0  0.440656         0  0.204212         0  0.604256        0  0.619844\n",
      "        7   1.591109         3  1.381378         1  1.829701         5  1.806483         0  1.057391         1  0.432399        3  0.614912\n",
      "        1   2.196024         1  1.849629         0  1.458642         0  0.973077         0  0.755697         2  0.432399        0  0.614912\n",
      "        2   1.547129         0  1.472885         0  1.458642         0  0.976561         0  0.511971         0  0.432399        0  0.614912\n",
      "        1  -0.382448         0 -0.631912         0  0.744771         0  0.328381         0 -0.155307         0  0.131216        0  0.268690\n",
      "        0   0.687876         0  0.049876         0  1.458642         0  0.426782         0  0.511971         0  0.291825        0  0.553523\n",
      "        0  -0.830281         0  0.055298         0  0.744771         0  0.328381         0 -0.155307         0  0.131216        1  0.478534\n",
      "        3   6.140195         0  4.258707         0  1.458642         1  0.790414         0  1.184288         1  0.383717        0  0.750607\n",
      "        0   1.591109         1  1.198243         1  1.458642         0  1.000541         0  0.511971         0  0.756001        1  1.221570\n",
      "        1   0.586897         0  0.419453         0  0.744771         1  0.377312         0  0.015394         0  0.131216        0  0.321343\n",
      "        0   2.838208         0  0.791456         0  1.458642         0  0.908197         0  0.755697         0  0.525767        0  0.614912\n",
      "        0   7.069701         0  4.908152         0  1.458642         0  0.539025         0  0.594179         0  0.313421        0  0.608483\n",
      "        0  -1.743887         0 -0.471867         1  0.744771         0  0.327592         0  2.222463         0  0.131216        0  0.268690\n",
      "       16  17.560534         4  5.527528         0  1.458642         2  0.650448         0  0.755697         0  0.525767        0  0.614912\n",
      "        0 -10.310785         0 -1.766500         0  0.744771         0  0.293357         0  0.353766         0  0.059444        0  0.314914\n",
      "        0   1.874009         0  2.245958         0  1.458642         0  1.030074         0  0.755697         1  1.006681        0  0.614912\n",
      "        3   8.343937         4  4.834149         0  1.458642         0  1.341997         0  1.354989         1  0.802609        0  0.953395\n",
      "        1  17.560534         0  5.527528         0  1.458642         0  0.650448         0  0.755697         0  0.525767        0  0.614912\n",
      "        1   1.897961         0  0.833164         2  1.458642         1  0.703367         1  0.655805         0  0.291825        0  0.553523\n",
      "        4  13.541750         1  6.738773         0  1.458642         0  1.030074         2  1.336314         0  0.432399        0  0.614912\n",
      "        0  -0.205466         0 -0.055414         0  0.744771         0  0.299408         0  0.015394         0  0.131216        0  0.561282\n",
      "        1   2.909725         0  0.670154         3  1.458642         0  0.948210         1  0.511971         0  0.432399        0  0.614912\n",
      "        0   0.665280         0  0.624596         0  1.458642         1  0.805000         0  0.511971         0  0.291825        0  0.553523\n",
      "        3   1.155338         0  0.824533         0  1.458642         0  0.708453         0  0.511971         0  0.432399        0  0.553523\n",
      "        3   2.348659         0  1.625583         0  1.458642         0  0.936588         0  0.755697         0  0.525767        2  0.608483\n",
      "        5   7.169231         1  5.150026         0  1.458642         1  0.832012         0  1.184288         1  0.708671        0  0.750607\n",
      "        2   1.426149         0  1.908543         0  1.458642         0  1.242705         0  0.951315         0  0.432399        0  0.614912\n",
      "        0   0.920160         0  0.602588         0  0.744771         0  0.326867         0  0.321552         0  0.131216        0  0.349370\n",
      "        0   2.145529         0  1.995308         1  1.458642         0  0.679963         0  0.511971         0  0.291825        0  0.602581\n",
      "        1   2.008165         8  1.468143         2  1.458642         1  1.967705         0  0.511971         0  0.291825        0  0.602581\n",
      "        1   2.719659         6  2.532547         5  3.644618         3  3.783703         0  0.511971         0  0.432399        0  0.602581\n",
      "        0   1.609563         0  1.334906         0  1.458642         0  0.890013         0  0.511971         0  0.432399        0  0.535249\n",
      "        0   3.741411         5  0.500526         1  1.458642         0  0.598598         1  0.341270         0  0.432399        0  0.553523\n",
      "       14   6.304813         6  3.227205         9  1.458642         1  1.030074         2  0.755697         0  0.432399        1  0.614912\n",
      "        0   2.470807         0  1.709237         0  1.458642         0  1.030074         0  0.755697         0  0.432399        0  0.614912\n",
      "        0   1.655107         0  1.216420         0  1.458642         0  1.007537         0  0.511971         0  0.432399        0  0.602581\n",
      "       10   7.948423         6  6.121530         0  1.458642         0  1.034816         0  0.511971         0  0.432399        0  0.614912\n",
      "        0   0.823440         0  0.925706         0  1.458642         0  0.859272         0  0.511971         0  0.432399        0  0.614912\n",
      "        2   2.124682         0  1.725409         6  1.458642         2  0.737054         2  0.511971         3  0.432399        0  0.602581\n",
      "        0   0.766284         0  0.144132         0  1.458642         0  0.738134         0  0.511971         0  0.432399        0  0.614912\n",
      "        0   0.053324         0 -0.107712         0  0.744771         1  0.328270         0  0.015394         0  0.131216        0  0.561282\n",
      "        0   0.379460         0  0.456947         0  0.744771         0  0.321638         2  0.067252         0  0.457150        0  0.307191\n",
      "        1   2.196024         1  1.849629         0  1.458642         0  0.962774         0  0.755697         0  0.432399        0  0.614912\n",
      "        0  -2.506829         0 -1.766500         0  0.744771         0  0.293357         0 -0.146124         0  0.059444        1  0.314914\n",
      "        0   1.000834         0  1.269594         1  3.644618         0  1.013210         0  0.594179         0  0.313421        0  0.608483\n",
      "       15   6.954463         3  5.010977         5  1.458642         3  1.525897         0  1.545219         0  1.127564        2  0.860790\n",
      "        0  -0.003606         0 -0.017921         0  0.744771         0  0.323375         0  0.067252         0  0.024756        0  0.285867\n",
      "        2  11.542610         4  6.083189         0  1.458642         0  1.035923         0  0.511971         0  0.432399        0  0.614912\n",
      "        0   2.306739         2  1.275888         0  1.458642         1  3.771221         2  1.696764         1  0.291825        0  0.602581\n",
      "        0   0.994311         0  1.198243         0  1.458642         0  0.948210         0  0.511971         1  1.006681        0  0.614912\n",
      "        1   1.359681         1  1.413971         0  1.458642         0  0.973077         0  0.755697         2  0.432399        1  0.614912\n",
      "        0   0.944260         0  0.162188         0  0.744771         0  0.377312         0  0.015394         0  0.131216        0  0.321343\n",
      "        0   1.593429         0  1.380453         0  1.458642         0  1.027922         0  0.511971         0  0.432399        0  0.614912\n",
      "        0   1.937234         0  1.718793         7  1.829701        15  1.244712         4  1.301117         2  0.432399        1  0.614912\n",
      "        0   1.160743         3  0.988752         1  1.458642         0  0.805000         0  0.511971         0  0.291825        0  0.602581\n",
      "        0   1.591109         0  1.381378         0  1.458642         0  0.950517         0  0.511971         0  0.432399        0  0.614912\n",
      "        0   1.169566         0  1.263121         0  1.458642         1  0.853423         1  0.755697         0  0.525767        1  0.614912\n",
      "        0   2.186086         0  2.188517        11  3.644618        32  3.671433         3  0.511971         2  0.432399        0  0.614912\n",
      "        0   0.650233         0  0.880831         0  0.744771         0  0.321638         0 -0.130846         0  1.286743        0  0.395035\n",
      "        2   2.152043         1  1.941136         0  1.458642         0  0.978714         0  0.755697         0  0.432399        0  0.614912\n",
      "        0   1.924372         0  1.381378         0  1.458642         1  1.329061         1  0.818128         4  0.432399        1  1.353004\n",
      "        0   1.415803         1  1.005989         1  1.458642         0  3.799822         2  1.696764         0  0.432399        0  0.602581\n",
      "        2   3.712870         1  3.785232         0  1.458642         1  1.160811         0  4.640405         0  0.672521        0  0.937485\n",
      "        0  -0.188169         0 -0.732421         0  0.744771         0  0.293357         0 -0.146124         0  0.059444        0  0.314914\n",
      "       17   1.817406         6  2.461414        13  1.458642         4  0.791084         0  2.041846         0  1.643371        0  0.608483\n",
      "        0   0.766284         0  0.144132         0  1.458642         0  0.455273         0  0.511971         0  0.432399        1  0.602581\n",
      "        0   1.133892         0  3.126311         0  1.458642         0  1.000464         0  0.151901         0  0.432399        0  0.614912\n",
      "       18   2.492083        18  0.454040         1  1.458642         2  0.897145         3  0.511971         1  0.432399        0  0.614912\n",
      "        0  -1.248424         1 -0.107712         0  0.744771         2  0.327592         0  2.222463         0  0.131216        0  0.268690\n",
      "        6   4.632077         4  3.535687         2  1.458642         0  0.957061         8  1.354989         0  0.383717        2  0.770055\n",
      "        0  -0.428511         0 -0.338572         0  0.744771         0  0.321446         0  0.111302         0  0.548063        0  0.192622\n",
      "        5  17.560534         3  5.527528         0  1.458642         0  0.650448         0  0.755697         0  0.432399        0  0.614912\n",
      "        0   1.591109         1  1.198243         1  1.829701         2  1.775829         1  1.057391         3  0.432399        1  0.602581\n",
      "        0  -0.382448         0 -0.631912         0  0.744771         0  0.328381         0 -0.155307         0  0.131216        0  0.268690\n",
      "       14   8.373019        14  5.663559         3  1.458642         9  0.969727         1  1.354989         2  1.127564        1  0.953395\n",
      "        0   0.991485         2 -0.621339         0  1.458642         0  0.584554         0  0.341270         0  0.291825        0  0.553523\n",
      "        3   8.103608         8  6.848069         6  1.458642         0  0.979147         1  1.354989         1  1.127564        0  0.953395\n",
      "        0   1.937234         2  1.718793         4  1.829701         3  1.244712         0  1.301117         0  0.525767        1  0.614912\n",
      "        1   2.348659         1  2.017477         0  1.458642         0  0.770937         0  0.755697         1  0.525767        1  0.608483\n",
      "        0   0.357856         0 -0.471867         0  0.744771         0  0.343023         0  0.159228         0  0.131216        0  0.268690\n",
      "        8   4.383040         5  3.341305         1  1.458642         1  1.586044         3  2.039686         1  1.127564        2  0.953395\n",
      "       16  10.737637         2  8.871346         6  1.458642         1  1.030074         0  0.755697         0  0.525767        1  0.614912\n",
      "        0   1.550942         2  1.268194         0  1.458642         0  0.479549         0  0.365731         0  0.604256        0  0.693882\n",
      "        1   1.903192         0 -0.107712         4  0.744771         1  0.328270         0  0.015394         0  0.131216        0  0.321343\n",
      "        3   1.467660         0  1.340641         2  1.458642         0  1.092438         0  0.755697         0  0.432399        2  0.614912\n",
      "        0   1.426149         1  1.908543         0  1.458642         0  1.234703         1  0.951315         0  0.432399        0  0.614912\n",
      "        0   0.048499         0 -0.111079         0  1.970215         0  0.341071         0  0.111302         0  0.223108        0  0.452984\n",
      "        0   3.186987         1  2.195018         4  1.458642         3  2.474027         1  1.193471         2  1.127564        0  0.860790\n",
      "        0  -0.916021         1  1.524204         0  0.744771         0  0.328381         0 -0.155307         2  0.131216        0  0.268690\n",
      "        0   3.025656         0  0.981206         2  1.458642         0  0.918891         2  0.511971         0  0.432399        0  0.614912\n",
      "        6   1.937234         6  2.821657         2  1.458642         0  0.973077         0  2.041846         2  1.762349        0  0.614912\n",
      "        3   5.856354         1  2.207581         0  1.458642         0  1.085575         2  0.755697         0  0.782893        0  0.614912\n",
      "        0  -0.916021         0 -0.471867         4  6.665905         1  0.883412         1  1.892232         0  0.620676        3  0.952096\n",
      "        4   4.423594        21  4.917127         0  1.458642         2  1.104386         0  0.755697         2  0.525767        0  0.614912\n",
      "        4   3.015619         4  3.991379         2  1.458642         1  0.679963         0  0.511971         1  0.291825        0  0.602581\n",
      "        0   1.198853         0  1.151761         0  1.458642         0  0.863790         0  0.511971         0  0.291825        0  0.553523\n",
      "        0  -0.736726         0 -0.059014         0  0.744771         0  0.328381         0  0.015394         0  0.131216        0  0.317748\n",
      "        0   2.470807         0  2.245958         0  1.458642         0  1.030074         1  0.755697         0  0.525767        0  0.614912\n",
      "        0  -1.637750         0 -1.568716         0  0.744771         0  0.321638         0  0.257482         0  0.467187        0  0.347990\n",
      "        0  -0.003606         0 -0.017921         0  0.744771         0  0.323375         0  0.067252         0  0.024756        0  0.285867\n",
      "        2   2.703940         6  3.057754         0  1.458642         0  1.203388         0  1.193471         7  1.127564        0  0.860790\n",
      "        0  -0.370450         0 -0.301179         0  1.458642         0  0.509414         0  0.350452         0  0.313421        0  0.608483\n",
      "        0   0.220315         0 -0.507299         9  2.684085         4  1.265439         1  1.050427         1  0.604256        1  0.858018\n",
      "        0  -0.261446         0  0.190763         0  1.458642         0  0.819447         0  0.341270         0  0.291825        2  0.553523\n",
      "        2   2.470807         2  2.245958         3  1.458642         0  1.719250         0  0.755697         3  0.756001        0 10.092593\n",
      "        0   1.334639         0  0.587428         0  1.458642         0  1.000464         0  0.511971         0  0.432399        0  0.614912\n",
      "        0  -0.786217         0 -1.285165         0  1.970215         0  0.325171         0  0.553850         0  0.024756        0  0.415557\n",
      "        1   2.008165         3  1.468143         0  1.829701         1  2.211738         1  1.057391         0  0.291825        0  0.602581\n",
      "        0   1.666327         2  2.017477         0  1.458642         0  0.770937         0  0.755697         0  0.313421        0  0.608483\n",
      "        1   0.132759         3  0.167997         3  1.458642         0  0.577668         1  0.945927         1  0.313421        0  0.608483\n",
      "        2   1.332319         1  1.250541         4  1.829701         1  1.244712         0  1.057391         0  0.432399        3  0.614912\n",
      "        1   3.398559         0  1.908543         2  1.458642         0  1.042563         2  0.826505         1  0.432399        1  0.614912\n",
      "        3  -0.015047         2 -1.399204         0  0.744771         0  0.328381         0 -0.155307         0  0.131216        0  0.268690\n",
      "        1   3.025656         0  0.798072         0  1.458642         0  0.918891         0  0.511971         0  0.432399        0  0.614912\n",
      "        0   0.486649         0 -0.444227         0  1.458642         0  1.912120         0  0.402310         0  0.604256        0  0.765412\n",
      "        6   5.064558        11  7.090172         6  1.458642         0  1.493996         0  1.545219         0  0.802609        0  0.860790\n",
      "        0   2.145546         0  1.995308         3  1.458642         2  0.660880         4  0.511971         4  0.291825        0  0.602581\n",
      "        3   2.008165         1  1.468143         2  1.458642         1  0.621173         2  0.511971         0  0.291825        0  0.602581\n",
      "        0   2.766866         0  0.850370         0  1.458642         0  0.883432         0  0.511971         0  0.432399        0  0.614912\n",
      "        0   0.919238         0  0.670154         1  1.458642         2  1.068347         1  0.647428         0  0.291825        1  1.094722\n",
      "        0  -0.507830         0 -0.300254         2  1.458642         0  0.649452         0  0.702200         0  0.313421        0  0.608483\n",
      "        0  -2.130798         0 -1.941779         3  0.744771         0  0.293357         0 -0.146124         0  0.059444        0  0.314914\n",
      "       71   8.900437        31  5.985540         7  1.458642         1  1.030074         2  0.755697         1  0.404334        1  0.666994\n",
      "        2   2.541738         0  1.995308         1  1.829701         0  2.219221         0  1.057391         1  0.291825        0  0.602581\n",
      "        0   1.357607         4  1.718793         0  1.458642         0  0.973077         0  0.755697         1  0.432399        0  0.614912\n",
      "        0   3.371780         0  1.318621         1  1.458642         0  0.913043         0  0.755697         0  0.525767        0  0.614912\n",
      "        2   1.588604         0  1.193952         4  2.684085         8  1.349398         0  0.607879         0  0.708671        2  0.869458\n",
      "        7   3.942616         1  1.670336         5  1.458642         2  0.688726         2  0.341270         1  0.291825        0  0.553523\n",
      "       13   3.730250        14  3.549108         3  1.458642        17  1.912708         6  0.755697         3  0.432399        3  0.614912\n",
      "       17   1.332319         8  1.250541         0  1.458642         2  0.931958         2  0.511971         0  0.432399        0  0.614912\n",
      "        0   0.405858         0  0.462455         0  1.458642         0  0.533658         1  0.594179         0  0.313421        1  0.608483\n",
      "        0   2.877985         0  2.090378         0  1.458642         0  0.777957         0  0.755697         0  0.525767        0  0.614912\n",
      "        2   3.179297         4  3.258067         0  1.458642         0  1.116104         0  4.885802         0  0.672521        1  0.665502\n",
      "        2   2.470807         3  2.245958         1  1.458642         4  2.166435         2  0.755697         0  0.432399        0  0.614912\n",
      "        0  -0.916021         0 -0.471867         0  0.744771         0  0.328381         0 -0.155307         0  0.131216        0  0.268690\n",
      "        1   2.186086         3  2.005382         3  3.644618        15  3.671433         3  0.511971         1  0.432399        2  0.614912\n",
      "       10   3.407230         3  2.530589        32  1.458642         6  1.478176         3  1.193471         0  0.802609       19  0.860790\n",
      "        1  -0.504832         0 -0.471867         0  0.744771         0  0.328381         0 -0.155307         0  0.131216        0  0.268690\n",
      "        0   2.706336         0  3.007366         1  0.744771         0  0.328381         2  4.143827         0  1.274627        0  0.538330\n",
      "        0   9.530331         0  6.564628         0  1.458642         0  0.928420         0  1.193471         0  1.315907        0  5.488215\n",
      "        0  16.823483         1  0.167997         0  1.458642         0  0.577668         0  0.945927         0  0.313421        0  0.608483\n",
      "        4   2.827603         9  2.530589         0  1.458642         0  1.478176         1  1.545219         0  0.802609        1  0.860790\n",
      "        3  11.355162         4  6.207410         0  1.458642         0  0.973077         0  0.755697         0  0.432399        0  0.614912\n",
      "        1   0.518526         0 -0.872039         0  0.744771         0  0.328381         0 -0.155307         0  0.131216        0  0.268690\n",
      "        8   2.864986         1  1.381378         3  1.458642         2  1.064816        10  0.826505         0  0.432399        0  0.614912\n",
      "        1   1.591109         2  1.381378        29  9.224761         3  1.122557        14  2.559512         1  0.921858        1  4.586046\n",
      "        0   0.853319         0 -0.107712         1  0.744771         1  0.343023         0  0.159228         0  0.131216        0  0.317748\n",
      "        1   3.208803         0  4.406358         0  1.458642         0  1.609158         0  0.833401         0  1.127564        0  0.860790\n",
      "        1   4.634206         0  4.380067         3  1.458642         8  1.495715         1  2.039686         0  0.544933        0  0.974797\n",
      "        0   2.294288         5  1.468143         3  1.829701         0  2.211738         0  1.057391         0  0.291825        3  0.602581\n",
      "        1   1.591109         0  1.198243         1  1.458642         0  0.868880         0  0.511971         0  0.432399        0  0.602581\n",
      "        0   1.591109         0  1.381378         0  1.458642         1  0.997110         1  0.511971         0  0.432399        0  0.614912\n",
      "        0   1.937234         0  1.042260         0  1.458642         0  1.017408         0  0.755697         0  0.525767        0  0.614912\n",
      "        0   0.328107         0  0.471751         4  0.744771         0  0.299408         0  0.015394         0  0.131216        0  0.321343\n",
      "        0   4.957167         0  5.444292         0  1.458642         1  1.138949         0  0.755697         0  0.432399        1  0.614912\n",
      "        9  14.223207         4  7.110359         0  1.458642         4  1.030074         0  1.336314         0  0.525767        0  0.614912\n"
     ]
    }
   ],
   "source": [
    "dfs = []\n",
    "\n",
    "complist_vars = [complist_ya1,\n",
    "                 complist_ya2,\n",
    "                 complist_yb1,\n",
    "                 complist_yb2,\n",
    "                 complist_yb3,\n",
    "                 complist_yb4,\n",
    "                 complist_yc]\n",
    "\n",
    "for i, complist in enumerate(complist_vars):\n",
    "    df = pd.DataFrame(complist, columns=[\"true_\" + variables[i], \"pred_\" + variables[i]])\n",
    "    dfs.append(df)\n",
    "\n",
    "result = pd.concat(dfs, axis=1)\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "\n",
    "print(result.to_string(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
