{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning para Previsão de Taxas de Qualis de Professores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliotecas Importadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import warnings as wrn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importação de Bibliotecas de Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import balanced_accuracy_score, roc_auc_score, make_scorer\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importação de Bibliotecas de Otimização de Hiperparâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Integer, Categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leitura e Seleção de Colunas do Arquivo CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>siape</th>\n",
       "      <th>formacao</th>\n",
       "      <th>tipo_jornada_trabalho</th>\n",
       "      <th>vinculo</th>\n",
       "      <th>lotacao</th>\n",
       "      <th>admissao</th>\n",
       "      <th>categoria</th>\n",
       "      <th>classe_funcional</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1543339</td>\n",
       "      <td>MESTRADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Ativo Permanente</td>\n",
       "      <td>NÚCLEO DE EDUCAÇÃO DA INFÂNCIA</td>\n",
       "      <td>2006/07/24 00:00:00.000000000</td>\n",
       "      <td>PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO</td>\n",
       "      <td>DIV                                           ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1554468</td>\n",
       "      <td>DOUTORADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Ativo Permanente</td>\n",
       "      <td>ESCOLA AGRÍCOLA DE JUNDIAÍ</td>\n",
       "      <td>2008/09/12 00:00:00.000000000</td>\n",
       "      <td>PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO</td>\n",
       "      <td>DV                                            ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1177821</td>\n",
       "      <td>MESTRADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Ativo Permanente</td>\n",
       "      <td>ESCOLA DE MÚSICA</td>\n",
       "      <td>1998/04/28 00:00:00.000000000</td>\n",
       "      <td>PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO</td>\n",
       "      <td>DIV                                           ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2360824</td>\n",
       "      <td>MESTRADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Ativo Permanente</td>\n",
       "      <td>ESCOLA AGRÍCOLA DE JUNDIAÍ</td>\n",
       "      <td>2017/01/25 00:00:00.000000000</td>\n",
       "      <td>PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO</td>\n",
       "      <td>DIII                                          ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2364334</td>\n",
       "      <td>DOUTORADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Ativo Permanente</td>\n",
       "      <td>ESCOLA AGRÍCOLA DE JUNDIAÍ</td>\n",
       "      <td>2009/10/13 00:00:00.000000000</td>\n",
       "      <td>PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO</td>\n",
       "      <td>DIV                                           ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2765</th>\n",
       "      <td>4246363</td>\n",
       "      <td>DOUTORADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Professor Visitante</td>\n",
       "      <td>INSTITUTO DE POLÍTICAS PÚBLICAS</td>\n",
       "      <td>2023/05/23 00:00:00.000000000</td>\n",
       "      <td>PROFESSOR MAGISTERIO SUPERIOR - VISITANTE</td>\n",
       "      <td>Adjunto                                       ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2766</th>\n",
       "      <td>3304576</td>\n",
       "      <td>DOUTORADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Professor Visitante</td>\n",
       "      <td>ESCOLA DE CIÊNCIAS E TECNOLOGIA</td>\n",
       "      <td>2022/08/12 00:00:00.000000000</td>\n",
       "      <td>PROFESSOR MAGISTERIO SUPERIOR - VISITANTE</td>\n",
       "      <td>Titular                                       ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2767</th>\n",
       "      <td>1056188</td>\n",
       "      <td>DOUTORADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Professor Visitante</td>\n",
       "      <td>DEPARTAMENTO DE BIOLOGIA CELULAR E GENÉTICA</td>\n",
       "      <td>2022/10/03 00:00:00.000000000</td>\n",
       "      <td>PROFESSOR MAGISTERIO SUPERIOR - VISITANTE</td>\n",
       "      <td>A                                             ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2768</th>\n",
       "      <td>3330361</td>\n",
       "      <td>DOUTORADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Professor Visitante</td>\n",
       "      <td>INSTITUTO METROPOLE DIGITAL</td>\n",
       "      <td>2023/02/15 00:00:00.000000000</td>\n",
       "      <td>PROFESSOR MAGISTERIO SUPERIOR - VISITANTE</td>\n",
       "      <td>A                                             ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2769</th>\n",
       "      <td>3309092</td>\n",
       "      <td>DOUTORADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Professor Visitante</td>\n",
       "      <td>DEPARTAMENTO DE GEOFÍSICA</td>\n",
       "      <td>2022/09/06 00:00:00.000000000</td>\n",
       "      <td>PROFESSOR MAGISTERIO SUPERIOR - VISITANTE</td>\n",
       "      <td>Titular                                       ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2770 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        siape   formacao           tipo_jornada_trabalho              vinculo  \\\n",
       "0     1543339   MESTRADO  Dedicação exclusiva                Ativo Permanente   \n",
       "1     1554468  DOUTORADO  Dedicação exclusiva                Ativo Permanente   \n",
       "2     1177821   MESTRADO  Dedicação exclusiva                Ativo Permanente   \n",
       "3     2360824   MESTRADO  Dedicação exclusiva                Ativo Permanente   \n",
       "4     2364334  DOUTORADO  Dedicação exclusiva                Ativo Permanente   \n",
       "...       ...        ...                             ...                  ...   \n",
       "2765  4246363  DOUTORADO  Dedicação exclusiva             Professor Visitante   \n",
       "2766  3304576  DOUTORADO  Dedicação exclusiva             Professor Visitante   \n",
       "2767  1056188  DOUTORADO  Dedicação exclusiva             Professor Visitante   \n",
       "2768  3330361  DOUTORADO  Dedicação exclusiva             Professor Visitante   \n",
       "2769  3309092  DOUTORADO  Dedicação exclusiva             Professor Visitante   \n",
       "\n",
       "                                          lotacao  \\\n",
       "0                  NÚCLEO DE EDUCAÇÃO DA INFÂNCIA   \n",
       "1                      ESCOLA AGRÍCOLA DE JUNDIAÍ   \n",
       "2                                ESCOLA DE MÚSICA   \n",
       "3                      ESCOLA AGRÍCOLA DE JUNDIAÍ   \n",
       "4                      ESCOLA AGRÍCOLA DE JUNDIAÍ   \n",
       "...                                           ...   \n",
       "2765              INSTITUTO DE POLÍTICAS PÚBLICAS   \n",
       "2766              ESCOLA DE CIÊNCIAS E TECNOLOGIA   \n",
       "2767  DEPARTAMENTO DE BIOLOGIA CELULAR E GENÉTICA   \n",
       "2768                  INSTITUTO METROPOLE DIGITAL   \n",
       "2769                    DEPARTAMENTO DE GEOFÍSICA   \n",
       "\n",
       "                           admissao  \\\n",
       "0     2006/07/24 00:00:00.000000000   \n",
       "1     2008/09/12 00:00:00.000000000   \n",
       "2     1998/04/28 00:00:00.000000000   \n",
       "3     2017/01/25 00:00:00.000000000   \n",
       "4     2009/10/13 00:00:00.000000000   \n",
       "...                             ...   \n",
       "2765  2023/05/23 00:00:00.000000000   \n",
       "2766  2022/08/12 00:00:00.000000000   \n",
       "2767  2022/10/03 00:00:00.000000000   \n",
       "2768  2023/02/15 00:00:00.000000000   \n",
       "2769  2022/09/06 00:00:00.000000000   \n",
       "\n",
       "                                             categoria  \\\n",
       "0     PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO   \n",
       "1     PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO   \n",
       "2     PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO   \n",
       "3     PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO   \n",
       "4     PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO   \n",
       "...                                                ...   \n",
       "2765         PROFESSOR MAGISTERIO SUPERIOR - VISITANTE   \n",
       "2766         PROFESSOR MAGISTERIO SUPERIOR - VISITANTE   \n",
       "2767         PROFESSOR MAGISTERIO SUPERIOR - VISITANTE   \n",
       "2768         PROFESSOR MAGISTERIO SUPERIOR - VISITANTE   \n",
       "2769         PROFESSOR MAGISTERIO SUPERIOR - VISITANTE   \n",
       "\n",
       "                                       classe_funcional  \n",
       "0     DIV                                           ...  \n",
       "1     DV                                            ...  \n",
       "2     DIV                                           ...  \n",
       "3     DIII                                          ...  \n",
       "4     DIV                                           ...  \n",
       "...                                                 ...  \n",
       "2765  Adjunto                                       ...  \n",
       "2766  Titular                                       ...  \n",
       "2767  A                                             ...  \n",
       "2768  A                                             ...  \n",
       "2769  Titular                                       ...  \n",
       "\n",
       "[2770 rows x 8 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# selecionar atributos dos professores que sao de interesse\n",
    "\n",
    "tp_cols = [\"siape\", \"formacao\", \"tipo_jornada_trabalho\",\n",
    "           \"vinculo\", \"lotacao\", \"admissao\", \"categoria\",\n",
    "           \"classe_funcional\"]\n",
    "\n",
    "tp_df = pd.read_csv(\"./perfis/docentes.csv\", sep=\";\")\n",
    "tp_df = tp_df[tp_cols]\n",
    "\n",
    "tp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tipos de Dados das Colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "siape                     int64\n",
       "formacao                 object\n",
       "tipo_jornada_trabalho    object\n",
       "vinculo                  object\n",
       "lotacao                  object\n",
       "admissao                 object\n",
       "categoria                object\n",
       "classe_funcional         object\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resumo Estatístico do DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>siape</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.770000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.114588e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.142222e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.274600e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.297595e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.810985e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.722937e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.350807e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              siape\n",
       "count  2.770000e+03\n",
       "mean   2.114588e+06\n",
       "std    1.142222e+06\n",
       "min    1.274600e+04\n",
       "25%    1.297595e+06\n",
       "50%    1.810985e+06\n",
       "75%    2.722937e+06\n",
       "max    9.350807e+06"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparação dos Dados de Qualis das Revistas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>siape</th>\n",
       "      <th>revista_a1</th>\n",
       "      <th>revista_a2</th>\n",
       "      <th>revista_b1</th>\n",
       "      <th>revista_b2</th>\n",
       "      <th>revista_b3</th>\n",
       "      <th>revista_b4</th>\n",
       "      <th>revista_b5</th>\n",
       "      <th>revista_c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.756000e+03</td>\n",
       "      <td>2756.000000</td>\n",
       "      <td>2756.000000</td>\n",
       "      <td>2756.000000</td>\n",
       "      <td>2756.000000</td>\n",
       "      <td>2756.000000</td>\n",
       "      <td>2756.000000</td>\n",
       "      <td>2756.000000</td>\n",
       "      <td>2756.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.112227e+06</td>\n",
       "      <td>2.634978</td>\n",
       "      <td>1.933599</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>1.269231</td>\n",
       "      <td>0.818215</td>\n",
       "      <td>0.568578</td>\n",
       "      <td>0.054790</td>\n",
       "      <td>0.889332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.137681e+06</td>\n",
       "      <td>6.073799</td>\n",
       "      <td>3.917333</td>\n",
       "      <td>5.375914</td>\n",
       "      <td>2.891393</td>\n",
       "      <td>2.413658</td>\n",
       "      <td>1.778480</td>\n",
       "      <td>0.330389</td>\n",
       "      <td>3.855806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.274600e+04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.296285e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.808676e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.721404e+06</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.350807e+06</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>124.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              siape   revista_a1   revista_a2   revista_b1   revista_b2  \\\n",
       "count  2.756000e+03  2756.000000  2756.000000  2756.000000  2756.000000   \n",
       "mean   2.112227e+06     2.634978     1.933599     1.750000     1.269231   \n",
       "std    1.137681e+06     6.073799     3.917333     5.375914     2.891393   \n",
       "min    1.274600e+04     0.000000     0.000000     0.000000     0.000000   \n",
       "25%    1.296285e+06     0.000000     0.000000     0.000000     0.000000   \n",
       "50%    1.808676e+06     0.000000     0.000000     0.000000     0.000000   \n",
       "75%    2.721404e+06     3.000000     2.000000     2.000000     1.000000   \n",
       "max    9.350807e+06    71.000000    51.000000    99.000000    46.000000   \n",
       "\n",
       "        revista_b3   revista_b4   revista_b5    revista_c  \n",
       "count  2756.000000  2756.000000  2756.000000  2756.000000  \n",
       "mean      0.818215     0.568578     0.054790     0.889332  \n",
       "std       2.413658     1.778480     0.330389     3.855806  \n",
       "min       0.000000     0.000000     0.000000     0.000000  \n",
       "25%       0.000000     0.000000     0.000000     0.000000  \n",
       "50%       0.000000     0.000000     0.000000     0.000000  \n",
       "75%       1.000000     0.000000     0.000000     1.000000  \n",
       "max      41.000000    32.000000     8.000000   124.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# selecionar atributos que desejamos prever. o siape é incluso para unir as tabelas.\n",
    "\n",
    "qualis = [\"siape\", \"revista_a1\", \"revista_a2\", \"revista_b1\",\n",
    "          \"revista_b2\", \"revista_b3\", \"revista_b4\", \"revista_b5\", \"revista_c\"]\n",
    "\n",
    "ti_df_list = []\n",
    "for year in range(2010, 2021):\n",
    "    ti_df_y = pd.read_csv(\n",
    "        \"./indicadores/indicadores-pesquisa-\" + str(year) + \".csv\", sep=\";\")\n",
    "    ti_df_y = ti_df_y[qualis]\n",
    "    ti_df_list.append(ti_df_y)\n",
    "\n",
    "ti_df = pd.concat(ti_df_list)\n",
    "ti_df = ti_df.groupby(\"siape\", as_index=False).sum()\n",
    "ti_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fusão de Dados e Remoção da Coluna \"siape\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>formacao</th>\n",
       "      <th>tipo_jornada_trabalho</th>\n",
       "      <th>vinculo</th>\n",
       "      <th>lotacao</th>\n",
       "      <th>admissao</th>\n",
       "      <th>categoria</th>\n",
       "      <th>classe_funcional</th>\n",
       "      <th>revista_a1</th>\n",
       "      <th>revista_a2</th>\n",
       "      <th>revista_b1</th>\n",
       "      <th>revista_b2</th>\n",
       "      <th>revista_b3</th>\n",
       "      <th>revista_b4</th>\n",
       "      <th>revista_b5</th>\n",
       "      <th>revista_c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MESTRADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Ativo Permanente</td>\n",
       "      <td>NÚCLEO DE EDUCAÇÃO DA INFÂNCIA</td>\n",
       "      <td>2006/07/24 00:00:00.000000000</td>\n",
       "      <td>PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO</td>\n",
       "      <td>DIV                                           ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DOUTORADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Ativo Permanente</td>\n",
       "      <td>ESCOLA AGRÍCOLA DE JUNDIAÍ</td>\n",
       "      <td>2008/09/12 00:00:00.000000000</td>\n",
       "      <td>PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO</td>\n",
       "      <td>DV                                            ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MESTRADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Ativo Permanente</td>\n",
       "      <td>ESCOLA DE MÚSICA</td>\n",
       "      <td>1998/04/28 00:00:00.000000000</td>\n",
       "      <td>PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO</td>\n",
       "      <td>DIV                                           ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MESTRADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Ativo Permanente</td>\n",
       "      <td>ESCOLA AGRÍCOLA DE JUNDIAÍ</td>\n",
       "      <td>2017/01/25 00:00:00.000000000</td>\n",
       "      <td>PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO</td>\n",
       "      <td>DIII                                          ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DOUTORADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Ativo Permanente</td>\n",
       "      <td>ESCOLA AGRÍCOLA DE JUNDIAÍ</td>\n",
       "      <td>2009/10/13 00:00:00.000000000</td>\n",
       "      <td>PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO</td>\n",
       "      <td>DIV                                           ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2748</th>\n",
       "      <td>DOUTORADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Professor Visitante</td>\n",
       "      <td>INSTITUTO DE POLÍTICAS PÚBLICAS</td>\n",
       "      <td>2023/05/23 00:00:00.000000000</td>\n",
       "      <td>PROFESSOR MAGISTERIO SUPERIOR - VISITANTE</td>\n",
       "      <td>Adjunto                                       ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2749</th>\n",
       "      <td>DOUTORADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Professor Visitante</td>\n",
       "      <td>ESCOLA DE CIÊNCIAS E TECNOLOGIA</td>\n",
       "      <td>2022/08/12 00:00:00.000000000</td>\n",
       "      <td>PROFESSOR MAGISTERIO SUPERIOR - VISITANTE</td>\n",
       "      <td>Titular                                       ...</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2750</th>\n",
       "      <td>DOUTORADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Professor Visitante</td>\n",
       "      <td>DEPARTAMENTO DE BIOLOGIA CELULAR E GENÉTICA</td>\n",
       "      <td>2022/10/03 00:00:00.000000000</td>\n",
       "      <td>PROFESSOR MAGISTERIO SUPERIOR - VISITANTE</td>\n",
       "      <td>A                                             ...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2751</th>\n",
       "      <td>DOUTORADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Professor Visitante</td>\n",
       "      <td>INSTITUTO METROPOLE DIGITAL</td>\n",
       "      <td>2023/02/15 00:00:00.000000000</td>\n",
       "      <td>PROFESSOR MAGISTERIO SUPERIOR - VISITANTE</td>\n",
       "      <td>A                                             ...</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2752</th>\n",
       "      <td>DOUTORADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Professor Visitante</td>\n",
       "      <td>DEPARTAMENTO DE GEOFÍSICA</td>\n",
       "      <td>2022/09/06 00:00:00.000000000</td>\n",
       "      <td>PROFESSOR MAGISTERIO SUPERIOR - VISITANTE</td>\n",
       "      <td>Titular                                       ...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2753 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       formacao           tipo_jornada_trabalho              vinculo  \\\n",
       "0      MESTRADO  Dedicação exclusiva                Ativo Permanente   \n",
       "1     DOUTORADO  Dedicação exclusiva                Ativo Permanente   \n",
       "2      MESTRADO  Dedicação exclusiva                Ativo Permanente   \n",
       "3      MESTRADO  Dedicação exclusiva                Ativo Permanente   \n",
       "4     DOUTORADO  Dedicação exclusiva                Ativo Permanente   \n",
       "...         ...                             ...                  ...   \n",
       "2748  DOUTORADO  Dedicação exclusiva             Professor Visitante   \n",
       "2749  DOUTORADO  Dedicação exclusiva             Professor Visitante   \n",
       "2750  DOUTORADO  Dedicação exclusiva             Professor Visitante   \n",
       "2751  DOUTORADO  Dedicação exclusiva             Professor Visitante   \n",
       "2752  DOUTORADO  Dedicação exclusiva             Professor Visitante   \n",
       "\n",
       "                                          lotacao  \\\n",
       "0                  NÚCLEO DE EDUCAÇÃO DA INFÂNCIA   \n",
       "1                      ESCOLA AGRÍCOLA DE JUNDIAÍ   \n",
       "2                                ESCOLA DE MÚSICA   \n",
       "3                      ESCOLA AGRÍCOLA DE JUNDIAÍ   \n",
       "4                      ESCOLA AGRÍCOLA DE JUNDIAÍ   \n",
       "...                                           ...   \n",
       "2748              INSTITUTO DE POLÍTICAS PÚBLICAS   \n",
       "2749              ESCOLA DE CIÊNCIAS E TECNOLOGIA   \n",
       "2750  DEPARTAMENTO DE BIOLOGIA CELULAR E GENÉTICA   \n",
       "2751                  INSTITUTO METROPOLE DIGITAL   \n",
       "2752                    DEPARTAMENTO DE GEOFÍSICA   \n",
       "\n",
       "                           admissao  \\\n",
       "0     2006/07/24 00:00:00.000000000   \n",
       "1     2008/09/12 00:00:00.000000000   \n",
       "2     1998/04/28 00:00:00.000000000   \n",
       "3     2017/01/25 00:00:00.000000000   \n",
       "4     2009/10/13 00:00:00.000000000   \n",
       "...                             ...   \n",
       "2748  2023/05/23 00:00:00.000000000   \n",
       "2749  2022/08/12 00:00:00.000000000   \n",
       "2750  2022/10/03 00:00:00.000000000   \n",
       "2751  2023/02/15 00:00:00.000000000   \n",
       "2752  2022/09/06 00:00:00.000000000   \n",
       "\n",
       "                                             categoria  \\\n",
       "0     PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO   \n",
       "1     PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO   \n",
       "2     PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO   \n",
       "3     PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO   \n",
       "4     PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO   \n",
       "...                                                ...   \n",
       "2748         PROFESSOR MAGISTERIO SUPERIOR - VISITANTE   \n",
       "2749         PROFESSOR MAGISTERIO SUPERIOR - VISITANTE   \n",
       "2750         PROFESSOR MAGISTERIO SUPERIOR - VISITANTE   \n",
       "2751         PROFESSOR MAGISTERIO SUPERIOR - VISITANTE   \n",
       "2752         PROFESSOR MAGISTERIO SUPERIOR - VISITANTE   \n",
       "\n",
       "                                       classe_funcional  revista_a1  \\\n",
       "0     DIV                                           ...           0   \n",
       "1     DV                                            ...           1   \n",
       "2     DIV                                           ...           0   \n",
       "3     DIII                                          ...           0   \n",
       "4     DIV                                           ...           0   \n",
       "...                                                 ...         ...   \n",
       "2748  Adjunto                                       ...           0   \n",
       "2749  Titular                                       ...           8   \n",
       "2750  A                                             ...           4   \n",
       "2751  A                                             ...          44   \n",
       "2752  Titular                                       ...           4   \n",
       "\n",
       "      revista_a2  revista_b1  revista_b2  revista_b3  revista_b4  revista_b5  \\\n",
       "0              0           0           0           0           0           0   \n",
       "1              1           5           0           0           4           0   \n",
       "2              0           0           0           0           0           0   \n",
       "3              0           0           0           0           0           0   \n",
       "4              0           0           1           0           0           0   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "2748           0           0           1           0           0           0   \n",
       "2749           4           7           0           2           0           0   \n",
       "2750           2           5           0           0           0           0   \n",
       "2751           1           0           0           0           0           0   \n",
       "2752           0           0           0           0           0           0   \n",
       "\n",
       "      revista_c  \n",
       "0             0  \n",
       "1             0  \n",
       "2             0  \n",
       "3             0  \n",
       "4             0  \n",
       "...         ...  \n",
       "2748          1  \n",
       "2749          0  \n",
       "2750          0  \n",
       "2751          0  \n",
       "2752          0  \n",
       "\n",
       "[2753 rows x 15 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unir ambas as tabelas e manter apenas as entradas que possuem siapes em comum\n",
    "\n",
    "df = tp_df.merge(ti_df, on=\"siape\", how=\"inner\")\n",
    "del df[\"siape\"]\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cálculo dos Semestres na Universidade e Seleção de Colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>formacao</th>\n",
       "      <th>tipo_jornada_trabalho</th>\n",
       "      <th>vinculo</th>\n",
       "      <th>categoria</th>\n",
       "      <th>classe_funcional</th>\n",
       "      <th>lotacao</th>\n",
       "      <th>num_semestres</th>\n",
       "      <th>revista_a1</th>\n",
       "      <th>revista_a2</th>\n",
       "      <th>revista_b1</th>\n",
       "      <th>revista_b2</th>\n",
       "      <th>revista_b3</th>\n",
       "      <th>revista_b4</th>\n",
       "      <th>revista_c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MESTRADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Ativo Permanente</td>\n",
       "      <td>PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO</td>\n",
       "      <td>DIV                                           ...</td>\n",
       "      <td>NÚCLEO DE EDUCAÇÃO DA INFÂNCIA</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DOUTORADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Ativo Permanente</td>\n",
       "      <td>PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO</td>\n",
       "      <td>DV                                            ...</td>\n",
       "      <td>ESCOLA AGRÍCOLA DE JUNDIAÍ</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MESTRADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Ativo Permanente</td>\n",
       "      <td>PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO</td>\n",
       "      <td>DIV                                           ...</td>\n",
       "      <td>ESCOLA DE MÚSICA</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MESTRADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Ativo Permanente</td>\n",
       "      <td>PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO</td>\n",
       "      <td>DIII                                          ...</td>\n",
       "      <td>ESCOLA AGRÍCOLA DE JUNDIAÍ</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DOUTORADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Ativo Permanente</td>\n",
       "      <td>PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO</td>\n",
       "      <td>DIV                                           ...</td>\n",
       "      <td>ESCOLA AGRÍCOLA DE JUNDIAÍ</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2748</th>\n",
       "      <td>DOUTORADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Professor Visitante</td>\n",
       "      <td>PROFESSOR MAGISTERIO SUPERIOR - VISITANTE</td>\n",
       "      <td>Adjunto                                       ...</td>\n",
       "      <td>INSTITUTO DE POLÍTICAS PÚBLICAS</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2749</th>\n",
       "      <td>DOUTORADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Professor Visitante</td>\n",
       "      <td>PROFESSOR MAGISTERIO SUPERIOR - VISITANTE</td>\n",
       "      <td>Titular                                       ...</td>\n",
       "      <td>ESCOLA DE CIÊNCIAS E TECNOLOGIA</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2750</th>\n",
       "      <td>DOUTORADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Professor Visitante</td>\n",
       "      <td>PROFESSOR MAGISTERIO SUPERIOR - VISITANTE</td>\n",
       "      <td>A                                             ...</td>\n",
       "      <td>DEPARTAMENTO DE BIOLOGIA CELULAR E GENÉTICA</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2751</th>\n",
       "      <td>DOUTORADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Professor Visitante</td>\n",
       "      <td>PROFESSOR MAGISTERIO SUPERIOR - VISITANTE</td>\n",
       "      <td>A                                             ...</td>\n",
       "      <td>INSTITUTO METROPOLE DIGITAL</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2752</th>\n",
       "      <td>DOUTORADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Professor Visitante</td>\n",
       "      <td>PROFESSOR MAGISTERIO SUPERIOR - VISITANTE</td>\n",
       "      <td>Titular                                       ...</td>\n",
       "      <td>DEPARTAMENTO DE GEOFÍSICA</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2753 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       formacao           tipo_jornada_trabalho              vinculo  \\\n",
       "0      MESTRADO  Dedicação exclusiva                Ativo Permanente   \n",
       "1     DOUTORADO  Dedicação exclusiva                Ativo Permanente   \n",
       "2      MESTRADO  Dedicação exclusiva                Ativo Permanente   \n",
       "3      MESTRADO  Dedicação exclusiva                Ativo Permanente   \n",
       "4     DOUTORADO  Dedicação exclusiva                Ativo Permanente   \n",
       "...         ...                             ...                  ...   \n",
       "2748  DOUTORADO  Dedicação exclusiva             Professor Visitante   \n",
       "2749  DOUTORADO  Dedicação exclusiva             Professor Visitante   \n",
       "2750  DOUTORADO  Dedicação exclusiva             Professor Visitante   \n",
       "2751  DOUTORADO  Dedicação exclusiva             Professor Visitante   \n",
       "2752  DOUTORADO  Dedicação exclusiva             Professor Visitante   \n",
       "\n",
       "                                             categoria  \\\n",
       "0     PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO   \n",
       "1     PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO   \n",
       "2     PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO   \n",
       "3     PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO   \n",
       "4     PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO   \n",
       "...                                                ...   \n",
       "2748         PROFESSOR MAGISTERIO SUPERIOR - VISITANTE   \n",
       "2749         PROFESSOR MAGISTERIO SUPERIOR - VISITANTE   \n",
       "2750         PROFESSOR MAGISTERIO SUPERIOR - VISITANTE   \n",
       "2751         PROFESSOR MAGISTERIO SUPERIOR - VISITANTE   \n",
       "2752         PROFESSOR MAGISTERIO SUPERIOR - VISITANTE   \n",
       "\n",
       "                                       classe_funcional  \\\n",
       "0     DIV                                           ...   \n",
       "1     DV                                            ...   \n",
       "2     DIV                                           ...   \n",
       "3     DIII                                          ...   \n",
       "4     DIV                                           ...   \n",
       "...                                                 ...   \n",
       "2748  Adjunto                                       ...   \n",
       "2749  Titular                                       ...   \n",
       "2750  A                                             ...   \n",
       "2751  A                                             ...   \n",
       "2752  Titular                                       ...   \n",
       "\n",
       "                                          lotacao  num_semestres  revista_a1  \\\n",
       "0                  NÚCLEO DE EDUCAÇÃO DA INFÂNCIA             34           0   \n",
       "1                      ESCOLA AGRÍCOLA DE JUNDIAÍ             30           1   \n",
       "2                                ESCOLA DE MÚSICA             51           0   \n",
       "3                      ESCOLA AGRÍCOLA DE JUNDIAÍ             13           0   \n",
       "4                      ESCOLA AGRÍCOLA DE JUNDIAÍ             28           0   \n",
       "...                                           ...            ...         ...   \n",
       "2748              INSTITUTO DE POLÍTICAS PÚBLICAS              1           0   \n",
       "2749              ESCOLA DE CIÊNCIAS E TECNOLOGIA              2           8   \n",
       "2750  DEPARTAMENTO DE BIOLOGIA CELULAR E GENÉTICA              2           4   \n",
       "2751                  INSTITUTO METROPOLE DIGITAL              1          44   \n",
       "2752                    DEPARTAMENTO DE GEOFÍSICA              2           4   \n",
       "\n",
       "      revista_a2  revista_b1  revista_b2  revista_b3  revista_b4  revista_c  \n",
       "0              0           0           0           0           0          0  \n",
       "1              1           5           0           0           4          0  \n",
       "2              0           0           0           0           0          0  \n",
       "3              0           0           0           0           0          0  \n",
       "4              0           0           1           0           0          0  \n",
       "...          ...         ...         ...         ...         ...        ...  \n",
       "2748           0           0           1           0           0          1  \n",
       "2749           4           7           0           2           0          0  \n",
       "2750           2           5           0           0           0          0  \n",
       "2751           1           0           0           0           0          0  \n",
       "2752           0           0           0           0           0          0  \n",
       "\n",
       "[2753 rows x 14 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converter a data de admissao para quantos semestres o professor está na universidade.\n",
    "\n",
    "def num_semestres(data: str, data_atual: str):\n",
    "    data = data[:10]\n",
    "    anos = int(data_atual[6:]) - int(data[:4])\n",
    "    if int(data_atual[3:5]) < 7 and int(data[5:7]) < 7 or int(data_atual[3:5]) >= 7 and int(data[5:7]) >= 7:\n",
    "        return 2*anos\n",
    "    elif int(data_atual[3:5]) < 7 and int(data[5:7]) > 7:\n",
    "        return 2*anos - 1\n",
    "    else:\n",
    "        return 2*anos + 1\n",
    "\n",
    "data_atual = \"18/10/2023\"\n",
    "\n",
    "df['num_semestres'] = df['admissao'].apply(lambda x: num_semestres(x, data_atual))\n",
    "df = df[[\"formacao\", \"tipo_jornada_trabalho\", \"vinculo\", \"categoria\",\"classe_funcional\", \"lotacao\", \"num_semestres\", \"revista_a1\",\n",
    "         \"revista_a2\", \"revista_b1\", \"revista_b2\", \"revista_b3\", \"revista_b4\", \"revista_c\"]]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tipos de Dados das Colunas do DataFrame Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "formacao                 object\n",
       "tipo_jornada_trabalho    object\n",
       "vinculo                  object\n",
       "categoria                object\n",
       "classe_funcional         object\n",
       "lotacao                  object\n",
       "num_semestres             int64\n",
       "revista_a1                int64\n",
       "revista_a2                int64\n",
       "revista_b1                int64\n",
       "revista_b2                int64\n",
       "revista_b3                int64\n",
       "revista_b4                int64\n",
       "revista_c                 int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise de Dados no DataFrame Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "existem 2753 entradas diferentes;\n",
      "existem 6 formacoes diferentes;\n",
      "existem 3 tipos de jornada de trabalho diferentes;\n",
      "existem 8 tipos de vinculo diferentes;\n",
      "existem 18 classes funcionais diferentes;\n",
      "existem 7 categorias diferentes;\n",
      "existem 135 lotacoes diferentes;\n",
      "existem 89 datas de admissao diferentes;\n"
     ]
    }
   ],
   "source": [
    "print(\"existem\", len(df), \"entradas diferentes;\")\n",
    "print(\"existem\", len(df[\"formacao\"].unique()), \"formacoes diferentes;\")\n",
    "print(\"existem\", len(df[\"tipo_jornada_trabalho\"].unique()),\n",
    "      \"tipos de jornada de trabalho diferentes;\")\n",
    "print(\"existem\", len(df[\"vinculo\"].unique()), \"tipos de vinculo diferentes;\")\n",
    "print(\"existem\", len(df[\"classe_funcional\"].unique()),\"classes funcionais diferentes;\")\n",
    "print(\"existem\", len(df[\"categoria\"].unique()),\"categorias diferentes;\")\n",
    "print(\"existem\", len(df[\"lotacao\"].unique()), \"lotacoes diferentes;\")\n",
    "print(\"existem\", len(df[\"num_semestres\"].unique()),\"datas de admissao diferentes;\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contagem de Professores por Formação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MESTRADO: 431\n",
      "DOUTORADO: 2189\n",
      "ESPECIALIZAÇÃO: 120\n",
      "GRADUAÇÃO: 11\n",
      "PÓS-DOUTORADO: 1\n",
      "DESCONHECIDA: 1\n"
     ]
    }
   ],
   "source": [
    "for formacao in df[\"formacao\"].unique():\n",
    "    print(formacao, \": \", len(df[df[\"formacao\"] == formacao]), sep=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remoção de Professores com Formação Desconhecida e Contagem por Formação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MESTRADO: 431\n",
      "DOUTORADO: 2189\n",
      "ESPECIALIZAÇÃO: 120\n",
      "GRADUAÇÃO: 11\n",
      "PÓS-DOUTORADO: 1\n"
     ]
    }
   ],
   "source": [
    "# retirar professores de formação desconhecida.\n",
    "\n",
    "df = df[df[\"formacao\"] != \"DESCONHECIDA\"]\n",
    "for formacao in df[\"formacao\"].unique():\n",
    "    print(formacao, \": \", len(df[df[\"formacao\"] == formacao]), sep=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classificação por Nível de Formação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3: 431\n",
      "4: 2189\n",
      "2: 120\n",
      "1: 11\n",
      "5: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mathe\\AppData\\Local\\Temp\\ipykernel_14028\\852662980.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"formacao\"].replace(nivel_formacao, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# colocar uma ordem de classificacao. pos-doc > doc > mestrado > esp > grad\n",
    "\n",
    "nivel_formacao = {\"GRADUAÇÃO\":1, \"ESPECIALIZAÇÃO\":2, \"MESTRADO\":3,\"DOUTORADO\":4,\"PÓS-DOUTORADO\":5}\n",
    "\n",
    "df[\"formacao\"].replace(nivel_formacao, inplace=True)\n",
    "for formacao in df[\"formacao\"].unique():\n",
    "    print(formacao, \": \", len(df[df[\"formacao\"] == formacao]), sep=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contagem de Professores por Tipo de Jornada de Trabalho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dedicação exclusiva           : 2155\n",
      "20 horas semanais             : 307\n",
      "40 horas semanais             : 290\n"
     ]
    }
   ],
   "source": [
    "for tipo_jornada_trabalho in df[\"tipo_jornada_trabalho\"].unique():\n",
    "    print(tipo_jornada_trabalho, \": \", len(\n",
    "        df[df[\"tipo_jornada_trabalho\"] == tipo_jornada_trabalho]), sep=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contagem de Professores por Tipo de Vínculo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ativo Permanente: 2376\n",
      "Celetista: 1\n",
      "Colaborador PCCTAE e Magistério Federal: 2\n",
      "Excedente de lotação: 3\n",
      "Exercicio provisorio: 18\n",
      "Professor Substituto: 260\n",
      "Professor Temporario: 50\n",
      "Professor Visitante: 42\n"
     ]
    }
   ],
   "source": [
    "for vinculo in df[\"vinculo\"].unique():\n",
    "    print(vinculo, \": \", len(df[df[\"vinculo\"] == vinculo]), sep=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remoção de Vínculos com Poucas Entradas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ativo Permanente: 2376\n",
      "Exercicio provisorio: 18\n",
      "Professor Substituto: 260\n",
      "Professor Temporario: 50\n",
      "Professor Visitante: 42\n"
     ]
    }
   ],
   "source": [
    "# há poucas pessoas com esses atributos:\n",
    "\n",
    "df = df[df[\"vinculo\"] != \"Celetista\"]\n",
    "df = df[df[\"vinculo\"] != \"Colaborador PCCTAE e Magistério Federal\"]\n",
    "df = df[df[\"vinculo\"] != \"Excedente de lotação\"]\n",
    "for vinculo in df[\"vinculo\"].unique():\n",
    "    print(vinculo, \": \", len(df[df[\"vinculo\"] == vinculo]), sep=\"\")\n",
    "\n",
    "# então decidi retirá-los"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contagem de Professores por Categoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO: 215\n",
      "PROFESSOR DO MAGISTERIO SUPERIOR: 2178\n",
      "PROFESSOR 3 GRAU                        : 1\n",
      "PROF ENS BAS TEC TECNOLOGICO-SUBSTITUTO: 29\n",
      "PROFESSOR DO MAGISTERIO SUPERIOR - SUBSTITUTO: 231\n",
      "PROFESSOR DO MAGISTERIO SUPERIOR - TEMPORARIO: 50\n",
      "PROFESSOR MAGISTERIO SUPERIOR - VISITANTE: 42\n"
     ]
    }
   ],
   "source": [
    "for categoria in df[\"categoria\"].unique():\n",
    "    print(categoria, \": \", len(df[df[\"categoria\"] == categoria]), sep=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veja que a informação de \"SUBSTITUTO\", \"TEMPORARIO\" e \"VISITANTE\" já está informada na coluna \"vínculo\". Então, irei retirá-la dos dados, assim como o único professor de terceiro grau."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Atualização e Simplificação de Categorias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO: 244\n",
      "PROFESSOR DO MAGISTERIO SUPERIOR: 2501\n"
     ]
    }
   ],
   "source": [
    "retirar_vinculo = {\"PROF ENS BAS TEC TECNOLOGICO-SUBSTITUTO\":\"PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO\",\n",
    "                   \"PROFESSOR DO MAGISTERIO SUPERIOR - SUBSTITUTO\":\"PROFESSOR DO MAGISTERIO SUPERIOR\",\n",
    "                   \"PROFESSOR DO MAGISTERIO SUPERIOR - TEMPORARIO\":\"PROFESSOR DO MAGISTERIO SUPERIOR\",\n",
    "                   \"PROFESSOR MAGISTERIO SUPERIOR - VISITANTE\":\"PROFESSOR DO MAGISTERIO SUPERIOR\"}\n",
    "\n",
    "df = df[df[\"categoria\"] != \"PROFESSOR 3 GRAU                        \"]\n",
    "\n",
    "df[\"categoria\"].replace(retirar_vinculo, inplace=True)\n",
    "\n",
    "for categoria in df[\"categoria\"].unique():\n",
    "    print(categoria, \": \", len(df[df[\"categoria\"] == categoria]), sep=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verifique que a soma de elementos de uma mesma categoria se manteve. Agora, iremos ranquear os professores com base em sua classe funcional:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classificação de Professores por Classe Funcional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DIV                                                                                                 : 75\n",
      "DV                                                                                                  : 32\n",
      "DIII                                                                                                : 78\n",
      "DI                                                                                                  : 47\n",
      "D                                                                                                   : 7\n",
      "DII                                                                                                 : 4\n",
      "Classe A - Adjunto A                                                                                : 141\n",
      "Classe C - Adjunto                                                                                  : 757\n",
      "Classe A - Auxiliar                                                                                 : 46\n",
      "Classe E - Titular                                                                                  : 307\n",
      "Classe D - Associado                                                                                : 834\n",
      "Classe B - Assistente                                                                               : 59\n",
      "Classe A - Assistente A                                                                             : 22\n",
      "Não Informada                                                                                       : 16\n",
      "Auxiliar                                                                                            : 278\n",
      "A                                                                                                   : 20\n",
      "Titular                                                                                             : 13\n",
      "Adjunto                                                                                             : 9\n"
     ]
    }
   ],
   "source": [
    "for classe_funcional in df[\"classe_funcional\"].unique():\n",
    "    print(classe_funcional, \": \", len(df[df[\"classe_funcional\"] == classe_funcional]), sep=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver, há 17 professores com classes não-informadas, e algmas estão repetidas e com outros nomes. Ainda, há 20 professores de classe A sem uma subclasse. O mapeamento, segundo a [PROGESP](https://progesp.ufrn.br/secao/carreira), se dá da seguinte maneira:\n",
    "\n",
    "| Original | Mapeamento |\n",
    "|-|-|\n",
    "|DV|1|\n",
    "|DIV|2|\n",
    "|DIII|3|\n",
    "|DII|4|\n",
    "|DI|5|\n",
    "|Classe E - Titular<br>Titular|6|\n",
    "|Classe D - Associado<br>D|7|\n",
    "|Classe C - Adjunto<br>Adjunto|8|\n",
    "|Classe B - Assistente|9|\n",
    "|Classe A - Auxiliar<br>Auxiliar|10|\n",
    "|Classe A - Assistente A<br>A|11|\n",
    "|Classe A - Adjunto A|12|\n",
    "\n",
    "É importante notar também que iremos retirar professores sem categoria. E professores classe A sem denominação específica serão tratados como Assistentes, pois têm o valor médio da classe A."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapeamento e Classificação das Classes Funcionais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapear_class_func = {\n",
    "    \"DV                                                                                                  \":1,\n",
    "    \"DIV                                                                                                 \":2,\n",
    "    \"DIII                                                                                                \":3,\n",
    "    \"DII                                                                                                 \":4,\n",
    "    \"DI                                                                                                  \":5,\n",
    "    \"Classe E - Titular                                                                                  \":6,\n",
    "    \"Titular                                                                                             \":6,\n",
    "    \"Classe D - Associado                                                                                \":7,\n",
    "    \"D                                                                                                   \":7,\n",
    "    \"Classe C - Adjunto                                                                                  \":8,\n",
    "    \"Adjunto                                                                                             \":8,\n",
    "    \"Classe B - Assistente                                                                               \":9,\n",
    "    \"Classe A - Auxiliar                                                                                 \":10,\n",
    "    \"Auxiliar                                                                                            \":10,\n",
    "    \"Classe A - Assistente A                                                                             \":11,\n",
    "    \"A                                                                                                   \":11,\n",
    "    \"Classe A - Adjunto A                                                                                \":12,\n",
    "}\n",
    "\n",
    "df = df[df[\"classe_funcional\"] != \"Não Informada                                                                                       \"]\n",
    "\n",
    "df[\"classe_funcional\"].replace(mapear_class_func, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contagem de Professores por Classe Funcional Após Classificação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2: 75\n",
      "1: 32\n",
      "3: 78\n",
      "5: 47\n",
      "7: 841\n",
      "4: 4\n",
      "12: 141\n",
      "8: 766\n",
      "10: 324\n",
      "6: 320\n",
      "9: 59\n",
      "11: 42\n"
     ]
    }
   ],
   "source": [
    "for classe_funcional in df[\"classe_funcional\"].unique():\n",
    "    print(classe_funcional, \": \", len(df[df[\"classe_funcional\"] == classe_funcional]), sep=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reset do Índice e Resumo Estatístico do DataFrame Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>formacao</th>\n",
       "      <th>classe_funcional</th>\n",
       "      <th>num_semestres</th>\n",
       "      <th>revista_a1</th>\n",
       "      <th>revista_a2</th>\n",
       "      <th>revista_b1</th>\n",
       "      <th>revista_b2</th>\n",
       "      <th>revista_b3</th>\n",
       "      <th>revista_b4</th>\n",
       "      <th>revista_c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2729.000000</td>\n",
       "      <td>2729.000000</td>\n",
       "      <td>2729.000000</td>\n",
       "      <td>2729.000000</td>\n",
       "      <td>2729.000000</td>\n",
       "      <td>2729.000000</td>\n",
       "      <td>2729.000000</td>\n",
       "      <td>2729.000000</td>\n",
       "      <td>2729.000000</td>\n",
       "      <td>2729.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.744229</td>\n",
       "      <td>7.521803</td>\n",
       "      <td>25.477831</td>\n",
       "      <td>2.646757</td>\n",
       "      <td>1.939538</td>\n",
       "      <td>1.755955</td>\n",
       "      <td>1.270429</td>\n",
       "      <td>0.814584</td>\n",
       "      <td>0.569073</td>\n",
       "      <td>0.890070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.548749</td>\n",
       "      <td>2.113959</td>\n",
       "      <td>20.856943</td>\n",
       "      <td>6.095930</td>\n",
       "      <td>3.929876</td>\n",
       "      <td>5.398132</td>\n",
       "      <td>2.900249</td>\n",
       "      <td>2.394411</td>\n",
       "      <td>1.780601</td>\n",
       "      <td>3.868675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>124.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          formacao  classe_funcional  num_semestres   revista_a1   revista_a2  \\\n",
       "count  2729.000000       2729.000000    2729.000000  2729.000000  2729.000000   \n",
       "mean      3.744229          7.521803      25.477831     2.646757     1.939538   \n",
       "std       0.548749          2.113959      20.856943     6.095930     3.929876   \n",
       "min       1.000000          1.000000       0.000000     0.000000     0.000000   \n",
       "25%       4.000000          7.000000      10.000000     0.000000     0.000000   \n",
       "50%       4.000000          7.000000      24.000000     0.000000     0.000000   \n",
       "75%       4.000000          8.000000      30.000000     3.000000     2.000000   \n",
       "max       5.000000         12.000000      97.000000    71.000000    51.000000   \n",
       "\n",
       "        revista_b1   revista_b2   revista_b3   revista_b4    revista_c  \n",
       "count  2729.000000  2729.000000  2729.000000  2729.000000  2729.000000  \n",
       "mean      1.755955     1.270429     0.814584     0.569073     0.890070  \n",
       "std       5.398132     2.900249     2.394411     1.780601     3.868675  \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "75%       2.000000     1.000000     1.000000     0.000000     1.000000  \n",
       "max      99.000000    46.000000    41.000000    32.000000   124.000000  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.reset_index(drop=True, inplace=True)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resumo Estatístico das Colunas de Texto no DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tipo_jornada_trabalho</th>\n",
       "      <th>vinculo</th>\n",
       "      <th>categoria</th>\n",
       "      <th>lotacao</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2729</td>\n",
       "      <td>2729</td>\n",
       "      <td>2729</td>\n",
       "      <td>2729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Ativo Permanente</td>\n",
       "      <td>PROFESSOR DO MAGISTERIO SUPERIOR</td>\n",
       "      <td>ESCOLA AGRÍCOLA DE JUNDIAÍ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>2133</td>\n",
       "      <td>2376</td>\n",
       "      <td>2486</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 tipo_jornada_trabalho           vinculo  \\\n",
       "count                             2729              2729   \n",
       "unique                               3                 5   \n",
       "top     Dedicação exclusiva             Ativo Permanente   \n",
       "freq                              2133              2376   \n",
       "\n",
       "                               categoria                     lotacao  \n",
       "count                               2729                        2729  \n",
       "unique                                 2                         134  \n",
       "top     PROFESSOR DO MAGISTERIO SUPERIOR  ESCOLA AGRÍCOLA DE JUNDIAÍ  \n",
       "freq                                2486                         119  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include=\"object\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparação dos Dados para Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep = ['revista_a1',\n",
    "        'revista_a2',\n",
    "        'revista_b1',\n",
    "        'revista_b2',\n",
    "        'revista_b3',\n",
    "        'revista_b4',\n",
    "        'revista_c']\n",
    "\n",
    "X = df.drop(keep, axis=1).copy()\n",
    "\n",
    "[ya1,\n",
    " ya2,\n",
    " yb1,\n",
    " yb2,\n",
    " yb3,\n",
    " yb4,\n",
    " yc] = [df[col].copy() for col in keep]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Codificação de Variáveis Categóricas em Dados Numéricos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>formacao</th>\n",
       "      <th>classe_funcional</th>\n",
       "      <th>num_semestres</th>\n",
       "      <th>tipo_jornada_trabalho_20 horas semanais</th>\n",
       "      <th>tipo_jornada_trabalho_40 horas semanais</th>\n",
       "      <th>tipo_jornada_trabalho_Dedicação exclusiva</th>\n",
       "      <th>vinculo_Ativo Permanente</th>\n",
       "      <th>vinculo_Exercicio provisorio</th>\n",
       "      <th>vinculo_Professor Substituto</th>\n",
       "      <th>vinculo_Professor Temporario</th>\n",
       "      <th>...</th>\n",
       "      <th>lotacao_SECRETARIA DE EDUCAÇÃO BÁSICA, TÉCNICA E TECNOLÓGICA DA UFRN</th>\n",
       "      <th>lotacao_SECRETARIA DE GESTÃO DE PROJETOS</th>\n",
       "      <th>lotacao_SECRETARIA DE GOVERNANÇA INSTITUCIONAL</th>\n",
       "      <th>lotacao_SECRETARIA DE INCLUSÃO E ACESSIBILIDADE- SIA</th>\n",
       "      <th>lotacao_SECRETARIA DE RELAÇOES INTERNACIONAIS</th>\n",
       "      <th>lotacao_SUPERINTENDENCIA DE COMUNICACAO</th>\n",
       "      <th>lotacao_SUPERINTENDÊNCIA DE INFRAESTRUTURA</th>\n",
       "      <th>lotacao_SUPERINTENDÊNCIA DE TECNOLOGIA DA INFORMAÇÃO</th>\n",
       "      <th>lotacao_SUPERINTENDÊNCIA DO HUOL - EBSERH</th>\n",
       "      <th>lotacao_UNIVERSIDADE FEDERAL DO RIO GRANDE DO NORTE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>51</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2724</th>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2725</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2726</th>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2727</th>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2728</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2729 rows × 147 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      formacao  classe_funcional  num_semestres  \\\n",
       "0            3                 2             34   \n",
       "1            4                 1             30   \n",
       "2            3                 2             51   \n",
       "3            3                 3             13   \n",
       "4            4                 2             28   \n",
       "...        ...               ...            ...   \n",
       "2724         4                 8              1   \n",
       "2725         4                 6              2   \n",
       "2726         4                11              2   \n",
       "2727         4                11              1   \n",
       "2728         4                 6              2   \n",
       "\n",
       "      tipo_jornada_trabalho_20 horas semanais               \\\n",
       "0                                                 False      \n",
       "1                                                 False      \n",
       "2                                                 False      \n",
       "3                                                 False      \n",
       "4                                                 False      \n",
       "...                                                 ...      \n",
       "2724                                              False      \n",
       "2725                                              False      \n",
       "2726                                              False      \n",
       "2727                                              False      \n",
       "2728                                              False      \n",
       "\n",
       "      tipo_jornada_trabalho_40 horas semanais               \\\n",
       "0                                                 False      \n",
       "1                                                 False      \n",
       "2                                                 False      \n",
       "3                                                 False      \n",
       "4                                                 False      \n",
       "...                                                 ...      \n",
       "2724                                              False      \n",
       "2725                                              False      \n",
       "2726                                              False      \n",
       "2727                                              False      \n",
       "2728                                              False      \n",
       "\n",
       "      tipo_jornada_trabalho_Dedicação exclusiva             \\\n",
       "0                                                  True      \n",
       "1                                                  True      \n",
       "2                                                  True      \n",
       "3                                                  True      \n",
       "4                                                  True      \n",
       "...                                                 ...      \n",
       "2724                                               True      \n",
       "2725                                               True      \n",
       "2726                                               True      \n",
       "2727                                               True      \n",
       "2728                                               True      \n",
       "\n",
       "      vinculo_Ativo Permanente  vinculo_Exercicio provisorio  \\\n",
       "0                         True                         False   \n",
       "1                         True                         False   \n",
       "2                         True                         False   \n",
       "3                         True                         False   \n",
       "4                         True                         False   \n",
       "...                        ...                           ...   \n",
       "2724                     False                         False   \n",
       "2725                     False                         False   \n",
       "2726                     False                         False   \n",
       "2727                     False                         False   \n",
       "2728                     False                         False   \n",
       "\n",
       "      vinculo_Professor Substituto  vinculo_Professor Temporario  ...  \\\n",
       "0                            False                         False  ...   \n",
       "1                            False                         False  ...   \n",
       "2                            False                         False  ...   \n",
       "3                            False                         False  ...   \n",
       "4                            False                         False  ...   \n",
       "...                            ...                           ...  ...   \n",
       "2724                         False                         False  ...   \n",
       "2725                         False                         False  ...   \n",
       "2726                         False                         False  ...   \n",
       "2727                         False                         False  ...   \n",
       "2728                         False                         False  ...   \n",
       "\n",
       "      lotacao_SECRETARIA DE EDUCAÇÃO BÁSICA, TÉCNICA E TECNOLÓGICA DA UFRN  \\\n",
       "0                                                 False                      \n",
       "1                                                 False                      \n",
       "2                                                 False                      \n",
       "3                                                 False                      \n",
       "4                                                 False                      \n",
       "...                                                 ...                      \n",
       "2724                                              False                      \n",
       "2725                                              False                      \n",
       "2726                                              False                      \n",
       "2727                                              False                      \n",
       "2728                                              False                      \n",
       "\n",
       "      lotacao_SECRETARIA DE GESTÃO DE PROJETOS  \\\n",
       "0                                        False   \n",
       "1                                        False   \n",
       "2                                        False   \n",
       "3                                        False   \n",
       "4                                        False   \n",
       "...                                        ...   \n",
       "2724                                     False   \n",
       "2725                                     False   \n",
       "2726                                     False   \n",
       "2727                                     False   \n",
       "2728                                     False   \n",
       "\n",
       "      lotacao_SECRETARIA DE GOVERNANÇA INSTITUCIONAL  \\\n",
       "0                                              False   \n",
       "1                                              False   \n",
       "2                                              False   \n",
       "3                                              False   \n",
       "4                                              False   \n",
       "...                                              ...   \n",
       "2724                                           False   \n",
       "2725                                           False   \n",
       "2726                                           False   \n",
       "2727                                           False   \n",
       "2728                                           False   \n",
       "\n",
       "      lotacao_SECRETARIA DE INCLUSÃO E ACESSIBILIDADE- SIA  \\\n",
       "0                                                 False      \n",
       "1                                                 False      \n",
       "2                                                 False      \n",
       "3                                                 False      \n",
       "4                                                 False      \n",
       "...                                                 ...      \n",
       "2724                                              False      \n",
       "2725                                              False      \n",
       "2726                                              False      \n",
       "2727                                              False      \n",
       "2728                                              False      \n",
       "\n",
       "      lotacao_SECRETARIA DE RELAÇOES INTERNACIONAIS  \\\n",
       "0                                             False   \n",
       "1                                             False   \n",
       "2                                             False   \n",
       "3                                             False   \n",
       "4                                             False   \n",
       "...                                             ...   \n",
       "2724                                          False   \n",
       "2725                                          False   \n",
       "2726                                          False   \n",
       "2727                                          False   \n",
       "2728                                          False   \n",
       "\n",
       "      lotacao_SUPERINTENDENCIA DE COMUNICACAO  \\\n",
       "0                                       False   \n",
       "1                                       False   \n",
       "2                                       False   \n",
       "3                                       False   \n",
       "4                                       False   \n",
       "...                                       ...   \n",
       "2724                                    False   \n",
       "2725                                    False   \n",
       "2726                                    False   \n",
       "2727                                    False   \n",
       "2728                                    False   \n",
       "\n",
       "      lotacao_SUPERINTENDÊNCIA DE INFRAESTRUTURA  \\\n",
       "0                                          False   \n",
       "1                                          False   \n",
       "2                                          False   \n",
       "3                                          False   \n",
       "4                                          False   \n",
       "...                                          ...   \n",
       "2724                                       False   \n",
       "2725                                       False   \n",
       "2726                                       False   \n",
       "2727                                       False   \n",
       "2728                                       False   \n",
       "\n",
       "      lotacao_SUPERINTENDÊNCIA DE TECNOLOGIA DA INFORMAÇÃO  \\\n",
       "0                                                 False      \n",
       "1                                                 False      \n",
       "2                                                 False      \n",
       "3                                                 False      \n",
       "4                                                 False      \n",
       "...                                                 ...      \n",
       "2724                                              False      \n",
       "2725                                              False      \n",
       "2726                                              False      \n",
       "2727                                              False      \n",
       "2728                                              False      \n",
       "\n",
       "      lotacao_SUPERINTENDÊNCIA DO HUOL - EBSERH  \\\n",
       "0                                         False   \n",
       "1                                         False   \n",
       "2                                         False   \n",
       "3                                         False   \n",
       "4                                         False   \n",
       "...                                         ...   \n",
       "2724                                      False   \n",
       "2725                                      False   \n",
       "2726                                      False   \n",
       "2727                                      False   \n",
       "2728                                      False   \n",
       "\n",
       "      lotacao_UNIVERSIDADE FEDERAL DO RIO GRANDE DO NORTE  \n",
       "0                                                 False    \n",
       "1                                                 False    \n",
       "2                                                 False    \n",
       "3                                                 False    \n",
       "4                                                 False    \n",
       "...                                                 ...    \n",
       "2724                                              False    \n",
       "2725                                              False    \n",
       "2726                                              False    \n",
       "2727                                              False    \n",
       "2728                                              False    \n",
       "\n",
       "[2729 rows x 147 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_encoded = pd.get_dummies(X, columns=[\"tipo_jornada_trabalho\",\n",
    "                                       \"vinculo\",\n",
    "                                       \"categoria\",\n",
    "                                       \"lotacao\"])\n",
    "\n",
    "X_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cálculo das Médias das Taxas por Categoria de Revista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ya1': 2.646757053865885,\n",
       " 'ya2': 1.939538292414804,\n",
       " 'yb1': 1.7559545621106631,\n",
       " 'yb2': 1.2704287284719677,\n",
       " 'yb3': 0.8145840967387321,\n",
       " 'yb4': 0.5690729204836936,\n",
       " 'yc': 0.8900696225723709}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\"ya1\": (sum(ya1) / len(ya1)),\n",
    " \"ya2\": (sum(ya2) / len(ya2)),\n",
    " \"yb1\": (sum(yb1) / len(yb1)),\n",
    " \"yb2\": (sum(yb2) / len(yb2)),\n",
    " \"yb3\": (sum(yb3) / len(yb3)),\n",
    " \"yb4\": (sum(yb4) / len(yb4)),\n",
    " \"yc\": (sum(yc) / len(yc))}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparação dos Conjuntos de Treinamento e Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_vars = [(ya1, \"ya1\"),\n",
    "               (ya2, \"ya2\"),\n",
    "               (yb1, \"yb1\"),\n",
    "               (yb2, \"yb2\"),\n",
    "               (yb3, \"yb3\"),\n",
    "               (yb4, \"yb4\"),\n",
    "               (yc, \"yc\")]\n",
    "\n",
    "train_test_sets = {}\n",
    "\n",
    "for var, var_name in target_vars:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_encoded, var, random_state=42)\n",
    "    train_test_sets[var_name] = (X_train, X_test, y_train, y_test)\n",
    "\n",
    "# Agora, você pode acessar os conjuntos de treinamento e teste usando o nome da variável alvo desejada\n",
    "X_train_ya1, X_test_ya1, ya1_train, ya1_test = train_test_sets[\"ya1\"]\n",
    "X_train_ya2, X_test_ya2, ya2_train, ya2_test = train_test_sets[\"ya2\"]\n",
    "X_train_yb1, X_test_yb1, yb1_train, yb1_test = train_test_sets[\"yb1\"]\n",
    "X_train_yb2, X_test_yb2, yb2_train, yb2_test = train_test_sets[\"yb2\"]\n",
    "X_train_yb3, X_test_yb3, yb3_train, yb3_test = train_test_sets[\"yb3\"]\n",
    "X_train_yb4, X_test_yb4, yb4_train, yb4_test = train_test_sets[\"yb4\"]\n",
    "X_train_yc, X_test_yc, yc_train, yc_test = train_test_sets[\"yc\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Médias das Taxas nas Partições de Treinamento e Teste por Categoria de Revista (TRAIN & TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ya1': (2.639784946236559, 2.6676427525622253),\n",
       " 'ya2': (1.9472140762463344, 1.916544655929722),\n",
       " 'yb1': (1.6715542521994136, 2.0087847730600292),\n",
       " 'yb2': (1.1901270772238515, 1.5109809663250366),\n",
       " 'yb3': (0.8093841642228738, 0.8301610541727672),\n",
       " 'yb4': (0.5650048875855328, 0.5812591508052709),\n",
       " 'yc': (0.9496578690127078, 0.7115666178623719)}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test_pairs = {\n",
    "    \"ya1\": (sum(ya1_train) / len(ya1_train), sum(ya1_test) / len(ya1_test)),\n",
    "    \"ya2\": (sum(ya2_train) / len(ya2_train), sum(ya2_test) / len(ya2_test)),\n",
    "    \"yb1\": (sum(yb1_train) / len(yb1_train), sum(yb1_test) / len(yb1_test)),\n",
    "    \"yb2\": (sum(yb2_train) / len(yb2_train), sum(yb2_test) / len(yb2_test)),\n",
    "    \"yb3\": (sum(yb3_train) / len(yb3_train), sum(yb3_test) / len(yb3_test)),\n",
    "    \"yb4\": (sum(yb4_train) / len(yb4_train), sum(yb4_test) / len(yb4_test)),\n",
    "    \"yc\" : (sum(yc_train) / len(yc_train), sum(yc_test) / len(yc_test))\n",
    "}\n",
    "\n",
    "train_test_pairs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Espaço de Parâmetros para Otimização do Modelo XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_space = {\n",
    "    \"max_depth\": Integer(1,20),\n",
    "    \"n_estimators\": Integer(10,1000),\n",
    "    \"reg_lambda\": Real(0, 10),\n",
    "    \"eta\": Real(0.01, 1),\n",
    "    \"gamma\": Real(0,7)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinamento e Otimização do Modelo XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo XGBoost para \"ya1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\data.py:335: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(dtype):\n",
      "c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\data.py:338: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  is_categorical_dtype(dtype) or is_pa_ext_categorical_dtype(dtype)\n",
      "c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\data.py:384: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_categorical_dtype(dtype):\n",
      "c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\data.py:359: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  return is_int or is_bool or is_float or is_categorical_dtype(dtype)\n",
      "c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\data.py:520: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(data):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BayesSearchCV(cv=5,\n",
       "              estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "              search_spaces={&#x27;eta&#x27;: Real(low=0.01, high=1, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;gamma&#x27;: Real(low=0, high=7, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;max_depth&#x27;: Integer(low=1, high=20, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;n_estimators&#x27;: Integer(low=10, high=1000, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;reg_lambda&#x27;: Real(low=0, high=10, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;)},\n",
       "              verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BayesSearchCV</label><div class=\"sk-toggleable__content\"><pre>BayesSearchCV(cv=5,\n",
       "              estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "              search_spaces={&#x27;eta&#x27;: Real(low=0.01, high=1, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;gamma&#x27;: Real(low=0, high=7, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;max_depth&#x27;: Integer(low=1, high=20, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;n_estimators&#x27;: Integer(low=10, high=1000, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;reg_lambda&#x27;: Real(low=0, high=10, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;)},\n",
       "              verbose=True)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "BayesSearchCV(cv=5,\n",
       "              estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "              search_spaces={'eta': Real(low=0.01, high=1, prior='uniform', transform='normalize'),\n",
       "                             'gamma': Real(low=0, high=7, prior='uniform', transform='normalize'),\n",
       "                             'max_depth': Integer(low=1, high=20, prior='uniform', transform='normalize'),\n",
       "                             'n_estimators': Integer(low=10, high=1000, prior='uniform', transform='normalize'),\n",
       "                             'reg_lambda': Real(low=0, high=10, prior='uniform', transform='normalize')},\n",
       "              verbose=True)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_xgb_ya1 = xgb.XGBRegressor()\n",
    "\n",
    "xgb_bayes_ya1 = BayesSearchCV(reg_xgb_ya1,\n",
    "                              param_space,\n",
    "                              n_iter=32,\n",
    "                              scoring=\"neg_root_mean_squared_error\",\n",
    "                              verbose=True,\n",
    "                              cv=5,\n",
    "                              n_jobs=8,\n",
    "                              random_state=42)\n",
    "\n",
    "xgb_bayes_ya1.fit(X_train_ya1, ya1_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo XGBoost para \"ya2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\data.py:335: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(dtype):\n",
      "c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\data.py:338: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  is_categorical_dtype(dtype) or is_pa_ext_categorical_dtype(dtype)\n",
      "c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\data.py:384: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_categorical_dtype(dtype):\n",
      "c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\data.py:359: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  return is_int or is_bool or is_float or is_categorical_dtype(dtype)\n",
      "c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\data.py:520: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(data):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BayesSearchCV(cv=5,\n",
       "              estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "              search_spaces={&#x27;eta&#x27;: Real(low=0.01, high=1, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;gamma&#x27;: Real(low=0, high=7, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;max_depth&#x27;: Integer(low=1, high=20, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;n_estimators&#x27;: Integer(low=10, high=1000, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;reg_lambda&#x27;: Real(low=0, high=10, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;)},\n",
       "              verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BayesSearchCV</label><div class=\"sk-toggleable__content\"><pre>BayesSearchCV(cv=5,\n",
       "              estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "              search_spaces={&#x27;eta&#x27;: Real(low=0.01, high=1, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;gamma&#x27;: Real(low=0, high=7, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;max_depth&#x27;: Integer(low=1, high=20, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;n_estimators&#x27;: Integer(low=10, high=1000, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;reg_lambda&#x27;: Real(low=0, high=10, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;)},\n",
       "              verbose=True)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "BayesSearchCV(cv=5,\n",
       "              estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "              search_spaces={'eta': Real(low=0.01, high=1, prior='uniform', transform='normalize'),\n",
       "                             'gamma': Real(low=0, high=7, prior='uniform', transform='normalize'),\n",
       "                             'max_depth': Integer(low=1, high=20, prior='uniform', transform='normalize'),\n",
       "                             'n_estimators': Integer(low=10, high=1000, prior='uniform', transform='normalize'),\n",
       "                             'reg_lambda': Real(low=0, high=10, prior='uniform', transform='normalize')},\n",
       "              verbose=True)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_xgb_ya2 = xgb.XGBRegressor()\n",
    "\n",
    "xgb_bayes_ya2 = BayesSearchCV(reg_xgb_ya2,\n",
    "                              param_space,\n",
    "                              n_iter=32,\n",
    "                              scoring=\"neg_root_mean_squared_error\",\n",
    "                              verbose=True,\n",
    "                              cv=5,\n",
    "                              n_jobs=8,\n",
    "                              random_state=42)\n",
    "\n",
    "xgb_bayes_ya2.fit(X_train_ya2, ya2_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo XGBoost para \"yb1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\data.py:335: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(dtype):\n",
      "c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\data.py:338: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  is_categorical_dtype(dtype) or is_pa_ext_categorical_dtype(dtype)\n",
      "c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\data.py:384: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_categorical_dtype(dtype):\n",
      "c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\data.py:359: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  return is_int or is_bool or is_float or is_categorical_dtype(dtype)\n",
      "c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\data.py:520: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(data):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BayesSearchCV(cv=5,\n",
       "              estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "              search_spaces={&#x27;eta&#x27;: Real(low=0.01, high=1, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;gamma&#x27;: Real(low=0, high=7, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;max_depth&#x27;: Integer(low=1, high=20, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;n_estimators&#x27;: Integer(low=10, high=1000, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;reg_lambda&#x27;: Real(low=0, high=10, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;)},\n",
       "              verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BayesSearchCV</label><div class=\"sk-toggleable__content\"><pre>BayesSearchCV(cv=5,\n",
       "              estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "              search_spaces={&#x27;eta&#x27;: Real(low=0.01, high=1, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;gamma&#x27;: Real(low=0, high=7, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;max_depth&#x27;: Integer(low=1, high=20, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;n_estimators&#x27;: Integer(low=10, high=1000, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;reg_lambda&#x27;: Real(low=0, high=10, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;)},\n",
       "              verbose=True)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "BayesSearchCV(cv=5,\n",
       "              estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "              search_spaces={'eta': Real(low=0.01, high=1, prior='uniform', transform='normalize'),\n",
       "                             'gamma': Real(low=0, high=7, prior='uniform', transform='normalize'),\n",
       "                             'max_depth': Integer(low=1, high=20, prior='uniform', transform='normalize'),\n",
       "                             'n_estimators': Integer(low=10, high=1000, prior='uniform', transform='normalize'),\n",
       "                             'reg_lambda': Real(low=0, high=10, prior='uniform', transform='normalize')},\n",
       "              verbose=True)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_xgb_yb1 = xgb.XGBRegressor()\n",
    "\n",
    "xgb_bayes_yb1 = BayesSearchCV(reg_xgb_yb1,\n",
    "                              param_space,\n",
    "                              n_iter=32,\n",
    "                              scoring=\"neg_root_mean_squared_error\",\n",
    "                              verbose=True,\n",
    "                              cv=5,\n",
    "                              n_jobs=8,\n",
    "                              random_state=42)\n",
    "\n",
    "xgb_bayes_yb1.fit(X_train_yb1, yb1_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo XGBoost para \"yb2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\data.py:335: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(dtype):\n",
      "c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\data.py:338: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  is_categorical_dtype(dtype) or is_pa_ext_categorical_dtype(dtype)\n",
      "c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\data.py:384: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_categorical_dtype(dtype):\n",
      "c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\data.py:359: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  return is_int or is_bool or is_float or is_categorical_dtype(dtype)\n",
      "c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\data.py:520: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(data):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BayesSearchCV(cv=5,\n",
       "              estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "              search_spaces={&#x27;eta&#x27;: Real(low=0.01, high=1, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;gamma&#x27;: Real(low=0, high=7, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;max_depth&#x27;: Integer(low=1, high=20, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;n_estimators&#x27;: Integer(low=10, high=1000, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;reg_lambda&#x27;: Real(low=0, high=10, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;)},\n",
       "              verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BayesSearchCV</label><div class=\"sk-toggleable__content\"><pre>BayesSearchCV(cv=5,\n",
       "              estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "              search_spaces={&#x27;eta&#x27;: Real(low=0.01, high=1, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;gamma&#x27;: Real(low=0, high=7, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;max_depth&#x27;: Integer(low=1, high=20, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;n_estimators&#x27;: Integer(low=10, high=1000, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;reg_lambda&#x27;: Real(low=0, high=10, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;)},\n",
       "              verbose=True)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "BayesSearchCV(cv=5,\n",
       "              estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "              search_spaces={'eta': Real(low=0.01, high=1, prior='uniform', transform='normalize'),\n",
       "                             'gamma': Real(low=0, high=7, prior='uniform', transform='normalize'),\n",
       "                             'max_depth': Integer(low=1, high=20, prior='uniform', transform='normalize'),\n",
       "                             'n_estimators': Integer(low=10, high=1000, prior='uniform', transform='normalize'),\n",
       "                             'reg_lambda': Real(low=0, high=10, prior='uniform', transform='normalize')},\n",
       "              verbose=True)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_xgb_yb2 = xgb.XGBRegressor()\n",
    "\n",
    "xgb_bayes_yb2 = BayesSearchCV(reg_xgb_yb2,\n",
    "                              param_space,\n",
    "                              n_iter=32,\n",
    "                              scoring=\"neg_root_mean_squared_error\",\n",
    "                              verbose=True,\n",
    "                              cv=5,\n",
    "                              n_jobs=8,\n",
    "                              random_state=42)\n",
    "\n",
    "xgb_bayes_yb2.fit(X_train_yb2, yb2_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo XGBoost para \"yb3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\data.py:335: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(dtype):\n",
      "c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\data.py:338: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  is_categorical_dtype(dtype) or is_pa_ext_categorical_dtype(dtype)\n",
      "c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\data.py:384: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_categorical_dtype(dtype):\n",
      "c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\data.py:359: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  return is_int or is_bool or is_float or is_categorical_dtype(dtype)\n",
      "c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\data.py:520: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(data):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BayesSearchCV(cv=5,\n",
       "              estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "              search_spaces={&#x27;eta&#x27;: Real(low=0.01, high=1, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;gamma&#x27;: Real(low=0, high=7, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;max_depth&#x27;: Integer(low=1, high=20, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;n_estimators&#x27;: Integer(low=10, high=1000, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;reg_lambda&#x27;: Real(low=0, high=10, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;)},\n",
       "              verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BayesSearchCV</label><div class=\"sk-toggleable__content\"><pre>BayesSearchCV(cv=5,\n",
       "              estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "              search_spaces={&#x27;eta&#x27;: Real(low=0.01, high=1, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;gamma&#x27;: Real(low=0, high=7, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;max_depth&#x27;: Integer(low=1, high=20, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;n_estimators&#x27;: Integer(low=10, high=1000, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;reg_lambda&#x27;: Real(low=0, high=10, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;)},\n",
       "              verbose=True)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "BayesSearchCV(cv=5,\n",
       "              estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "              search_spaces={'eta': Real(low=0.01, high=1, prior='uniform', transform='normalize'),\n",
       "                             'gamma': Real(low=0, high=7, prior='uniform', transform='normalize'),\n",
       "                             'max_depth': Integer(low=1, high=20, prior='uniform', transform='normalize'),\n",
       "                             'n_estimators': Integer(low=10, high=1000, prior='uniform', transform='normalize'),\n",
       "                             'reg_lambda': Real(low=0, high=10, prior='uniform', transform='normalize')},\n",
       "              verbose=True)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_xgb_yb3 = xgb.XGBRegressor()\n",
    "\n",
    "xgb_bayes_yb3 = BayesSearchCV(reg_xgb_yb3,\n",
    "                              param_space,\n",
    "                              n_iter=32,\n",
    "                              scoring=\"neg_root_mean_squared_error\",\n",
    "                              verbose=True,\n",
    "                              cv=5,\n",
    "                              n_jobs=8,\n",
    "                              random_state=42)\n",
    "\n",
    "xgb_bayes_yb3.fit(X_train_yb3, yb3_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo XGBoost para \"yb4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\data.py:335: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(dtype):\n",
      "c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\data.py:338: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  is_categorical_dtype(dtype) or is_pa_ext_categorical_dtype(dtype)\n",
      "c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\data.py:384: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_categorical_dtype(dtype):\n",
      "c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\data.py:359: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  return is_int or is_bool or is_float or is_categorical_dtype(dtype)\n",
      "c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\data.py:520: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(data):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BayesSearchCV(cv=5,\n",
       "              estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "              search_spaces={&#x27;eta&#x27;: Real(low=0.01, high=1, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;gamma&#x27;: Real(low=0, high=7, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;max_depth&#x27;: Integer(low=1, high=20, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;n_estimators&#x27;: Integer(low=10, high=1000, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;reg_lambda&#x27;: Real(low=0, high=10, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;)},\n",
       "              verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BayesSearchCV</label><div class=\"sk-toggleable__content\"><pre>BayesSearchCV(cv=5,\n",
       "              estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "              search_spaces={&#x27;eta&#x27;: Real(low=0.01, high=1, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;gamma&#x27;: Real(low=0, high=7, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;max_depth&#x27;: Integer(low=1, high=20, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;n_estimators&#x27;: Integer(low=10, high=1000, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;reg_lambda&#x27;: Real(low=0, high=10, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;)},\n",
       "              verbose=True)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "BayesSearchCV(cv=5,\n",
       "              estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "              search_spaces={'eta': Real(low=0.01, high=1, prior='uniform', transform='normalize'),\n",
       "                             'gamma': Real(low=0, high=7, prior='uniform', transform='normalize'),\n",
       "                             'max_depth': Integer(low=1, high=20, prior='uniform', transform='normalize'),\n",
       "                             'n_estimators': Integer(low=10, high=1000, prior='uniform', transform='normalize'),\n",
       "                             'reg_lambda': Real(low=0, high=10, prior='uniform', transform='normalize')},\n",
       "              verbose=True)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_xgb_yb4 = xgb.XGBRegressor()\n",
    "\n",
    "xgb_bayes_yb4 = BayesSearchCV(reg_xgb_yb4,\n",
    "                              param_space,\n",
    "                              n_iter=32,\n",
    "                              scoring=\"neg_root_mean_squared_error\",\n",
    "                              verbose=True,\n",
    "                              cv=5,\n",
    "                              n_jobs=8,\n",
    "                              random_state=42)\n",
    "\n",
    "xgb_bayes_yb4.fit(X_train_yb4, yb4_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo XGBoost para \"yc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\data.py:335: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(dtype):\n",
      "c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\data.py:338: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  is_categorical_dtype(dtype) or is_pa_ext_categorical_dtype(dtype)\n",
      "c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\data.py:384: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_categorical_dtype(dtype):\n",
      "c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\data.py:359: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  return is_int or is_bool or is_float or is_categorical_dtype(dtype)\n",
      "c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\data.py:520: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(data):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BayesSearchCV(cv=5,\n",
       "              estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "              search_spaces={&#x27;eta&#x27;: Real(low=0.01, high=1, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;gamma&#x27;: Real(low=0, high=7, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;max_depth&#x27;: Integer(low=1, high=20, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;n_estimators&#x27;: Integer(low=10, high=1000, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;reg_lambda&#x27;: Real(low=0, high=10, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;)},\n",
       "              verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BayesSearchCV</label><div class=\"sk-toggleable__content\"><pre>BayesSearchCV(cv=5,\n",
       "              estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "              search_spaces={&#x27;eta&#x27;: Real(low=0.01, high=1, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;gamma&#x27;: Real(low=0, high=7, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;max_depth&#x27;: Integer(low=1, high=20, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;n_estimators&#x27;: Integer(low=10, high=1000, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;reg_lambda&#x27;: Real(low=0, high=10, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;)},\n",
       "              verbose=True)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" ><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "BayesSearchCV(cv=5,\n",
       "              estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "              search_spaces={'eta': Real(low=0.01, high=1, prior='uniform', transform='normalize'),\n",
       "                             'gamma': Real(low=0, high=7, prior='uniform', transform='normalize'),\n",
       "                             'max_depth': Integer(low=1, high=20, prior='uniform', transform='normalize'),\n",
       "                             'n_estimators': Integer(low=10, high=1000, prior='uniform', transform='normalize'),\n",
       "                             'reg_lambda': Real(low=0, high=10, prior='uniform', transform='normalize')},\n",
       "              verbose=True)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_xgb_yc = xgb.XGBRegressor()\n",
    "\n",
    "xgb_bayes_yc = BayesSearchCV(reg_xgb_yc,\n",
    "                             param_space,\n",
    "                             n_iter=32,\n",
    "                             scoring=\"neg_root_mean_squared_error\",\n",
    "                             verbose=True,\n",
    "                             cv=5,\n",
    "                             n_jobs=8,\n",
    "                             random_state=42)\n",
    "\n",
    "xgb_bayes_yc.fit(X_train_yc, yc_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lista de Variáveis Alvo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = [\"ya1\",\n",
    "             \"ya2\",\n",
    "             \"yb1\",\n",
    "             \"yb2\",\n",
    "             \"yb3\",\n",
    "             \"yb4\",\n",
    "             \"yc\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Melhores Parâmetros e Pontuações dos Modelos XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ya1 params: OrderedDict([('eta', 0.6819801039220021), ('gamma', 7.0), ('max_depth', 1), ('n_estimators', 178), ('reg_lambda', 0.7441291807581816)])\n",
      "    score : 5.070935799081243\n",
      "\n",
      "ya2 params: OrderedDict([('eta', 0.23795487705752305), ('gamma', 0.396483686417526), ('max_depth', 1), ('n_estimators', 1000), ('reg_lambda', 9.942953172304561)])\n",
      "    score : 3.5111916498146747\n",
      "\n",
      "yb1 params: OrderedDict([('eta', 0.0767425263728436), ('gamma', 5.684946091773975), ('max_depth', 18), ('n_estimators', 34), ('reg_lambda', 6.095441348912608)])\n",
      "    score : 4.251398255522526\n",
      "\n",
      "yb2 params: OrderedDict([('eta', 0.013594004182195795), ('gamma', 5.724810137646261), ('max_depth', 15), ('n_estimators', 262), ('reg_lambda', 5.786643362283849)])\n",
      "    score : 2.484272186331002\n",
      "\n",
      "yb3 params: OrderedDict([('eta', 0.39683716415545056), ('gamma', 7.0), ('max_depth', 1), ('n_estimators', 416), ('reg_lambda', 9.775113804233674)])\n",
      "    score : 2.2985392668740716\n",
      "\n",
      "yb4 params: OrderedDict([('eta', 0.01), ('gamma', 7.0), ('max_depth', 20), ('n_estimators', 323), ('reg_lambda', 10.0)])\n",
      "    score : 1.5857074556695365\n",
      "\n",
      "yc params: OrderedDict([('eta', 0.01), ('gamma', 7.0), ('max_depth', 11), ('n_estimators', 156), ('reg_lambda', 10.0)])\n",
      "    score : 3.6921400628130625\n",
      "\n"
     ]
    }
   ],
   "source": [
    "estimator_ya1 = xgb_bayes_ya1.best_estimator_\n",
    "estimator_ya2 = xgb_bayes_ya2.best_estimator_\n",
    "estimator_yb1 = xgb_bayes_yb1.best_estimator_\n",
    "estimator_yb2 = xgb_bayes_yb2.best_estimator_\n",
    "estimator_yb3 = xgb_bayes_yb3.best_estimator_\n",
    "estimator_yb4 = xgb_bayes_yb4.best_estimator_\n",
    "estimator_yc  = xgb_bayes_yc.best_estimator_\n",
    "\n",
    "bayes_estimators = [xgb_bayes_ya1,\n",
    "                    xgb_bayes_ya2,\n",
    "                    xgb_bayes_yb1,\n",
    "                    xgb_bayes_yb2,\n",
    "                    xgb_bayes_yb3,\n",
    "                    xgb_bayes_yb4,\n",
    "                    xgb_bayes_yc]\n",
    "\n",
    "for var, estimator in zip(variables, bayes_estimators):\n",
    "    best_params = estimator.best_params_\n",
    "    best_score = -estimator.best_score_\n",
    "    print(f\"{var} params: {best_params}\\n    score : {best_score}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaliação das Previsões do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ya1: 5.939133634285067\n",
      "ya2: 3.375217650139085\n",
      "yb1: 5.350164057834889\n",
      "yb2: 3.1885227192079357\n",
      "yb3: 2.012453922553288\n",
      "yb4: 1.9316194348028335\n",
      "yc: 2.4180963299695573\n"
     ]
    }
   ],
   "source": [
    "wrn.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "estimators = [estimator_ya1,\n",
    "              estimator_ya2,\n",
    "              estimator_yb1,\n",
    "              estimator_yb2,\n",
    "              estimator_yb3,\n",
    "              estimator_yb4,\n",
    "              estimator_yc]\n",
    "\n",
    "X_tests = [X_test_ya1,\n",
    "           X_test_ya2,\n",
    "           X_test_yb1,\n",
    "           X_test_yb2,\n",
    "           X_test_yb3,\n",
    "           X_test_yb4,\n",
    "           X_test_yc]\n",
    "\n",
    "y_tests = [ya1_test,\n",
    "           ya2_test,\n",
    "           yb1_test,\n",
    "           yb2_test,\n",
    "           yb3_test,\n",
    "           yb4_test,\n",
    "           yc_test]\n",
    "\n",
    "predict = {}\n",
    "\n",
    "for var, estimator, X_test, y_test in zip(variables, estimators, X_tests, y_tests):\n",
    "    predict[var] = estimator.predict(X_test)\n",
    "    rmse = np.sqrt(mean_squared_error(predict[var], y_test))\n",
    "    print(f\"{var}: {rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listas de Comparação entre Valores Reais e Previsões"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "complist_ya1 = [(true, pred) for true, pred in zip(ya1_test, predict[\"ya1\"])]\n",
    "complist_ya2 = [(true, pred) for true, pred in zip(ya2_test, predict[\"ya2\"])]\n",
    "complist_yb1 = [(true, pred) for true, pred in zip(yb1_test, predict[\"yb1\"])]\n",
    "complist_yb2 = [(true, pred) for true, pred in zip(yb2_test, predict[\"yb2\"])]\n",
    "complist_yb3 = [(true, pred) for true, pred in zip(yb3_test, predict[\"yb3\"])]\n",
    "complist_yb4 = [(true, pred) for true, pred in zip(yb4_test, predict[\"yb4\"])]\n",
    "complist_yc  = [(true, pred) for true, pred in zip(yc_test, predict[\"yc\"])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tabela de Comparação entre Valores Reais e Previsões"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " true_ya1   pred_ya1  true_ya2  pred_ya2  true_yb1  pred_yb1  true_yb2  pred_yb2  true_yb3  pred_yb3  true_yb4  pred_yb4  true_yc  pred_yc\n",
      "        0   1.654421         1  0.375438         0  0.271460         0  0.308012         0  0.315903         0  0.218795        0 0.375555\n",
      "        8   7.742039         4  3.960713         7  0.651989         0  0.772474         2  1.197855         0  0.395286        0 0.798866\n",
      "        0   2.189793         2  0.891291         0  0.720555         5  0.689071         0  0.461431         0  0.347457        0 0.649156\n",
      "        8   2.152405         3  1.885669         1  1.372312         0  0.817744         0  0.797951         0  0.990039        0 0.659197\n",
      "        1   0.966937         0  0.914665         0  0.666572         0  0.400605         0  0.504329         3  0.586500        1 0.994602\n",
      "        0  -0.207665         0 -0.158082         0  0.235499         0  0.303711         0  0.315903         0  0.218795        0 0.365749\n",
      "       11   4.661025         9  2.412734         6  2.531567         3  4.013461         5  1.342102         0  0.920173        0 1.735030\n",
      "        0  -0.451847         0  0.050865         0  0.222117         0  0.290343         0 -0.107611         0  0.460539        0 0.365749\n",
      "        1  -0.350347         0  0.768281         0  0.290105         0  0.253011         0  0.578125         0  0.233242        0 0.375555\n",
      "        4   4.661163         0  3.703556         0  1.001268         0  0.841845         0  1.310529         4  0.406473        0 0.808672\n",
      "        1   3.793111         0  3.576566         1  3.757722         2  3.771843         2  0.521003         3  0.369160        0 1.031458\n",
      "        5   6.007607         3  2.565964         0  0.690077         0  0.661249         0  0.521003         0  0.347457        1 0.649156\n",
      "        1   1.720854         1  0.403829         0  0.893074         1  3.460527         1  0.521003         0  0.347457        0 0.649156\n",
      "        3   3.794233         2  2.104352         0  1.378892         4  0.615998         1  0.408329         0  0.336270        3 0.639350\n",
      "        3  11.790098         5  8.544147         3  1.105179         8  0.979446         3  1.360559         1  1.672390        0 1.637487\n",
      "        1   1.664284         0  1.546577         1  5.762775         3  1.321988         1  0.521003         0  0.369160        0 0.659197\n",
      "        0   0.818692         0  1.362960         0  0.801806         2  0.921174         0  0.521003         0  0.369160        0 0.659197\n",
      "        0   2.169525         6  1.546577         0  0.955346         0  0.816841         0  0.521003         5  0.369160        1 0.659197\n",
      "        0   1.164871         0  1.329956         0  0.606914         0  0.363166         0  0.504329         0  0.398260        3 0.848213\n",
      "       46   5.015874        14  3.910461         3  1.577925         1  1.865586         1  1.584398        13  0.838275        2 0.897026\n",
      "        0   3.170341         0  1.354104         0  0.730967         1  0.924501         0  0.747921         0  0.422216        0 0.659197\n",
      "        0  -0.580871         1 -0.511177         1  0.222117         0  0.303711         0 -0.107611         0  0.218795        0 0.365749\n",
      "        0   2.189793         0  1.524770        14  2.758381         5  2.307745         1  0.866967         0  0.336270        4 0.649156\n",
      "        1   6.102502         2  4.426960         0  1.577925         1  1.221502         1  1.166914         7  0.788431        0 0.851744\n",
      "        1   5.490651         2  5.340927         5  1.729115         4  1.996967         0  0.952020         0  0.794297        3 0.851744\n",
      "        0   2.503108         2  2.492778         0  1.577925         3  1.452095         2  1.630373         0  0.788431        0 0.851744\n",
      "        4   0.541218         4  0.848662         9  0.671212         8  1.286747         5  0.348757         3  0.336270        5 0.639350\n",
      "        0   1.255861         2  0.850513         3  3.673317         4  3.943832         0  0.747921         0  0.422216        0 0.659197\n",
      "        1   1.017587         0  1.500215         1  1.084197         0  0.921174         0  0.571033         0  0.369160        2 0.659197\n",
      "        0   6.034958         0  2.748618         0  1.513070         0  1.816196         0  1.166914         0  0.794297        4 1.043390\n",
      "        0   2.668032         0  1.885669         2  1.160134         1  1.007644         2  0.747921         0  0.422216        1 0.659197\n",
      "        0   1.512800         0  1.885669         2  1.171058         1  0.946136         1  0.797951         0  0.495314        0 0.659197\n",
      "        0   2.152405         2  1.885669         0  1.160134         2  1.007644         2  0.747921         0  0.422216        0 0.659197\n",
      "        0   1.598644         0  1.500721         0  0.831807         0  0.764110         0  0.797951         0  0.520768        0 0.659197\n",
      "        0  -0.387985         1 -0.289296         1  0.671212         0  0.654713         0  0.348757         0  0.336270        0 0.639350\n",
      "        1   2.512442         0  1.022877         1  0.831807         0  0.911894         0  0.797951         0  0.520768        0 0.659197\n",
      "        3   4.281231         5  3.962022         9  5.608441        11  8.160089         2  0.747921         1  0.422216        5 1.031458\n",
      "        0   2.152405         2  1.532574         0  1.105256         0  0.793314         1  0.747921         0  0.422216        0 0.659197\n",
      "        1   2.152405         5  2.096408        21 36.766426         3  3.655504         6  2.695175         1  1.089119        9 5.009901\n",
      "       15   5.005488         4  3.851779         1  1.218932         0  1.272402         0  1.360559         0  0.838275        0 0.897026\n",
      "        0   2.152405         0  1.885669         2  1.372312         0  1.007644         3  0.797951         0  0.495314        0 0.659197\n",
      "        2   4.056167         1  2.186823         0  1.160134         3  1.007644         0  0.797951         0  0.422216        0 0.659197\n",
      "        1   2.152405         8  1.885669         1  6.856147         0  4.030385         0  0.797951         0  9.514479        1 0.787900\n",
      "        0   1.461143         0  1.071800         2  0.494042         1  0.229832         0  0.704669         0  0.406473        0 0.772965\n",
      "        1  -0.207665         0 -0.158082         0  0.222117         1  0.303711         0  0.203229         0  0.218795        0 0.365749\n",
      "       18  20.063534         2  7.684214         0  1.059434         2  0.520106         0  1.360559         0  0.589697        0 0.897026\n",
      "        0   1.713724         0 -0.532075         0  0.633948         0  0.203079         0 -0.078980         0  0.239107        0 0.375555\n",
      "        0  -0.099875         0 -0.701367         0  0.241352         0  0.203079         0  0.195532         0  0.218795        0 0.375555\n",
      "        0   2.716701         0  3.209096         3  1.542314         1  1.007644         0  1.972032         6  1.722136        0 0.659197\n",
      "        0  -1.133177         0 -1.329632         0  0.271460         0  0.203079         0 -0.138552         0  0.218795        0 0.375555\n",
      "        0   1.677288         1  0.341261        37  2.082157         8  0.703796         0  2.551560         2  0.612840        8 4.435337\n",
      "        0  -0.945043         0 -0.072298         0  0.870947         0  0.437154         0  0.238353         0  0.218795        0 0.365749\n",
      "        0   0.968823         1  1.396356         0  0.811098         1  1.319485         3  0.521003         1  0.361903        0 0.649156\n",
      "        0   0.457264         0  0.814643         0  1.076853         2  0.521919         2  0.064635         0  0.218795        0 0.375555\n",
      "        0   0.828889         0  0.984763         0  0.831807         0  0.514575         0  0.797951         0  0.429806        0 0.659197\n",
      "        0   0.061199         0 -0.532075         0  0.601210         0  0.203079         0 -0.078980         0  0.230873        0 0.375555\n",
      "        0   0.334603         0  0.220585         0  0.271460         0  0.253011         0  0.005064         0  0.218795        0 0.615496\n",
      "        0   4.113098         6  6.664793         0  1.152628         0  0.911894         0  0.797951         0  0.520768        0 0.659197\n",
      "        0   0.334603         0  0.768281         1  0.290105         0  0.377124         0  0.064635         0  0.233242        0 0.375555\n",
      "        6   2.152405         1  1.489563         4  1.160134         2  1.007644         4  0.797951         3  0.422216       37 5.465328\n",
      "        0   0.569087         2  0.616134         0  0.604272         0  0.772788         0  0.454299         0  0.308978        0 0.804519\n",
      "        0   0.457264         0  0.266947         0  0.271460         0  0.308012         0  0.005064         0  0.218795        0 0.375555\n",
      "        0  -0.580871         0 -0.072298         0  0.870947         0  0.437154         0  0.238353         0  0.218795        0 0.365749\n",
      "        1   1.996815         1  1.694454         0  0.801126         0  0.782224         0  0.797951         0  0.520768        0 0.659197\n",
      "        4   8.627864         0  4.839797         0  1.158633         0  0.838827         0  1.197855         0  0.395286        0 0.798866\n",
      "        1   1.009359         0  1.246049         0  0.894771         0  0.976175         0  0.521003         0  0.369160        1 0.659197\n",
      "        2   8.771587         0  5.749548         0  1.446741         1  1.007644         1  0.797951         0  1.160394        0 0.662278\n",
      "        1   4.125641         0  3.280351        11  2.870595        19  1.012901         0  1.021790         1  0.429806        1 1.031458\n",
      "        0   0.830471         0  0.069023         0  0.271460         0  0.308012         1  0.315903         0  0.218795        0 0.375555\n",
      "        4   0.626148         0  0.573854         0  0.671212         1  0.654713         0  0.348757         0  0.336270        0 0.639350\n",
      "        0   1.664284         2  1.632362         4  2.716729         3  1.907366         0  0.866967         0  0.369160        1 0.659197\n",
      "        2   1.138272         2  1.022520         6  1.372312         8  1.007644         5  0.797951         0  0.495314        2 0.659197\n",
      "        3   8.283463         4  5.410453         0  0.969319         0  0.976175         0  0.521003         0  0.372110        0 0.382479\n",
      "        0   0.641609         0  0.923134         0  0.300105         0  0.284618         0  0.064635         0  0.218795        0 0.375555\n",
      "        0   1.383135         0  0.971423         3  0.811098         0  0.678078         1  0.521003         0  0.361903        1 0.649156\n",
      "        0  -1.718218         0 -1.339086         0  0.208614         0  0.203079         0 -0.078980         0  0.230873        0 0.375555\n",
      "        0  -0.848676         0 -0.497060         1  0.260676         1  0.337229         0  1.133935         0  0.218795        0 0.365749\n",
      "        3   0.684625         1  1.154476         1  0.773101         0  0.466391         0  0.604306         0  0.429806        0 0.659197\n",
      "        7   2.228579         5  2.870004         0  1.125348         0  1.148667         0  1.695084         0  1.054054        0 0.659197\n",
      "       42   2.617399        35  1.270242         0  0.806800         0  0.661249         0  0.521003         0  0.347457        2 0.649156\n",
      "        1   1.349762         3  1.885669         7  1.372312         5  1.070399         6  3.085603         0  0.422216        0 0.659197\n",
      "        0   0.785948         0  0.782571         0  3.248100         0  2.547647         0  1.762548         0  0.361903        0 0.649156\n",
      "        1   0.496357         0  0.836887         0  0.955346         0  0.789092         0  0.521003         0  0.354714        0 0.659197\n",
      "        0   0.154870         0  0.952521         3  0.783161         0  0.921174         0  0.511461         0  0.369160        1 0.659197\n",
      "        0   1.664284         4  1.546577         8  1.782609         2  2.616786         0  0.521003         3  1.731427        1 0.787900\n",
      "        0   3.170341         0  1.307742         1  0.795744         1  0.924501         0  0.797951         0  0.495314        0 0.659197\n",
      "        0   3.821128         7  3.653414         3  1.260114         9  2.132534         0  0.747921         4  0.422216        0 0.659197\n",
      "        0   1.654421         0  0.375438         2  0.271460         3  0.308012         0  0.315903         0  0.218795        0 0.375555\n",
      "        5   4.433836         5  1.864719         2  1.552526         3  0.661249         2  0.408329        32  0.336270        2 0.639350\n",
      "        1   1.664284         1  1.434437         0  1.949398         1  1.797829         2  0.866967         0  0.369160        2 0.659197\n",
      "        0   1.664284         4  1.513029        15 13.963074         4  1.237358         0  2.468257         2  1.032676        2 4.840610\n",
      "        5   3.608283         9  6.475746         1  3.419940         0  0.985503         0  0.521003         0  0.369160        0 0.659197\n",
      "        3   2.682219         1  0.968650         1  0.658249         0  0.893032         0  0.521003         0  0.369160        0 0.659197\n",
      "        4  13.343287         6  8.402519         4  1.172605         2  0.838827         4  1.197855         1  0.781130        1 0.382479\n",
      "        0   3.703794         2  3.635256         0  1.169516         0  2.122955         1  0.747921         4  0.414959        0 0.649156\n",
      "        0   1.664284         2  1.546577         2  0.955346         5  0.968593         0  0.521003         0  0.369160        8 0.659197\n",
      "        0   1.024678         2  1.348653         1  0.818341         2  0.923878         5  0.521003         1  0.369160        0 0.659197\n",
      "        0   4.084860         1  3.948630         0  1.693727         0  1.649609         1  5.204334         2  2.283812       12 2.884263\n",
      "       49   8.696653         7  5.131703        11  2.927374         7  1.022052         0  1.166914         0  0.786062        4 1.224006\n",
      "        0   0.735080         0  0.561850         0  0.270350         0  0.243023         0  0.248302         0  0.277811        0 0.387296\n",
      "        0   0.115567         0  0.782801         0  0.671212         0  0.609462         0  0.348757         0  0.336270        0 0.639350\n",
      "        8   2.914424        11  3.070981        13 11.282069        12 10.108543         1  0.747921         1  0.422216        2 0.659197\n",
      "        0   0.780622         0  0.952290         0  1.447979         0  1.718695         0  1.812578         0  0.369160        0 0.659197\n",
      "        1   2.628625         0  5.264621         0  1.087678         0  0.809598         0  0.604306         0  0.429806        0 0.659197\n",
      "        0  -0.451847         0  0.136649         0  0.870947         1  0.437154         1  0.238353         0  0.218795        0 0.375555\n",
      "        0  -1.341871         0 -0.706007         0  0.294693         2  0.337229         4  1.133935         0  0.218795        0 0.365749\n",
      "        2   4.486420         1  4.049636         2  1.048077         2  1.140390         2  4.986957         0  0.731374        0 0.682281\n",
      "        0   0.966937         0  0.914665         0  0.666572         0  0.400605         0  0.504329         4  0.586500        0 0.994602\n",
      "        0   1.349762         1  1.885669        12  1.372312         7  1.070399         3  3.085603         0  0.495314        0 0.659197\n",
      "        0   0.966937         0  0.914665         6  2.166929         0  1.464276         0  0.504329         1  0.316235        4 0.892874\n",
      "        0   1.231033         1  0.616134         1  0.604272         0  0.779143         0  0.574980         0  0.308978        0 0.804519\n",
      "        0  -0.053253         0 -1.526058         0  0.237613         0  0.229815         0 -0.025002         0  0.586500        0 0.400805\n",
      "        0  -1.105391         0 -1.508904         0  0.202670         0  0.204318         0 -0.025002         0  0.180316        0 0.357618\n",
      "        0   0.343638         0  0.266947         0  0.271460         0  0.308012         0  0.315903         0  0.233242        0 0.375555\n",
      "        0   1.541623         3  1.116896         1  3.960285         0  1.040983         0  2.408684         0  1.039932        3 0.695208\n",
      "        0   1.751544         0  0.961027         1  2.759746         2  1.464276         0  0.574980         0  0.316235        0 0.814560\n",
      "        0  -1.738821         0 -0.158082         1  0.222117         0  0.303711         0 -0.107611         0  0.218795        0 0.365749\n",
      "        0   0.360461         0  0.707051         0  0.300105         0  0.280316         0  0.064635         0  0.218795        0 0.375555\n",
      "        0   0.839856         0 -0.194043         0  0.844369         0  0.744433         0  0.461431         0  0.369160        0 0.659197\n",
      "        0  -0.068573         0  0.138136         0  0.271460         0  0.294168         0  0.005064         0  0.218795        0 0.375555\n",
      "        1   1.749229         2  1.803220         0  1.065290         0  0.955334         2  0.747921         0  0.422216        3 0.659197\n",
      "        2   5.768898         1  2.149657         0  1.372312         1  1.007644         2  0.797951         0  0.422216        1 0.659197\n",
      "        3   3.170341         0  1.307742         0  0.795744         0  0.924501         0  0.797951         0  0.422216        0 0.659197\n",
      "        0   1.791010         0  1.734108         1  1.260114         1  0.984136         0  0.747921         0  0.422216        0 0.659197\n",
      "        6   2.189793         1  1.524770         0  2.758381         0  2.307745         0  0.866967         0  0.336270        0 0.649156\n",
      "        0   1.086158         0  1.414514         0  0.955346         1  1.389124         1  0.521003         0  0.369160        0 0.659197\n",
      "        1   2.919750         3  2.854898        10 11.282069        14  7.989062         6  0.747921         4  0.414959        2 0.649156\n",
      "        0  -2.479153         0 -0.867773         0  0.235499         0  0.299540         0 -0.107611         0  0.218795        0 0.365749\n",
      "        2   2.152405         1  1.885669        11  1.941495        17  5.031395         3  0.747921         5  4.307831        0 0.787900\n",
      "        4   2.169525         3  1.546577         7  0.955346         0  0.816841         2  0.521003         6  0.369160        0 0.659197\n",
      "        5   4.486420         3  4.049636         1  1.048077         1  1.140390         3  4.986957         2  0.731374        2 0.682281\n",
      "        0   1.158554         1  0.375438         0  0.271460         0  0.331533         0  0.005064         0  0.218795        1 0.375555\n",
      "        0   4.213542         0  4.279626         0  1.152628         3  2.069863         0  0.797951         0  0.520768        0 0.659197\n",
      "        4   3.960910        15  4.157237         3  1.583898         2  1.592630         5  4.986957         0  1.683638        4 2.498775\n",
      "        2   2.152405         0  1.971453         7  3.165539        16  1.252795         3  1.143915         1  0.422216        1 0.659197\n",
      "        2   1.029019         3  1.694454         3  0.831807         1  0.789806         1  0.797951         0  0.520768        0 0.659197\n",
      "        3   1.009359         4  1.048125         3  0.894771         6  0.972147         1  0.521003         0  0.369160        0 0.659197\n",
      "        0  -0.087675         0  0.050865         0  0.222117         0  0.303711         0 -0.107611         0  0.218795        0 0.365749\n",
      "        0   2.275066         0  1.932031         0  1.260114         0  1.007644         0  0.747921         0  1.286700        0 0.659197\n",
      "        0   1.644084         0 -0.004076         0  0.582577         0  0.578617         0  0.348757         0  0.336270        0 0.639350\n",
      "        0   1.068048         0  0.459433         0  0.410026         1  0.278110         0  0.100480         0  0.286298        0 0.375555\n",
      "        0   0.334603         0  0.220585         0  0.271460         0  0.460625         0  0.055093         0  0.233242        0 0.375555\n",
      "        1   6.478668         0  3.173720         0  0.527156         0  0.203079         0 -0.078980         0  0.233823        0 3.517925\n",
      "        1   0.334603         0  0.220585         0  0.271460         0  0.253011         0  0.055093         0  0.233242        0 0.375555\n",
      "        2   1.348368         2  0.832216         1  0.640390         0  0.873609         0  0.574980         1  0.316235        0 0.814560\n",
      "        2   2.152405         2  1.885669         2  1.160134         0  0.817744         0  0.747921         0  0.990039        0 0.659197\n",
      "        4   5.993897         1  3.121772         0  1.372312         4  1.007644         0  0.797951         0  0.422216        1 0.659197\n",
      "        0   1.664284         0  0.800959         0  0.844369         0  0.996996         0  0.461431         0  0.369160        0 0.818124\n",
      "        0   8.485573         3  3.741550         0  4.277310         0  3.566045         0  1.360559         0  1.604660        0 0.905983\n",
      "        0  -0.580871         0 -0.158082         0  0.222117         0  0.303711         0 -0.107611         0  0.218795        0 0.365749\n",
      "        5   3.415894         6  2.816503         1  1.373060         1  0.976175         0  0.521003         0  0.369160        0 0.670555\n",
      "        0   2.337785         4  3.814090         0  0.955346         0  0.972147         0  0.521003         0  0.369160        1 0.659197\n",
      "        0  -0.700443         0 -0.513292         0  0.222117         0  0.229815         0 -0.071766         0  0.567026        0 0.379259\n",
      "        0   6.031285         1  2.675089         0  0.806800         1  0.661249         2  0.521003         0  0.336270        0 0.639350\n",
      "        0   2.275066         0  1.191368         0  1.260114         1  0.946273         0  0.556847         0  0.422216        0 0.659197\n",
      "        6   0.870505         0  1.546577         1  0.978182         2  0.976175         1  0.521003         0  0.369160        0 0.659197\n",
      "        0   1.499555         0  1.813255         0  1.732487         0  0.837390         1  0.797951         0  0.542284        0 0.659197\n",
      "        0   0.464420         0  1.029967         0  0.879870         0  0.897505         0  0.521003         0  0.350716        1 0.649156\n",
      "       31   5.484684         5  5.103433        16  2.002528         5  1.588167         3  5.632868         0  1.449948        0 2.486830\n",
      "        0   2.152405         0  1.932031         1  1.091451         0  1.007644         0  0.747921         0  0.422216        0 0.659197\n",
      "       14   1.664284         8  1.546577         1  0.955346         0  0.976175         1  0.521003         0  2.298588        0 0.659197\n",
      "        4  10.495440         1  5.915679         0  0.831807         2  0.684829         1  0.797951         0  0.429806        0 0.659197\n",
      "        0   4.500247         0  2.632507         0  1.018393         0  0.970400         0  1.300987         0  0.773941        1 0.897026\n",
      "        0   2.682219         2  0.968650         2  0.658249         0  0.893032         0  0.521003         0  0.369160        0 0.659197\n",
      "        0   1.140249         0  1.546577         0  1.306062         2  0.976175         3  0.521003         0  0.369160        3 0.659197\n",
      "        1   3.122640         1  1.438985         1  0.806800         1  0.541037         0  0.521003         0  0.347457        0 0.649156\n",
      "        4   8.349358         9  6.151638         3  1.160134         0  1.007644         1  0.747921         2  0.422216        1 0.659197\n",
      "        0   4.655837         4  3.689900         5  1.004556         0  0.814811         3  1.310529         3  0.413730        1 1.043390\n",
      "        0   0.519042         0  0.998883         2  0.783161         1  0.921174         0  0.461431         0  0.369160        0 0.659197\n",
      "        0   0.767738         0  0.511421         1  1.041619         1  3.524820         0  0.521003         0  0.369160        0 0.659197\n",
      "        6   1.465302        12  1.885669         5  1.160134         3  1.007644         4  0.797951         1  0.422216        4 2.614476\n",
      "        1   1.668349         0  1.885669         0  1.160134         1  0.980372         2  0.747921         0  0.422216        0 0.659197\n",
      "        0   0.626148         0  0.573854         2  1.043461         0  0.535674         1  0.348757         0  1.145837        0 0.639350\n",
      "        6  12.100518         0  6.848938         2  1.160134         0  1.007644         0  0.747921         0  0.422216        0 0.659197\n",
      "        0   4.667187         0  3.718027         0  1.522703         0  1.584677         0  4.927385         0  2.114370        0 2.228085\n",
      "        0   1.996815         0  1.858830         0 40.325397         0 11.598891         0  2.745205         0  0.615210        0 5.596858\n",
      "        0   2.265011         0 -0.983764         0  0.724111         0  0.306666         0  0.317816         0  0.410622        0 0.659197\n",
      "        0   1.664284         0  1.179116         0  0.955346         0  0.983818         0  0.521003         0  0.369160        0 0.659197\n",
      "        6   3.596740         4  3.411612         0  1.291641         2  1.525065         0  4.927385         5  1.275597        2 1.556241\n",
      "        0   1.664284         0  1.546577         0  0.955346         0  0.968593         0  0.521003         0  0.369160        0 0.659197\n",
      "        0  -0.029568         0  0.220585         0  0.271460         0  0.253011         0  0.055093         0  0.218795        0 0.375555\n",
      "       13   4.500247         0  3.683036         0  1.218932         0  1.439303         0  1.360559         0  0.838275        0 0.897026\n",
      "        1   2.337785         1  4.012013         3  0.955346         0  0.976175         0  0.521003         0  0.369160        0 0.659197\n",
      "        0   0.334603         0  0.266947         0  0.271460         0  0.253011         0  0.005064         0  0.218795        0 0.450590\n",
      "        2   2.037490         1  1.546577         1  1.071746         0  1.303367         0  0.831843         0  0.438937        0 1.426972\n",
      "        0   0.571266         0  0.561850         0  0.270350         0  0.243023         0  0.248302         0  0.277811        0 0.387296\n",
      "        0   1.428674         1  3.248238         0  0.671212         1  0.654713         0  0.348757         1  0.336270        0 0.639350\n",
      "        0   1.541623         0  1.500215         0  0.801806         0  0.921174         0  0.521003         0  0.369160        0 0.659197\n",
      "        4   1.343868         2  0.773267         0  0.831807         0  0.920429         1  0.797951         0  1.721208        0 0.659197\n",
      "        1   1.086158         0  0.866820         0  0.844369         0  1.377453         0  0.461431         0  0.369160        0 0.659197\n",
      "        2   4.093556         0  1.740140         0  0.806800         0  0.661249         0  0.521003         0  0.347457        0 0.649156\n",
      "        1   1.546949         0  1.494871         9 15.236650         3  1.237358         1  2.468257         0  1.032676        4 4.840610\n",
      "        1  -0.002478         0 -0.212241         0  0.801949         0  0.466391         0  0.544734         0  0.429806        0 1.996958\n",
      "        3   3.170341         0  1.307742         0  0.795744         0  0.924501         0  0.797951         0  0.495314        0 0.659197\n",
      "        0  -1.619772         0 -0.658826         0  0.258077         0  0.299540         0 -0.107611         0  0.218795        0 0.375555\n",
      "        5   4.449031         3  4.496330         1  1.788687         5  1.649609         6  5.213875         1  1.746260        1 2.420798\n",
      "        0  -2.242253         0 -1.339086         0  0.208614         0  0.203079         0 -0.078980         0  0.230873        0 0.375555\n",
      "       13  20.063534        10  7.730576         0  0.990751         0  0.520106         0  1.310529         0  0.413730        0 0.818713\n",
      "        0   2.152405         2  1.885669         0  1.372312         2  1.007644         0  0.797951         1  0.422216        0 0.659197\n",
      "        0   2.152405         0  1.808973         0  1.269344         2  2.478953         0  0.747921         0  0.763006        0 5.366849\n",
      "        0   0.334603         0  0.768281         0  0.290105         0  0.253011         0  0.064635         0  0.233242        0 0.375555\n",
      "        3  11.827263         0  4.858598         0  1.762872         0  0.466391         0  1.271879         0  0.427437        0 0.659197\n",
      "        0  -1.636510         0 -1.249293         0  0.248651         0  0.203079         0  1.437077         0  0.233242        0 0.375555\n",
      "        0   0.141349         0  0.100280         0  0.270350         0  0.227463         0  0.118613         0  0.180316        0 0.387296\n",
      "        4   6.359698         0  1.022877         2  1.568242         0  2.779599         1  0.797951         1  0.520768        0 0.659197\n",
      "        1   2.914424         0  3.024618        17  6.445128        16  5.634775         2  0.797951         0  0.495314        0 0.659197\n",
      "        0   1.086158         0  1.414514         1  0.864748         0  1.361880         0  0.521003         1  0.361903        0 0.649156\n",
      "        3   2.152405         2  1.885669         2  1.082456         1  1.000062         0  0.797951         0  0.422216        5 0.659197\n",
      "       18   5.742351         9  5.184003         7  2.002528         1  1.949752         6  5.632868         4  1.449948        1 2.486830\n",
      "        2   1.184609         3  1.885669         0  1.160134         0  1.007644         2  0.747921         0  0.422216        0 0.659197\n",
      "        0   1.664284         0  1.546577         9  5.762775         0  1.321988         0  0.521003         0  0.369160        6 0.659197\n",
      "        2   1.434803         0  1.532332         0  1.169516         0  0.972385         0  0.747921         0  0.414959        0 0.649156\n",
      "        0   1.482013         0  1.551941         0  0.725257         0  0.400605         0  0.504329         3  0.586500        0 0.994602\n",
      "        3   1.608099         8  4.124882         0  1.372312         1  1.007644         1  0.583057         0  0.495314        1 0.659197\n",
      "        0  -0.557224         0 -0.039256         0  0.202670         0  0.204318         0  0.047961         0  0.180316        0 0.357618\n",
      "        6   2.667481         0  2.608729         0  3.165539         0  1.252795         0  1.143915         0  0.542284        0 0.659197\n",
      "       28  16.954645         2  4.971713         0  0.811098         1  0.532140         0  0.521003         0  0.361903        0 0.649156\n",
      "        1   1.751544         1  0.961027        25  3.697525        14  1.464276         1  0.574980         0  0.316235        0 0.814560\n",
      "        0  -1.707861         0 -1.367489         0  0.270350         0  0.251921         0 -0.145684         0  0.180316        0 0.387296\n",
      "        9   6.629075         3  5.940452        11  2.927932        11  1.069056         2  1.584398         1  0.838275        2 1.269288\n",
      "        0   0.334603         0  0.220585         0  0.271460         0  0.253011         0  0.055093         0  0.218795        0 0.375555\n",
      "        0   3.170341         0  1.307742         0  0.795744         1  0.924501         0  0.797951         2  0.422216        0 0.659197\n",
      "       34  10.651030        13  6.106896         0  1.372312         0  1.007644         1  0.797951         1  0.422216        1 0.659197\n",
      "        0   0.485508         0  0.695234         0  0.271460         0  0.454977         0  0.055093         0  0.218795        0 0.375555\n",
      "        2   1.996815         3  1.524734         2  0.831807         2  0.684829         2  0.797951         0  0.520768        0 0.659197\n",
      "        0   2.230687         0  2.254760         0  0.773101         0  1.298648         0  0.604306         0  0.435671        0 0.659197\n",
      "        2   1.541623         0  1.585999         1  2.890565         4  1.244923         1  0.866967         0  0.369160        2 0.659197\n",
      "        2   2.037490         0  1.348653        12  3.285446         3  1.308181         0  0.831843         0  0.438937        1 1.681325\n",
      "        0   1.546949         0  1.160775         0  0.811098         0  0.678078         0  0.521003         0  0.361903        0 0.649156\n",
      "        0   2.152405         0  1.885669         0  1.598584         2  1.131906         0  0.747921         0  0.422216        0 0.659197\n",
      "        1   1.182778         4  0.868585         0  1.949398         0  2.307745         0  0.694721         0  0.347457        0 0.649156\n",
      "        0   3.608283         2  6.277821         0  3.419940         0  0.965903         1  0.521003         0  0.361903        0 0.649156\n",
      "        0   2.152405         1  1.489563         1  1.160134         0  1.007644         0  0.797951         0  0.422216        0 5.465328\n",
      "        5   2.782935         1  1.329361         0  1.372312         0  1.007644         0  0.797951         0  0.422216        0 0.659197\n",
      "        0   1.541623         0  1.664591         5  6.217247         0  1.040983         0  2.468257         0  1.039932        1 3.882008\n",
      "        0   1.664284         0  1.348653         0  1.552613         0  2.172819         0  0.521003         0  2.369929        0 0.787900\n",
      "        0  -0.009666         0  0.339865         0  0.202670         0  0.204318         0  0.248302         0  0.277811        0 0.357618\n",
      "        7  10.651030         9  6.106896         0  1.372312         2  1.007644         0  0.797951         0  0.495314        2 0.659197\n",
      "        0   0.886698         0  1.199687         0  0.808310         0  0.921174         0  0.571033         3  0.442258        0 0.659197\n",
      "        2   3.793111         9  3.576566         3  3.757722         2  2.169111         0  0.521003         1  0.369160        3 1.031458\n",
      "        0  -1.497348         0 -1.329632         0  0.271460         3  0.203079         0 -0.138552         0  0.233242        0 0.375555\n",
      "        5   0.457264         0  0.266947         0  0.271460         0  0.308012         0  0.005064         0  0.218795        0 0.615496\n",
      "        0  -0.218487         0 -0.700678         0  0.237613         0  0.229815         0 -0.145684         0  0.586500        0 0.400805\n",
      "        0  -1.136797         0  0.050865         0  0.222117         0  0.303711         0  0.355849         0  0.218795        0 0.365749\n",
      "        0  -0.087675         0  0.050865         0  0.222117         0  0.303711         0 -0.107611         0  0.218795        0 0.365749\n",
      "        1   1.751544         0  0.763103         0  0.694869         0  0.923606         0  0.574980         0  0.316235        1 0.814560\n",
      "        6   4.750210         3  4.049636         3  1.048077         3  1.140390         9  4.986957         1  0.731374        1 0.731817\n",
      "        0  -0.898013         0 -0.380067         0  0.201358         0  0.233428         0 -0.107611         0  0.218795        0 0.347812\n",
      "        1   0.684625         0  0.335454         0  0.773101         0  0.466391         0  0.604306         0  0.429806        1 0.659197\n",
      "        0   0.575824         1  2.236818         2  1.645983         0  0.678078         0  1.971231         0  0.350716        0 0.649156\n",
      "        0   1.664284         0  1.710953        21  3.683669         6  1.040983         3  2.468257         0  1.039932        0 3.882008\n",
      "        5  20.063534         9  7.684214         0  1.100235         0  0.520106         0  1.360559         0  0.589697        0 0.897026\n",
      "        8   3.961354         2  2.573348         0  1.577925         1  1.583087         4  1.166914         2  0.838275        4 0.851744\n",
      "        1   1.119344         1  0.782801         1  0.671212         0  0.682535         0  0.348757         0  0.336270        0 0.639350\n",
      "        2   2.370100         6  3.695475         0  0.806800         2  0.661249         0  0.521003         0  0.336270        0 0.639350\n",
      "        0   1.791010         0  1.932031         1  1.260114         0  0.980372         0  0.747921         0  0.422216        1 0.659197\n",
      "        2   2.716701         6  3.209096         2  1.542314         0  1.007644         0  1.972032         0  1.435365        1 0.659197\n",
      "        0   0.942293         0  0.416024         0  0.773101         0  0.466391         0  0.604306         0  0.429806        0 0.659197\n",
      "        0   1.229807         0  1.108510         0  0.706198         0  0.754357         0  0.521003         0  0.361903        0 0.622726\n",
      "        0   1.872651         0  1.217001         0  0.701900         0  0.459033         0  0.521003         0  0.347457        0 0.622726\n",
      "       26  17.071980         6  4.989871         0  0.955346         0  0.547713         0  0.521003         0  0.369160        0 0.659197\n",
      "        0   8.771587         5  5.749548         1  1.446741         0  1.007644         0  0.797951         0  0.491481        0 0.662278\n",
      "        6   1.751544         3  0.961027        36  2.759746        17  1.464276         1  0.574980         0  0.316235        1 0.814560\n",
      "        0   3.170341         0  1.307742         0  0.730967         0  0.924501         0  0.747921         0  0.422216        0 0.659197\n",
      "        2   2.609933        10  2.558639         4  1.679714         1  1.221502         3  1.166914         2  0.794297        1 0.851744\n",
      "        0   1.546949         1  0.971423         0  0.811098         0  0.956574         1  0.521003         0  0.361903        0 0.649156\n",
      "        4   1.541623         0  1.104110         1  0.801806         0  0.921174         0  0.521003         0  0.369160        2 5.465328\n",
      "        1   0.544525         0  0.229091         0  0.270350         0  0.243023         0  0.118613         0  0.180316        0 0.387296\n",
      "        6   7.008869         1  4.378849        19  2.267257        11  3.894730        28  1.904709         5  1.263135        4 1.835565\n",
      "        0   0.998957         0  4.771086         0  0.936357         1  0.303711         0 -0.107611         0  0.218795        0 0.365749\n",
      "        0   4.180720         0  2.498585         0  2.082157         0  0.703796         0  3.114168         0  0.959682        0 4.435337\n",
      "        8   3.574456         4  1.895404        25  1.439475        16  0.670518         8  0.408329         1  0.336270        1 0.639350\n",
      "        0   2.668032         0  1.932031         0  1.091451         0  1.007644         0  0.747921         0  0.422216        0 0.659197\n",
      "        0  -0.371020         1 -0.071211         0  0.271460         0  0.308012         0  0.005064         0  0.233242        1 0.544211\n",
      "        0   0.053395         0  0.050865         0  0.328430         0  0.272482         0 -0.107611         0  0.218795        0 0.375555\n",
      "        1   0.379023         3  0.620805         1  0.811098         0  0.533266         0  0.521003         0  0.361903        0 0.649156\n",
      "       22   7.173384        14  3.054124         3  1.372238         7  5.552722         0  1.166914         3  1.314097        1 0.860701\n",
      "        3   5.574552         9  4.603340         2  2.927932         9  1.022052         0  1.166914         0  0.788431        0 1.224006\n",
      "        1   1.644900         2  2.522944         1  1.661916         0  1.007644         0  0.797951         0  0.542284        0 0.659197\n",
      "       30  17.560102         0  5.526890         0  1.273001         1  0.561849         0  0.797951         0  0.495314        0 0.659197\n",
      "        3   6.432703         4  5.914739         6  2.307817         4  1.805969        10  5.766942         6  2.219324        5 2.894081\n",
      "        0   1.668349         0  1.885669         0  1.160134         0  0.980372         0  0.747921         1  0.422216        0 0.659197\n",
      "        0   2.220263         5  2.492778         0  1.577925         0  1.221502         1  1.166914         0  0.788431        0 0.851744\n",
      "        0   1.541623         0  1.585999         5  2.890565         0  1.244923         1  0.916997         2  0.369160        2 0.659197\n",
      "        0   1.514495         0  1.293785         0  0.619863         2  0.393559         0  0.704669         0  0.586500        2 0.910400\n",
      "        3   0.635182         1  0.573854         2  2.073839         0  1.066409         0  0.659597         0  0.406047        0 0.822307\n",
      "        4   6.027165         6  1.348653         2  1.841842        12  1.801067         4  0.521003         0  0.369160        0 0.659197\n",
      "        1   3.641706         0  3.226209         0  0.990751         2  0.983645         2  1.310529         0  0.413730        0 0.818713\n",
      "        0   0.334603         0  0.220585         0  0.271460         0  0.253011         0  0.005064         0  0.233242        0 0.375555\n",
      "        0   0.274994         0  0.657377         1  0.270350         0  0.229815         0  0.047961         0  0.586500        0 0.400805\n",
      "        0  -1.063973         0 -1.268623         0  0.271445         0  0.203079         0  1.102994         0  0.230873        0 0.375555\n",
      "        0   0.830471         0  0.266947         0  0.271460         3  0.308012         0  0.315903         0  0.218795        0 0.375555\n",
      "        0   0.839856         0  0.551577         0  0.955346         0  0.744433         0  0.521003         0  0.369160        0 0.659197\n",
      "        5   2.782935         2  1.329361         1  1.372312         2  1.007644         0  0.797951         0  0.422216        0 0.659197\n",
      "        2   4.500247         1  3.180202         2  1.453749         2  0.979446         1  1.360559         0  0.773941        5 0.897026\n",
      "        4   1.823620         9  1.438985         4  0.829636         1  0.661249         0  0.521003         6  0.347457        0 0.649156\n",
      "       12   5.066847         0  3.819849         0  1.372312         1  1.007644         0  0.797951         0  0.495314        0 0.659197\n",
      "       12   1.261107         9  1.417766         0  0.900868         0  0.923865         0  0.521003         0  0.369160        0 0.659197\n",
      "        2   1.546949         1  1.330495         6  1.236194        11  2.169801         1  0.521003        12  2.369929        3 0.777859\n",
      "        2   5.542614         5  3.012648         0  2.540346         0  1.007644         0  0.747921         0  0.422216        0 0.659197\n",
      "        0   1.068048         0  0.459433         0  0.410026         0  0.278110         0  0.100480         3  0.286298        0 0.375555\n",
      "        0   1.349762         0  1.885669         0  1.372312         2  1.070399         0  3.085603         0  0.495314        0 0.659197\n",
      "        0   0.765653         0  1.337976         1  1.093231         0  1.007644         0  0.738379         1  0.523066        1 0.659197\n",
      "        0   2.617399         0  1.438985         1  5.510848         0  2.562545         0  0.521003         1  0.347457        1 0.649156\n",
      "        3   1.293421         0  1.101227         0  0.806800         1  0.611957         0  0.521003         0  0.336270        0 0.639350\n",
      "        2   2.682219         2  0.968650         0  0.658249         0  0.893032         0  0.521003         0  0.369160        0 0.659197\n",
      "        0   0.457264         0  0.455570         0  0.775033         0  0.308012         0  0.064635         0  0.233242        0 0.375555\n",
      "        1   1.754234         0  1.691936         2  1.160134         1  1.294418         0  0.797951         2  0.422216        0 0.659197\n",
      "        0  -0.099875         0 -0.701367         0  0.241352         0  0.203079         0 -0.078980         0  0.218795        0 0.375555\n",
      "        7   5.170912         5  4.164551         2  1.018201         0  0.814811         1  1.360559         0  0.773941        0 1.043390\n",
      "        1   2.152405         4  1.932031         0  1.091451         3  2.363599         0  0.747921         0  0.422216        2 0.659197\n",
      "        0  -0.118018         0  0.335454         0  0.773101         0  1.285514         0  2.891958         0  0.429806        0 0.659197\n",
      "        1   1.546949         6  1.330495         3  1.236194         7  2.172819         0  0.521003         1  2.369929        0 0.777859\n",
      "        6   8.283463         1  5.212528         1  0.969319         0  0.972147         0  0.521003         0  0.372110        0 0.382479\n",
      "        0   3.170341         0  1.307742         0  0.795744         0  0.924501         0  0.797951         0  0.495314        0 0.659197\n",
      "        0   3.254181         0  2.036928         0  0.208614         0  0.203079         0 -0.078980         0  0.230873        0 0.375555\n",
      "       11  11.527143        17  9.455228         2  1.661916         0  1.007644         2  0.797951         0  0.542284        0 0.659197\n",
      "        2   2.152405         0  1.716925         0  1.160134         0  1.007644         0  0.747921         0  0.422216        0 0.659197\n",
      "        9   8.760597         1  4.795078         2  0.671212         0  0.654713         0  0.348757         0  0.336270        0 0.639350\n",
      "        0   0.966937         0  0.914665         0  0.923967         0  0.400605         0  0.504329         0  0.586500        0 0.994602\n",
      "        0   2.152405         0  1.885669         0  1.372312         0  0.817744         0  0.797951         0  0.640818        0 0.659197\n",
      "       16   8.367759        12  3.663059         4  1.305336         4  6.197467         4  1.166914         2  1.305241        1 0.860701\n",
      "        1   1.664284         1  1.187504         0  0.955346         0  0.983818         0  0.521003         0  0.369160        0 0.659197\n",
      "        0   0.334603         0  0.220585         0  0.271460         0  0.363350         0  0.005064         0  0.218795        0 0.375555\n",
      "        1   2.152405         0  1.885669         5  1.598584         2  1.131906         1  0.747921         0  0.422216        1 0.659197\n",
      "        8   2.682219         2  0.968650         0  0.658249         1  0.893032         9  0.521003         1  0.369160        2 0.659197\n",
      "        0   1.668349         2  1.885669         1  1.160134         1  0.980372         0  0.797951         0  0.422216        0 0.659197\n",
      "        0  13.880086         0  6.965965         0  3.117817         0  1.007644         0  1.415494         1  0.422216        2 0.659197\n",
      "        0   2.782935         0  1.329361         0  1.160134         0  1.007644         0  0.797951         0  0.422216        0 0.659197\n",
      "        0   1.024678         0  1.546577         0  0.818341         2  0.923878         2  0.521003         3  0.369160        0 0.659197\n",
      "        0   2.426302         1  2.685527         0  2.992478         2  5.402347         0  0.521003         0  0.369160        0 0.659197\n",
      "        2   1.962475         4  1.138457         5  0.875572         6  0.880676         0  0.521003         0  0.347457        2 0.649156\n",
      "        4   2.716701         8  3.209096         3  1.542314         6  1.007644         0  1.972032         1  1.722136        0 0.659197\n",
      "       13   2.152405         1  1.489563         2  1.160134         3  1.007644         2  0.797951         0  0.422216       42 5.465328\n",
      "        0   0.942293         1  0.246304         0  0.797417         0  0.524452         0  0.878818         0  0.429806        0 0.659197\n",
      "        0   7.431051         0  3.134694         0  1.372238         0  5.914306         0  1.441425         0  1.363941        0 0.860701\n",
      "        0   1.531761         0  0.329075         1  0.271460         1  0.253011         0  0.315903         0  0.218795        0 0.375555\n",
      "        0  -0.175518         0 -1.100461         0  0.208614         0  0.193620         0 -0.078980         0  0.620354        0 0.375555\n",
      "        1   1.664284         0  1.632362         1  2.716729         1  1.907366         2  0.866967         0  0.369160        0 0.659197\n",
      "        2   3.188059         6  2.492778         3  1.577925         4  1.755578         3  1.166914         0  0.794297        2 0.851744\n",
      "        0   1.111318         0  1.164974         0  0.604272         0  0.743293         0  0.704669         0  0.406473        0 0.808672\n",
      "        2   1.266111         1  1.352844         3  0.955346         1  1.006353         0  0.521003         0  0.369160        5 0.659197\n",
      "        2   5.047507         1  0.335454         0  1.509535         3  3.202483         0  0.604306         0  0.429806        0 0.659197\n",
      "        0   1.391405         0  0.790052         0  4.128850         0  2.194098         2  1.979924         0  0.422216        0 0.659197\n",
      "        6   4.479259         6  5.372140         4  1.661916         6  2.052280         1  0.797951         1  0.542284        0 0.659197\n",
      "        0  -1.110256         0  0.050865         0  0.258077         1  0.303711         0 -0.107611         0  0.218795        0 0.375555\n",
      "       37   5.735208        21  5.841074         0  1.395240         0  0.979446         1  2.534639         0  1.841586        0 0.897026\n",
      "        0   1.906480         1  1.975020         2  1.527827         4  1.424599         4  2.039496         0  0.520768        0 0.659197\n",
      "        8   6.251858         8  5.121706         3  2.493307         1  1.449319         1  1.360559         0  0.838275        0 0.908385\n",
      "        0   1.492154         1  4.980033         0  0.972317         0  0.303711         0 -0.107611         0  0.218795        0 0.375555\n",
      "        3   2.643752         9  4.731993         3  1.577925         6  1.243995         1  0.952020         1  0.788431        1 0.851744\n",
      "        3   0.811346         1  0.051872        42  4.508568         8  1.464276         1  0.504329         8  0.369377       11 0.892874\n",
      "        0   0.966937         0  0.914665         0  0.666552         1  0.927634         0  0.454299         0  0.316235        0 0.814560\n",
      "        0   0.755172         0  0.868585         1  1.888277         2  2.307745         0  0.694721         0  0.336270        1 0.639350\n",
      "        0   1.281215         0  0.375438         0  0.271460         0  0.331533         0  0.005064         0  0.218795        0 0.375555\n",
      "        1   1.138446         0  1.417766         0  0.775645         3  0.923865         0  0.521003         0  0.369160        3 0.659197\n",
      "       44  13.724496        20  6.774747         9  2.789489         5  0.684829         5  1.465524         1  0.520768        1 0.659197\n",
      "        2   0.261976         1  0.659638         0  2.691363         0  2.307745         0  0.694721         0  0.336270        0 0.639350\n",
      "        0   1.664284         0  1.546577         0  1.886548         3  2.401426         8  0.521003         5  1.731427        0 0.787900\n",
      "        0   1.447534         0  0.416024         0  0.773101         0  0.314478         0  0.604306         0  0.429806        0 0.659197\n",
      "        3   3.793111         3  3.576566        14  3.757722         5  3.771843         4  0.521003         0  0.369160        2 1.031458\n",
      "        0   2.012557         0  2.222416        23  1.560567        10  1.007644         1  0.797951         0  0.542284        1 0.659197\n",
      "        0  -0.197659         0  0.514115         0  0.382437         0  0.308012         0  0.064635         0  0.233242        2 0.375555\n",
      "        0   0.331509         0 -0.517128         0  0.748427         0  0.515493         0  0.592327         0  0.412991        0 0.818124\n",
      "        1   2.152405         1  1.716131         6  1.160134         4  1.007644         0  0.747921         0  0.422216        0 0.659197\n",
      "        0   1.668349         0  1.885669         1  1.160134         0  0.980372         8  0.747921         0  0.422216        0 0.659197\n",
      "        0  -0.945043         0 -0.158082         0  0.222117         0  0.303711         0 -0.107611         0  0.218795        0 0.365749\n",
      "        5   2.052191         2  1.330495         0  0.811098         0  0.568523         0  0.521003         0  0.361903        0 0.649156\n",
      "        7   3.961354         6  2.573348         0  1.577925         2  1.583087         0  1.441425         0  0.838275        0 0.851744\n",
      "        1   0.966937         0  0.914665         0  2.166929         0  1.464276         0  0.504329         0  0.316235        0 0.892874\n",
      "        0   5.547097         0  4.863110         0  1.372312         0  1.007644         1  0.797951         0  0.495314        0 0.659197\n",
      "        6   8.771587         4  5.749548         1  1.174107         0  1.007644         0  0.747921         0  0.491481        0 0.382479\n",
      "        0   3.747221         0  1.230607         0  1.008691         1  0.678078         0  0.408329         0  0.350716        1 0.639350\n",
      "       19  19.841534        15  5.745568         0  1.552526         9  0.282787         1  0.408329         2  0.336270        0 0.639350\n",
      "        0   1.541623         0  1.500215         6  0.801806         1  0.921174         0  0.521003         0  0.369160        0 0.659197\n",
      "        0   2.152405         0  1.421902         0  1.160134         0  1.007644         0  0.797951         1  0.422216        0 0.659197\n",
      "        0   1.349762         4  1.885669         2  1.160134         2  1.070399         2  3.035573         0  0.422216        0 0.659197\n",
      "        0   1.546949         1  1.494871        11 15.236650         1  1.237358         0  2.468257         2  1.032676        1 4.840610\n",
      "        1   4.655837         4  3.803365         1  1.059434         1  0.983645         0  1.310529         0  0.413730        0 0.818713\n",
      "       16   4.655837         8  4.089362         0  0.990751         0  0.976063         1  1.310529         0  0.413730        0 0.818713\n",
      "        0   0.861640         0  1.546577         1  0.955346         1  1.198977         1  2.808655         0  0.369160        0 0.659197\n",
      "        4   1.499555         2  1.650627         0  1.223199         0  0.741641         0  0.797951         1  0.520768        3 0.659197\n",
      "        0   1.828524         0  1.180730         0  1.883632         0  1.133870         0  0.377388         0  0.410622        0 0.659197\n",
      "        4   3.596740         3  3.609536         0  1.522703         3  1.592630         6  4.927385        12  2.120340        1 2.906027\n",
      "        6   4.449031        27  4.542693         6  1.720004         6  1.649609         7  5.213875         6  1.746260        2 2.420798\n",
      "        0   2.641020         0  2.083339         0  1.324374         0  1.527480         0  0.604306         0  0.427437        0 0.659197\n",
      "        1  -0.042652         1  0.782801         0  0.707173         0  0.654713         0  0.348757         1  0.336270        0 0.649156\n",
      "        0   1.347142         1  1.126669         0  0.791348         0  0.769930         0  0.521003         0  0.369160        0 0.632767\n",
      "        0   2.477930         4  2.573348         1  1.577925         4  1.221502         0  1.166914         0  0.788431        0 0.851744\n",
      "        2   1.024678         4  1.546577         0  0.818341         1  0.923878         0  0.521003         0  0.369160        2 0.659197\n",
      "        3   3.125418         1  1.885669         2  3.250096         2  1.201605         0  0.797951         0  0.495314        2 0.659197\n",
      "        4   2.152405         0  1.885669         3  1.372312         1  0.817744         0  0.797951         0  0.640818        0 0.659197\n",
      "       11   6.027165         1  1.546577         2  1.841842         0  1.793424         2  0.521003         0  0.369160        2 0.659197\n",
      "        0   1.000066         0  0.159355         0  0.271460         0  0.303711         0  0.005064         0  0.218795        0 0.375555\n",
      "        1   1.664284         0  1.434437         7  1.949398         9  1.797829         0  0.866967         1  0.369160        0 0.659197\n",
      "        5   1.330414         0  1.315822         1  3.929921         0  2.307745         0  0.866967         0  0.336270        0 0.639350\n",
      "        2   2.617399         2  1.438985         1  1.179048         0  0.542210         1  0.521003         0  1.157024        0 0.649156\n",
      "       22   2.637296        12  1.546577         8  2.400378        11  1.054000        15  0.521003         1  0.369160        2 0.659197\n",
      "        0   2.559558         0  0.922287         1  0.655478         0  0.838032         0  0.571033         0  0.442258        0 0.659197\n",
      "        0   2.208953         0  2.661520         0  0.358753         0  0.303711         4  4.358343         0  0.704467        3 0.654829\n",
      "        0   1.332426         0  0.682344         0  0.684595         2  0.661249         0  0.461431         0  0.336270        0 0.639350\n",
      "        0   1.541623         0  1.664591         4  2.814825         2  1.040983         0  2.468257         1  1.039932        0 3.597472\n",
      "        0   1.172388         0  0.699454         0  0.831807         0  0.455318         1  0.797951         0  0.520768        2 0.659197\n",
      "        4  11.119431         0  7.774336         0  1.586087         0  1.454105         1  1.584398         0  1.254912        0 1.416418\n",
      "        4   1.482013         0  1.551941         6  2.166929         3  1.464276         0  0.504329         1  0.398260        3 0.892874\n",
      "       13   7.486122         5  5.677591         4 11.282069         3  7.989062         0  1.197855         0  0.395286        1 0.798866\n",
      "        2   1.300876         5  1.010251         4  0.740363         1  0.466391         1  0.604306         1  0.427437        0 0.659197\n",
      "        0   1.942100         2  1.293785         6  5.599721         4  1.330942         0  0.704669         0  0.406473        0 0.853046\n",
      "        0   3.697606         0  3.851779         1  1.577925         1  2.073498         0  3.648211         0  0.838275        0 0.897026\n",
      "        0  -0.285100         0 -0.110866         0  0.271460         0  0.223764         0  0.055093         0  0.233242        4 0.544211\n",
      "        0   0.898899         0  1.544012         0  0.376090         0  0.253011         0  1.229174         0  0.437025        0 0.375555\n",
      "        0   0.717195         0  0.505214         0  0.801806         0  0.689432         0  0.521003         0  0.369160        0 0.659197\n",
      "        0   1.143451         0  1.306482         0  0.801806         0  0.951352         0  0.521003         0  0.369160        0 0.659197\n",
      "       23   6.369591        13  5.975831         1  1.577925         1  5.028660         1  1.166914         0  0.838275        0 0.851744\n",
      "        2   5.542614         5  3.012648         1  2.540346         5  1.007644         0  0.747921         0  0.422216        1 0.659197\n",
      "        0   4.802867         0  4.346871         0  0.740363         0  1.214412         0  0.604306         1  0.427437        0 0.659197\n",
      "        0   1.183786         0  1.871907         0  0.230836         0  1.039824         0 -0.107611         0  0.218795        0 0.466041\n",
      "        0   1.351586         0  2.452572         0  0.223036         1  0.303711         0  4.358343         0  1.105267        0 0.633897\n",
      "        0   0.063780         0  0.050865         0  0.222117         0  0.303711         0 -0.107611         0  0.218795        0 0.365749\n",
      "        1   3.170341         1  1.307742         3  0.730967         0  0.924501         0  0.797951         0  0.422216        1 0.659197\n",
      "        0  -0.451847         0  0.050865         0  0.258077         0  0.303711         0 -0.107611         0  0.218795        0 0.375555\n",
      "        0   0.830471         0  0.069023         0  0.271460         0  0.308012         0  0.315903         0  0.218795        0 0.375555\n",
      "       27   3.170341         1  1.307742         0  0.730967         0  0.924501         1  0.747921         1  0.422216        2 0.659197\n",
      "        2   4.500247         2  3.683036         3  1.577925         8  1.449319         1  1.360559         1  0.838275        3 0.897026\n",
      "        0   0.984479         0  1.175978         0  1.442883         0  0.837390         0  0.797951         0  0.495314        0 0.659197\n",
      "        0   2.037490         5  1.348653         0  3.285446         0  1.308181         0  0.831843         0  0.438937        1 1.681325\n",
      "        3   1.140249        11  1.546577        13  1.306062        14  0.976175         9  0.521003         1  0.369160        3 0.659197\n",
      "        0  -0.723982         0 -0.050003         0  0.694003         0  0.463630         0  0.377388         0  0.412991        0 0.659197\n",
      "        0   3.170341         0  1.307742         0  0.795744         0  0.924501         0  0.797951         0  0.422216        0 0.659197\n",
      "        0   1.266111         0  1.154920         0  0.955346         1  1.013997         0  0.521003         0  0.369160        0 0.659197\n",
      "        3   5.064366         0  1.548044         0  1.552526         4  0.661249         0  0.408329         0  0.336270        0 0.639350\n",
      "        0   1.119344         0  1.330495         1  1.236194         0  2.169801         2  0.521003         3  2.369929        0 0.777859\n",
      "        0   3.170341         0  1.307742         0  0.795744         0  0.924501         0  0.797951         0  0.495314        0 0.659197\n",
      "        0   3.428899         1  1.446811         0  2.202138         0  0.466391         0  0.604306         0  0.427437        2 0.670555\n",
      "        0   1.664284         0  1.377040         0  0.955346         0  0.983818         0  0.521003         0  0.369160        0 0.659197\n",
      "        0   0.738979         0  1.500215         0  0.909660         0  1.143977         0  2.858685         0  0.442258        0 0.659197\n",
      "        0  -1.599966         0 -0.458611         0  0.235499         0  0.303711         0 -0.107611         0  0.218795        0 0.365749\n",
      "        0   2.682219         0  0.770726         0  0.652258         0  0.877460         0  0.521003         0  0.361903        3 0.649156\n",
      "       10   1.664284         0  1.179910         0  0.955346         0  0.972147         0  0.521003         0  0.369160        0 0.659197\n",
      "        0   2.152405         0  1.716925         1  1.160134         1  1.007644         0  0.747921         0  0.422216        0 0.659197\n",
      "        0   0.738979         0  1.500215         1  0.909660         0  1.143977         1  2.858685         1  0.442258        0 0.659197\n",
      "        1   0.696487         3  1.348653         0  0.955346         1  0.983818         0  0.521003         0  0.369160        0 0.659197\n",
      "        0   1.754234         0  1.691936         0  1.372312         0  1.097728         0  0.797951         0  0.495314        0 0.659197\n",
      "        0   2.667481         0  2.608729         0  3.165539         0  1.252795         0  1.143915         1  0.542284        0 0.659197\n",
      "        0   0.942293         1 -0.324642         1  1.784881         2  1.013496         1  0.687744         2  1.199465        2 0.769610\n",
      "        1   2.914424         8  3.070981         5 11.282069         6 10.108543         1  0.747921         0  0.422216        0 0.659197\n",
      "        0   1.541623         0  0.952521         0  0.783161         0  0.921174         0  0.511461         0  0.369160        0 0.659197\n",
      "        2   1.255861         3  0.896876        12  3.673317         6  3.943832         1  0.747921         0  0.422216        0 0.659197\n",
      "        0   1.009359         1  1.048125         2  0.864748         0  0.956574         0  0.521003         0  0.361903        0 0.649156\n",
      "        1   2.806121         1  2.573348         1  1.431167         0  1.516812         1  1.441425         0  0.838275        1 0.851744\n",
      "        2   1.234989         1  0.573854         0  1.466301         0  0.732538         3  0.348757         0  0.336270        1 0.639350\n",
      "        1   0.886698         0  1.199687         0  0.769548         0  0.921174         0  0.521003         0  0.369160        3 0.659197\n",
      "        0   0.466299         0  0.069023         0  0.271460         0  0.308012         0  0.315903         0  0.218795        0 0.375555\n",
      "        0   0.494205         0 -0.006161         0  0.496390         0  0.352218         0  0.728168         0  0.369377        0 0.802931\n",
      "        3   4.257665         0  3.849262         4  1.199546         0  1.062926         0  1.360559         0  1.005840        2 0.897026\n",
      "        7   3.474078        13  3.609536         0  1.461495         3  1.537629         8  4.927385         0  2.120340        1 2.828049\n",
      "        0   1.472423         3  1.932031         0  1.260114         3  1.070399         1  3.035573         0  0.422216        0 0.659197\n",
      "        0   2.657647         0  1.885669         0  1.160134         0  0.827517         0  0.747921         0  0.422216        0 0.659197\n",
      "        0  -0.485847         0 -0.142868         0  0.222117         0  0.303711         0 -0.107611         0  0.218795        0 0.365749\n",
      "        0   0.979332         2  1.348653         1  0.955346         0  1.072436         0  0.984463         0  0.369160        0 0.659197\n",
      "        6   3.170341         3  1.307742         2  0.795744         0  0.924501         0  0.797951         0  0.495314        0 0.659197\n",
      "        0   3.922122         2  3.976322         0  1.679714         5  1.865586         0  1.584398         0  0.838275        0 0.897026\n",
      "        4   6.084483         0  2.885717         0  1.557961         0  1.180029         0  1.166914         0  0.786062        0 0.851744\n",
      "        1   3.188059         2  2.492778         0  1.198974         0  1.243644         0  1.166914         0  0.738312        0 0.935182\n",
      "        1   2.219227         0  1.245252         0  0.893957         3  0.675835         0  0.521003         0  0.347457        1 0.649156\n",
      "        0   2.603018         1  1.766885         0  1.379615         1  1.112366         0  1.166914         0  0.786062        0 0.851744\n",
      "        0  -0.580871         0 -0.158082         0  0.222117         0  0.331533         0 -0.107611         0  0.218795        0 0.365749\n",
      "        0   1.180228         2  1.348653         1  0.955346         0  0.983818         0  0.521003         0  0.369160        0 0.659197\n",
      "        0  -0.549892         0 -0.194793         0  0.222117         0  0.243023         0  0.076056         0  0.277811        0 0.377490\n",
      "        9   2.152405         5  1.885669        40  1.160134        11  1.007644         7  0.797951         1  0.422216        0 0.659197\n",
      "        3   0.811346         0  0.723449         0  0.667098         2  0.400605         0  0.504329         0  0.586500        0 0.976312\n",
      "        3   0.670233         1  0.910433         0  0.955346         0  0.983818         1  0.521003         0  0.369160        0 0.659197\n",
      "       13   4.449031         1  4.496330         5  1.949584         3  1.649609        11  5.263906         0  1.746260        0 2.477011\n",
      "        0  -0.945043         0 -0.517155         0  0.614713         1  0.303711         0 -0.107611         0  0.218795        0 0.365749\n",
      "        0   1.317068         3  0.522960         0  0.494042         0  0.359138         0  0.574980         0  0.308978        0 0.768813\n",
      "        0   1.497481         0  1.585140         0  1.270963         0  1.007644         0  0.797951         0  0.495314        0 0.659197\n",
      "        0   2.194009         0  2.054557         0  1.577925         2  1.221502        10  1.166914         1  0.788431        0 0.851744\n",
      "        0   0.861640         0  1.546577         0  0.955346         0  1.198977         0  2.808655         3  0.369160        0 0.659197\n",
      "        0   1.664284         3  1.710953        25 12.438658         4  1.040983        13  2.468257         1  1.039932        1 3.882008\n",
      "        0  -0.916076         0 -0.194793         0  0.940631         1  0.487295         1  0.076056         0  0.277811        0 0.419336\n",
      "        0   3.670450         0  3.576566         0  5.407771         0  7.408731         0  0.521003         0  0.369160        0 1.031458\n",
      "       44   3.537464         1  1.766593         0  1.439475         0  0.611957         0  0.408329         0  0.336270        0 0.639350\n",
      "        2   2.948568         3  4.199545         0  1.260114         1  0.999630         0  0.747921         0  0.422216        0 0.659197\n",
      "        0   2.617441         0  1.885418         0  1.377386         1  1.583087         0  1.381853         8  0.838275        0 1.067750\n",
      "        0   1.632644         0  1.146761         4  0.920141         0  0.684829         0  0.738379         0  0.621618        0 0.659197\n",
      "        0   0.830471         0  0.069023         0  0.271460         0  0.308012         0  0.315903         0  0.218795        0 0.375555\n",
      "        0  -0.185720         0 -0.194793         0  0.222117         0  0.229815         0  0.076056         1  0.586500        0 0.390999\n",
      "        3   1.664284        12  1.546577         2  0.955346         0  0.976175         0  0.521003         0  0.369160        1 0.659197\n",
      "        1   1.754234         1  1.691936         0  1.160134         2  1.294418         1  0.797951         0  0.422216        0 0.659197\n",
      "        0   2.152405         1  1.885669         0  1.294634         0  1.000062         0  0.797951         0  0.422216        0 0.659197\n",
      "       10   5.413317         5  4.397570         4  1.172157         3  1.148343         0  4.874283         0  0.737344        1 1.131848\n",
      "        2   1.664284         4  1.632362         5  2.716729         1  1.907366         2  0.866967         0  0.369160        2 0.659197\n",
      "        4   1.664284         5  1.434437         2  1.949398         0  1.797829         0  0.866967         0  0.361903        0 0.649156\n",
      "        0   5.904504         0  1.500215         0  3.332702         1  1.738423         0  0.571033         0  0.369160        0 0.659197\n",
      "        2   4.500247         3  4.016155        98 26.672853        32  3.060300         5  3.307813         1  1.011894        1 5.596858\n",
      "        0  13.880086         4  6.965965         0  3.117817         0  1.007644         0  1.415494         0  0.422216        0 0.659197\n",
      "        0   0.861640         0  1.348653         1  0.955346         1  1.194949         2  2.808655         1  0.369160        2 0.659197\n",
      "        2   8.349358         2  6.151638         0  1.372312         0  1.007644         0  0.797951         3  0.422216        0 0.659197\n",
      "        0   5.189508         1  3.668287         0  1.260114         0  0.987958         0  0.747921         0  0.422216        2 0.659197\n",
      "        1   2.617399         2  1.438985         3  0.806800         0  0.661249         1  0.521003         2  0.347457        2 0.649156\n",
      "        0   2.152405         0  1.885669         4  6.856147         0  9.482788         0  0.797951         3  9.514479        0 0.787900\n",
      "       31   6.062172        19  5.500387         2  1.661916         0  1.007644         3  0.797951         4  0.542284        1 0.659197\n",
      "        0   5.058975         0  4.524014         0  2.096673         0  0.976175         0  0.521003         3  0.422559        0 0.659197\n",
      "        3   3.231777         2  3.683743         5  1.322631         0  0.911894         0  1.972032         8  1.722136        5 0.659197\n",
      "       26   6.840417        11  5.550784         4  1.577925         9  1.583087         0  1.441425         7  0.838275        4 0.851744\n",
      "        0  -1.450195         0 -1.286919         0  0.270350         0  0.229815         0  0.128828         0  0.586500        0 0.400805\n",
      "       14   6.201898        14  5.962306         0  1.199546        13  2.213043         0  1.360559         0  0.589697        0 0.897026\n",
      "        0   3.170341         1  1.307742         0  0.730967         0  0.924501         0  0.797951         0  0.422216        0 0.659197\n",
      "        0   1.546949         0  1.160958         0  0.811098         2  0.691753         1  0.521003         0  0.361903        0 0.649156\n",
      "        0   0.942293         0  0.416024         0  0.797417         9  1.179419         0  0.604306         0  0.429806        0 0.659197\n",
      "        0   6.137730         2  2.447015         0  1.626555         0  1.394741         0  0.747921         0  0.693170        0 0.659197\n",
      "        0   3.164649         0  0.314852         0  0.222117         0  0.303711         0 -0.107611         0  0.218795        0 0.365749\n",
      "        0   1.011336         1  1.099042         0  0.955346         0  0.983818         0  0.521003         0  0.463765        0 0.659197\n",
      "        2   0.626148         6  1.121547         1  1.236194         2  2.169801         0  0.521003         0  2.369929        0 0.768053\n",
      "        1   0.496357         0  0.836887         0  0.955346         0  0.805921         0  0.521003         0  0.369160        0 0.659197\n",
      "        0   2.152405         4  1.885669         1  6.856147         3  9.482788         1  0.797951         0  9.514479        1 0.787900\n",
      "        0   0.735080         0  0.561850         0  0.270350         0  0.243023         0  0.248302         0  0.277811        0 0.387296\n",
      "        1   2.189793         0  1.085891         0  0.806800         0  0.545546         0  0.521003         0  0.347457        0 0.649156\n",
      "        0  -0.580871         0 -0.158082         0  0.222117         0  0.303711         3 -0.107611         0  0.218795        0 0.365749\n",
      "        1   2.189793         0  1.438985         0  0.806800         0  0.661249         0  0.521003         0  0.336270        0 0.649156\n",
      "        0   0.886698         0  1.199687         2  0.769548         3  0.921174         0  0.521003         0  0.369160        1 0.659197\n",
      "        0   2.716701         1  3.209096         3  1.330137         0  1.007644         0  1.922002         0  1.435365        2 0.659197\n",
      "        0   0.625151         0  0.194040         0  0.688577         0  0.422791         0  0.878818         0  0.429806        0 0.632767\n",
      "        0   1.119977         1  3.785789         0  0.955346         0  0.976175         0  0.306109         0  0.369160        0 0.659197\n",
      "        1   1.664284         1  1.632362         0  2.716729         0  1.907366         3  0.866967         0  0.369160        0 0.659197\n",
      "        2   4.592787         0  4.746137         2  2.104184         7  0.983645         5  1.360559        11  1.095876       12 0.897026\n",
      "        1   2.143446         0  2.522944         0  1.661916         0  1.007644         0  0.797951         0  0.542284        0 0.659197\n",
      "        1  -0.560318         0 -0.776968         0  0.496390         0  0.352218         0  0.310683         0  0.369377        0 0.802931\n",
      "        7   1.664284         3  1.632362         1  2.716729         5  1.907366         0  0.866967         1  0.369160        3 0.659197\n",
      "        1   2.790693         1  1.932031         0  1.260114         0  1.007644         0  0.747921         2  0.422216        0 0.659197\n",
      "        2   1.261107         0  1.417766         0  0.900868         0  0.923865         0  0.521003         0  0.369160        0 0.659197\n",
      "        1  -0.580871         0 -0.511177         0  0.222117         0  0.303711         0 -0.107611         0  0.218795        0 0.365749\n",
      "        0   0.505986         0  0.235037         0  0.806800         0  0.436554         0  0.521003         0  0.336270        0 0.639350\n",
      "        0  -1.775340         0 -0.298317         0  0.222117         0  0.303711         0 -0.107611         0  0.218795        1 0.503486\n",
      "        3   5.864723         0  4.329697         0  1.045581         1  0.838827         0  1.197855         1  0.395286        0 0.798866\n",
      "        0   1.546949         1  1.253799         1  0.811098         0  1.077116         0  0.521003         0  0.702694        1 1.145336\n",
      "        1   0.457264         0  0.069023         0  0.271460         1  0.331533         0  0.005064         0  0.218795        0 0.375555\n",
      "        0   3.170341         0  1.307742         0  0.795744         0  0.924501         0  0.797951         0  0.495314        0 0.659197\n",
      "        0   7.139246         0  4.681989         0  0.773101         0  0.466391         0  0.604306         0  0.429806        0 0.659197\n",
      "        0  -2.113870         0 -0.158082         1  0.222117         0  0.323678         0  2.180041         0  0.218795        0 0.365749\n",
      "       16  17.560102         4  5.526890         0  1.273001         2  0.561849         0  0.797951         0  0.495314        0 0.659197\n",
      "        0 -12.192975         0 -1.166548         0  0.208614         0  0.198908         0  0.234528         0  0.230873        0 0.375555\n",
      "        0   1.499459         0  1.636058         0  1.160134         0  1.007644         0  0.747921         1  0.845386        0 0.659197\n",
      "        3   8.341741         4  5.087884         0  1.577925         0  1.449319         0  1.360559         1  0.838275        0 0.897026\n",
      "        1  17.560102         0  5.526890         0  1.273001         0  0.561849         0  0.797951         0  0.495314        0 0.659197\n",
      "        1   1.232976         0  0.573854         2  1.466301         1  0.732538         1  0.348757         0  0.336270        0 0.639350\n",
      "        4  13.880086         1  6.965965         0  3.117817         0  1.007644         2  1.415494         0  0.422216        0 0.659197\n",
      "        0   0.334603         0  0.220585         0  0.271460         0  0.253011         0  0.055093         0  0.218795        0 0.615496\n",
      "        1   3.837235         0  0.800959         3  1.683616         0  0.972147         1  0.461431         0  0.369160        0 0.659197\n",
      "        0   1.041674         0  0.929510         0  0.875572         1  0.880676         0  0.521003         0  0.336270        0 0.639350\n",
      "        3   0.259964         0  0.952804         0  0.811098         0  0.678078         0  0.521003         0  0.350716        0 0.639350\n",
      "        3   1.996815         0  1.022877         0  0.801126         0  0.904312         0  0.797951         0  0.520768        2 0.659197\n",
      "        5   6.724103         1  4.538642         0  1.158633         1  0.838827         0  1.197855         1  0.395286        0 0.798866\n",
      "        2   0.979332         0  1.546577         0  0.955346         0  1.084108         0  0.984463         0  0.369160        0 0.659197\n",
      "        0   0.830471         0  0.266947         0  0.271460         0  0.308012         0  0.315903         0  0.218795        0 0.375555\n",
      "        0   1.659806         0  1.438985         1  0.829636         0  0.661249         0  0.521003         0  0.347457        0 0.649156\n",
      "        1   2.189793         8  1.438985         2  5.510848         1  2.562545         0  0.521003         0  0.347457        0 0.649156\n",
      "        1   2.308968         6  2.469445         5  4.135006         3  3.989593         0  0.521003         0  0.361903        0 0.649156\n",
      "        0   1.347142         0  1.126669         0  0.791348         0  0.769930         0  0.521003         0  0.369160        0 0.632767\n",
      "        0   4.134625         5  1.208985         1  0.828003         0  0.601982         1  0.408329         0  0.350716        0 0.639350\n",
      "       14   5.993897         6  3.121772         9  1.372312         1  1.007644         2  0.797951         0  0.422216        1 0.659197\n",
      "        0   2.152405         0  1.716925         0  1.160134         0  1.007644         0  0.797951         0  0.422216        0 0.659197\n",
      "        0   1.266111         0  1.154920         0  0.951906         0  0.986753         0  0.521003         0  0.361903        0 0.649156\n",
      "       10   7.861236         6  5.812544         0  0.955346         0  0.976175         0  0.521003         0  0.369160        0 0.659197\n",
      "        0   0.496357         0  0.836887         0  0.955346         0  0.805921         0  0.521003         0  0.369160        0 0.659197\n",
      "        2   0.552898         0  0.892274         6  0.811098         2  0.691753         2  0.521003         3  0.361903        0 0.649156\n",
      "        0   0.839856         0  0.353652         0  0.955346         0  0.744433         0  0.521003         0  0.369160        0 0.659197\n",
      "        0   0.457264         0  0.069023         0  0.271460         1  0.308012         0  0.005064         0  0.218795        0 0.615496\n",
      "        0   0.544525         0  0.031166         0  0.270350         0  0.229815         2  0.118613         0  0.586500        0 0.400805\n",
      "        1   2.275066         1  1.762311         0  1.260114         0  0.991986         0  0.747921         0  0.422216        0 0.659197\n",
      "        0  -2.886143         0 -2.048779         0  0.208614         0  0.198908         0 -0.078980         0  0.230873        1 0.375555\n",
      "        0   0.861602         0  0.917254         1  1.324374         0  1.527480         0  0.604306         0  0.427437        0 0.659197\n",
      "       15   6.360168         3  4.507529         5  1.577925         3  1.583087         0  1.441425         0  0.838275        2 0.851744\n",
      "        0   0.421864         0  0.182728         0  0.270350         0  0.243023         0  0.118613         0  0.180316        0 0.387296\n",
      "        2  11.612395         4  6.311919         0  0.955346         0  0.983818         0  0.521003         0  0.369160        0 0.659197\n",
      "        0   1.856398         2  0.891061         0  3.243802         1  2.527800         2  1.762548         1  0.347457        0 0.649156\n",
      "        0   1.011336         0  1.099042         0  0.955346         0  0.972147         0  0.521003         1  0.463765        0 0.659197\n",
      "        1   1.749229         1  1.803220         0  1.065290         0  0.955334         0  0.747921         2  0.422216        1 0.659197\n",
      "        0   1.281215         0  0.177514         0  0.271460         0  0.331533         0  0.005064         0  0.218795        0 0.375555\n",
      "        0   1.664284         0  0.998883         0  0.844369         0  0.976175         0  0.461431         0  0.369160        0 0.659197\n",
      "        0   2.152405         0  1.971453         7  3.165539        15  1.252795         4  1.093885         2  0.422216        1 0.659197\n",
      "        0   1.534870         3  1.138457         1  0.875572         0  0.880676         0  0.521003         0  0.336270        0 0.649156\n",
      "        0   1.664284         0  1.377040         0  0.955346         0  0.983818         0  0.521003         0  0.369160        0 0.659197\n",
      "        0   0.984479         0  1.175978         0  1.442883         1  0.837390         1  0.797951         0  0.495314        1 0.659197\n",
      "        0   2.426302         0  2.685527        11  2.992478        32  3.282866         3  0.521003         2  0.369160        0 0.659197\n",
      "        0   0.274994         0  0.820006         0  0.270350         0  0.229815         0  0.047961         0  0.586500        0 0.400805\n",
      "        2   1.871890         1  1.803220         0  1.205635         0  0.955334         0  0.747921         0  0.422216        0 0.659197\n",
      "        0   2.037490         0  1.546577         0  1.071746         1  1.303367         1  0.831843         4  0.438937        1 1.426972\n",
      "        0   0.785948         1  0.782571         1  3.248100         0  2.554002         2  1.762548         0  0.361903        0 0.649156\n",
      "        2   3.415971         1  3.393454         0  0.933803         1  1.140390         0  4.814712         0  0.731374        0 0.682281\n",
      "        0   0.061199         0 -0.720697         0  0.238722         0  0.203079         0 -0.138552         0  0.218795        0 0.375555\n",
      "       17   2.196939         6  2.470188        13  1.055753         4  0.684829         0  1.912460         0  1.652302        0 0.659197\n",
      "        0   0.722522         0  0.335493         0  0.811098         0  0.453383         0  0.521003         0  0.361903        1 0.649156\n",
      "        0   0.997315         0  3.739426         0  0.801806         0  0.921174         0  0.356139         0  0.369160        0 0.659197\n",
      "       18   2.682219        18  0.968650         1  0.658249         2  0.893032         3  0.521003         1  0.369160        0 0.659197\n",
      "        0  -1.254490         1  0.050865         0  0.222117         2  0.323678         0  2.180041         0  0.218795        0 0.365749\n",
      "        6   5.286366         4  3.533050         2  0.990751         0  0.983645         8  1.310529         0  0.413730        2 0.818713\n",
      "        0  -0.502862         0 -0.416778         0  0.201358         0  0.204318         0  0.076056         0  0.277811        0 0.347812\n",
      "        5  17.560102         3  5.526890         0  1.273001         0  0.561849         0  0.797951         0  0.422216        0 0.659197\n",
      "        0   1.664284         1  1.434437         1  1.949398         2  1.797829         1  0.866967         3  0.361903        1 0.649156\n",
      "        0  -0.580871         0 -0.511177         0  0.222117         0  0.303711         0 -0.107611         0  0.218795        0 0.365749\n",
      "       14   8.561125        14  5.807253         3  1.254257         9  0.979446         1  1.360559         2  0.773941        1 0.897026\n",
      "        0   1.644084         2 -0.004076         0  0.582577         0  0.578617         0  0.348757         0  0.336270        0 0.639350\n",
      "        3   7.894941         8  6.157638         6  1.084010         0  0.970400         1  1.360559         1  0.773941        0 0.897026\n",
      "        0   2.152405         2  1.971453         4  3.165539         3  1.252795         0  1.143915         0  0.495314        1 0.659197\n",
      "        1   1.996815         1  1.694454         0  0.831807         0  0.684829         0  0.797951         1  0.520768        1 0.659197\n",
      "        0   0.025957         0 -0.158082         0  0.222117         0  0.381536         0 -0.107611         0  0.218795        0 0.365749\n",
      "        8   4.500247         5  3.344155         1  1.577925         1  1.601489         3  1.584398         1  0.838275        2 0.851744\n",
      "       16  11.012066         2  8.817951         6  1.372312         1  1.007644         0  0.797951         0  0.495314        1 0.659197\n",
      "        0   1.164871         2  1.329956         0  0.606914         0  0.363166         0  0.504329         0  0.398260        0 0.848213\n",
      "        1   2.630216         0  0.069023         4  0.477400         1  0.308012         0  0.005064         0  0.218795        0 0.375555\n",
      "        3   1.754234         0  1.738298         2  1.091451         0  1.294418         0  0.747921         0  0.422216        2 0.659197\n",
      "        0   0.979332         1  1.546577         0  0.955346         0  1.076464         1  0.984463         0  0.369160        0 0.659197\n",
      "        0  -0.056696         0  0.014154         0  5.876444         0  0.487295         0  0.076056         0  0.277811        0 0.429142\n",
      "        0   2.549181         1  1.538191         4  3.220622         3  2.606211         1  1.166914         2  0.788431        0 0.851744\n",
      "        0  -0.271541         1  2.307356         0  0.222117         0  0.303711         0 -0.107611         2  0.218795        0 0.365749\n",
      "        0   2.682219         0  0.968650         2  0.658249         0  0.893032         2  0.521003         0  0.369160        0 0.659197\n",
      "        6   2.716701         6  3.255459         2  1.261454         0  1.007644         0  1.922002         2  1.435365        0 0.659197\n",
      "        3   6.137730         1  2.447015         0  1.626555         0  1.394741         2  0.747921         0  0.693170        0 0.659197\n",
      "        0  -0.580871         0  0.006293         4  2.428361         1  0.941999         1  1.839644         0  0.421503        3 0.878748\n",
      "        4   5.076271        21  5.288157         0  1.372312         2  1.084815         0  0.797951         2  0.495314        0 0.659197\n",
      "        4   3.290901         4  3.904423         2  0.806800         1  0.661249         0  0.521003         1  0.347457        0 0.649156\n",
      "        0   1.041674         0  0.929510         0  0.875572         0  0.880676         0  0.521003         0  0.336270        0 0.639350\n",
      "        0  -0.742599         0  0.298032         0  0.362002         0  0.303711         0  0.064635         0  0.218795        0 0.375555\n",
      "        0   2.152405         0  1.716131         0  1.372312         0  1.007644         1  0.797951         0  0.495314        0 0.659197\n",
      "        0  -0.788249         0 -1.286919         0  0.270350         0  0.229815         0  0.249509         0  0.586500        0 0.400805\n",
      "        0   0.421864         0  0.182728         0  0.270350         0  0.243023         0  0.118613         0  0.180316        0 0.387296\n",
      "        2   2.390235         6  2.492778         0  1.577925         0  1.209074         0  1.166914         7  0.794297        0 0.851744\n",
      "        0   0.073842         0 -0.597697         0  0.724111         0  0.463630         0  0.317816         0  0.412991        0 0.659197\n",
      "        0   0.811346         0  0.279355         9  2.918971         4  1.375925         1  0.728168         1  0.369377        1 0.847592\n",
      "        0   0.100248         0  0.482273         0  0.739985         0  0.874140         0  0.348757         0  0.336270        2 0.639350\n",
      "        2   2.152405         2  1.808973         3  2.478001         0  2.478953         0  0.797951         3  0.763006        0 7.323237\n",
      "        0   1.541623         0  0.488754         0  0.783190         0  0.921174         0  0.511461         0  0.369160        0 0.659197\n",
      "        0  -0.395672         0 -0.452580         0  1.716429         0  0.385029         0  0.271800         0  0.180316        0 0.429142\n",
      "        1   2.189793         3  1.524770         0  2.758381         1  2.307745         1  0.866967         0  0.336270        0 0.649156\n",
      "        0   1.203037         2  1.694454         0  0.831807         0  0.684829         0  0.797951         0  0.429806        0 0.659197\n",
      "        1  -0.025504         3  0.416024         3  0.797417         0  0.524452         1  0.878818         1  0.429806        0 0.659197\n",
      "        2   1.541623         1  1.585999         4  2.890565         1  1.244923         0  0.916997         0  0.369160        3 0.659197\n",
      "        1   2.637296         0  1.546577         2  2.400378         0  1.054000         2  0.521003         1  0.369160        1 0.659197\n",
      "        3   0.072893         2 -0.736011         0  0.222117         0  0.303711         0 -0.107611         0  0.218795        0 0.365749\n",
      "        1   2.682219         0  0.770726         0  0.658249         0  0.893032         0  0.521003         0  0.369160        0 0.659197\n",
      "        0   1.355479         0 -0.026619         0  0.754427         0  1.880961         0  0.431365         0  0.625218        0 0.847592\n",
      "        6   5.389723        11  7.502514         6  1.115292         0  1.926294         0  1.441425         0  0.838275        0 0.851744\n",
      "        0   1.977793         0  1.438985         3  0.749201         2  0.615998         4  0.521003         4  0.347457        0 0.649156\n",
      "        3   2.189793         1  1.438985         2  0.806800         1  0.661249         2  0.521003         0  0.336270        0 0.649156\n",
      "        0   2.559558         0  0.922287         0  0.655478         0  0.838032         0  0.571033         0  0.369160        0 0.659197\n",
      "        0   1.128379         0  0.782801         1  1.965835         2  1.066409         1  0.659597         0  0.417234        1 0.832112\n",
      "        0  -0.246616         0  0.096428         2  0.718319         0  0.910361         0  0.651899         0  0.412991        0 0.659197\n",
      "        0  -2.029720         0 -2.364790         3  0.267077         0  0.203079         0 -0.138552         0  0.239107        0 0.375555\n",
      "       71   8.771587        31  5.749548         7  1.446741         1  1.007644         2  0.797951         1  0.491481        1 0.662278\n",
      "        2   2.189793         0  1.524770         1  2.758381         0  2.307745         0  0.866967         1  0.336270        0 0.649156\n",
      "        0   1.184609         4  1.885669         0  1.160134         0  1.007644         0  0.747921         1  0.422216        0 0.659197\n",
      "        0   3.170341         0  1.307742         1  0.795744         0  0.924501         0  0.797951         0  0.495314        0 0.659197\n",
      "        2   1.150323         0  0.746090         4  6.333641         8  1.316535         0  0.532423         0  0.406473        2 0.853046\n",
      "        7   3.419704         1  1.241203         5  1.552526         2  0.661249         2  0.408329         1  0.336270        0 0.639350\n",
      "       13   3.698467        14  3.804976         3  1.372312        17  2.152219         6  0.797951         3  0.422216        3 0.659197\n",
      "       17   1.541623         8  1.500215         0  0.801806         2  0.921174         2  0.521003         0  0.369160        0 0.659197\n",
      "        0   0.099584         0 -0.461328         0  0.740363         0  0.466391         1  0.604306         0  0.427437        1 0.659197\n",
      "        0   3.172723         0  2.360315         0  1.063567         0  0.735967         0  0.797951         0  0.520768        0 0.659197\n",
      "        2   3.415971         4  3.393454         0  0.883828         0  1.133854         0  4.814712         0  0.731374        1 0.682281\n",
      "        2   2.152405         3  1.885669         1  1.160134         4  2.363599         2  0.797951         0  0.422216        0 0.659197\n",
      "        0  -0.945043         0 -0.158082         0  0.222117         0  0.303711         0 -0.107611         0  0.218795        0 0.365749\n",
      "        1   2.426302         3  2.487603         3  4.135006        15  3.989593         3  0.521003         1  0.369160        2 0.659197\n",
      "       10   3.445726         3  2.573348        32  1.577925         6  1.583087         3  1.166914         0  0.838275       19 0.851744\n",
      "        1  -0.075630         0 -0.158082         0  0.222117         0  0.272482         0 -0.107611         0  0.218795        0 0.365749\n",
      "        0   1.844782         0  2.661520         1  0.273011         0  0.303711         2  4.358343         0  1.105267        0 0.633897\n",
      "        0   9.222198         0  5.799503         0  2.935838         0  1.190029         0  1.166914         0  1.252543        0 3.517925\n",
      "        0  25.944698         1  1.020594         0  0.797417         0  0.524452         0  0.878818         0  0.429806        0 0.659197\n",
      "        4   2.477930         9  2.573348         0  1.577925         0  1.583087         1  1.441425         0  0.838275        1 0.851744\n",
      "        3  12.100518         4  6.895300         0  1.091451         0  1.007644         0  0.747921         0  0.422216        0 0.659197\n",
      "        1   0.072893         0 -0.736011         0  0.222117         0  0.303711         0 -0.107611         0  0.218795        0 0.365749\n",
      "        8   2.637296         1  1.546577         3  2.400378         2  1.054000        10  0.521003         0  0.369160        0 0.659197\n",
      "        1   1.664284         2  1.710953        29  3.683669         3  1.040983        14  2.468257         1  1.039932        1 3.882008\n",
      "        0   0.885337         0  0.050865         1  0.258077         1  0.381536         0 -0.107611         0  0.218795        0 0.375555\n",
      "        1   2.901419         0  4.812563         0  1.577925         0  1.558576         0  0.952020         0  0.788431        0 0.851744\n",
      "        1   4.500247         0  3.910461         3  1.198974         8  1.243644         1  1.584398         0  0.738312        0 0.980464\n",
      "        0   2.453584         5  1.524770         3  2.758381         0  2.307745         0  0.866967         0  0.347457        3 0.649156\n",
      "        1   3.226086         0  1.632069         1  0.864748         0  0.956574         0  0.521003         0  0.361903        0 0.649156\n",
      "        0   1.664284         0  1.377040         0  0.955346         1  0.976175         1  0.521003         0  0.369160        0 0.659197\n",
      "        0   2.782935         0  1.329361         0  1.372312         0  1.007644         0  0.797951         0  0.495314        0 0.659197\n",
      "        0   0.334603         0  0.220585         4  0.271460         0  0.253011         0  0.055093         0  0.218795        0 0.375555\n",
      "        0   5.076271         0  5.288157         0  1.372312         1  1.084815         0  0.797951         0  0.422216        1 0.659197\n",
      "        9  14.395163         4  7.603241         0  3.619599         4  1.007644         0  1.465524         0  0.542284        0 0.659197\n"
     ]
    }
   ],
   "source": [
    "dfs = []\n",
    "\n",
    "complist_vars = [complist_ya1,\n",
    "                 complist_ya2,\n",
    "                 complist_yb1,\n",
    "                 complist_yb2,\n",
    "                 complist_yb3,\n",
    "                 complist_yb4,\n",
    "                 complist_yc]\n",
    "\n",
    "for i, complist in enumerate(complist_vars):\n",
    "    df = pd.DataFrame(complist, columns=[\"true_\" + variables[i], \"pred_\" + variables[i]])\n",
    "    dfs.append(df)\n",
    "\n",
    "result = pd.concat(dfs, axis=1)\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "\n",
    "print(result.to_string(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
