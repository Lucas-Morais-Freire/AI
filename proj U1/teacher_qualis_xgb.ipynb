{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning para Previsão de Taxas de Qualis de Professores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliotecas Importadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import warnings as wrn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importação de Bibliotecas de Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import balanced_accuracy_score, roc_auc_score, make_scorer\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importação de Bibliotecas de Otimização de Hiperparâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Integer, Categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leitura e Seleção de Colunas do Arquivo CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>siape</th>\n",
       "      <th>sexo</th>\n",
       "      <th>formacao</th>\n",
       "      <th>tipo_jornada_trabalho</th>\n",
       "      <th>vinculo</th>\n",
       "      <th>id_unidade_lotacao</th>\n",
       "      <th>lotacao</th>\n",
       "      <th>admissao</th>\n",
       "      <th>categoria</th>\n",
       "      <th>classe_funcional</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1543339</td>\n",
       "      <td>F</td>\n",
       "      <td>MESTRADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Ativo Permanente</td>\n",
       "      <td>1452</td>\n",
       "      <td>NÚCLEO DE EDUCAÇÃO DA INFÂNCIA</td>\n",
       "      <td>2006/07/24 00:00:00.000000000</td>\n",
       "      <td>PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO</td>\n",
       "      <td>DIV                                           ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1554468</td>\n",
       "      <td>M</td>\n",
       "      <td>DOUTORADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Ativo Permanente</td>\n",
       "      <td>351</td>\n",
       "      <td>ESCOLA AGRÍCOLA DE JUNDIAÍ</td>\n",
       "      <td>2008/09/12 00:00:00.000000000</td>\n",
       "      <td>PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO</td>\n",
       "      <td>DV                                            ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1177821</td>\n",
       "      <td>M</td>\n",
       "      <td>MESTRADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Ativo Permanente</td>\n",
       "      <td>284</td>\n",
       "      <td>ESCOLA DE MÚSICA</td>\n",
       "      <td>1998/04/28 00:00:00.000000000</td>\n",
       "      <td>PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO</td>\n",
       "      <td>DIV                                           ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2360824</td>\n",
       "      <td>M</td>\n",
       "      <td>MESTRADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Ativo Permanente</td>\n",
       "      <td>351</td>\n",
       "      <td>ESCOLA AGRÍCOLA DE JUNDIAÍ</td>\n",
       "      <td>2017/01/25 00:00:00.000000000</td>\n",
       "      <td>PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO</td>\n",
       "      <td>DIII                                          ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2364334</td>\n",
       "      <td>F</td>\n",
       "      <td>DOUTORADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Ativo Permanente</td>\n",
       "      <td>351</td>\n",
       "      <td>ESCOLA AGRÍCOLA DE JUNDIAÍ</td>\n",
       "      <td>2009/10/13 00:00:00.000000000</td>\n",
       "      <td>PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO</td>\n",
       "      <td>DIV                                           ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2765</th>\n",
       "      <td>4246363</td>\n",
       "      <td>M</td>\n",
       "      <td>DOUTORADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Professor Visitante</td>\n",
       "      <td>1824</td>\n",
       "      <td>INSTITUTO DE POLÍTICAS PÚBLICAS</td>\n",
       "      <td>2023/05/23 00:00:00.000000000</td>\n",
       "      <td>PROFESSOR MAGISTERIO SUPERIOR - VISITANTE</td>\n",
       "      <td>Adjunto                                       ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2766</th>\n",
       "      <td>3304576</td>\n",
       "      <td>M</td>\n",
       "      <td>DOUTORADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Professor Visitante</td>\n",
       "      <td>4885</td>\n",
       "      <td>ESCOLA DE CIÊNCIAS E TECNOLOGIA</td>\n",
       "      <td>2022/08/12 00:00:00.000000000</td>\n",
       "      <td>PROFESSOR MAGISTERIO SUPERIOR - VISITANTE</td>\n",
       "      <td>Titular                                       ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2767</th>\n",
       "      <td>1056188</td>\n",
       "      <td>M</td>\n",
       "      <td>DOUTORADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Professor Visitante</td>\n",
       "      <td>179</td>\n",
       "      <td>DEPARTAMENTO DE BIOLOGIA CELULAR E GENÉTICA</td>\n",
       "      <td>2022/10/03 00:00:00.000000000</td>\n",
       "      <td>PROFESSOR MAGISTERIO SUPERIOR - VISITANTE</td>\n",
       "      <td>A                                             ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2768</th>\n",
       "      <td>3330361</td>\n",
       "      <td>F</td>\n",
       "      <td>DOUTORADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Professor Visitante</td>\n",
       "      <td>6069</td>\n",
       "      <td>INSTITUTO METROPOLE DIGITAL</td>\n",
       "      <td>2023/02/15 00:00:00.000000000</td>\n",
       "      <td>PROFESSOR MAGISTERIO SUPERIOR - VISITANTE</td>\n",
       "      <td>A                                             ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2769</th>\n",
       "      <td>3309092</td>\n",
       "      <td>M</td>\n",
       "      <td>DOUTORADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Professor Visitante</td>\n",
       "      <td>4894</td>\n",
       "      <td>DEPARTAMENTO DE GEOFÍSICA</td>\n",
       "      <td>2022/09/06 00:00:00.000000000</td>\n",
       "      <td>PROFESSOR MAGISTERIO SUPERIOR - VISITANTE</td>\n",
       "      <td>Titular                                       ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2770 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        siape sexo   formacao           tipo_jornada_trabalho  \\\n",
       "0     1543339    F   MESTRADO  Dedicação exclusiva              \n",
       "1     1554468    M  DOUTORADO  Dedicação exclusiva              \n",
       "2     1177821    M   MESTRADO  Dedicação exclusiva              \n",
       "3     2360824    M   MESTRADO  Dedicação exclusiva              \n",
       "4     2364334    F  DOUTORADO  Dedicação exclusiva              \n",
       "...       ...  ...        ...                             ...   \n",
       "2765  4246363    M  DOUTORADO  Dedicação exclusiva              \n",
       "2766  3304576    M  DOUTORADO  Dedicação exclusiva              \n",
       "2767  1056188    M  DOUTORADO  Dedicação exclusiva              \n",
       "2768  3330361    F  DOUTORADO  Dedicação exclusiva              \n",
       "2769  3309092    M  DOUTORADO  Dedicação exclusiva              \n",
       "\n",
       "                  vinculo  id_unidade_lotacao  \\\n",
       "0        Ativo Permanente                1452   \n",
       "1        Ativo Permanente                 351   \n",
       "2        Ativo Permanente                 284   \n",
       "3        Ativo Permanente                 351   \n",
       "4        Ativo Permanente                 351   \n",
       "...                   ...                 ...   \n",
       "2765  Professor Visitante                1824   \n",
       "2766  Professor Visitante                4885   \n",
       "2767  Professor Visitante                 179   \n",
       "2768  Professor Visitante                6069   \n",
       "2769  Professor Visitante                4894   \n",
       "\n",
       "                                          lotacao  \\\n",
       "0                  NÚCLEO DE EDUCAÇÃO DA INFÂNCIA   \n",
       "1                      ESCOLA AGRÍCOLA DE JUNDIAÍ   \n",
       "2                                ESCOLA DE MÚSICA   \n",
       "3                      ESCOLA AGRÍCOLA DE JUNDIAÍ   \n",
       "4                      ESCOLA AGRÍCOLA DE JUNDIAÍ   \n",
       "...                                           ...   \n",
       "2765              INSTITUTO DE POLÍTICAS PÚBLICAS   \n",
       "2766              ESCOLA DE CIÊNCIAS E TECNOLOGIA   \n",
       "2767  DEPARTAMENTO DE BIOLOGIA CELULAR E GENÉTICA   \n",
       "2768                  INSTITUTO METROPOLE DIGITAL   \n",
       "2769                    DEPARTAMENTO DE GEOFÍSICA   \n",
       "\n",
       "                           admissao  \\\n",
       "0     2006/07/24 00:00:00.000000000   \n",
       "1     2008/09/12 00:00:00.000000000   \n",
       "2     1998/04/28 00:00:00.000000000   \n",
       "3     2017/01/25 00:00:00.000000000   \n",
       "4     2009/10/13 00:00:00.000000000   \n",
       "...                             ...   \n",
       "2765  2023/05/23 00:00:00.000000000   \n",
       "2766  2022/08/12 00:00:00.000000000   \n",
       "2767  2022/10/03 00:00:00.000000000   \n",
       "2768  2023/02/15 00:00:00.000000000   \n",
       "2769  2022/09/06 00:00:00.000000000   \n",
       "\n",
       "                                             categoria  \\\n",
       "0     PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO   \n",
       "1     PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO   \n",
       "2     PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO   \n",
       "3     PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO   \n",
       "4     PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO   \n",
       "...                                                ...   \n",
       "2765         PROFESSOR MAGISTERIO SUPERIOR - VISITANTE   \n",
       "2766         PROFESSOR MAGISTERIO SUPERIOR - VISITANTE   \n",
       "2767         PROFESSOR MAGISTERIO SUPERIOR - VISITANTE   \n",
       "2768         PROFESSOR MAGISTERIO SUPERIOR - VISITANTE   \n",
       "2769         PROFESSOR MAGISTERIO SUPERIOR - VISITANTE   \n",
       "\n",
       "                                       classe_funcional  \n",
       "0     DIV                                           ...  \n",
       "1     DV                                            ...  \n",
       "2     DIV                                           ...  \n",
       "3     DIII                                          ...  \n",
       "4     DIV                                           ...  \n",
       "...                                                 ...  \n",
       "2765  Adjunto                                       ...  \n",
       "2766  Titular                                       ...  \n",
       "2767  A                                             ...  \n",
       "2768  A                                             ...  \n",
       "2769  Titular                                       ...  \n",
       "\n",
       "[2770 rows x 10 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# selecionar atributos dos professores que sao de interesse\n",
    "\n",
    "tp_cols = [\"siape\", \"sexo\", \"formacao\", \"tipo_jornada_trabalho\",\n",
    "           \"vinculo\", \"id_unidade_lotacao\", \"lotacao\", \"admissao\", \"categoria\",\n",
    "           \"classe_funcional\"]\n",
    "\n",
    "tp_df = pd.read_csv(\"./perfis/docentes.csv\", sep=\";\")\n",
    "tp_df = tp_df[tp_cols]\n",
    "\n",
    "tp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tipos de Dados das Colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "siape                     int64\n",
       "sexo                     object\n",
       "formacao                 object\n",
       "tipo_jornada_trabalho    object\n",
       "vinculo                  object\n",
       "id_unidade_lotacao        int64\n",
       "lotacao                  object\n",
       "admissao                 object\n",
       "categoria                object\n",
       "classe_funcional         object\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resumo Estatístico do DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>siape</th>\n",
       "      <th>id_unidade_lotacao</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.770000e+03</td>\n",
       "      <td>2770.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.114588e+06</td>\n",
       "      <td>2821.146209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.142222e+06</td>\n",
       "      <td>5617.495694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.274600e+04</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.297595e+06</td>\n",
       "      <td>142.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.810985e+06</td>\n",
       "      <td>202.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.722937e+06</td>\n",
       "      <td>4890.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.350807e+06</td>\n",
       "      <td>31231.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              siape  id_unidade_lotacao\n",
       "count  2.770000e+03         2770.000000\n",
       "mean   2.114588e+06         2821.146209\n",
       "std    1.142222e+06         5617.495694\n",
       "min    1.274600e+04            2.000000\n",
       "25%    1.297595e+06          142.000000\n",
       "50%    1.810985e+06          202.000000\n",
       "75%    2.722937e+06         4890.000000\n",
       "max    9.350807e+06        31231.000000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparação dos Dados de Qualis das Revistas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>siape</th>\n",
       "      <th>revista_a1</th>\n",
       "      <th>revista_a2</th>\n",
       "      <th>revista_b1</th>\n",
       "      <th>revista_b2</th>\n",
       "      <th>revista_b3</th>\n",
       "      <th>revista_b4</th>\n",
       "      <th>revista_b5</th>\n",
       "      <th>revista_c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.756000e+03</td>\n",
       "      <td>2756.000000</td>\n",
       "      <td>2756.000000</td>\n",
       "      <td>2756.000000</td>\n",
       "      <td>2756.000000</td>\n",
       "      <td>2756.000000</td>\n",
       "      <td>2756.000000</td>\n",
       "      <td>2756.000000</td>\n",
       "      <td>2756.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.112227e+06</td>\n",
       "      <td>2.634978</td>\n",
       "      <td>1.933599</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>1.269231</td>\n",
       "      <td>0.818215</td>\n",
       "      <td>0.568578</td>\n",
       "      <td>0.054790</td>\n",
       "      <td>0.889332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.137681e+06</td>\n",
       "      <td>6.073799</td>\n",
       "      <td>3.917333</td>\n",
       "      <td>5.375914</td>\n",
       "      <td>2.891393</td>\n",
       "      <td>2.413658</td>\n",
       "      <td>1.778480</td>\n",
       "      <td>0.330389</td>\n",
       "      <td>3.855806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.274600e+04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.296285e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.808676e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.721404e+06</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.350807e+06</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>124.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              siape   revista_a1   revista_a2   revista_b1   revista_b2  \\\n",
       "count  2.756000e+03  2756.000000  2756.000000  2756.000000  2756.000000   \n",
       "mean   2.112227e+06     2.634978     1.933599     1.750000     1.269231   \n",
       "std    1.137681e+06     6.073799     3.917333     5.375914     2.891393   \n",
       "min    1.274600e+04     0.000000     0.000000     0.000000     0.000000   \n",
       "25%    1.296285e+06     0.000000     0.000000     0.000000     0.000000   \n",
       "50%    1.808676e+06     0.000000     0.000000     0.000000     0.000000   \n",
       "75%    2.721404e+06     3.000000     2.000000     2.000000     1.000000   \n",
       "max    9.350807e+06    71.000000    51.000000    99.000000    46.000000   \n",
       "\n",
       "        revista_b3   revista_b4   revista_b5    revista_c  \n",
       "count  2756.000000  2756.000000  2756.000000  2756.000000  \n",
       "mean      0.818215     0.568578     0.054790     0.889332  \n",
       "std       2.413658     1.778480     0.330389     3.855806  \n",
       "min       0.000000     0.000000     0.000000     0.000000  \n",
       "25%       0.000000     0.000000     0.000000     0.000000  \n",
       "50%       0.000000     0.000000     0.000000     0.000000  \n",
       "75%       1.000000     0.000000     0.000000     1.000000  \n",
       "max      41.000000    32.000000     8.000000   124.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# selecionar atributos que desejamos prever. o siape é incluso para unir as tabelas.\n",
    "\n",
    "qualis = [\"siape\", \"revista_a1\", \"revista_a2\", \"revista_b1\",\n",
    "          \"revista_b2\", \"revista_b3\", \"revista_b4\", \"revista_b5\", \"revista_c\"]\n",
    "\n",
    "ti_df_list = []\n",
    "for year in range(2010, 2021):\n",
    "    ti_df_y = pd.read_csv(\n",
    "        \"./indicadores/indicadores-pesquisa-\" + str(year) + \".csv\", sep=\";\")\n",
    "    ti_df_y = ti_df_y[qualis]\n",
    "    ti_df_list.append(ti_df_y)\n",
    "\n",
    "ti_df = pd.concat(ti_df_list)\n",
    "ti_df = ti_df.groupby(\"siape\", as_index=False).sum()\n",
    "ti_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fusão de Dados e Remoção da Coluna \"siape\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sexo</th>\n",
       "      <th>formacao</th>\n",
       "      <th>tipo_jornada_trabalho</th>\n",
       "      <th>vinculo</th>\n",
       "      <th>id_unidade_lotacao</th>\n",
       "      <th>lotacao</th>\n",
       "      <th>admissao</th>\n",
       "      <th>categoria</th>\n",
       "      <th>classe_funcional</th>\n",
       "      <th>revista_a1</th>\n",
       "      <th>revista_a2</th>\n",
       "      <th>revista_b1</th>\n",
       "      <th>revista_b2</th>\n",
       "      <th>revista_b3</th>\n",
       "      <th>revista_b4</th>\n",
       "      <th>revista_b5</th>\n",
       "      <th>revista_c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F</td>\n",
       "      <td>MESTRADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Ativo Permanente</td>\n",
       "      <td>1452</td>\n",
       "      <td>NÚCLEO DE EDUCAÇÃO DA INFÂNCIA</td>\n",
       "      <td>2006/07/24 00:00:00.000000000</td>\n",
       "      <td>PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO</td>\n",
       "      <td>DIV                                           ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>DOUTORADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Ativo Permanente</td>\n",
       "      <td>351</td>\n",
       "      <td>ESCOLA AGRÍCOLA DE JUNDIAÍ</td>\n",
       "      <td>2008/09/12 00:00:00.000000000</td>\n",
       "      <td>PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO</td>\n",
       "      <td>DV                                            ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "      <td>MESTRADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Ativo Permanente</td>\n",
       "      <td>284</td>\n",
       "      <td>ESCOLA DE MÚSICA</td>\n",
       "      <td>1998/04/28 00:00:00.000000000</td>\n",
       "      <td>PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO</td>\n",
       "      <td>DIV                                           ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>MESTRADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Ativo Permanente</td>\n",
       "      <td>351</td>\n",
       "      <td>ESCOLA AGRÍCOLA DE JUNDIAÍ</td>\n",
       "      <td>2017/01/25 00:00:00.000000000</td>\n",
       "      <td>PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO</td>\n",
       "      <td>DIII                                          ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F</td>\n",
       "      <td>DOUTORADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Ativo Permanente</td>\n",
       "      <td>351</td>\n",
       "      <td>ESCOLA AGRÍCOLA DE JUNDIAÍ</td>\n",
       "      <td>2009/10/13 00:00:00.000000000</td>\n",
       "      <td>PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO</td>\n",
       "      <td>DIV                                           ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2748</th>\n",
       "      <td>M</td>\n",
       "      <td>DOUTORADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Professor Visitante</td>\n",
       "      <td>1824</td>\n",
       "      <td>INSTITUTO DE POLÍTICAS PÚBLICAS</td>\n",
       "      <td>2023/05/23 00:00:00.000000000</td>\n",
       "      <td>PROFESSOR MAGISTERIO SUPERIOR - VISITANTE</td>\n",
       "      <td>Adjunto                                       ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2749</th>\n",
       "      <td>M</td>\n",
       "      <td>DOUTORADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Professor Visitante</td>\n",
       "      <td>4885</td>\n",
       "      <td>ESCOLA DE CIÊNCIAS E TECNOLOGIA</td>\n",
       "      <td>2022/08/12 00:00:00.000000000</td>\n",
       "      <td>PROFESSOR MAGISTERIO SUPERIOR - VISITANTE</td>\n",
       "      <td>Titular                                       ...</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2750</th>\n",
       "      <td>M</td>\n",
       "      <td>DOUTORADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Professor Visitante</td>\n",
       "      <td>179</td>\n",
       "      <td>DEPARTAMENTO DE BIOLOGIA CELULAR E GENÉTICA</td>\n",
       "      <td>2022/10/03 00:00:00.000000000</td>\n",
       "      <td>PROFESSOR MAGISTERIO SUPERIOR - VISITANTE</td>\n",
       "      <td>A                                             ...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2751</th>\n",
       "      <td>F</td>\n",
       "      <td>DOUTORADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Professor Visitante</td>\n",
       "      <td>6069</td>\n",
       "      <td>INSTITUTO METROPOLE DIGITAL</td>\n",
       "      <td>2023/02/15 00:00:00.000000000</td>\n",
       "      <td>PROFESSOR MAGISTERIO SUPERIOR - VISITANTE</td>\n",
       "      <td>A                                             ...</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2752</th>\n",
       "      <td>M</td>\n",
       "      <td>DOUTORADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Professor Visitante</td>\n",
       "      <td>4894</td>\n",
       "      <td>DEPARTAMENTO DE GEOFÍSICA</td>\n",
       "      <td>2022/09/06 00:00:00.000000000</td>\n",
       "      <td>PROFESSOR MAGISTERIO SUPERIOR - VISITANTE</td>\n",
       "      <td>Titular                                       ...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2753 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sexo   formacao           tipo_jornada_trabalho              vinculo  \\\n",
       "0       F   MESTRADO  Dedicação exclusiva                Ativo Permanente   \n",
       "1       M  DOUTORADO  Dedicação exclusiva                Ativo Permanente   \n",
       "2       M   MESTRADO  Dedicação exclusiva                Ativo Permanente   \n",
       "3       M   MESTRADO  Dedicação exclusiva                Ativo Permanente   \n",
       "4       F  DOUTORADO  Dedicação exclusiva                Ativo Permanente   \n",
       "...   ...        ...                             ...                  ...   \n",
       "2748    M  DOUTORADO  Dedicação exclusiva             Professor Visitante   \n",
       "2749    M  DOUTORADO  Dedicação exclusiva             Professor Visitante   \n",
       "2750    M  DOUTORADO  Dedicação exclusiva             Professor Visitante   \n",
       "2751    F  DOUTORADO  Dedicação exclusiva             Professor Visitante   \n",
       "2752    M  DOUTORADO  Dedicação exclusiva             Professor Visitante   \n",
       "\n",
       "      id_unidade_lotacao                                      lotacao  \\\n",
       "0                   1452               NÚCLEO DE EDUCAÇÃO DA INFÂNCIA   \n",
       "1                    351                   ESCOLA AGRÍCOLA DE JUNDIAÍ   \n",
       "2                    284                             ESCOLA DE MÚSICA   \n",
       "3                    351                   ESCOLA AGRÍCOLA DE JUNDIAÍ   \n",
       "4                    351                   ESCOLA AGRÍCOLA DE JUNDIAÍ   \n",
       "...                  ...                                          ...   \n",
       "2748                1824              INSTITUTO DE POLÍTICAS PÚBLICAS   \n",
       "2749                4885              ESCOLA DE CIÊNCIAS E TECNOLOGIA   \n",
       "2750                 179  DEPARTAMENTO DE BIOLOGIA CELULAR E GENÉTICA   \n",
       "2751                6069                  INSTITUTO METROPOLE DIGITAL   \n",
       "2752                4894                    DEPARTAMENTO DE GEOFÍSICA   \n",
       "\n",
       "                           admissao  \\\n",
       "0     2006/07/24 00:00:00.000000000   \n",
       "1     2008/09/12 00:00:00.000000000   \n",
       "2     1998/04/28 00:00:00.000000000   \n",
       "3     2017/01/25 00:00:00.000000000   \n",
       "4     2009/10/13 00:00:00.000000000   \n",
       "...                             ...   \n",
       "2748  2023/05/23 00:00:00.000000000   \n",
       "2749  2022/08/12 00:00:00.000000000   \n",
       "2750  2022/10/03 00:00:00.000000000   \n",
       "2751  2023/02/15 00:00:00.000000000   \n",
       "2752  2022/09/06 00:00:00.000000000   \n",
       "\n",
       "                                             categoria  \\\n",
       "0     PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO   \n",
       "1     PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO   \n",
       "2     PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO   \n",
       "3     PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO   \n",
       "4     PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO   \n",
       "...                                                ...   \n",
       "2748         PROFESSOR MAGISTERIO SUPERIOR - VISITANTE   \n",
       "2749         PROFESSOR MAGISTERIO SUPERIOR - VISITANTE   \n",
       "2750         PROFESSOR MAGISTERIO SUPERIOR - VISITANTE   \n",
       "2751         PROFESSOR MAGISTERIO SUPERIOR - VISITANTE   \n",
       "2752         PROFESSOR MAGISTERIO SUPERIOR - VISITANTE   \n",
       "\n",
       "                                       classe_funcional  revista_a1  \\\n",
       "0     DIV                                           ...           0   \n",
       "1     DV                                            ...           1   \n",
       "2     DIV                                           ...           0   \n",
       "3     DIII                                          ...           0   \n",
       "4     DIV                                           ...           0   \n",
       "...                                                 ...         ...   \n",
       "2748  Adjunto                                       ...           0   \n",
       "2749  Titular                                       ...           8   \n",
       "2750  A                                             ...           4   \n",
       "2751  A                                             ...          44   \n",
       "2752  Titular                                       ...           4   \n",
       "\n",
       "      revista_a2  revista_b1  revista_b2  revista_b3  revista_b4  revista_b5  \\\n",
       "0              0           0           0           0           0           0   \n",
       "1              1           5           0           0           4           0   \n",
       "2              0           0           0           0           0           0   \n",
       "3              0           0           0           0           0           0   \n",
       "4              0           0           1           0           0           0   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "2748           0           0           1           0           0           0   \n",
       "2749           4           7           0           2           0           0   \n",
       "2750           2           5           0           0           0           0   \n",
       "2751           1           0           0           0           0           0   \n",
       "2752           0           0           0           0           0           0   \n",
       "\n",
       "      revista_c  \n",
       "0             0  \n",
       "1             0  \n",
       "2             0  \n",
       "3             0  \n",
       "4             0  \n",
       "...         ...  \n",
       "2748          1  \n",
       "2749          0  \n",
       "2750          0  \n",
       "2751          0  \n",
       "2752          0  \n",
       "\n",
       "[2753 rows x 17 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unir ambas as tabelas e manter apenas as entradas que possuem siapes em comum\n",
    "\n",
    "df = tp_df.merge(ti_df, on=\"siape\", how=\"inner\")\n",
    "del df[\"siape\"]\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapeamento e Contagem dos Sexos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 1269\n",
      "1: 1484\n"
     ]
    }
   ],
   "source": [
    "sex_map = {\"F\": 0, \"M\": 1}\n",
    "df[\"sexo\"].replace(sex_map, inplace=True)\n",
    "\n",
    "for sexo in df[\"sexo\"].unique():\n",
    "    print(sexo, \": \", len(df[df[\"sexo\"] == sexo]), sep=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapeamento de unidade acadêmica para município"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lot_df = pd.read_csv(\"unidades/unidades.csv\", sep=\";\")\n",
    "\n",
    "lot_df = lot_df[[\"id_unidade\", \"municipio\"]]\n",
    "\n",
    "lot_df.loc[len(lot_df.index)] = [-1, \"DESCONHECIDO\"]\n",
    "\n",
    "\n",
    "lot_df.set_index(\"id_unidade\", inplace=True)\n",
    "lot_df\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    df.loc[index, \"id_unidade_lotacao\"] = lot_df.loc[row[\"id_unidade_lotacao\"] if row[\"id_unidade_lotacao\"] in lot_df.index else -1][\"municipio\"]\n",
    "\n",
    "df.rename(columns={\"id_unidade_lotacao\":\"municipio\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DEPARTAMENTO DE SAÚDE COLETIVA' 'PRÓ-REITORIA DE GRADUAÇÃO'\n",
      " 'DEPARTAMENTO DE ENGENHARIA DE COMUNICAÇÕES'\n",
      " 'DEPARTAMENTO DE ENGENHARIA MECANICA' 'DEPARTAMENTO DE ODONTOLOGIA'\n",
      " 'DEPARTAMENTO DE COMUNICAÇÃO SOCIAL' 'DEPARTAMENTO DE PSICOLOGIA'\n",
      " 'DEPARTAMENTO DE SERVIÇO SOCIAL - DESSO' 'DEPARTAMENTO DE ESTATISTICA'\n",
      " 'DEPARTAMENTO DE OCEANOGRAFIA E LIMNOLOGIA'\n",
      " 'SECRETARIA DE EDUCAÇÃO BÁSICA, TÉCNICA E TECNOLÓGICA DA UFRN'\n",
      " 'ADMINISTRAÇÃO DO CB']\n"
     ]
    }
   ],
   "source": [
    "temp_df = df[df['municipio'] == 'DESCONHECIDO']\n",
    "\n",
    "print(temp_df[\"lotacao\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Não há muitas lotações com municípios desconhecidos, portanto, iremos completar estas informações manualmente. Verificamos que todas as lotações com município desconhecido são de Natal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NATAL: 2295\n",
      "MACAÍBA: 121\n",
      "CAICÓ: 177\n",
      "SANTA CRUZ: 104\n",
      "CURRAIS NOVOS: 56\n"
     ]
    }
   ],
   "source": [
    "unknown_map = {\n",
    "    'DESCONHECIDO':'NATAL'\n",
    "}\n",
    "\n",
    "df['municipio'].replace(unknown_map, inplace=True)\n",
    "\n",
    "for municipio in df[\"municipio\"].unique():\n",
    "    print(municipio, \": \", len(df[df[\"municipio\"] == municipio]), sep=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cálculo dos Semestres na Universidade e Seleção de Colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sexo</th>\n",
       "      <th>formacao</th>\n",
       "      <th>tipo_jornada_trabalho</th>\n",
       "      <th>vinculo</th>\n",
       "      <th>categoria</th>\n",
       "      <th>classe_funcional</th>\n",
       "      <th>municipio</th>\n",
       "      <th>num_semestres</th>\n",
       "      <th>revista_a1</th>\n",
       "      <th>revista_a2</th>\n",
       "      <th>revista_b1</th>\n",
       "      <th>revista_b2</th>\n",
       "      <th>revista_b3</th>\n",
       "      <th>revista_b4</th>\n",
       "      <th>revista_c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>MESTRADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Ativo Permanente</td>\n",
       "      <td>PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO</td>\n",
       "      <td>DIV                                           ...</td>\n",
       "      <td>NATAL</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>DOUTORADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Ativo Permanente</td>\n",
       "      <td>PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO</td>\n",
       "      <td>DV                                            ...</td>\n",
       "      <td>MACAÍBA</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>MESTRADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Ativo Permanente</td>\n",
       "      <td>PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO</td>\n",
       "      <td>DIV                                           ...</td>\n",
       "      <td>NATAL</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>MESTRADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Ativo Permanente</td>\n",
       "      <td>PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO</td>\n",
       "      <td>DIII                                          ...</td>\n",
       "      <td>MACAÍBA</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>DOUTORADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Ativo Permanente</td>\n",
       "      <td>PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO</td>\n",
       "      <td>DIV                                           ...</td>\n",
       "      <td>MACAÍBA</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2748</th>\n",
       "      <td>1</td>\n",
       "      <td>DOUTORADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Professor Visitante</td>\n",
       "      <td>PROFESSOR MAGISTERIO SUPERIOR - VISITANTE</td>\n",
       "      <td>Adjunto                                       ...</td>\n",
       "      <td>NATAL</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2749</th>\n",
       "      <td>1</td>\n",
       "      <td>DOUTORADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Professor Visitante</td>\n",
       "      <td>PROFESSOR MAGISTERIO SUPERIOR - VISITANTE</td>\n",
       "      <td>Titular                                       ...</td>\n",
       "      <td>NATAL</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2750</th>\n",
       "      <td>1</td>\n",
       "      <td>DOUTORADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Professor Visitante</td>\n",
       "      <td>PROFESSOR MAGISTERIO SUPERIOR - VISITANTE</td>\n",
       "      <td>A                                             ...</td>\n",
       "      <td>NATAL</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2751</th>\n",
       "      <td>0</td>\n",
       "      <td>DOUTORADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Professor Visitante</td>\n",
       "      <td>PROFESSOR MAGISTERIO SUPERIOR - VISITANTE</td>\n",
       "      <td>A                                             ...</td>\n",
       "      <td>NATAL</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2752</th>\n",
       "      <td>1</td>\n",
       "      <td>DOUTORADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Professor Visitante</td>\n",
       "      <td>PROFESSOR MAGISTERIO SUPERIOR - VISITANTE</td>\n",
       "      <td>Titular                                       ...</td>\n",
       "      <td>NATAL</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2753 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sexo   formacao           tipo_jornada_trabalho              vinculo  \\\n",
       "0        0   MESTRADO  Dedicação exclusiva                Ativo Permanente   \n",
       "1        1  DOUTORADO  Dedicação exclusiva                Ativo Permanente   \n",
       "2        1   MESTRADO  Dedicação exclusiva                Ativo Permanente   \n",
       "3        1   MESTRADO  Dedicação exclusiva                Ativo Permanente   \n",
       "4        0  DOUTORADO  Dedicação exclusiva                Ativo Permanente   \n",
       "...    ...        ...                             ...                  ...   \n",
       "2748     1  DOUTORADO  Dedicação exclusiva             Professor Visitante   \n",
       "2749     1  DOUTORADO  Dedicação exclusiva             Professor Visitante   \n",
       "2750     1  DOUTORADO  Dedicação exclusiva             Professor Visitante   \n",
       "2751     0  DOUTORADO  Dedicação exclusiva             Professor Visitante   \n",
       "2752     1  DOUTORADO  Dedicação exclusiva             Professor Visitante   \n",
       "\n",
       "                                             categoria  \\\n",
       "0     PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO   \n",
       "1     PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO   \n",
       "2     PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO   \n",
       "3     PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO   \n",
       "4     PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO   \n",
       "...                                                ...   \n",
       "2748         PROFESSOR MAGISTERIO SUPERIOR - VISITANTE   \n",
       "2749         PROFESSOR MAGISTERIO SUPERIOR - VISITANTE   \n",
       "2750         PROFESSOR MAGISTERIO SUPERIOR - VISITANTE   \n",
       "2751         PROFESSOR MAGISTERIO SUPERIOR - VISITANTE   \n",
       "2752         PROFESSOR MAGISTERIO SUPERIOR - VISITANTE   \n",
       "\n",
       "                                       classe_funcional municipio  \\\n",
       "0     DIV                                           ...     NATAL   \n",
       "1     DV                                            ...   MACAÍBA   \n",
       "2     DIV                                           ...     NATAL   \n",
       "3     DIII                                          ...   MACAÍBA   \n",
       "4     DIV                                           ...   MACAÍBA   \n",
       "...                                                 ...       ...   \n",
       "2748  Adjunto                                       ...     NATAL   \n",
       "2749  Titular                                       ...     NATAL   \n",
       "2750  A                                             ...     NATAL   \n",
       "2751  A                                             ...     NATAL   \n",
       "2752  Titular                                       ...     NATAL   \n",
       "\n",
       "      num_semestres  revista_a1  revista_a2  revista_b1  revista_b2  \\\n",
       "0                34           0           0           0           0   \n",
       "1                30           1           1           5           0   \n",
       "2                51           0           0           0           0   \n",
       "3                13           0           0           0           0   \n",
       "4                28           0           0           0           1   \n",
       "...             ...         ...         ...         ...         ...   \n",
       "2748              1           0           0           0           1   \n",
       "2749              2           8           4           7           0   \n",
       "2750              2           4           2           5           0   \n",
       "2751              1          44           1           0           0   \n",
       "2752              2           4           0           0           0   \n",
       "\n",
       "      revista_b3  revista_b4  revista_c  \n",
       "0              0           0          0  \n",
       "1              0           4          0  \n",
       "2              0           0          0  \n",
       "3              0           0          0  \n",
       "4              0           0          0  \n",
       "...          ...         ...        ...  \n",
       "2748           0           0          1  \n",
       "2749           2           0          0  \n",
       "2750           0           0          0  \n",
       "2751           0           0          0  \n",
       "2752           0           0          0  \n",
       "\n",
       "[2753 rows x 15 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converter a data de admissao para quantos semestres o professor está na universidade.\n",
    "\n",
    "def num_semestres(data: str, data_atual: str):\n",
    "    data = data[:10]\n",
    "    anos = int(data_atual[6:]) - int(data[:4])\n",
    "    if int(data_atual[3:5]) < 7 and int(data[5:7]) < 7 or int(data_atual[3:5]) >= 7 and int(data[5:7]) >= 7:\n",
    "        return 2*anos\n",
    "    elif int(data_atual[3:5]) < 7 and int(data[5:7]) > 7:\n",
    "        return 2*anos - 1\n",
    "    else:\n",
    "        return 2*anos + 1\n",
    "\n",
    "data_atual = \"18/10/2023\"\n",
    "\n",
    "df['num_semestres'] = df['admissao'].apply(lambda x: num_semestres(x, data_atual))\n",
    "df = df[[\"sexo\", \"formacao\", \"tipo_jornada_trabalho\", \"vinculo\", \"categoria\",\"classe_funcional\", \"municipio\", \"num_semestres\", \"revista_a1\",\n",
    "         \"revista_a2\", \"revista_b1\", \"revista_b2\", \"revista_b3\", \"revista_b4\", \"revista_c\"]]\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tipos de Dados das Colunas do DataFrame Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sexo                      int64\n",
       "formacao                 object\n",
       "tipo_jornada_trabalho    object\n",
       "vinculo                  object\n",
       "categoria                object\n",
       "classe_funcional         object\n",
       "municipio                object\n",
       "num_semestres             int64\n",
       "revista_a1                int64\n",
       "revista_a2                int64\n",
       "revista_b1                int64\n",
       "revista_b2                int64\n",
       "revista_b3                int64\n",
       "revista_b4                int64\n",
       "revista_c                 int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise de Dados no DataFrame Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "existem 2753 entradas diferentes;\n",
      "existem 6 formacoes diferentes;\n",
      "existem 3 tipos de jornada de trabalho diferentes;\n",
      "existem 8 tipos de vinculo diferentes;\n",
      "existem 18 classes funcionais diferentes;\n",
      "existem 7 categorias diferentes;\n",
      "existem 89 datas de admissao diferentes;\n",
      "existem 5 municipios diferentes;\n"
     ]
    }
   ],
   "source": [
    "print(\"existem\", len(df), \"entradas diferentes;\")\n",
    "print(\"existem\", len(df[\"formacao\"].unique()), \"formacoes diferentes;\")\n",
    "print(\"existem\", len(df[\"tipo_jornada_trabalho\"].unique()),\n",
    "      \"tipos de jornada de trabalho diferentes;\")\n",
    "print(\"existem\", len(df[\"vinculo\"].unique()), \"tipos de vinculo diferentes;\")\n",
    "print(\"existem\", len(df[\"classe_funcional\"].unique()),\"classes funcionais diferentes;\")\n",
    "print(\"existem\", len(df[\"categoria\"].unique()),\"categorias diferentes;\")\n",
    "# print(\"existem\", len(df[\"lotacao\"].unique()), \"lotacoes diferentes;\")\n",
    "print(\"existem\", len(df[\"num_semestres\"].unique()),\"datas de admissao diferentes;\")\n",
    "print(\"existem\", len(df[\"municipio\"].unique()),\"municipios diferentes;\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contagem de Professores por Formação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MESTRADO: 431\n",
      "DOUTORADO: 2189\n",
      "ESPECIALIZAÇÃO: 120\n",
      "GRADUAÇÃO: 11\n",
      "PÓS-DOUTORADO: 1\n",
      "DESCONHECIDA: 1\n"
     ]
    }
   ],
   "source": [
    "for formacao in df[\"formacao\"].unique():\n",
    "    print(formacao, \": \", len(df[df[\"formacao\"] == formacao]), sep=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remoção de Professores com Formação Desconhecida e Contagem por Formação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MESTRADO: 431\n",
      "DOUTORADO: 2189\n",
      "ESPECIALIZAÇÃO: 120\n",
      "GRADUAÇÃO: 11\n",
      "PÓS-DOUTORADO: 1\n"
     ]
    }
   ],
   "source": [
    "# retirar professores de formação desconhecida.\n",
    "\n",
    "df = df[df[\"formacao\"] != \"DESCONHECIDA\"]\n",
    "for formacao in df[\"formacao\"].unique():\n",
    "    print(formacao, \": \", len(df[df[\"formacao\"] == formacao]), sep=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classificação por Nível de Formação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3: 431\n",
      "4: 2189\n",
      "2: 120\n",
      "1: 11\n",
      "5: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lucas\\AppData\\Local\\Temp\\ipykernel_12856\\852662980.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"formacao\"].replace(nivel_formacao, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# colocar uma ordem de classificacao. pos-doc > doc > mestrado > esp > grad\n",
    "\n",
    "nivel_formacao = {\"GRADUAÇÃO\":1, \"ESPECIALIZAÇÃO\":2, \"MESTRADO\":3,\"DOUTORADO\":4,\"PÓS-DOUTORADO\":5}\n",
    "\n",
    "df[\"formacao\"].replace(nivel_formacao, inplace=True)\n",
    "for formacao in df[\"formacao\"].unique():\n",
    "    print(formacao, \": \", len(df[df[\"formacao\"] == formacao]), sep=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contagem de Professores por Tipo de Jornada de Trabalho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dedicação exclusiva           : 2155\n",
      "20 horas semanais             : 307\n",
      "40 horas semanais             : 290\n"
     ]
    }
   ],
   "source": [
    "for tipo_jornada_trabalho in df[\"tipo_jornada_trabalho\"].unique():\n",
    "    print(tipo_jornada_trabalho, \": \", len(\n",
    "        df[df[\"tipo_jornada_trabalho\"] == tipo_jornada_trabalho]), sep=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contagem de Professores por Tipo de Vínculo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ativo Permanente: 2376\n",
      "Celetista: 1\n",
      "Colaborador PCCTAE e Magistério Federal: 2\n",
      "Excedente de lotação: 3\n",
      "Exercicio provisorio: 18\n",
      "Professor Substituto: 260\n",
      "Professor Temporario: 50\n",
      "Professor Visitante: 42\n"
     ]
    }
   ],
   "source": [
    "for vinculo in df[\"vinculo\"].unique():\n",
    "    print(vinculo, \": \", len(df[df[\"vinculo\"] == vinculo]), sep=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remoção de Vínculos com Poucas Entradas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ativo Permanente: 2376\n",
      "Exercicio provisorio: 18\n",
      "Professor Substituto: 260\n",
      "Professor Temporario: 50\n",
      "Professor Visitante: 42\n"
     ]
    }
   ],
   "source": [
    "# há poucas pessoas com esses atributos:\n",
    "\n",
    "df = df[df[\"vinculo\"] != \"Celetista\"]\n",
    "df = df[df[\"vinculo\"] != \"Colaborador PCCTAE e Magistério Federal\"]\n",
    "df = df[df[\"vinculo\"] != \"Excedente de lotação\"]\n",
    "for vinculo in df[\"vinculo\"].unique():\n",
    "    print(vinculo, \": \", len(df[df[\"vinculo\"] == vinculo]), sep=\"\")\n",
    "\n",
    "# então decidi retirá-los"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contagem de Professores por Categoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO: 215\n",
      "PROFESSOR DO MAGISTERIO SUPERIOR: 2178\n",
      "PROFESSOR 3 GRAU                        : 1\n",
      "PROF ENS BAS TEC TECNOLOGICO-SUBSTITUTO: 29\n",
      "PROFESSOR DO MAGISTERIO SUPERIOR - SUBSTITUTO: 231\n",
      "PROFESSOR DO MAGISTERIO SUPERIOR - TEMPORARIO: 50\n",
      "PROFESSOR MAGISTERIO SUPERIOR - VISITANTE: 42\n"
     ]
    }
   ],
   "source": [
    "for categoria in df[\"categoria\"].unique():\n",
    "    print(categoria, \": \", len(df[df[\"categoria\"] == categoria]), sep=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veja que a informação de \"SUBSTITUTO\", \"TEMPORARIO\" e \"VISITANTE\" já está informada na coluna \"vínculo\". Então, irei retirá-la dos dados, assim como o único professor de terceiro grau."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Atualização e Simplificação de Categorias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO: 244\n",
      "PROFESSOR DO MAGISTERIO SUPERIOR: 2501\n"
     ]
    }
   ],
   "source": [
    "retirar_vinculo = {\"PROF ENS BAS TEC TECNOLOGICO-SUBSTITUTO\":\"PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO\",\n",
    "                   \"PROFESSOR DO MAGISTERIO SUPERIOR - SUBSTITUTO\":\"PROFESSOR DO MAGISTERIO SUPERIOR\",\n",
    "                   \"PROFESSOR DO MAGISTERIO SUPERIOR - TEMPORARIO\":\"PROFESSOR DO MAGISTERIO SUPERIOR\",\n",
    "                   \"PROFESSOR MAGISTERIO SUPERIOR - VISITANTE\":\"PROFESSOR DO MAGISTERIO SUPERIOR\"}\n",
    "\n",
    "df = df[df[\"categoria\"] != \"PROFESSOR 3 GRAU                        \"]\n",
    "\n",
    "df[\"categoria\"].replace(retirar_vinculo, inplace=True)\n",
    "\n",
    "for categoria in df[\"categoria\"].unique():\n",
    "    print(categoria, \": \", len(df[df[\"categoria\"] == categoria]), sep=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verifique que a soma de elementos de uma mesma categoria se manteve. Agora, iremos ranquear os professores com base em sua classe funcional:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classificação de Professores por Classe Funcional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DIV                                                                                                 : 75\n",
      "DV                                                                                                  : 32\n",
      "DIII                                                                                                : 78\n",
      "DI                                                                                                  : 47\n",
      "D                                                                                                   : 7\n",
      "DII                                                                                                 : 4\n",
      "Classe A - Adjunto A                                                                                : 141\n",
      "Classe C - Adjunto                                                                                  : 757\n",
      "Classe A - Auxiliar                                                                                 : 46\n",
      "Classe E - Titular                                                                                  : 307\n",
      "Classe D - Associado                                                                                : 834\n",
      "Classe B - Assistente                                                                               : 59\n",
      "Classe A - Assistente A                                                                             : 22\n",
      "Não Informada                                                                                       : 16\n",
      "Auxiliar                                                                                            : 278\n",
      "A                                                                                                   : 20\n",
      "Titular                                                                                             : 13\n",
      "Adjunto                                                                                             : 9\n"
     ]
    }
   ],
   "source": [
    "for classe_funcional in df[\"classe_funcional\"].unique():\n",
    "    print(classe_funcional, \": \", len(df[df[\"classe_funcional\"] == classe_funcional]), sep=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver, há 17 professores com classes não-informadas, e algmas estão repetidas e com outros nomes. Ainda, há 20 professores de classe A sem uma subclasse. O mapeamento, segundo a [PROGESP](https://progesp.ufrn.br/secao/carreira), se dá da seguinte maneira:\n",
    "\n",
    "| Original | Mapeamento |\n",
    "|-|-|\n",
    "|DV|1|\n",
    "|DIV|2|\n",
    "|DIII|3|\n",
    "|DII|4|\n",
    "|DI|5|\n",
    "|Classe E - Titular<br>Titular|6|\n",
    "|Classe D - Associado<br>D|7|\n",
    "|Classe C - Adjunto<br>Adjunto|8|\n",
    "|Classe B - Assistente|9|\n",
    "|Classe A - Auxiliar<br>Auxiliar|10|\n",
    "|Classe A - Assistente A<br>A|11|\n",
    "|Classe A - Adjunto A|12|\n",
    "\n",
    "É importante notar também que iremos retirar professores sem categoria. E professores classe A sem denominação específica serão tratados como Assistentes, pois têm o valor médio da classe A."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapeamento e Classificação das Classes Funcionais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapear_class_func = {\n",
    "    \"DV                                                                                                  \":1,\n",
    "    \"DIV                                                                                                 \":2,\n",
    "    \"DIII                                                                                                \":3,\n",
    "    \"DII                                                                                                 \":4,\n",
    "    \"DI                                                                                                  \":5,\n",
    "    \"Classe E - Titular                                                                                  \":6,\n",
    "    \"Titular                                                                                             \":6,\n",
    "    \"Classe D - Associado                                                                                \":7,\n",
    "    \"D                                                                                                   \":7,\n",
    "    \"Classe C - Adjunto                                                                                  \":8,\n",
    "    \"Adjunto                                                                                             \":8,\n",
    "    \"Classe B - Assistente                                                                               \":9,\n",
    "    \"Classe A - Auxiliar                                                                                 \":10,\n",
    "    \"Auxiliar                                                                                            \":10,\n",
    "    \"Classe A - Assistente A                                                                             \":11,\n",
    "    \"A                                                                                                   \":11,\n",
    "    \"Classe A - Adjunto A                                                                                \":12,\n",
    "}\n",
    "\n",
    "df = df[df[\"classe_funcional\"] != \"Não Informada                                                                                       \"]\n",
    "\n",
    "df[\"classe_funcional\"].replace(mapear_class_func, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contagem de Professores por Classe Funcional Após Classificação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2: 75\n",
      "1: 32\n",
      "3: 78\n",
      "5: 47\n",
      "7: 841\n",
      "4: 4\n",
      "12: 141\n",
      "8: 766\n",
      "10: 324\n",
      "6: 320\n",
      "9: 59\n",
      "11: 42\n"
     ]
    }
   ],
   "source": [
    "for classe_funcional in df[\"classe_funcional\"].unique():\n",
    "    print(classe_funcional, \": \", len(df[df[\"classe_funcional\"] == classe_funcional]), sep=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reset do Índice e Resumo Estatístico do DataFrame Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sexo</th>\n",
       "      <th>formacao</th>\n",
       "      <th>classe_funcional</th>\n",
       "      <th>num_semestres</th>\n",
       "      <th>revista_a1</th>\n",
       "      <th>revista_a2</th>\n",
       "      <th>revista_b1</th>\n",
       "      <th>revista_b2</th>\n",
       "      <th>revista_b3</th>\n",
       "      <th>revista_b4</th>\n",
       "      <th>revista_c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2729.000000</td>\n",
       "      <td>2729.000000</td>\n",
       "      <td>2729.000000</td>\n",
       "      <td>2729.000000</td>\n",
       "      <td>2729.000000</td>\n",
       "      <td>2729.000000</td>\n",
       "      <td>2729.000000</td>\n",
       "      <td>2729.000000</td>\n",
       "      <td>2729.000000</td>\n",
       "      <td>2729.000000</td>\n",
       "      <td>2729.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.540857</td>\n",
       "      <td>3.744229</td>\n",
       "      <td>7.521803</td>\n",
       "      <td>25.477831</td>\n",
       "      <td>2.646757</td>\n",
       "      <td>1.939538</td>\n",
       "      <td>1.755955</td>\n",
       "      <td>1.270429</td>\n",
       "      <td>0.814584</td>\n",
       "      <td>0.569073</td>\n",
       "      <td>0.890070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.498419</td>\n",
       "      <td>0.548749</td>\n",
       "      <td>2.113959</td>\n",
       "      <td>20.856943</td>\n",
       "      <td>6.095930</td>\n",
       "      <td>3.929876</td>\n",
       "      <td>5.398132</td>\n",
       "      <td>2.900249</td>\n",
       "      <td>2.394411</td>\n",
       "      <td>1.780601</td>\n",
       "      <td>3.868675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>124.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              sexo     formacao  classe_funcional  num_semestres   revista_a1  \\\n",
       "count  2729.000000  2729.000000       2729.000000    2729.000000  2729.000000   \n",
       "mean      0.540857     3.744229          7.521803      25.477831     2.646757   \n",
       "std       0.498419     0.548749          2.113959      20.856943     6.095930   \n",
       "min       0.000000     1.000000          1.000000       0.000000     0.000000   \n",
       "25%       0.000000     4.000000          7.000000      10.000000     0.000000   \n",
       "50%       1.000000     4.000000          7.000000      24.000000     0.000000   \n",
       "75%       1.000000     4.000000          8.000000      30.000000     3.000000   \n",
       "max       1.000000     5.000000         12.000000      97.000000    71.000000   \n",
       "\n",
       "        revista_a2   revista_b1   revista_b2   revista_b3   revista_b4  \\\n",
       "count  2729.000000  2729.000000  2729.000000  2729.000000  2729.000000   \n",
       "mean      1.939538     1.755955     1.270429     0.814584     0.569073   \n",
       "std       3.929876     5.398132     2.900249     2.394411     1.780601   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       2.000000     2.000000     1.000000     1.000000     0.000000   \n",
       "max      51.000000    99.000000    46.000000    41.000000    32.000000   \n",
       "\n",
       "         revista_c  \n",
       "count  2729.000000  \n",
       "mean      0.890070  \n",
       "std       3.868675  \n",
       "min       0.000000  \n",
       "25%       0.000000  \n",
       "50%       0.000000  \n",
       "75%       1.000000  \n",
       "max     124.000000  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.reset_index(drop=True, inplace=True)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resumo Estatístico das Colunas de Texto no DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tipo_jornada_trabalho</th>\n",
       "      <th>vinculo</th>\n",
       "      <th>categoria</th>\n",
       "      <th>municipio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2729</td>\n",
       "      <td>2729</td>\n",
       "      <td>2729</td>\n",
       "      <td>2729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Ativo Permanente</td>\n",
       "      <td>PROFESSOR DO MAGISTERIO SUPERIOR</td>\n",
       "      <td>NATAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>2133</td>\n",
       "      <td>2376</td>\n",
       "      <td>2486</td>\n",
       "      <td>2274</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 tipo_jornada_trabalho           vinculo  \\\n",
       "count                             2729              2729   \n",
       "unique                               3                 5   \n",
       "top     Dedicação exclusiva             Ativo Permanente   \n",
       "freq                              2133              2376   \n",
       "\n",
       "                               categoria municipio  \n",
       "count                               2729      2729  \n",
       "unique                                 2         5  \n",
       "top     PROFESSOR DO MAGISTERIO SUPERIOR     NATAL  \n",
       "freq                                2486      2274  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include=\"object\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparação dos Dados para Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep = ['revista_a1',\n",
    "        'revista_a2',\n",
    "        'revista_b1',\n",
    "        'revista_b2',\n",
    "        'revista_b3',\n",
    "        'revista_b4',\n",
    "        'revista_c']\n",
    "\n",
    "X = df.drop(keep, axis=1).copy()\n",
    "\n",
    "[ya1,\n",
    " ya2,\n",
    " yb1,\n",
    " yb2,\n",
    " yb3,\n",
    " yb4,\n",
    " yc] = [df[col].copy() for col in keep]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Codificação de Variáveis Categóricas em Dados Numéricos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sexo</th>\n",
       "      <th>formacao</th>\n",
       "      <th>classe_funcional</th>\n",
       "      <th>num_semestres</th>\n",
       "      <th>tipo_jornada_trabalho_20 horas semanais</th>\n",
       "      <th>tipo_jornada_trabalho_40 horas semanais</th>\n",
       "      <th>tipo_jornada_trabalho_Dedicação exclusiva</th>\n",
       "      <th>vinculo_Ativo Permanente</th>\n",
       "      <th>vinculo_Exercicio provisorio</th>\n",
       "      <th>vinculo_Professor Substituto</th>\n",
       "      <th>vinculo_Professor Temporario</th>\n",
       "      <th>vinculo_Professor Visitante</th>\n",
       "      <th>categoria_PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO</th>\n",
       "      <th>categoria_PROFESSOR DO MAGISTERIO SUPERIOR</th>\n",
       "      <th>municipio_CAICÓ</th>\n",
       "      <th>municipio_CURRAIS NOVOS</th>\n",
       "      <th>municipio_MACAÍBA</th>\n",
       "      <th>municipio_NATAL</th>\n",
       "      <th>municipio_SANTA CRUZ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>51</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2724</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2725</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2726</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2727</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2728</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2729 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sexo  formacao  classe_funcional  num_semestres  \\\n",
       "0        0         3                 2             34   \n",
       "1        1         4                 1             30   \n",
       "2        1         3                 2             51   \n",
       "3        1         3                 3             13   \n",
       "4        0         4                 2             28   \n",
       "...    ...       ...               ...            ...   \n",
       "2724     1         4                 8              1   \n",
       "2725     1         4                 6              2   \n",
       "2726     1         4                11              2   \n",
       "2727     0         4                11              1   \n",
       "2728     1         4                 6              2   \n",
       "\n",
       "      tipo_jornada_trabalho_20 horas semanais               \\\n",
       "0                                                 False      \n",
       "1                                                 False      \n",
       "2                                                 False      \n",
       "3                                                 False      \n",
       "4                                                 False      \n",
       "...                                                 ...      \n",
       "2724                                              False      \n",
       "2725                                              False      \n",
       "2726                                              False      \n",
       "2727                                              False      \n",
       "2728                                              False      \n",
       "\n",
       "      tipo_jornada_trabalho_40 horas semanais               \\\n",
       "0                                                 False      \n",
       "1                                                 False      \n",
       "2                                                 False      \n",
       "3                                                 False      \n",
       "4                                                 False      \n",
       "...                                                 ...      \n",
       "2724                                              False      \n",
       "2725                                              False      \n",
       "2726                                              False      \n",
       "2727                                              False      \n",
       "2728                                              False      \n",
       "\n",
       "      tipo_jornada_trabalho_Dedicação exclusiva             \\\n",
       "0                                                  True      \n",
       "1                                                  True      \n",
       "2                                                  True      \n",
       "3                                                  True      \n",
       "4                                                  True      \n",
       "...                                                 ...      \n",
       "2724                                               True      \n",
       "2725                                               True      \n",
       "2726                                               True      \n",
       "2727                                               True      \n",
       "2728                                               True      \n",
       "\n",
       "      vinculo_Ativo Permanente  vinculo_Exercicio provisorio  \\\n",
       "0                         True                         False   \n",
       "1                         True                         False   \n",
       "2                         True                         False   \n",
       "3                         True                         False   \n",
       "4                         True                         False   \n",
       "...                        ...                           ...   \n",
       "2724                     False                         False   \n",
       "2725                     False                         False   \n",
       "2726                     False                         False   \n",
       "2727                     False                         False   \n",
       "2728                     False                         False   \n",
       "\n",
       "      vinculo_Professor Substituto  vinculo_Professor Temporario  \\\n",
       "0                            False                         False   \n",
       "1                            False                         False   \n",
       "2                            False                         False   \n",
       "3                            False                         False   \n",
       "4                            False                         False   \n",
       "...                            ...                           ...   \n",
       "2724                         False                         False   \n",
       "2725                         False                         False   \n",
       "2726                         False                         False   \n",
       "2727                         False                         False   \n",
       "2728                         False                         False   \n",
       "\n",
       "      vinculo_Professor Visitante  \\\n",
       "0                           False   \n",
       "1                           False   \n",
       "2                           False   \n",
       "3                           False   \n",
       "4                           False   \n",
       "...                           ...   \n",
       "2724                         True   \n",
       "2725                         True   \n",
       "2726                         True   \n",
       "2727                         True   \n",
       "2728                         True   \n",
       "\n",
       "      categoria_PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO  \\\n",
       "0                                                  True            \n",
       "1                                                  True            \n",
       "2                                                  True            \n",
       "3                                                  True            \n",
       "4                                                  True            \n",
       "...                                                 ...            \n",
       "2724                                              False            \n",
       "2725                                              False            \n",
       "2726                                              False            \n",
       "2727                                              False            \n",
       "2728                                              False            \n",
       "\n",
       "      categoria_PROFESSOR DO MAGISTERIO SUPERIOR  municipio_CAICÓ  \\\n",
       "0                                          False            False   \n",
       "1                                          False            False   \n",
       "2                                          False            False   \n",
       "3                                          False            False   \n",
       "4                                          False            False   \n",
       "...                                          ...              ...   \n",
       "2724                                        True            False   \n",
       "2725                                        True            False   \n",
       "2726                                        True            False   \n",
       "2727                                        True            False   \n",
       "2728                                        True            False   \n",
       "\n",
       "      municipio_CURRAIS NOVOS  municipio_MACAÍBA  municipio_NATAL  \\\n",
       "0                       False              False             True   \n",
       "1                       False               True            False   \n",
       "2                       False              False             True   \n",
       "3                       False               True            False   \n",
       "4                       False               True            False   \n",
       "...                       ...                ...              ...   \n",
       "2724                    False              False             True   \n",
       "2725                    False              False             True   \n",
       "2726                    False              False             True   \n",
       "2727                    False              False             True   \n",
       "2728                    False              False             True   \n",
       "\n",
       "      municipio_SANTA CRUZ  \n",
       "0                    False  \n",
       "1                    False  \n",
       "2                    False  \n",
       "3                    False  \n",
       "4                    False  \n",
       "...                    ...  \n",
       "2724                 False  \n",
       "2725                 False  \n",
       "2726                 False  \n",
       "2727                 False  \n",
       "2728                 False  \n",
       "\n",
       "[2729 rows x 19 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_encoded = pd.get_dummies(X, columns=[\"tipo_jornada_trabalho\",\n",
    "                                       \"vinculo\",\n",
    "                                       \"categoria\",\n",
    "                                       \"municipio\"])\n",
    "\n",
    "X_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cálculo das Médias das Taxas por Categoria de Revista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ya1': 2.646757053865885,\n",
       " 'ya2': 1.939538292414804,\n",
       " 'yb1': 1.7559545621106631,\n",
       " 'yb2': 1.2704287284719677,\n",
       " 'yb3': 0.8145840967387321,\n",
       " 'yb4': 0.5690729204836936,\n",
       " 'yc': 0.8900696225723709}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\"ya1\": (sum(ya1) / len(ya1)),\n",
    " \"ya2\": (sum(ya2) / len(ya2)),\n",
    " \"yb1\": (sum(yb1) / len(yb1)),\n",
    " \"yb2\": (sum(yb2) / len(yb2)),\n",
    " \"yb3\": (sum(yb3) / len(yb3)),\n",
    " \"yb4\": (sum(yb4) / len(yb4)),\n",
    " \"yc\": (sum(yc) / len(yc))}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparação dos Conjuntos de Treinamento e Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_vars = [(ya1, \"ya1\"),\n",
    "               (ya2, \"ya2\"),\n",
    "               (yb1, \"yb1\"),\n",
    "               (yb2, \"yb2\"),\n",
    "               (yb3, \"yb3\"),\n",
    "               (yb4, \"yb4\"),\n",
    "               (yc, \"yc\")]\n",
    "\n",
    "train_test_sets = {}\n",
    "\n",
    "for var, var_name in target_vars:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_encoded, var, random_state=42)\n",
    "    train_test_sets[var_name] = (X_train, X_test, y_train, y_test)\n",
    "\n",
    "# Agora, você pode acessar os conjuntos de treinamento e teste usando o nome da variável alvo desejada\n",
    "X_train_ya1, X_test_ya1, ya1_train, ya1_test = train_test_sets[\"ya1\"]\n",
    "X_train_ya2, X_test_ya2, ya2_train, ya2_test = train_test_sets[\"ya2\"]\n",
    "X_train_yb1, X_test_yb1, yb1_train, yb1_test = train_test_sets[\"yb1\"]\n",
    "X_train_yb2, X_test_yb2, yb2_train, yb2_test = train_test_sets[\"yb2\"]\n",
    "X_train_yb3, X_test_yb3, yb3_train, yb3_test = train_test_sets[\"yb3\"]\n",
    "X_train_yb4, X_test_yb4, yb4_train, yb4_test = train_test_sets[\"yb4\"]\n",
    "X_train_yc, X_test_yc, yc_train, yc_test = train_test_sets[\"yc\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Médias das Taxas nas Partições de Treinamento e Teste por Categoria de Revista (TRAIN & TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ya1': (2.639784946236559, 2.6676427525622253),\n",
       " 'ya2': (1.9472140762463344, 1.916544655929722),\n",
       " 'yb1': (1.6715542521994136, 2.0087847730600292),\n",
       " 'yb2': (1.1901270772238515, 1.5109809663250366),\n",
       " 'yb3': (0.8093841642228738, 0.8301610541727672),\n",
       " 'yb4': (0.5650048875855328, 0.5812591508052709),\n",
       " 'yc': (0.9496578690127078, 0.7115666178623719)}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test_pairs = {\n",
    "    \"ya1\": (sum(ya1_train) / len(ya1_train), sum(ya1_test) / len(ya1_test)),\n",
    "    \"ya2\": (sum(ya2_train) / len(ya2_train), sum(ya2_test) / len(ya2_test)),\n",
    "    \"yb1\": (sum(yb1_train) / len(yb1_train), sum(yb1_test) / len(yb1_test)),\n",
    "    \"yb2\": (sum(yb2_train) / len(yb2_train), sum(yb2_test) / len(yb2_test)),\n",
    "    \"yb3\": (sum(yb3_train) / len(yb3_train), sum(yb3_test) / len(yb3_test)),\n",
    "    \"yb4\": (sum(yb4_train) / len(yb4_train), sum(yb4_test) / len(yb4_test)),\n",
    "    \"yc\" : (sum(yc_train) / len(yc_train), sum(yc_test) / len(yc_test))\n",
    "}\n",
    "\n",
    "train_test_pairs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Espaço de Parâmetros para Otimização do Modelo XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_space = {\n",
    "    \"max_depth\": Integer(1,20),\n",
    "    \"n_estimators\": Integer(10,1000),\n",
    "    \"reg_lambda\": Real(0, 10),\n",
    "    \"eta\": Real(0.01, 1),\n",
    "    \"gamma\": Real(0,7)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinamento e Otimização do Modelo XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo XGBoost para \"ya1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BayesSearchCV(cv=5,\n",
       "              estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "              search_spaces={&#x27;eta&#x27;: Real(low=0.01, high=1, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;gamma&#x27;: Real(low=0, high=7, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;max_depth&#x27;: Integer(low=1, high=20, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;n_estimators&#x27;: Integer(low=10, high=1000, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;reg_lambda&#x27;: Real(low=0, high=10, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;)},\n",
       "              verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BayesSearchCV</label><div class=\"sk-toggleable__content\"><pre>BayesSearchCV(cv=5,\n",
       "              estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "              search_spaces={&#x27;eta&#x27;: Real(low=0.01, high=1, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;gamma&#x27;: Real(low=0, high=7, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;max_depth&#x27;: Integer(low=1, high=20, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;n_estimators&#x27;: Integer(low=10, high=1000, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;reg_lambda&#x27;: Real(low=0, high=10, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;)},\n",
       "              verbose=True)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "BayesSearchCV(cv=5,\n",
       "              estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "              search_spaces={'eta': Real(low=0.01, high=1, prior='uniform', transform='normalize'),\n",
       "                             'gamma': Real(low=0, high=7, prior='uniform', transform='normalize'),\n",
       "                             'max_depth': Integer(low=1, high=20, prior='uniform', transform='normalize'),\n",
       "                             'n_estimators': Integer(low=10, high=1000, prior='uniform', transform='normalize'),\n",
       "                             'reg_lambda': Real(low=0, high=10, prior='uniform', transform='normalize')},\n",
       "              verbose=True)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrn.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "reg_xgb_ya1 = xgb.XGBRegressor()\n",
    "\n",
    "xgb_bayes_ya1 = BayesSearchCV(reg_xgb_ya1,\n",
    "                              param_space,\n",
    "                              n_iter=32,\n",
    "                              scoring=\"neg_root_mean_squared_error\",\n",
    "                              verbose=True,\n",
    "                              cv=5,\n",
    "                              n_jobs=8,\n",
    "                              random_state=42)\n",
    "\n",
    "xgb_bayes_ya1.fit(X_train_ya1, ya1_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo XGBoost para \"ya2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BayesSearchCV(cv=5,\n",
       "              estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "              search_spaces={&#x27;eta&#x27;: Real(low=0.01, high=1, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;gamma&#x27;: Real(low=0, high=7, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;max_depth&#x27;: Integer(low=1, high=20, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;n_estimators&#x27;: Integer(low=10, high=1000, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;reg_lambda&#x27;: Real(low=0, high=10, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;)},\n",
       "              verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BayesSearchCV</label><div class=\"sk-toggleable__content\"><pre>BayesSearchCV(cv=5,\n",
       "              estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "              search_spaces={&#x27;eta&#x27;: Real(low=0.01, high=1, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;gamma&#x27;: Real(low=0, high=7, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;max_depth&#x27;: Integer(low=1, high=20, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;n_estimators&#x27;: Integer(low=10, high=1000, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;reg_lambda&#x27;: Real(low=0, high=10, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;)},\n",
       "              verbose=True)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "BayesSearchCV(cv=5,\n",
       "              estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "              search_spaces={'eta': Real(low=0.01, high=1, prior='uniform', transform='normalize'),\n",
       "                             'gamma': Real(low=0, high=7, prior='uniform', transform='normalize'),\n",
       "                             'max_depth': Integer(low=1, high=20, prior='uniform', transform='normalize'),\n",
       "                             'n_estimators': Integer(low=10, high=1000, prior='uniform', transform='normalize'),\n",
       "                             'reg_lambda': Real(low=0, high=10, prior='uniform', transform='normalize')},\n",
       "              verbose=True)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrn.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "reg_xgb_ya2 = xgb.XGBRegressor()\n",
    "\n",
    "xgb_bayes_ya2 = BayesSearchCV(reg_xgb_ya2,\n",
    "                              param_space,\n",
    "                              n_iter=32,\n",
    "                              scoring=\"neg_root_mean_squared_error\",\n",
    "                              verbose=True,\n",
    "                              cv=5,\n",
    "                              n_jobs=8,\n",
    "                              random_state=42)\n",
    "\n",
    "xgb_bayes_ya2.fit(X_train_ya2, ya2_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo XGBoost para \"yb1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BayesSearchCV(cv=5,\n",
       "              estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "              search_spaces={&#x27;eta&#x27;: Real(low=0.01, high=1, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;gamma&#x27;: Real(low=0, high=7, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;max_depth&#x27;: Integer(low=1, high=20, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;n_estimators&#x27;: Integer(low=10, high=1000, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;reg_lambda&#x27;: Real(low=0, high=10, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;)},\n",
       "              verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BayesSearchCV</label><div class=\"sk-toggleable__content\"><pre>BayesSearchCV(cv=5,\n",
       "              estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "              search_spaces={&#x27;eta&#x27;: Real(low=0.01, high=1, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;gamma&#x27;: Real(low=0, high=7, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;max_depth&#x27;: Integer(low=1, high=20, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;n_estimators&#x27;: Integer(low=10, high=1000, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;reg_lambda&#x27;: Real(low=0, high=10, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;)},\n",
       "              verbose=True)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "BayesSearchCV(cv=5,\n",
       "              estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "              search_spaces={'eta': Real(low=0.01, high=1, prior='uniform', transform='normalize'),\n",
       "                             'gamma': Real(low=0, high=7, prior='uniform', transform='normalize'),\n",
       "                             'max_depth': Integer(low=1, high=20, prior='uniform', transform='normalize'),\n",
       "                             'n_estimators': Integer(low=10, high=1000, prior='uniform', transform='normalize'),\n",
       "                             'reg_lambda': Real(low=0, high=10, prior='uniform', transform='normalize')},\n",
       "              verbose=True)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrn.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "reg_xgb_yb1 = xgb.XGBRegressor()\n",
    "\n",
    "xgb_bayes_yb1 = BayesSearchCV(reg_xgb_yb1,\n",
    "                              param_space,\n",
    "                              n_iter=32,\n",
    "                              scoring=\"neg_root_mean_squared_error\",\n",
    "                              verbose=True,\n",
    "                              cv=5,\n",
    "                              n_jobs=8,\n",
    "                              random_state=42)\n",
    "\n",
    "xgb_bayes_yb1.fit(X_train_yb1, yb1_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo XGBoost para \"yb2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BayesSearchCV(cv=5,\n",
       "              estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "              search_spaces={&#x27;eta&#x27;: Real(low=0.01, high=1, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;gamma&#x27;: Real(low=0, high=7, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;max_depth&#x27;: Integer(low=1, high=20, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;n_estimators&#x27;: Integer(low=10, high=1000, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;reg_lambda&#x27;: Real(low=0, high=10, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;)},\n",
       "              verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BayesSearchCV</label><div class=\"sk-toggleable__content\"><pre>BayesSearchCV(cv=5,\n",
       "              estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "              search_spaces={&#x27;eta&#x27;: Real(low=0.01, high=1, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;gamma&#x27;: Real(low=0, high=7, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;max_depth&#x27;: Integer(low=1, high=20, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;n_estimators&#x27;: Integer(low=10, high=1000, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;reg_lambda&#x27;: Real(low=0, high=10, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;)},\n",
       "              verbose=True)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "BayesSearchCV(cv=5,\n",
       "              estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "              search_spaces={'eta': Real(low=0.01, high=1, prior='uniform', transform='normalize'),\n",
       "                             'gamma': Real(low=0, high=7, prior='uniform', transform='normalize'),\n",
       "                             'max_depth': Integer(low=1, high=20, prior='uniform', transform='normalize'),\n",
       "                             'n_estimators': Integer(low=10, high=1000, prior='uniform', transform='normalize'),\n",
       "                             'reg_lambda': Real(low=0, high=10, prior='uniform', transform='normalize')},\n",
       "              verbose=True)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrn.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "reg_xgb_yb2 = xgb.XGBRegressor()\n",
    "\n",
    "xgb_bayes_yb2 = BayesSearchCV(reg_xgb_yb2,\n",
    "                              param_space,\n",
    "                              n_iter=32,\n",
    "                              scoring=\"neg_root_mean_squared_error\",\n",
    "                              verbose=True,\n",
    "                              cv=5,\n",
    "                              n_jobs=8,\n",
    "                              random_state=42)\n",
    "\n",
    "xgb_bayes_yb2.fit(X_train_yb2, yb2_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo XGBoost para \"yb3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BayesSearchCV(cv=5,\n",
       "              estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "              search_spaces={&#x27;eta&#x27;: Real(low=0.01, high=1, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;gamma&#x27;: Real(low=0, high=7, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;max_depth&#x27;: Integer(low=1, high=20, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;n_estimators&#x27;: Integer(low=10, high=1000, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;reg_lambda&#x27;: Real(low=0, high=10, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;)},\n",
       "              verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BayesSearchCV</label><div class=\"sk-toggleable__content\"><pre>BayesSearchCV(cv=5,\n",
       "              estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "              search_spaces={&#x27;eta&#x27;: Real(low=0.01, high=1, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;gamma&#x27;: Real(low=0, high=7, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;max_depth&#x27;: Integer(low=1, high=20, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;n_estimators&#x27;: Integer(low=10, high=1000, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;reg_lambda&#x27;: Real(low=0, high=10, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;)},\n",
       "              verbose=True)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "BayesSearchCV(cv=5,\n",
       "              estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "              search_spaces={'eta': Real(low=0.01, high=1, prior='uniform', transform='normalize'),\n",
       "                             'gamma': Real(low=0, high=7, prior='uniform', transform='normalize'),\n",
       "                             'max_depth': Integer(low=1, high=20, prior='uniform', transform='normalize'),\n",
       "                             'n_estimators': Integer(low=10, high=1000, prior='uniform', transform='normalize'),\n",
       "                             'reg_lambda': Real(low=0, high=10, prior='uniform', transform='normalize')},\n",
       "              verbose=True)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrn.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "reg_xgb_yb3 = xgb.XGBRegressor()\n",
    "\n",
    "xgb_bayes_yb3 = BayesSearchCV(reg_xgb_yb3,\n",
    "                              param_space,\n",
    "                              n_iter=32,\n",
    "                              scoring=\"neg_root_mean_squared_error\",\n",
    "                              verbose=True,\n",
    "                              cv=5,\n",
    "                              n_jobs=8,\n",
    "                              random_state=42)\n",
    "\n",
    "xgb_bayes_yb3.fit(X_train_yb3, yb3_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo XGBoost para \"yb4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BayesSearchCV(cv=5,\n",
       "              estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "              search_spaces={&#x27;eta&#x27;: Real(low=0.01, high=1, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;gamma&#x27;: Real(low=0, high=7, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;max_depth&#x27;: Integer(low=1, high=20, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;n_estimators&#x27;: Integer(low=10, high=1000, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;reg_lambda&#x27;: Real(low=0, high=10, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;)},\n",
       "              verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BayesSearchCV</label><div class=\"sk-toggleable__content\"><pre>BayesSearchCV(cv=5,\n",
       "              estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "              search_spaces={&#x27;eta&#x27;: Real(low=0.01, high=1, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;gamma&#x27;: Real(low=0, high=7, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;max_depth&#x27;: Integer(low=1, high=20, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;n_estimators&#x27;: Integer(low=10, high=1000, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;reg_lambda&#x27;: Real(low=0, high=10, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;)},\n",
       "              verbose=True)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "BayesSearchCV(cv=5,\n",
       "              estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "              search_spaces={'eta': Real(low=0.01, high=1, prior='uniform', transform='normalize'),\n",
       "                             'gamma': Real(low=0, high=7, prior='uniform', transform='normalize'),\n",
       "                             'max_depth': Integer(low=1, high=20, prior='uniform', transform='normalize'),\n",
       "                             'n_estimators': Integer(low=10, high=1000, prior='uniform', transform='normalize'),\n",
       "                             'reg_lambda': Real(low=0, high=10, prior='uniform', transform='normalize')},\n",
       "              verbose=True)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrn.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "reg_xgb_yb4 = xgb.XGBRegressor()\n",
    "\n",
    "xgb_bayes_yb4 = BayesSearchCV(reg_xgb_yb4,\n",
    "                              param_space,\n",
    "                              n_iter=32,\n",
    "                              scoring=\"neg_root_mean_squared_error\",\n",
    "                              verbose=True,\n",
    "                              cv=5,\n",
    "                              n_jobs=8,\n",
    "                              random_state=42)\n",
    "\n",
    "xgb_bayes_yb4.fit(X_train_yb4, yb4_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo XGBoost para \"yc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BayesSearchCV(cv=5,\n",
       "              estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "              search_spaces={&#x27;eta&#x27;: Real(low=0.01, high=1, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;gamma&#x27;: Real(low=0, high=7, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;max_depth&#x27;: Integer(low=1, high=20, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;n_estimators&#x27;: Integer(low=10, high=1000, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;reg_lambda&#x27;: Real(low=0, high=10, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;)},\n",
       "              verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BayesSearchCV</label><div class=\"sk-toggleable__content\"><pre>BayesSearchCV(cv=5,\n",
       "              estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "              search_spaces={&#x27;eta&#x27;: Real(low=0.01, high=1, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;gamma&#x27;: Real(low=0, high=7, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;max_depth&#x27;: Integer(low=1, high=20, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;n_estimators&#x27;: Integer(low=10, high=1000, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;reg_lambda&#x27;: Real(low=0, high=10, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;)},\n",
       "              verbose=True)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" ><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "BayesSearchCV(cv=5,\n",
       "              estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "              search_spaces={'eta': Real(low=0.01, high=1, prior='uniform', transform='normalize'),\n",
       "                             'gamma': Real(low=0, high=7, prior='uniform', transform='normalize'),\n",
       "                             'max_depth': Integer(low=1, high=20, prior='uniform', transform='normalize'),\n",
       "                             'n_estimators': Integer(low=10, high=1000, prior='uniform', transform='normalize'),\n",
       "                             'reg_lambda': Real(low=0, high=10, prior='uniform', transform='normalize')},\n",
       "              verbose=True)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrn.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "reg_xgb_yc = xgb.XGBRegressor()\n",
    "\n",
    "xgb_bayes_yc = BayesSearchCV(reg_xgb_yc,\n",
    "                             param_space,\n",
    "                             n_iter=32,\n",
    "                             scoring=\"neg_root_mean_squared_error\",\n",
    "                             verbose=True,\n",
    "                             cv=5,\n",
    "                             n_jobs=8,\n",
    "                             random_state=42)\n",
    "\n",
    "xgb_bayes_yc.fit(X_train_yc, yc_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lista de Variáveis Alvo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = [\"ya1\",\n",
    "             \"ya2\",\n",
    "             \"yb1\",\n",
    "             \"yb2\",\n",
    "             \"yb3\",\n",
    "             \"yb4\",\n",
    "             \"yc\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Melhores Parâmetros e Pontuações dos Modelos XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ya1 params: OrderedDict([('eta', 0.5614610841647771), ('gamma', 6.336255229093742), ('max_depth', 1), ('n_estimators', 60), ('reg_lambda', 7.601098049295727)])\n",
      "    score : 5.548565830686883\n",
      "\n",
      "ya2 params: OrderedDict([('eta', 0.3277302024513811), ('gamma', 7.0), ('max_depth', 4), ('n_estimators', 629), ('reg_lambda', 10.0)])\n",
      "    score : 3.658864629154363\n",
      "\n",
      "yb1 params: OrderedDict([('eta', 0.7805085597918974), ('gamma', 0.4026888152528419), ('max_depth', 1), ('n_estimators', 10), ('reg_lambda', 10.0)])\n",
      "    score : 4.863985899621596\n",
      "\n",
      "yb2 params: OrderedDict([('eta', 0.01), ('gamma', 5.112131191772751), ('max_depth', 6), ('n_estimators', 1000), ('reg_lambda', 3.160665524645822)])\n",
      "    score : 2.588088170635773\n",
      "\n",
      "yb3 params: OrderedDict([('eta', 0.01), ('gamma', 0.0), ('max_depth', 1), ('n_estimators', 1000), ('reg_lambda', 10.0)])\n",
      "    score : 2.4040666038030754\n",
      "\n",
      "yb4 params: OrderedDict([('eta', 0.5040877958524675), ('gamma', 3.6867431813950278), ('max_depth', 7), ('n_estimators', 286), ('reg_lambda', 7.460729848600117)])\n",
      "    score : 1.5725947838546033\n",
      "\n",
      "yc params: OrderedDict([('eta', 0.11225743610058427), ('gamma', 7.0), ('max_depth', 1), ('n_estimators', 50), ('reg_lambda', 8.552717854452043)])\n",
      "    score : 3.7856292768349826\n",
      "\n"
     ]
    }
   ],
   "source": [
    "estimator_ya1 = xgb_bayes_ya1.best_estimator_\n",
    "estimator_ya2 = xgb_bayes_ya2.best_estimator_\n",
    "estimator_yb1 = xgb_bayes_yb1.best_estimator_\n",
    "estimator_yb2 = xgb_bayes_yb2.best_estimator_\n",
    "estimator_yb3 = xgb_bayes_yb3.best_estimator_\n",
    "estimator_yb4 = xgb_bayes_yb4.best_estimator_\n",
    "estimator_yc  = xgb_bayes_yc.best_estimator_\n",
    "\n",
    "bayes_estimators = [xgb_bayes_ya1,\n",
    "                    xgb_bayes_ya2,\n",
    "                    xgb_bayes_yb1,\n",
    "                    xgb_bayes_yb2,\n",
    "                    xgb_bayes_yb3,\n",
    "                    xgb_bayes_yb4,\n",
    "                    xgb_bayes_yc]\n",
    "\n",
    "for var, estimator in zip(variables, bayes_estimators):\n",
    "    best_params = estimator.best_params_\n",
    "    best_score = -estimator.best_score_\n",
    "    print(f\"{var} params: {best_params}\\n    score : {best_score}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaliação das Previsões do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ya1: 6.20046584973785\n",
      "ya2: 3.535340785005982\n",
      "yb1: 5.899939673686135\n",
      "yb2: 3.328128976990473\n",
      "yb3: 2.090232168274241\n",
      "yb4: 1.9834125260539714\n",
      "yc: 2.5808879212246865\n"
     ]
    }
   ],
   "source": [
    "wrn.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "estimators = [estimator_ya1,\n",
    "              estimator_ya2,\n",
    "              estimator_yb1,\n",
    "              estimator_yb2,\n",
    "              estimator_yb3,\n",
    "              estimator_yb4,\n",
    "              estimator_yc]\n",
    "\n",
    "X_tests = [X_test_ya1,\n",
    "           X_test_ya2,\n",
    "           X_test_yb1,\n",
    "           X_test_yb2,\n",
    "           X_test_yb3,\n",
    "           X_test_yb4,\n",
    "           X_test_yc]\n",
    "\n",
    "y_tests = [ya1_test,\n",
    "           ya2_test,\n",
    "           yb1_test,\n",
    "           yb2_test,\n",
    "           yb3_test,\n",
    "           yb4_test,\n",
    "           yc_test]\n",
    "\n",
    "predict = {}\n",
    "\n",
    "for var, estimator, X_test, y_test in zip(variables, estimators, X_tests, y_tests):\n",
    "    predict[var] = estimator.predict(X_test)\n",
    "    rmse = np.sqrt(mean_squared_error(predict[var], y_test))\n",
    "    print(f\"{var}: {rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listas de Comparação entre Valores Reais e Previsões"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "complist_ya1 = [(true, pred) for true, pred in zip(ya1_test, predict[\"ya1\"])]\n",
    "complist_ya2 = [(true, pred) for true, pred in zip(ya2_test, predict[\"ya2\"])]\n",
    "complist_yb1 = [(true, pred) for true, pred in zip(yb1_test, predict[\"yb1\"])]\n",
    "complist_yb2 = [(true, pred) for true, pred in zip(yb2_test, predict[\"yb2\"])]\n",
    "complist_yb3 = [(true, pred) for true, pred in zip(yb3_test, predict[\"yb3\"])]\n",
    "complist_yb4 = [(true, pred) for true, pred in zip(yb4_test, predict[\"yb4\"])]\n",
    "complist_yc  = [(true, pred) for true, pred in zip(yc_test, predict[\"yc\"])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tabela de Comparação entre Valores Reais e Previsões"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ya1            ya2            yb1            yb2           yb3            yb4            yc         \n",
      "   0  0.116832    1  0.728237    0  0.047043    0 0.349900    0  0.293103    0  0.192523   0 0.267770\n",
      "   8  8.659450    4  4.786130    7  1.913894    0 1.110315    2  1.438224    0  0.367634   0 0.856215\n",
      "   0  2.157198    2  1.025899    0  1.584957    5 0.855792    0  0.706637    0  0.267043   0 0.795511\n",
      "   8  3.986489    3  3.415594    1  2.189635    0 1.796222    0  1.008905    0  0.517500   0 1.363469\n",
      "   1  0.698594    0  0.198944    0  2.172586    0 0.700203    0  0.555383    3  0.585235   1 1.238930\n",
      "   0 -0.766464    0 -0.031058    0 -0.228698    0 0.331397    0  0.274331    0  0.192523   0 0.124934\n",
      "  11  3.853352    9  2.968174    6  2.468361    3 1.876393    5  1.008905    0  0.598679   0 1.363469\n",
      "   0  0.081164    0  0.268461    0  0.247606    0 0.350993    0  0.346712    0  0.258091   0 0.526305\n",
      "   1  0.947628    0  0.265107    0  0.817924    0 0.350993    0  0.394683    0  0.178165   0 0.728901\n",
      "   4  7.517219    0  4.886451    0  1.913894    0 1.224505    0  1.456996    4  0.367634   0 0.963747\n",
      "   1  2.703443    0  2.211377    1  2.155274    2 1.159101    2  0.779018    3  0.467436   0 0.865533\n",
      "   5  3.677784    3  2.373203    0  1.403229    0 0.932837    0  0.779018    0  0.332611   1 0.818514\n",
      "   1  3.183840    1  1.851763    0  1.879533    1 0.881048    1  0.779018    0  0.332611   0 0.795511\n",
      "   3  4.326072    2  3.327330    0  1.879533    4 0.875257    1  0.760246    0  0.332611   3 0.687980\n",
      "   3  7.223905    5  7.472474    3  2.468361    8 1.448066    3  1.486195    1  1.008818   0 1.448468\n",
      "   1  3.197387    0  2.373203    1  1.403229    3 1.290535    1  0.779018    0  0.769716   0 0.888536\n",
      "   0  2.237604    0  1.169783    0  1.678970    2 0.787741    0  0.808218    0  0.445407   0 0.888536\n",
      "   0  2.703443    6  1.851763    0  1.879533    0 1.121214    0  0.779018    5  0.467436   1 0.865533\n",
      "   0  2.019183    0  2.132137    0  1.975009    0 0.837980    0  0.555383    0  0.430926   3 1.261933\n",
      "  46  6.970785   14  6.530902    3  1.823122    1 2.133220    1  1.712668   13  1.220022   2 1.329288\n",
      "   0  3.986489    0  3.415594    0  2.189635    1 1.520247    0  0.979707    0  0.517500   0 0.914052\n",
      "   0  0.193318    1  0.018143    1 -0.228698    0 0.331397    0  0.274331    0  0.192523   0 0.124934\n",
      "   0  2.376539    0  2.099455   14  2.526096    5 2.302388    1  0.804220    0  0.332611   4 0.747198\n",
      "   1  5.143611    2  3.154139    0  1.823122    1 1.824009    1  1.292001    7  0.883666   0 1.290354\n",
      "   1  8.450237    2  3.708366    5  1.823122    4 2.721449    0  1.292001    0  1.705160   3 1.290354\n",
      "   0  4.649667    2  3.794479    0  2.299425    3 1.824009    2  1.292001    0  0.883666   0 1.267350\n",
      "   4  2.330923    4  1.375021    9  1.108653    8 0.907581    5  0.687865    3  0.267043   5 0.710983\n",
      "   0  3.492545    2  2.693069    3  2.665939    4 1.520247    0  1.008905    0  0.517500   0 0.891049\n",
      "   1  3.197387    0  2.030138    1  1.678970    0 1.432434    0  0.808218    0  0.357054   2 1.337953\n",
      "   0  8.450237    0  3.708366    0  1.823122    0 2.721449    0  1.292001    0  1.705160   4 1.290354\n",
      "   0  3.986489    0  3.415594    2  2.189635    1 1.520247    2  1.008905    0  0.517500   1 0.914052\n",
      "   0  3.853352    0  2.968174    2  2.468361    1 1.876393    1  1.008905    0  0.598679   0 1.363469\n",
      "   0  3.492545    2  2.693069    0  2.665939    2 1.520247    2  1.008905    0  0.517500   0 0.891049\n",
      "   0  3.600232    0  1.974028    0  1.823122    0 1.341458    0  1.008905    0  0.929348   0 1.244289\n",
      "   0  1.949133    1  0.894448    1  1.108653    0 0.907581    0  0.687865    0  0.267043   0 0.710983\n",
      "   1  3.600232    0  1.545986    1  1.823122    0 1.482718    0  1.008905    0  0.929348   0 1.363469\n",
      "   3  3.492545    5  2.693069    9  2.665939   11 1.520247    2  0.979707    1  0.517500   5 0.891049\n",
      "   0  3.986489    2  3.415594    0  2.189635    0 1.520247    1  1.008905    0  0.517500   0 0.914052\n",
      "   1  3.492545    5  2.693069   21  2.665939    3 1.520247    6  0.979707    1  0.517500   9 0.891049\n",
      "  15  6.970785    4  6.530902    1  1.823122    0 1.959087    0  1.486195    0  1.220022   0 1.329288\n",
      "   0  3.853352    0  2.968174    2  2.468361    0 1.876393    3  1.008905    0  0.598679   0 1.363469\n",
      "   2  3.986489    1  3.415594    0  2.189635    3 1.796222    0  1.008905    0  0.517500   0 1.363469\n",
      "   1  2.399626    8  1.427855    1  2.944665    0 2.432069    0  1.008905    0  9.768674   1 1.340466\n",
      "   0  2.940162    0  0.766820    2  1.913894    1 0.782583    0  0.614249    0  0.367634   0 0.963747\n",
      "   1 -1.260408    0 -0.031058    0  0.247606    1 0.331528    0  0.274331    0  0.192523   0 0.101931\n",
      "  18  7.357042    2  5.758461    0  2.189635    2 1.666116    0  1.486195    0  0.968142   0 1.448468\n",
      "   0  1.574988    0  0.153597    0 -0.024894    0 0.545954    0  0.200486    0  0.852141   0 0.593790\n",
      "   0 -1.265802    0  0.389141    0  0.451410    0 0.331474    0  0.621155    0  0.190678   0 0.575004\n",
      "   0  3.359408    0  2.245649    3  2.944665    1 1.876393    0  1.008905    6  0.543403   0 1.340466\n",
      "   0 -1.457036    0 -0.096275    0 -0.319470    0 0.275611    0  0.128106    0  0.112597   0 0.559072\n",
      "   0  2.101572    1  0.225160   37  2.299425    8 0.367404    0  0.814710    2  0.334616   8 1.058264\n",
      "   0 -1.260408    0  0.185543    0  1.370473    0 0.478635    0  0.371913    0  0.258091   0 0.526305\n",
      "   0  2.863620    1  1.851763    0  1.879533    1 1.053625    3  0.779018    1  0.363067   0 0.830229\n",
      "   0  0.947628    0  0.809257    0  0.542183    2 0.350993    2  0.365484    0  0.258091   0 0.244767\n",
      "   0  3.600232    0  1.974028    0  1.823122    0 1.296481    0  1.008905    0  0.482463   0 1.244289\n",
      "   0 -0.404275    0  0.153597    0 -0.024894    0 0.252119    0  0.200486    0  0.098106   0 0.469702\n",
      "   0  0.756394    0  0.234880    0  0.047043    0 0.349900    0  0.322302    0  0.112597   0 0.267770\n",
      "   0  3.853352    6  3.497502    0  2.468361    0 1.482718    0  1.008905    0  0.929348   0 1.363469\n",
      "   0  1.441572    0  0.573819    1  0.341620    0 0.369365    0  0.394683    0  0.266517   0 0.302488\n",
      "   6  3.986489    1  3.415594    4  2.189635    2 1.796222    4  1.008905    3  0.517500  37 1.363469\n",
      "   0  2.312497    2  0.682613    0  1.420542    0 0.954836    0  0.526184    0  0.277329   0 0.777211\n",
      "   0  0.756394    0  0.330119    0 -0.228698    0 0.349900    0  0.293103    0  0.192523   0 0.267770\n",
      "   0 -1.260408    0  0.185543    0  1.370473    0 0.478635    0  0.299532    0  0.192523   0 0.101931\n",
      "   1  3.600232    1  2.498456    0  1.823122    0 1.482718    0  1.008905    0  0.929348   0 1.244289\n",
      "   4  8.659450    0  4.786130    0  1.913894    0 1.110315    0  1.438224    0  0.367634   0 0.856215\n",
      "   1  1.226784    0  1.577574    0  2.155274    0 1.144989    0  0.779018    0  0.467436   1 0.865533\n",
      "   2  3.359408    0  2.245649    0  2.944665    1 1.876393    1  1.008905    0  0.543403   0 1.340466\n",
      "   1  2.010602    0  1.415581   11  2.299425   19 1.392264    0  1.235378    1  0.427188   1 1.221286\n",
      "   0 -0.697332    0  0.219260    0  0.247606    0 0.331528    1  0.293103    0  0.192523   0 0.244767\n",
      "   4  1.455188    0  0.606984    0  1.584957    1 0.855792    0  0.687865    0  0.267043   0 0.687980\n",
      "   0  1.743660    2  1.578015    4  3.278140    3 1.780145    0  0.804220    0  0.467436   1 0.865533\n",
      "   2  3.359408    2  2.245649    6  2.944665    8 1.876393    5  1.008905    0  0.543403   2 1.340466\n",
      "   3  2.703443    4  2.211377    0  2.155274    0 1.159101    0  0.779018    0  0.467436   0 0.865533\n",
      "   0  1.761793    0  1.043233    0  0.341620    0 0.369365    0  0.365484    0  0.258091   0 0.267770\n",
      "   0  1.903837    0  1.578015    3  1.879533    0 0.881048    1  0.779018    0  0.363067   1 0.830229\n",
      "   0 -0.917212    0 -0.209802    0 -0.024894    0 0.273954    0  0.200486    0  0.098106   0 0.469702\n",
      "   0  0.081164    0  0.268461    1  0.247606    1 0.331528    0  0.274331    0  0.192523   0 0.101931\n",
      "   3  1.773059    1  0.775242    1  1.823122    0 0.862278    0  0.814710    0  0.267157   0 1.205354\n",
      "   7  2.703443    5  2.211377    0  2.155274    0 1.279561    0  0.779018    0  0.467436   0 0.865533\n",
      "  42  3.677784   35  2.373203    0  1.403229    0 0.932837    0  0.779018    0  0.332611   2 0.818514\n",
      "   1  3.986489    3  3.415594    7  2.189635    5 1.796222    6  1.008905    0  0.517500   0 1.363469\n",
      "   0  3.357564    0  2.373203    0  1.403229    0 1.047027    0  0.779018    0  0.356561   0 0.853231\n",
      "   1  3.197387    0  2.933902    0  1.678970    0 1.295887    0  0.779018    0  0.436980   0 0.853819\n",
      "   0  2.018264    0  0.729575    3  1.860697    0 1.665794    0  0.808218    0  0.695714   1 1.739324\n",
      "   0  2.237604    4  2.013431    8  1.678970    2 4.039034    0  0.779018    3  1.654922   1 0.888536\n",
      "   0  3.359408    0  2.245649    1  2.944665    1 1.876393    0  1.008905    0  0.543403   0 1.340466\n",
      "   0  3.986489    7  2.230330    3  1.913894    9 1.294583    0  0.979707    4  0.684289   0 0.914052\n",
      "   0  0.116832    0  0.280919    2 -0.228698    3 0.349900    0  0.293103    0  0.192523   0 0.267770\n",
      "   5  4.820016    5  3.410518    2  1.403229    3 0.927045    2  0.760246   32  0.332611   2 0.710983\n",
      "   1  1.743660    1  1.578015    0  3.002400    1 1.591318    2  0.804220    0  0.634224   2 0.865533\n",
      "   0  2.863620    4  1.851763   15  1.879533    4 1.058686    0  0.779018    2  0.363067   2 0.830229\n",
      "   5  3.197387    9  2.373203    1  1.403229    0 1.154104    0  0.779018    0  0.769716   0 0.888536\n",
      "   3  3.197387    1  2.373203    1  1.678970    0 1.154104    0  0.779018    0  0.445407   0 0.888536\n",
      "   4  8.659450    6  4.786130    4  1.913894    2 1.110315    4  1.438224    1  0.367634   1 0.856215\n",
      "   0  4.146668    2  2.230330    0  1.913894    0 1.282891    1  0.979707    4  0.413132   0 0.878747\n",
      "   0  2.703443    2  1.851763    2  1.879533    5 1.121214    0  0.779018    0  0.467436   8 0.865533\n",
      "   0  2.703443    2  1.851763    1  1.879533    2 1.213988    5  0.779018    1  0.634224   0 0.865533\n",
      "   0  3.301311    1  2.665237    0  1.895058    0 1.796222    1  1.008905    2  1.341089  12 1.787843\n",
      "  49  8.450237    7  3.708366   11  1.823122    7 2.742217    0  1.292001    0  0.707487   4 1.290354\n",
      "   0  0.690404    0  0.170180    0  1.052847    0 0.321599    0  0.200715    0  0.293114   0 0.354695\n",
      "   0  1.836978    0  1.025899    0  1.584957    0 0.875257    0  0.760246    0  0.332611   0 1.112354\n",
      "   8  3.986489   11  3.415594   13  2.189635   12 1.520247    1  1.008905    1  0.517500   2 0.914052\n",
      "   0  3.197387    0  2.030138    0  1.678970    0 1.432434    0  0.808218    0  0.357054   0 1.337953\n",
      "   1  1.279115    0  1.415581    0  2.299425    0 0.862278    0  0.814710    0  0.267157   0 1.182351\n",
      "   0 -0.878618    0  0.435862    0  1.370473    1 0.478635    1  0.390685    0  0.258091   0 0.562520\n",
      "   0 -0.300626    0  0.018143    0  0.247606    2 0.331528    4  0.274331    0  0.192523   0 0.101931\n",
      "   2  2.842377    1  1.851763    2  1.879533    2 0.875257    2  0.779018    0  0.332611   0 0.795511\n",
      "   0  0.698594    0  0.198944    0  2.172586    0 0.700203    0  0.555383    4  0.585235   0 1.238930\n",
      "   0  3.359408    1  2.245649   12  2.944665    7 1.876393    3  1.008905    0  0.543403   0 1.340466\n",
      "   0  1.658376    0  0.515123    6  2.172586    0 0.729609    0  0.555383    1  0.212848   4 1.238930\n",
      "   0  2.312497    1  0.682613    1  1.420542    0 0.955160    0  0.559655    0  0.277329   0 0.777211\n",
      "   0 -2.448194    0  0.023800    0  0.468723    0 0.264257    0 -0.018876    0  0.585235   0 0.370679\n",
      "   0 -2.310869    0  0.426195    0  0.468723    0 0.321777    0 -0.018876    0  0.055291   0 0.494766\n",
      "   0 -0.203388    0  0.354312    0  0.047043    0 0.369365    0  0.365484    0  0.266517   0 0.726862\n",
      "   0  2.018264    3  0.603225    1  1.860697    0 1.241633    0  0.735837    0  0.401868   3 0.865533\n",
      "   0  1.658376    0  0.515123    1  2.172586    2 0.784435    0  0.559655    0  0.212848   0 0.789513\n",
      "   0 -1.260408    0 -0.031058    1  0.247606    0 0.350993    0  0.346712    0  0.258091   0 0.526305\n",
      "   0  1.428026    0  0.809257    0  0.542183    0 0.350993    0  0.365484    0  0.258091   0 0.209463\n",
      "   0  2.512208    0  1.375021    0  1.108653    0 1.248937    0  0.706637    0  0.870937   0 0.888536\n",
      "   0  0.756394    0  0.904750    0  0.047043    0 0.349900    0  0.293103    0  0.192523   0 0.267770\n",
      "   1  3.986489    2  3.415594    0  2.189635    0 1.520247    2  0.979707    0  0.517500   3 0.914052\n",
      "   2  3.492545    1  2.693069    0  2.665939    1 1.796222    2  1.008905    0  0.517500   1 1.340466\n",
      "   3  3.986489    0  3.415594    0  2.189635    0 1.796222    0  1.008905    0  0.517500   0 1.363469\n",
      "   0  3.986489    0  2.230330    1  1.913894    1 1.294583    0  0.979707    0  0.684289   0 0.914052\n",
      "   6  2.376539    1  2.099455    0  2.526096    0 2.302388    0  0.804220    0  0.332611   0 0.747198\n",
      "   0  2.703443    0  1.851763    0  1.879533    1 1.213988    1  0.779018    0  0.634224   0 0.865533\n",
      "   1  4.146668    3  2.230330   10  1.913894   14 1.224505    6  0.979707    4  0.413132   2 0.878747\n",
      "   0  0.193318    0  0.018143    0 -0.228698    0 0.300136    0  0.346712    0  0.258091   0 0.549308\n",
      "   2  2.532763    1  1.658533   11  2.665939   17 1.524055    3  1.008905    5  5.679029   0 0.891049\n",
      "   4  3.197387    3  2.373203    7  1.403229    0 1.154104    2  0.779018    6  0.769716   0 0.888536\n",
      "   5  2.842377    3  1.851763    1  1.879533    1 0.875257    3  0.779018    2  0.332611   2 0.724195\n",
      "   0  1.076615    1  0.904750    0  0.047043    0 0.349900    0  0.293103    0  0.192523   1 0.267770\n",
      "   0  3.853352    0  3.497502    0  2.468361    3 1.482718    0  1.008905    0  0.929348   0 1.363469\n",
      "   4  2.703443   15  2.211377    3  2.155274    2 1.279561    5  0.779018    0  0.467436   4 0.865533\n",
      "   2  3.026707    0  2.396716    7  3.312501   16 1.282995    3  1.034106    1  0.517500   1 1.363469\n",
      "   2  3.600232    3  2.498456    3  1.823122    1 1.482718    1  1.008905    0  0.929348   0 1.244289\n",
      "   3  1.720729    4  1.697140    3  1.403229    6 1.306899    1  0.779018    0  0.936505   0 0.888536\n",
      "   0  0.081164    0  0.268461    0  0.247606    0 0.331528    0  0.274331    0  0.192523   0 0.101931\n",
      "   0  3.492545    0  1.708889    0  2.665939    0 1.399787    0  0.979707    0  0.517500   0 0.891049\n",
      "   0  1.455188    0  0.606984    0  1.584957    0 0.855792    0  0.687865    0  0.267043   0 0.687980\n",
      "   0  0.431011    0  0.339943    0  1.328588    1 0.321599    0  0.113677    0  0.338611   0 0.305001\n",
      "   0  0.262450    0 -0.027863    0  0.523347    0 0.331528    0  0.322302    0  0.112597   0 0.728901\n",
      "   1  0.050599    0 -0.209802    0 -0.024894    0 0.273954    0  0.200486    0  0.098106   0 0.469702\n",
      "   1  0.623257    0  0.034681    0  0.325770    0 0.311831    0  0.322302    0  0.112597   0 0.751904\n",
      "   2  2.152320    2  0.950184    1  1.696283    0 0.969320    0  0.559655    1  0.212848   0 0.812516\n",
      "   2  3.986489    2  3.415594    2  2.189635    0 1.520247    0  1.008905    0  0.517500   0 0.914052\n",
      "   4  3.492545    1  2.693069    0  2.665939    4 1.796222    0  1.008905    0  0.517500   1 1.340466\n",
      "   0  2.512208    0  1.375021    0  1.108653    0 1.248937    0  0.706637    0  0.870937   0 0.888536\n",
      "   0  6.476840    3  4.274721    0  2.299425    0 1.448066    0  1.486195    0  0.832493   0 1.425465\n",
      "   0  0.193318    0  0.018143    0 -0.228698    0 0.331397    0  0.274331    0  0.192523   0 0.124934\n",
      "   5  2.703443    6  1.851763    1  1.879533    1 1.121214    0  0.779018    0  0.467436   0 0.865533\n",
      "   0  2.237604    4  2.099455    0  1.403229    0 1.306899    0  0.779018    0  0.936505   1 0.888536\n",
      "   0 -1.283081    0  0.318819    0  0.281967    0 0.270873    0  0.094905    0  0.585235   0 0.609542\n",
      "   0  2.842377    1  1.851763    0  1.879533    1 0.875257    2  0.760246    0  0.332611   0 0.687980\n",
      "   0  2.186825    0  1.745515    0  2.665939    1 1.288611    0  0.527212    0  0.517500   0 0.891049\n",
      "   6  2.237604    0  2.099455    1  1.403229    2 1.139993    1  0.779018    0  0.769716   0 0.888536\n",
      "   0  3.853352    0  4.852853    0  2.468361    0 1.716176    1  1.008905    0  0.929348   0 1.363469\n",
      "   0  1.539443    0  1.697140    0  1.403229    0 0.927045    0  0.779018    0  0.356561   1 0.781915\n",
      "  31  5.143611    5  3.154139   16  1.823122    5 1.824009    3  1.292001    0  0.883666   0 1.290354\n",
      "   0  3.492545    0  2.693069    1  2.665939    0 1.520247    0  0.979707    0  0.517500   0 0.891049\n",
      "  14  3.197387    8  2.373203    1  1.403229    0 1.154104    1  0.779018    0  0.769716   0 0.888536\n",
      "   4  3.106288    1  1.233298    0  2.299425    2 1.341458    1  1.008905    0  0.427188   0 1.221286\n",
      "   0  6.285606    0  3.384495    0  1.528545    0 1.326961    0  1.413814    0  0.754413   1 1.329288\n",
      "   0  3.197387    2  2.373203    2  1.678970    0 1.154104    0  0.779018    0  0.445407   0 0.888536\n",
      "   0  2.703443    0  2.211377    0  2.155274    2 1.279561    3  0.779018    0  0.467436   3 0.865533\n",
      "   1  3.183840    1  1.851763    1  1.879533    1 0.881048    0  0.779018    0  0.332611   0 0.795511\n",
      "   4  3.986489    9  3.415594    3  2.189635    0 1.520247    1  1.008905    2  0.517500   1 0.914052\n",
      "   0  7.357042    4  5.758461    5  2.189635    0 1.470683    3  1.486195    3  0.303153   1 0.999052\n",
      "   0  2.018264    0  0.603225    2  1.860697    1 1.241633    0  0.706637    0  0.401868   0 0.865533\n",
      "   0  3.197387    0  2.933902    1  1.678970    1 1.295887    0  0.779018    0  0.445407   0 0.888536\n",
      "   6  3.492545   12  2.693069    5  2.665939    3 1.796222    4  1.008905    1  0.517500   4 1.340466\n",
      "   1  3.986489    0  3.415594    0  2.189635    1 1.520247    2  1.008905    0  0.517500   0 0.914052\n",
      "   0  1.949133    0  0.894448    2  1.108653    0 0.907581    1  0.687865    0  0.267043   0 0.710983\n",
      "   6  3.986489    0  3.415594    2  2.189635    0 1.520247    0  1.008905    0  0.517500   0 0.914052\n",
      "   0  2.832429    0  2.323577    0  1.384394    0 1.304630    0  0.779018    0  0.775639   0 1.278193\n",
      "   0  3.106288    0  1.233298    0  2.299425    0 1.296481    0  1.008905    0  0.427188   0 1.221286\n",
      "   0  3.605406    0  0.073010    0  1.017880    0 1.078693    0  0.614021    0  0.174170   0 1.604212\n",
      "   0  2.703443    0  1.851763    0  1.879533    0 1.213988    0  0.779018    0  0.634224   0 0.865533\n",
      "   6  2.512208    4  1.375021    0  1.108653    2 1.268402    0  0.779018    5  1.108376   2 1.312911\n",
      "   0  2.703443    0  2.211377    0  2.155274    0 1.159101    0  0.779018    0  0.467436   0 0.865533\n",
      "   0  0.623257    0  0.034681    0  0.325770    0 0.331296    0  0.394683    0  0.245953   0 1.141561\n",
      "  13  6.970785    0  6.530902    0  1.823122    0 1.959087    0  1.486195    0  1.220022   0 1.329288\n",
      "   1  2.237604    1  2.013431    3  1.678970    0 1.306622    0  0.779018    0  0.445407   0 0.888536\n",
      "   0  0.756394    0  0.108530    0  0.047043    0 0.349900    0  0.293103    0  0.192523   0 0.267770\n",
      "   2  1.743660    1  1.578015    1  2.155274    0 1.144989    0  0.779018    0  0.467436   0 0.865533\n",
      "   0  0.690404    0  0.170180    0  1.052847    0 0.321599    0  0.200715    0  0.293114   0 0.354695\n",
      "   0  1.371140    1  1.325821    0  1.108653    1 0.927045    0  0.760246    1  0.332611   0 1.135357\n",
      "   0  2.703443    0  1.307613    0  2.155274    0 1.140133    0  0.808218    0  0.357054   0 0.865533\n",
      "   4  3.600232    2  1.545986    0  1.823122    0 1.482718    1  1.008905    0  0.929348   0 1.363469\n",
      "   1  2.018264    0  1.025899    0  1.584957    0 1.172390    0  0.706637    0  0.568656   0 0.865533\n",
      "   2  3.336321    0  2.373203    0  1.403229    0 0.927045    0  0.779018    0  0.332611   0 0.818514\n",
      "   1  2.863620    0  1.851763    9  1.879533    3 1.053625    1  0.779018    0  0.363067   4 0.830229\n",
      "   1  1.087880    0  0.645098    0  1.528545    0 0.774572    0  0.742329    0  0.349107   0 1.205354\n",
      "   3  3.853352    0  2.968174    0  2.468361    0 1.876393    0  1.008905    0  0.598679   0 1.363469\n",
      "   0  0.575108    0  0.330119    0 -0.228698    0 0.350862    0  0.365484    0  0.258091   0 0.585523\n",
      "   5  3.492545    3  2.693069    1  2.665939    5 1.520247    6  1.008905    1  0.517500   1 0.891049\n",
      "   0 -0.917212    0 -0.209802    0 -0.024894    0 0.273954    0  0.200486    0  0.098106   0 0.469702\n",
      "  13  7.357042   10  5.758461    0  2.189635    0 1.470683    0  1.456996    0  0.303153   0 0.999052\n",
      "   0  3.492545    2  2.693069    0  2.665939    2 1.796222    0  1.008905    1  0.517500   0 1.340466\n",
      "   0  3.492545    0  2.693069    0  2.665939    2 1.520247    0  1.008905    0  0.517500   0 0.891049\n",
      "   0  1.441572    0  0.573819    0  0.341620    0 0.369365    0  0.394683    0  0.266517   0 0.302488\n",
      "   3  1.627704    0  0.156178    0  1.823122    0 0.367404    0  0.814710    0  0.334616   0 1.081267\n",
      "   0 -0.771858    0 -0.251199    0 -0.024894    0 0.331474    0  0.621155    0  0.245953   0 0.632724\n",
      "   0  0.396506    0  0.319949    0  0.358932    0 0.321599    0  0.146121    0  0.202809   0 0.226468\n",
      "   4  3.106288    0  0.805257    2  2.299425    0 1.482718    1  1.008905    1  0.642964   0 1.340466\n",
      "   1  3.359408    0  2.245649   17  2.944665   16 1.876393    2  1.008905    0  0.543403   0 1.340466\n",
      "   0  2.863620    0  1.851763    1  1.879533    0 1.058686    0  0.779018    1  0.363067   0 0.830229\n",
      "   3  3.492545    2  2.693069    2  2.665939    1 1.796222    0  1.008905    0  0.517500   5 1.340466\n",
      "  18  4.649667    9  3.794479    7  2.299425    1 2.036608    6  1.292001    4  1.043697   1 1.267350\n",
      "   2  3.492545    3  2.693069    0  2.665939    0 1.520247    2  1.008905    0  0.517500   0 0.891049\n",
      "   0  2.703443    0  1.851763    9  1.879533    0 1.213988    0  0.779018    0  0.467436   6 0.865533\n",
      "   2  3.186884    0  3.307619    0  1.913894    0 0.911898    0  0.979707    0  0.413132   0 0.878747\n",
      "   0  1.059401    0  1.614872    0  1.975009    0 0.795627    0  0.555383    3  0.585235   0 1.261933\n",
      "   3  3.853352    8  2.968174    0  2.468361    1 1.876393    1  1.008905    0  0.598679   1 1.363469\n",
      "   0  0.396506    0  0.587520    0  0.358932    0 0.321599    0  0.141849    0  0.202809   0 0.675884\n",
      "   6  2.399626    0  1.640394    0  4.067532    0 1.315181    0  1.034106    0  0.642964   0 1.340466\n",
      "  28  3.357564    2  2.373203    0  1.403229    1 1.135233    0  0.779018    0  0.356561   0 0.853231\n",
      "   1  1.658376    1  0.515123   25  2.172586   14 0.990642    1  0.559655    0  0.212848   0 0.789513\n",
      "   0 -2.310869    0  0.426195    0  0.468723    0 0.251981    0 -0.052347    0  0.055291   0 0.494766\n",
      "   9  6.476840    3  6.092160   11  2.299425   11 2.133220    2  1.712668    1  1.043697   2 1.306285\n",
      "   0  0.623257    0  0.034681    0  0.325770    0 0.311831    0  0.322302    0  0.112597   0 0.717187\n",
      "   0  3.492545    0  2.693069    0  2.665939    1 1.796222    0  1.008905    2  0.517500   0 1.340466\n",
      "  34  3.492545   13  2.693069    0  2.665939    0 1.796222    1  1.008905    1  0.517500   1 1.340466\n",
      "   0  0.623257    0  0.232338    0  0.325770    0 0.331296    0  0.394683    0  0.245953   0 1.141561\n",
      "   2  3.106288    3  1.233298    2  2.299425    2 1.341458    2  1.008905    0  0.642964   0 1.221286\n",
      "   0  1.773059    0  0.984064    0  1.823122    0 0.862278    0  0.814710    0  0.509920   0 1.205354\n",
      "   2  1.743660    0  1.573662    1  3.278140    4 1.348222    1  0.833420    0  0.357054   2 0.865533\n",
      "   2  2.237604    0  2.099455   12  1.403229    3 1.306899    0  0.779018    0  0.936505   1 0.888536\n",
      "   0  2.863620    0  1.851763    0  1.879533    0 0.881048    0  0.779018    0  0.363067   0 0.830229\n",
      "   0  3.492545    0  2.693069    0  2.665939    2 1.520247    0  1.008905    0  0.517500   0 0.891049\n",
      "   1  1.218658    4  1.193300    0  2.707823    0 2.302388    0  0.804220    0  0.332611   0 1.219885\n",
      "   0  2.863620    2  1.851763    0  1.879533    0 1.058686    1  0.779018    0  0.363067   0 0.830229\n",
      "   0  3.492545    1  2.693069    1  2.665939    0 1.796222    0  1.008905    0  0.517500   0 1.340466\n",
      "   5  3.492545    1  2.693069    0  2.665939    0 1.796222    0  1.008905    0  0.517500   0 1.340466\n",
      "   0  2.703443    0  1.181264    5  2.155274    0 1.011412    0  0.808218    0  0.467436   1 0.865533\n",
      "   0  1.743660    0  1.859235    0  1.879533    0 1.657501    0  0.779018    0  2.907626   0 0.865533\n",
      "   0  0.348941    0  0.170180    0  1.052847    0 0.321599    0  0.200715    0  0.293114   0 0.283379\n",
      "   7  3.359408    9  2.245649    0  2.944665    2 1.876393    0  1.008905    0  0.543403   2 1.340466\n",
      "   0  1.587591    0  1.111418    0  1.957697    0 1.186468    0  0.808218    3  0.438233   0 1.337953\n",
      "   2  2.703443    9  1.851763    3  1.879533    2 1.121214    0  0.779018    1  0.467436   3 0.865533\n",
      "   0 -1.950981    0  0.054823    0  0.156833    3 0.261677    0  0.200486    0  0.030647   0 0.995161\n",
      "   5  0.262450    0  0.268461    0  0.247606    0 0.331528    0  0.293103    0  0.192523   0 0.244767\n",
      "   0 -1.449340    0  0.167573    0 -0.007581    0 0.264257    0 -0.052347    0  0.585235   0 0.393682\n",
      "   0  0.575108    0  0.330119    0 -0.228698    0 0.350862    0  0.346712    0  0.258091   0 0.549308\n",
      "   0  0.575108    0  0.330119    0 -0.228698    0 0.331397    0  0.274331    0  0.192523   0 0.124934\n",
      "   1  1.658376    0  0.448636    0  1.896846    0 0.966852    0  0.559655    0  0.212848   1 0.789513\n",
      "   6  3.183840    3  1.851763    3  1.879533    3 0.881048    9  0.779018    1  0.332611   1 0.795511\n",
      "   0  0.193318    0  0.018143    0 -0.228698    0 0.331397    0  0.274331    0  0.192523   0 0.124934\n",
      "   1  1.279115    0  1.415581    0  2.299425    0 0.862278    0  0.814710    0  0.267157   1 1.182351\n",
      "   0  2.522157    1  1.851763    2  1.879533    0 0.875257    0  0.779018    0  0.363067   0 0.758912\n",
      "   0  2.703443    0  2.211377   21  2.155274    6 1.159101    3  0.779018    0  0.467436   0 0.865533\n",
      "   5  7.357042    9  5.758461    0  2.189635    0 1.585867    0  1.486195    0  0.968142   0 1.448468\n",
      "   8  4.649667    2  3.794479    0  2.299425    1 2.036608    4  1.292001    2  1.043697   4 1.267350\n",
      "   1  2.330923    1  1.375021    1  1.108653    0 0.907581    0  0.687865    0  0.267043   0 0.710983\n",
      "   2  1.994749    6  1.618881    0  1.403229    2 0.927045    0  0.760246    0  0.332611   0 0.710983\n",
      "   0  3.492545    0  2.693069    1  2.665939    0 1.520247    0  0.979707    0  0.517500   1 0.891049\n",
      "   2  3.492545    6  2.693069    2  2.665939    0 1.796222    0  1.008905    0  0.517500   1 1.340466\n",
      "   0  1.773059    0  0.775242    0  1.823122    0 1.074878    0  0.814710    0  0.267157   0 1.205354\n",
      "   0  3.357564    0  2.373203    0  1.403229    0 1.135233    0  0.779018    0  0.356561   0 0.853231\n",
      "   0  3.336321    0  2.373203    0  1.403229    0 0.927045    0  0.779018    0  0.332611   0 0.818514\n",
      "  26  3.197387    6  2.373203    0  1.403229    0 1.268402    0  0.779018    0  0.936505   0 0.888536\n",
      "   0  3.986489    5  3.415594    1  2.189635    0 1.796222    0  1.008905    0  0.517500   0 1.363469\n",
      "   6  1.658376    3  0.515123   36  2.172586   17 0.784435    1  0.559655    0  0.212848   1 0.789513\n",
      "   0  3.492545    0  2.693069    0  2.665939    0 1.520247    0  1.008905    0  0.517500   0 0.891049\n",
      "   2  4.649667   10  3.794479    4  2.299425    1 1.824009    3  1.292001    2  1.044250   1 1.267350\n",
      "   0  1.903837    1  1.578015    0  1.879533    0 1.058686    1  0.779018    0  0.363067   0 0.830229\n",
      "   4  2.703443    0  1.307613    1  2.155274    0 1.140133    0  0.808218    0  0.357054   2 0.865533\n",
      "   1 -0.097438    0  0.085973    0  0.835236    0 0.321599    0  0.146121    0  0.202809   0 0.203465\n",
      "   6  6.476840    1  5.790173   19  2.299425   11 1.914110   28  1.486195    5  1.043697   4 1.306285\n",
      "   0 -0.300626    0  0.018143    0  0.247606    1 0.350993    0  0.346712    0  0.258091   0 0.526305\n",
      "   0  5.472123    0  2.704880    0  2.299425    0 1.329135    0  1.292001    0  0.707487   0 1.143263\n",
      "   8  4.438227    4  2.540650   25  1.403229   16 0.876320    8  0.760246    1  0.332611   1 0.710983\n",
      "   0  3.986489    0  3.415594    0  2.189635    0 1.520247    0  0.979707    0  0.517500   0 0.914052\n",
      "   0  0.262450    1  0.268461    0  0.247606    0 0.350993    0  0.365484    0  0.288547   1 0.703859\n",
      "   0  0.081164    0  0.268461    0  0.247606    0 0.350993    0  0.365484    0  0.258091   0 0.562520\n",
      "   1  3.357564    3  2.373203    1  1.403229    0 1.123917    0  0.779018    0  0.356561   0 0.853231\n",
      "  22  5.143611   14  3.154139    3  1.823122    7 1.824009    0  1.292001    3  0.883666   1 1.290354\n",
      "   3  5.143611    9  3.154139    2  1.823122    9 1.824009    0  1.292001    0  0.883666   0 1.290354\n",
      "   1  3.853352    2  4.852853    1  2.468361    0 1.716176    0  1.008905    0  0.929348   0 1.363469\n",
      "  30  3.853352    0  2.968174    0  2.468361    1 1.876393    0  1.008905    0  0.598679   0 1.363469\n",
      "   3  6.285606    4  4.380028    6  1.528545    4 1.959087   10  1.486195    6  1.220022   5 1.753662\n",
      "   0  3.492545    0  2.693069    0  2.665939    0 1.520247    0  1.008905    1  0.517500   0 0.891049\n",
      "   0  4.649667    5  3.794479    0  2.299425    0 1.824009    1  1.292001    0  0.883666   0 1.267350\n",
      "   0  1.743660    0  1.192492    5  3.278140    0 1.301944    1  0.833420    2  0.357054   2 1.314950\n",
      "   0  1.144972    0  0.533018    0  2.390198    2 0.660526    0  0.614249    0  0.585235   2 0.869427\n",
      "   3  0.989350    1  0.845247    2  1.108653    0 0.927045    0  0.760246    0  0.332611   0 1.135357\n",
      "   4  2.703443    6  1.851763    2  1.879533   12 1.213988    4  0.779018    0  0.634224   0 0.865533\n",
      "   1  7.357042    0  5.758461    0  2.189635    2 1.470683    2  1.486195    0  0.303153   0 0.999052\n",
      "   0  0.262450    0 -0.154213    0  0.523347    0 0.331528    0  0.322302    0  0.222979   0 0.279485\n",
      "   0 -0.696413    0  1.435776    1  0.637659    0 0.321599    0  0.141849    0  0.585235   0 0.675884\n",
      "   0 -0.129670    0 -0.096275    0 -0.319470    0 0.252119    0  0.200486    0  0.098106   0 0.894076\n",
      "   0 -0.697332    0  0.219260    0  0.523347    3 0.331528    0  0.293103    0  0.192523   0 0.244767\n",
      "   0  2.703443    0  2.211377    0  2.155274    0 1.159101    0  0.779018    0  0.467436   0 0.865533\n",
      "   5  3.492545    2  2.693069    1  2.665939    2 1.796222    0  1.008905    0  0.517500   0 1.340466\n",
      "   2  6.476840    1  4.274721    2  2.299425    2 1.448066    1  1.486195    0  0.832493   5 1.425465\n",
      "   4  2.224057    9  1.578015    4  1.879533    1 0.881048    0  0.779018    6  0.332611   0 0.795511\n",
      "  12  3.359408    0  2.245649    0  2.944665    1 1.876393    0  1.008905    0  0.543403   0 1.340466\n",
      "  12  3.197387    9  2.933902    0  1.678970    0 1.154104    0  0.779018    0  0.445407   0 0.888536\n",
      "   2  2.397781    1  2.380675    6  1.403229   11 1.400212    1  0.779018   12  2.144627   3 0.853231\n",
      "   2  3.492545    5  2.693069    0  2.665939    0 1.520247    0  1.008905    0  0.517500   0 0.891049\n",
      "   0  0.431011    0  0.339943    0  1.328588    0 0.321599    0  0.113677    3  0.338611   0 0.305001\n",
      "   0  3.359408    0  2.245649    0  2.944665    2 1.876393    0  1.008905    0  0.543403   0 1.340466\n",
      "   0  2.807367    0  2.115031    1  2.371362    0 1.796222    0  1.008905    1  1.341089   1 1.764840\n",
      "   0  3.183840    0  1.851763    1  1.879533    0 0.881048    0  0.779018    1  0.332611   1 0.795511\n",
      "   3  2.954531    0  1.892629    0  1.403229    1 0.927045    0  0.760246    0  0.332611   0 0.710983\n",
      "   2  3.197387    2  2.933902    0  1.678970    0 1.295887    0  0.779018    0  0.445407   0 0.888536\n",
      "   0 -0.012154    0  0.573591    0  0.817924    0 0.350993    0  0.365484    0  0.288547   0 0.279485\n",
      "   1  3.492545    0  2.693069    2  2.665939    1 1.796222    0  1.008905    2  0.517500   0 1.340466\n",
      "   0 -0.771858    0 -0.251199    0 -0.024894    0 0.331474    0  0.200486    0  0.030647   0 0.559072\n",
      "   7  7.223905    5  7.472474    2  2.468361    0 1.448066    1  1.486195    0  1.008818   0 1.448468\n",
      "   1  3.986489    4  3.415594    0  2.189635    3 1.520247    0  0.979707    0  0.517500   2 0.914052\n",
      "   0  1.773059    0  0.775242    0  1.823122    0 0.862278    0  0.814710    0  0.267157   0 1.205354\n",
      "   1  1.903837    6  1.859235    3  1.879533    7 1.485835    0  0.779018    1  2.907626   0 0.830229\n",
      "   6  2.703443    1  1.851763    1  1.879533    0 1.191854    0  0.779018    0  0.634224   0 0.865533\n",
      "   0  3.853352    0  2.968174    0  2.468361    0 1.876393    0  1.008905    0  0.598679   0 1.363469\n",
      "   0 -0.443345    0 -0.140819    0  0.451410    0 0.273954    0  0.200486    0  0.098106   0 0.446699\n",
      "  11  3.359408   17  2.458188    2  2.944665    0 1.716176    2  1.008905    0  0.642964   0 1.340466\n",
      "   2  3.986489    0  3.415594    0  2.189635    0 1.520247    0  1.008905    0  0.517500   0 0.914052\n",
      "   9  1.455188    1  0.606984    2  1.584957    0 0.875257    0  0.760246    0  0.332611   0 1.112354\n",
      "   0  1.192538    0  0.432920    0  1.696283    0 0.619953    0  0.555383    0  0.585235   0 1.261933\n",
      "   0  3.853352    0  2.968174    0  2.468361    0 1.876393    0  1.008905    0  0.598679   0 1.363469\n",
      "  16  6.470976   12  3.708366    4  1.823122    4 1.984194    4  1.292001    2  0.707487   1 1.166266\n",
      "   1  2.237604    1  2.099455    0  1.403229    0 1.334842    0  0.779018    0  0.769716   0 0.888536\n",
      "   0  0.756394    0  0.108530    0  0.047043    0 0.349900    0  0.322302    0  0.192523   0 0.267770\n",
      "   1  3.492545    0  2.693069    5  2.665939    2 1.520247    1  1.008905    0  0.517500   1 0.891049\n",
      "   8  3.197387    2  2.373203    0  1.678970    1 1.154104    9  0.779018    1  0.445407   2 0.888536\n",
      "   0  3.492545    2  2.693069    1  2.665939    1 1.796222    0  1.008905    0  0.517500   0 1.340466\n",
      "   0  3.986489    0  3.415594    0  2.189635    0 1.520247    0  1.008905    1  0.517500   2 0.914052\n",
      "   0  3.986489    0  3.415594    0  2.189635    0 1.796222    0  1.008905    0  0.517500   0 1.363469\n",
      "   0  2.703443    0  2.211377    0  2.155274    2 1.279561    2  0.779018    3  0.467436   0 0.865533\n",
      "   0  3.197387    1  2.933902    0  1.678970    2 1.154104    0  0.779018    0  0.445407   0 0.888536\n",
      "   2  2.201125    4  1.697140    5  1.403229    6 0.932837    0  0.779018    0  0.332611   2 0.818514\n",
      "   4  3.853352    8  2.968174    3  2.468361    6 1.876393    0  1.008905    1  0.598679   0 1.363469\n",
      "  13  3.986489    1  3.415594    2  2.189635    3 1.796222    2  1.008905    0  0.517500  42 1.363469\n",
      "   0  1.279115    1  1.415581    0  2.299425    0 1.828869    0  1.235378    0  0.427188   0 1.221286\n",
      "   0  4.649667    0  3.794479    0  2.299425    0 2.036608    0  1.712668    0  1.043697   0 1.306285\n",
      "   0 -0.377112    0  0.421752    1  0.523347    1 0.331528    0  0.322302    0  0.112597   0 0.244767\n",
      "   0 -0.450344    0 -0.209802    0 -0.024894    0 0.319744    0  0.200486    0  0.098106   0 0.469702\n",
      "   1  1.743660    0  1.918231    1  3.278140    1 1.780145    2  0.804220    0  0.467436   0 0.865533\n",
      "   2  5.143611    6  3.362961    3  1.823122    4 1.824009    3  1.292001    0  1.126429   2 1.290354\n",
      "   0  2.598699    0  0.766820    0  1.913894    0 0.782583    0  0.614249    0  0.367634   0 0.963747\n",
      "   2  3.197387    1  2.373203    3  1.678970    1 1.154104    0  0.779018    0  0.445407   5 0.888536\n",
      "   2  1.279115    1  1.415581    0  2.299425    3 0.862278    0  0.814710    0  0.267157   0 1.182351\n",
      "   0  3.301311    0  2.665237    0  1.895058    0 1.441348    2  0.936526    0  0.451932   0 1.363469\n",
      "   6  3.853352    6  4.852853    4  2.468361    6 1.716176    1  1.008905    1  0.929348   0 1.363469\n",
      "   0  0.575108    0  0.330119    0 -0.228698    1 0.331397    0  0.293103    0  0.192523   0 0.232465\n",
      "  37  7.223905   21  7.472474    0  2.468361    0 1.448066    1  1.486195    0  1.008818   0 1.448468\n",
      "   0  3.853352    1  3.497502    2  2.468361    4 1.482718    4  1.008905    0  0.929348   0 1.363469\n",
      "   8  6.476840    8  5.790173    3  2.299425    1 1.914110    1  1.486195    0  1.043697   0 1.306285\n",
      "   0  0.081164    1  0.268461    0  0.247606    0 0.350993    0  0.365484    0  0.258091   0 0.562520\n",
      "   3  5.143611    9  3.154139    3  1.823122    6 1.824009    1  1.292001    1  0.883666   1 1.290354\n",
      "   3  1.272119    1 -0.601464   42  1.806073    8 0.837980    1  0.555383    8  0.254601  11 1.238930\n",
      "   0  1.658376    0  0.515123    0  2.172586    1 0.780703    0  0.555383    0  0.212848   0 0.789513\n",
      "   0  0.877196    0  1.193300    1  2.707823    2 2.302388    0  0.785448    0  0.332611   1 1.112354\n",
      "   0  0.582670    0  0.268461    0  0.247606    0 0.331528    0  0.293103    0  0.192523   0 0.244767\n",
      "   1  3.197387    0  2.559977    0  1.678970    3 1.295887    0  0.779018    0  0.445407   3 0.888536\n",
      "  44  3.600232   20  1.974028    9  1.823122    5 1.341458    5  1.008905    1  0.929348   1 1.244289\n",
      "   2  0.989350    1  1.061848    0  2.231519    0 2.302388    0  0.785448    0  0.332611   0 1.135357\n",
      "   0  2.237604    0  2.380675    0  1.403229    3 1.991502    8  0.779018    5  1.654922   0 0.888536\n",
      "   0  1.773059    0  0.775242    0  1.823122    0 1.074878    0  0.814710    0  0.267157   0 1.205354\n",
      "   3  2.703443    3  2.211377   14  2.155274    5 1.279561    4  0.779018    0  0.467436   2 0.865533\n",
      "   0  1.882750    0  1.299738   23  2.944665   10 1.153969    1  1.008905    0  0.642964   1 1.340466\n",
      "   0 -0.035086    0  0.405253    0  0.065879    0 0.369365    0  0.365484    0  0.590827   2 0.302488\n",
      "   0  0.298778    0  0.073010    0  1.017880    0 0.981426    0  0.962309    0  0.188661   0 1.218773\n",
      "   1  3.986489    1  3.415594    6  2.189635    4 1.520247    0  1.008905    0  0.517500   0 0.914052\n",
      "   0  3.986489    0  3.415594    1  2.189635    0 1.520247    8  1.008905    0  0.517500   0 0.914052\n",
      "   0 -1.260408    0 -0.031058    0  0.247606    0 0.350993    0  0.346712    0  0.258091   0 0.526305\n",
      "   5  3.357564    2  2.373203    0  1.403229    0 1.123917    0  0.779018    0  0.356561   0 0.853231\n",
      "   7  4.649667    6  3.794479    0  2.299425    2 2.036608    0  1.712668    0  1.043697   0 1.306285\n",
      "   1  1.658376    0  0.515123    0  2.172586    0 0.729609    0  0.555383    0  0.212848   0 1.238930\n",
      "   0  3.853352    0  2.968174    0  2.468361    0 1.876393    1  1.008905    0  0.598679   0 1.363469\n",
      "   6  3.986489    4  3.415594    1  2.189635    0 1.520247    0  1.008905    0  0.517500   0 0.914052\n",
      "   0  4.118007    0  1.992568    0  1.403229    1 0.927045    0  0.760246    0  0.356561   1 0.745700\n",
      "  19  4.820016   15  3.410518    0  1.403229    9 0.927045    1  0.760246    2  0.332611   0 0.710983\n",
      "   0  2.237604    0  2.095102    6  1.678970    1 0.916462    0  0.808218    0  0.357054   0 0.888536\n",
      "   0  3.986489    0  3.415594    0  2.189635    0 1.796222    0  1.008905    1  0.517500   0 1.363469\n",
      "   0  3.492545    4  2.693069    2  2.665939    2 1.520247    2  1.008905    0  0.517500   0 0.891049\n",
      "   0  2.863620    1  1.851763   11  1.879533    1 1.053625    0  0.779018    2  0.363067   1 0.830229\n",
      "   1  7.357042    4  5.758461    1  2.189635    1 1.470683    0  1.486195    0  0.303153   0 0.999052\n",
      "  16  7.357042    8  5.758461    0  2.189635    0 1.470683    1  1.486195    0  0.303153   0 0.999052\n",
      "   0  2.703443    0  1.851763    1  1.879533    1 1.121214    1  0.779018    0  0.467436   0 0.865533\n",
      "   4  3.853352    2  3.497502    0  2.468361    0 1.482718    0  1.008905    1  0.929348   3 1.363469\n",
      "   0  1.312470    0  0.095337    0  1.788761    0 0.277171    0  0.614021    0  0.174170   0 1.032748\n",
      "   4  2.512208    3  2.323577    0  1.384394    3 1.304630    6  0.779018   12  0.784066   1 1.312911\n",
      "   6  3.986489   27  3.415594    6  2.189635    6 1.520247    7  0.979707    6  0.517500   2 0.914052\n",
      "   0  3.100424    0  0.984064    0  1.823122    0 1.469254    0  0.814710    0  0.334616   0 1.205354\n",
      "   1  2.330923    1  1.375021    0  1.108653    0 0.927045    0  0.779018    1  0.332611   0 1.171572\n",
      "   0  3.197387    1  2.373203    0  1.403229    0 1.268402    0  0.779018    0  0.936505   0 0.888536\n",
      "   0  4.649667    4  3.794479    1  2.299425    4 1.824009    0  1.292001    0  0.883666   0 1.267350\n",
      "   2  2.703443    4  1.851763    0  2.155274    1 1.159101    0  0.779018    0  0.467436   2 0.865533\n",
      "   3  3.359408    1  2.245649    2  2.944665    2 1.876393    0  1.008905    0  0.543403   2 1.340466\n",
      "   4  3.359408    0  2.245649    3  2.944665    1 1.876393    0  1.008905    0  0.543403   0 1.340466\n",
      "  11  2.703443    1  1.851763    2  1.879533    0 1.121214    2  0.779018    0  0.467436   2 0.865533\n",
      "   0  0.742847    0  0.268461    0  0.247606    0 0.331528    0  0.293103    0  0.192523   0 0.209463\n",
      "   1  1.743660    0  1.578015    7  3.002400    9 1.591318    0  0.804220    1  0.634224   0 0.865533\n",
      "   5  1.500805    0  1.159099    1  3.002400    0 2.302388    0  0.785448    0  0.332611   0 0.687980\n",
      "   2  3.183840    2  1.851763    1  1.879533    0 0.881048    1  0.779018    0  0.332611   0 0.795511\n",
      "  22  3.197387   12  2.933902    8  1.678970   11 1.295887   15  0.779018    1  0.445407   2 0.888536\n",
      "   0  3.064250    0  1.829939    1  1.957697    0 1.434024    0  0.808218    0  0.438233   0 1.337953\n",
      "   0  0.575108    0  0.330119    0 -0.228698    0 0.331397    4  0.293103    0  0.192523   3 0.161149\n",
      "   0  0.815626    0  0.557783    0  1.584957    2 0.875257    0  0.760246    0  0.332611   0 1.112354\n",
      "   0  2.703443    0  1.307613    4  2.155274    2 1.140133    0  0.808218    1  0.357054   0 0.865533\n",
      "   0  3.600232    0  1.974028    0  1.823122    0 1.341458    1  1.008905    0  0.929348   2 1.244289\n",
      "   4  6.476840    0  6.092160    0  2.299425    0 2.133220    1  1.712668    0  1.043697   0 1.306285\n",
      "   4  1.525239    0  0.861951    6  2.451313    3 0.837980    0  0.555383    1  0.254601   3 1.238930\n",
      "  13  8.659450    5  4.786130    4  1.913894    3 1.110315    0  1.438224    0  0.367634   1 0.856215\n",
      "   2  3.100424    5  0.984064    4  1.823122    1 0.711230    1  0.814710    1  0.334616   0 1.081267\n",
      "   0  2.446218    2  0.532843    6  2.390198    4 0.782583    0  0.614249    0  0.367634   0 0.940744\n",
      "   0  6.970785    0  6.530902    1  1.823122    1 1.914110    0  1.486195    0  1.220022   0 1.329288\n",
      "   0  0.370137    0  0.232338    0 -0.319470    0 0.311831    0  0.322302    0  0.112597   4 0.632724\n",
      "   0  0.262450    0 -0.027863    0  0.523347    0 0.331528    0  0.322302    0  0.112597   0 0.728901\n",
      "   0  3.197387    0  2.030138    0  1.678970    0 1.156459    0  0.808218    0  0.357054   0 0.888536\n",
      "   0  3.197387    0  1.903789    0  1.678970    0 1.027738    0  0.808218    0  0.445407   0 0.888536\n",
      "  23  4.649667   13  3.794479    1  2.299425    1 2.036608    1  1.292001    0  1.043697   0 1.267350\n",
      "   2  3.986489    5  3.415594    1  2.189635    5 1.520247    0  1.008905    0  0.517500   1 0.914052\n",
      "   0  3.100424    0  0.984064    0  1.823122    0 1.469254    0  0.814710    1  0.334616   0 1.205354\n",
      "   0 -0.300626    0  0.018143    0  0.247606    0 0.350993    0  0.346712    0  0.258091   0 0.526305\n",
      "   0 -0.300626    0  0.018143    0  0.247606    1 0.350993    0  0.346712    0  0.258091   0 0.526305\n",
      "   0  0.575108    0  0.330119    0 -0.228698    0 0.350862    0  0.346712    0  0.258091   0 0.549308\n",
      "   1  3.986489    1  3.415594    3  2.189635    0 1.796222    0  1.008905    0  0.517500   1 1.363469\n",
      "   0  0.081164    0  0.268461    0  0.247606    0 0.350993    0  0.365484    0  0.258091   0 0.562520\n",
      "   0 -0.697332    0  0.219260    0  0.247606    0 0.331528    0  0.293103    0  0.192523   0 0.244767\n",
      "  27  3.986489    1  3.415594    0  2.189635    0 1.520247    1  1.008905    1  0.517500   2 0.914052\n",
      "   2  6.970785    2  6.530902    3  1.823122    8 1.914110    1  1.486195    1  1.220022   3 1.329288\n",
      "   0  3.853352    0  2.968174    0  2.468361    0 1.876393    0  1.008905    0  0.598679   0 1.363469\n",
      "   0  2.237604    5  2.099455    0  1.403229    0 1.306899    0  0.779018    0  0.936505   1 0.888536\n",
      "   3  3.197387   11  2.373203   13  1.678970   14 1.154104    9  0.779018    1  0.445407   3 0.888536\n",
      "   0  0.983956    0  0.203154    0  1.312457    0 0.419908    0  0.614021    0  0.106711   0 1.179838\n",
      "   0  3.492545    0  2.693069    0  2.665939    0 1.796222    0  1.008905    0  0.517500   0 1.340466\n",
      "   0  2.703443    0  1.851763    0  1.879533    1 1.213988    0  0.779018    0  0.634224   0 0.865533\n",
      "   3  4.820016    0  3.410518    0  1.403229    4 0.927045    0  0.760246    0  0.332611   0 0.710983\n",
      "   0  2.056319    0  2.380675    1  1.403229    0 1.400212    2  0.779018    3  2.144627   0 0.853231\n",
      "   0  3.853352    0  2.968174    0  2.468361    0 1.876393    0  1.008905    0  0.598679   0 1.363469\n",
      "   0  2.101572    1  0.225160    0  2.299425    0 0.367404    0  0.814710    0  0.334616   2 1.058264\n",
      "   0  3.197387    0  2.373203    0  1.403229    0 1.290535    0  0.779018    0  0.769716   0 0.888536\n",
      "   0  3.064250    0  1.829939    0  1.957697    0 1.434024    0  0.808218    0  0.438233   0 1.337953\n",
      "   0 -1.777284    0 -0.031058    0  0.247606    0 0.350993    0  0.346712    0  0.258091   0 0.526305\n",
      "   0  2.863620    0  1.851763    0  1.879533    0 1.058686    0  0.779018    0  0.363067   3 0.830229\n",
      "  10  3.197387    0  2.373203    0  1.403229    0 1.268402    0  0.779018    0  0.936505   0 0.888536\n",
      "   0  3.986489    0  3.415594    1  2.189635    1 1.520247    0  1.008905    0  0.517500   0 0.914052\n",
      "   0  3.064250    0  1.829939    1  1.957697    0 1.434024    1  0.808218    1  0.438233   0 1.337953\n",
      "   1  3.197387    3  2.373203    0  1.403229    1 1.290535    0  0.779018    0  0.936505   0 0.888536\n",
      "   0  3.359408    0  2.245649    0  2.944665    0 1.876393    0  1.008905    0  0.543403   0 1.340466\n",
      "   0  2.399626    0  1.640394    0  4.067532    0 1.315181    0  1.034106    1  0.642964   0 1.340466\n",
      "   0 -0.492445    1  0.018778    1  1.823122    2 2.795036    1  0.782883    2  0.585235   2 1.244289\n",
      "   1  3.986489    8  3.415594    5  2.189635    6 1.520247    1  0.979707    0  0.517500   0 0.914052\n",
      "   0  1.552426    0  1.147143    0  1.384394    0 0.987703    0  0.735837    0  0.291486   0 1.337953\n",
      "   2  3.986489    3  3.415594   12  2.189635    6 1.520247    1  0.979707    0  0.517500   0 0.914052\n",
      "   0  1.386961    1  1.237358    2  1.879533    0 1.058686    0  0.779018    0  0.363067   0 0.830229\n",
      "   1  4.649667    1  3.794479    1  2.299425    0 2.036608    1  1.712668    0  1.043697   1 1.306285\n",
      "   2  1.949133    1  0.894448    0  1.108653    0 0.927045    3  0.760246    0  0.332611   1 1.135357\n",
      "   1  1.720729    0  0.767468    0  1.678970    0 1.013627    0  0.808218    0  0.445407   3 0.888536\n",
      "   0 -0.697332    0  0.219260    0  0.247606    0 0.350993    0  0.365484    0  0.258091   0 0.669142\n",
      "   0  0.176433    0  0.788858    0  1.806073    0 0.853273    0  0.781856    0  0.254601   0 1.119750\n",
      "   3  7.223905    0  5.096767    4  2.468361    0 1.666038    0  1.486195    0  2.690587   2 1.448468\n",
      "   7  2.512208   13  1.153432    0  1.384394    3 1.286167    8  0.808218    0  0.784066   1 1.312911\n",
      "   0  3.986489    3  2.230330    0  2.189635    3 1.378464    1  0.979707    0  0.517500   0 0.914052\n",
      "   0  3.492545    0  2.693069    0  2.665939    0 1.520247    0  1.008905    0  0.517500   0 0.891049\n",
      "   0  0.081164    0  0.268461    0  0.247606    0 0.331528    0  0.274331    0  0.192523   0 0.101931\n",
      "   0  2.703443    2  1.851763    1  1.879533    0 1.191854    0  0.779018    0  0.634224   0 0.865533\n",
      "   6  3.853352    3  2.968174    2  2.468361    0 1.876393    0  1.008905    0  0.598679   0 1.363469\n",
      "   0  6.970785    2  6.530902    0  1.823122    5 2.133220    0  1.712668    0  1.220022   0 1.329288\n",
      "   4  5.966068    0  2.635898    0  1.823122    0 1.329135    0  1.292001    0  0.707487   0 1.166266\n",
      "   1  4.183828    2  2.672695    0  1.823122    0 2.426405    0  1.292001    0  1.060333   0 1.290354\n",
      "   1  3.183840    0  1.851763    0  1.879533    3 0.881048    0  0.779018    0  0.332611   1 0.795511\n",
      "   0  4.998256    1  2.635898    0  1.823122    1 1.329135    0  1.292001    0  0.707487   0 1.166266\n",
      "   0  0.193318    0  0.018143    0 -0.228698    0 0.331397    0  0.274331    0  0.192523   0 0.124934\n",
      "   0  2.703443    2  1.851763    1  1.879533    0 1.213988    0  0.779018    0  0.634224   0 0.865533\n",
      "   0 -0.718027    0  0.134391    0  0.758271    0 0.321599    0  0.181943    0  0.293114   0 0.671538\n",
      "   9  3.986489    5  3.415594   40  2.189635   11 1.796222    7  1.008905    1  0.517500   0 1.363469\n",
      "   3  0.806281    0  1.137452    0  1.329769    2 0.760114    0  0.555383    0  0.585235   0 1.142753\n",
      "   3  3.197387    1  2.373203    0  1.403229    0 1.290535    1  0.779018    0  0.936505   0 0.888536\n",
      "  13  3.986489    1  3.415594    5  2.189635    3 1.796222   11  1.008905    0  0.517500   0 1.363469\n",
      "   0 -1.260408    0 -0.031058    0  0.247606    1 0.350993    0  0.346712    0  0.258091   0 0.526305\n",
      "   0  1.818553    3  0.448636    0  1.896846    0 0.955160    0  0.559655    0  0.277329   0 0.754209\n",
      "   0  1.882750    0  1.087199    0  2.944665    0 1.207189    0  1.008905    0  0.543403   0 1.340466\n",
      "   0  5.143611    0  3.154139    0  1.823122    2 1.824009   10  1.292001    1  0.883666   0 1.290354\n",
      "   0  3.197387    0  2.933902    0  1.678970    0 1.295887    0  0.779018    3  0.445407   0 0.888536\n",
      "   0  3.197387    3  2.373203   25  1.678970    4 1.154104   13  0.779018    1  0.445407   1 0.888536\n",
      "   0 -0.224083    0  0.134391    0  0.281967    1 0.270873    1  0.181943    0  0.293114   0 0.694541\n",
      "   0  2.703443    0  1.181264    0  2.155274    0 1.011412    0  0.779018    0  0.467436   0 0.865533\n",
      "  44  3.944282    1  2.457463    0  1.879533    0 0.875257    0  0.760246    0  0.332611   0 0.687980\n",
      "   2  2.532763    3  2.786178    0  2.390198    1 0.990029    0  0.979707    0  0.684289   0 0.891049\n",
      "   0  4.458433    0  2.632618    0  1.528545    1 2.036608    0  1.712668    8  1.220022   0 1.753662\n",
      "   0  2.915054    0  1.178643    4  1.528545    0 1.341458    0  1.008905    0  0.819167   0 1.668663\n",
      "   0 -0.203388    0  0.280919    0 -0.228698    0 0.349900    0  0.293103    0  0.192523   0 0.267770\n",
      "   0 -1.183866    0  0.172647    0  0.281967    0 0.302134    0  0.109562    1  0.585235   0 0.270167\n",
      "   3  2.703443   12  2.211377    2  2.155274    0 1.279561    0  0.779018    0  0.467436   1 0.865533\n",
      "   1  3.492545    1  2.693069    0  2.665939    2 1.796222    1  1.008905    0  0.517500   0 1.340466\n",
      "   0  3.492545    1  2.693069    0  2.665939    0 1.796222    0  1.008905    0  0.517500   0 1.340466\n",
      "  10  3.624061    5  1.909381    4  1.879533    3 0.875257    0  0.760246    0  0.363067   1 0.722697\n",
      "   2  1.743660    4  1.918231    5  3.278140    1 1.780145    2  0.804220    0  0.467436   2 0.865533\n",
      "   4  1.903837    5  1.578015    2  3.002400    0 1.591318    0  0.804220    0  0.363067   0 0.830229\n",
      "   0  2.703443    0  1.307613    0  2.155274    1 1.416109    0  0.808218    0  0.357054   0 1.314950\n",
      "   2  6.970785    3  6.530902   98  1.823122   32 1.959087    5  1.486195    1  1.220022   1 1.329288\n",
      "   0  3.986489    4  3.415594    0  2.189635    0 1.520247    0  1.008905    0  0.517500   0 0.914052\n",
      "   0  3.197387    0  2.373203    1  1.403229    1 1.268402    2  0.779018    1  0.936505   2 0.888536\n",
      "   2  3.492545    2  2.693069    0  2.665939    0 1.796222    0  1.008905    3  0.517500   0 1.340466\n",
      "   0  3.492545    1  1.708889    0  2.390198    0 1.294583    0  0.979707    0  0.684289   2 0.891049\n",
      "   1  3.183840    2  1.851763    3  1.879533    0 0.881048    1  0.779018    2  0.332611   2 0.795511\n",
      "   0  3.026707    0  2.396716    4  2.189635    0 7.792132    0  1.008905    3 11.063620   0 1.363469\n",
      "  31  3.853352   19  4.852853    2  2.468361    0 1.716176    3  1.008905    4  0.929348   1 1.363469\n",
      "   0  3.197387    0  2.373203    0  1.678970    0 1.154104    0  0.779018    3  0.445407   0 0.888536\n",
      "   3  3.359408    2  1.939853    5  2.944665    0 1.482718    0  1.008905    8  0.642964   5 1.340466\n",
      "  26  5.143611   11  3.154139    4  1.823122    9 2.036608    0  1.712668    7  1.220022   4 1.329288\n",
      "   0 -2.776707    0 -0.219229    0 -0.007581    0 0.321777    0  0.368321    0  0.585235   0 0.556704\n",
      "  14  7.357042   14  5.758461    0  2.189635   13 1.585867    0  1.486195    0  0.968142   0 1.448468\n",
      "   0  3.492545    1  2.693069    0  2.665939    0 1.796222    0  1.008905    0  0.517500   0 1.340466\n",
      "   0  2.863620    0  1.851763    0  1.879533    2 1.053625    1  0.779018    0  0.363067   0 0.830229\n",
      "   0  1.279115    0  1.415581    0  2.299425    9 1.074878    0  0.814710    0  0.427188   0 1.182351\n",
      "   0  3.492545    2  2.693069    0  2.665939    0 1.520247    0  1.008905    0  0.517500   0 0.891049\n",
      "   0  0.081164    0  0.268461    0  0.247606    0 0.350993    0  0.346712    0  0.258091   0 0.526305\n",
      "   0  3.197387    1  2.373203    0  1.403229    0 1.290535    0  0.779018    0  0.936505   0 0.888536\n",
      "   2  1.180584    6  1.440319    1  1.879533    2 1.466793    0  0.760246    0  4.371252   0 0.722697\n",
      "   1  3.197387    0  2.373203    0  1.403229    0 1.154104    0  0.779018    0  0.769716   0 0.888536\n",
      "   0  3.026707    4  2.396716    1  2.189635    3 7.792132    1  1.008905    0 11.063620   1 1.363469\n",
      "   0  0.690404    0  0.170180    0  1.052847    0 0.321599    0  0.200715    0  0.293114   0 0.354695\n",
      "   1  3.336321    0  2.373203    0  1.403229    0 0.927045    0  0.779018    0  0.332611   0 0.818514\n",
      "   0  0.193318    0  0.018143    0 -0.228698    0 0.331397    3  0.274331    0  0.192523   0 0.124934\n",
      "   1  2.842377    0  1.851763    0  1.879533    0 0.875257    0  0.779018    0  0.332611   0 0.724195\n",
      "   0  1.226784    0  1.233006    2  2.155274    3 1.126021    0  0.808218    0  0.357054   1 0.865533\n",
      "   0  3.492545    1  2.693069    3  2.665939    0 1.520247    0  1.008905    0  0.517500   2 0.891049\n",
      "   0  1.773059    0  0.775242    0  1.823122    0 1.392264    0  1.235378    0  0.482463   0 1.244289\n",
      "   0  3.197387    1  2.373203    0  1.678970    0 1.154104    0  0.779018    0  0.445407   0 0.888536\n",
      "   1  2.237604    1  2.099455    0  2.801836    0 1.780145    3  0.804220    0  0.445407   0 0.888536\n",
      "   2  6.729960    0  6.202289    2  2.944665    7 1.465338    5  1.486195   11  1.150960  12 1.425465\n",
      "   1  3.359408    0  2.458188    0  2.944665    0 1.716176    0  1.008905    0  0.642964   0 1.340466\n",
      "   1 -0.061110    0  0.148518    0  1.329769    0 0.853273    0  0.361188    0  0.094571   0 1.103818\n",
      "   7  1.743660    3  1.578015    1  3.278140    5 1.780145    0  0.804220    1  0.467436   3 0.865533\n",
      "   1  3.492545    1  2.693069    0  2.665939    0 1.520247    0  0.979707    2  0.517500   0 0.891049\n",
      "   2  3.197387    0  2.373203    0  1.403229    0 1.154104    0  0.779018    0  0.769716   0 0.888536\n",
      "   1  0.193318    0  0.018143    0 -0.228698    0 0.331397    0  0.274331    0  0.192523   0 0.124934\n",
      "   0  2.460587    0  1.432848    0  1.879533    0 0.824531    0  0.760246    0  0.332611   0 0.687980\n",
      "   0  0.193318    0  0.018143    0 -0.228698    0 0.300136    0  0.346712    0  0.258091   1 0.549308\n",
      "   3  7.783716    0  4.780808    0  2.390198    1 1.059589    0  1.438224    1  0.367634   0 0.833212\n",
      "   0  2.863620    1  1.851763    1  1.879533    0 1.058686    0  0.779018    0  0.363067   1 0.830229\n",
      "   1  0.756394    0  0.330119    0 -0.228698    1 0.349900    0  0.293103    0  0.192523   0 0.267770\n",
      "   0  3.359408    0  2.245649    0  2.944665    0 1.876393    0  1.008905    0  0.543403   0 1.340466\n",
      "   0  1.773059    0  0.775242    0  1.823122    0 1.074878    0  0.814710    0  0.267157   0 1.205354\n",
      "   0 -0.300626    0  0.018143    1  0.247606    0 0.300268    0  0.346712    0  0.258091   0 0.526305\n",
      "  16  3.853352    4  2.968174    0  2.468361    2 1.876393    0  1.008905    0  0.598679   0 1.363469\n",
      "   0 -0.450344    0  0.098183    0 -0.024894    0 0.281987    0  0.200486    0  0.098106   0 0.469702\n",
      "   0  3.986489    0  3.415594    0  2.189635    0 1.520247    0  1.008905    1  0.517500   0 0.914052\n",
      "   3  6.476840    4  5.790173    0  2.299425    0 1.914110    0  1.486195    1  1.043697   0 1.306285\n",
      "   1  3.853352    0  2.968174    0  2.468361    0 1.876393    0  1.008905    0  0.598679   0 1.363469\n",
      "   1  1.949133    0  0.894448    2  1.108653    1 0.942292    1  0.687865    0  0.267043   0 0.710983\n",
      "   4  3.986489    1  3.415594    0  2.189635    0 1.520247    2  1.008905    0  0.517500   0 0.914052\n",
      "   0  0.129313    0 -0.228063    0  0.802073    0 0.311831    0  0.322302    0  0.112597   0 0.694184\n",
      "   1  2.018264    0  1.025899    3  1.584957    0 1.191854    1  0.779018    0  0.806095   0 1.289908\n",
      "   0  0.983929    0  1.159099    0  1.879533    1 0.875257    0  0.760246    0  0.332611   0 0.687980\n",
      "   3  2.634311    0  1.892629    0  1.403229    0 0.876320    0  0.760246    0  0.356561   0 0.745700\n",
      "   3  3.600232    0  1.545986    0  1.823122    0 1.482718    0  1.008905    0  0.929348   2 1.363469\n",
      "   5  8.659450    1  4.786130    0  1.913894    1 1.110315    0  1.438224    1  0.367634   0 0.856215\n",
      "   2  3.197387    0  2.373203    0  1.403229    0 1.290535    0  0.779018    0  0.769716   0 0.888536\n",
      "   0 -0.203388    0  0.280919    0 -0.228698    0 0.349900    0  0.293103    0  0.192523   0 0.267770\n",
      "   0  2.718002    0  2.099455    1  1.403229    0 0.932837    0  0.779018    0  0.332611   0 0.818514\n",
      "   1  2.842377    8  1.851763    2  1.879533    1 0.875257    0  0.779018    0  0.332611   0 0.795511\n",
      "   1  3.357564    6  2.373203    5  1.403229    3 1.123917    0  0.779018    0  0.356561   0 0.853231\n",
      "   0  3.197387    0  2.373203    0  1.403229    0 1.268402    0  0.779018    0  0.936505   0 0.888536\n",
      "   0  3.624061    5  1.909381    1  1.879533    0 0.875257    1  0.760246    0  0.363067   0 0.722697\n",
      "  14  3.986489    6  3.415594    9  2.189635    1 1.796222    2  1.008905    0  0.517500   1 1.363469\n",
      "   0  3.986489    0  3.415594    0  2.189635    0 1.796222    0  1.008905    0  0.517500   0 1.363469\n",
      "   0  3.357564    0  2.373203    0  1.403229    0 1.135233    0  0.779018    0  0.356561   0 0.853231\n",
      "  10  3.197387    6  2.933902    0  1.678970    0 1.295887    0  0.779018    0  0.445407   0 0.888536\n",
      "   0  3.197387    0  2.373203    0  1.403229    0 1.290535    0  0.779018    0  0.769716   0 0.888536\n",
      "   2  3.357564    0  2.373203    6  1.403229    2 1.123917    2  0.779018    3  0.356561   0 0.853231\n",
      "   0  2.703443    0  1.851763    0  1.879533    0 1.191854    0  0.779018    0  0.634224   0 0.865533\n",
      "   0  0.262450    0  0.268461    0  0.247606    1 0.331528    0  0.293103    0  0.192523   0 0.244767\n",
      "   0 -0.563276    0  0.358206    0  0.083191    0 0.321599    2  0.146121    0  0.585235   0 0.226468\n",
      "   1  3.492545    1  1.708889    0  2.390198    0 1.323443    0  0.979707    0  0.517500   0 0.891049\n",
      "   0 -0.917212    0 -0.209802    0 -0.024894    0 0.273954    0  0.200486    0  0.098106   1 0.469702\n",
      "   0  1.627704    0  0.156178    1  1.823122    0 0.367404    0  0.814710    0  0.334616   0 1.081267\n",
      "  15  5.143611    3  3.154139    5  1.823122    3 2.036608    0  1.712668    0  1.220022   2 1.329288\n",
      "   0 -0.097438    0  0.152459    0  0.835236    0 0.321599    0  0.175320    0  0.202809   0 0.203465\n",
      "   2  3.197387    4  2.373203    0  1.403229    0 1.290535    0  0.779018    0  0.936505   0 0.888536\n",
      "   0  3.677784    2  2.373203    0  1.403229    1 0.932837    2  0.779018    1  0.332611   0 0.818514\n",
      "   0  2.703443    0  1.851763    0  1.879533    0 1.191854    0  0.779018    1  0.634224   0 0.865533\n",
      "   1  3.492545    1  2.693069    0  2.665939    0 1.520247    0  1.008905    2  0.517500   1 0.891049\n",
      "   0  0.582670    0  0.268461    0  0.247606    0 0.331528    0  0.293103    0  0.192523   0 0.244767\n",
      "   0  1.552426    0  1.325821    0  1.384394    0 1.120528    0  0.706637    0  0.379839   0 0.888536\n",
      "   0  2.532763    0  2.256445    7  3.788805   15 1.329273    4  1.034106    2  0.517500   1 0.891049\n",
      "   0  1.365718    3  1.237358    1  1.879533    0 0.875257    0  0.779018    0  0.332611   0 0.724195\n",
      "   0  2.703443    0  1.851763    0  1.879533    0 1.213988    0  0.779018    0  0.467436   0 0.865533\n",
      "   0  3.853352    0  2.968174    0  2.468361    1 1.876393    1  1.008905    0  0.598679   1 1.363469\n",
      "   0  2.703443    0  1.851763   11  1.879533   32 1.213988    3  0.779018    2  0.467436   0 0.865533\n",
      "   0 -0.696413    0  1.435776    0  0.637659    0 0.321599    0  0.141849    0  0.585235   0 0.675884\n",
      "   2  3.986489    1  2.230330    0  2.189635    0 1.378464    0  0.979707    0  0.517500   0 0.914052\n",
      "   0  1.743660    0  1.578015    0  2.155274    1 1.144989    1  0.779018    4  0.467436   1 0.865533\n",
      "   0  3.357564    1  2.373203    1  1.403229    0 1.123917    2  0.779018    0  0.356561   0 0.853231\n",
      "   2  2.330923    1  1.375021    0  1.108653    1 0.907581    0  0.706637    0  0.267043   0 0.747198\n",
      "   0 -0.129670    0 -0.096275    0 -0.319470    0 0.250565    0  0.128106    0  0.112597   0 0.434985\n",
      "  17  2.915054    6  1.178643   13  1.528545    4 1.296481    0  1.008905    0  0.372281   0 1.668663\n",
      "   0  2.863620    0  1.851763    0  1.879533    0 0.995238    0  0.779018    0  0.363067   1 0.830229\n",
      "   0  3.197387    0  2.030138    0  1.678970    0 1.432434    0  0.808218    0  0.357054   0 1.337953\n",
      "  18  2.703443   18  1.851763    1  1.879533    2 1.121214    3  0.779018    1  0.467436   0 0.865533\n",
      "   0  0.081164    1  0.268461    0  0.247606    2 0.350993    0  0.346712    0  0.258091   0 0.526305\n",
      "   6  6.863097    4  5.323399    2  2.665939    0 1.470683    8  1.456996    0  0.303153   2 0.976049\n",
      "   0 -0.224083    0  0.134391    0  0.281967    0 0.302134    0  0.109562    0  0.227546   0 0.270167\n",
      "   5  3.986489    3  3.415594    0  2.189635    0 1.796222    0  1.008905    0  0.517500   0 1.363469\n",
      "   0  1.903837    1  1.578015    1  3.002400    2 1.591318    1  0.804220    3  0.363067   1 0.830229\n",
      "   0  0.193318    0  0.018143    0 -0.228698    0 0.331397    0  0.274331    0  0.192523   0 0.124934\n",
      "  14  7.223905   14  7.472474    3  2.468361    9 1.448066    1  1.486195    2  1.008818   1 1.448468\n",
      "   0  1.455188    2  0.606984    0  1.584957    0 0.855792    0  0.687865    0  0.267043   0 0.687980\n",
      "   3  6.970785    8  5.015450    6  1.823122    0 1.448066    1  1.486195    1  1.008818   0 1.329288\n",
      "   0  2.399626    2  1.427855    4  4.067532    3 1.282995    0  1.034106    0  0.543403   1 1.340466\n",
      "   1  2.640450    1  0.955150    0  1.823122    0 0.679813    0  1.008905    1  0.929348   1 1.244289\n",
      "   0 -0.300626    0  0.018143    0  0.247606    0 0.335458    0  0.274331    0  0.192523   0 0.101931\n",
      "   8  5.875098    5  4.437521    1  1.823122    1 2.036608    3  1.712668    1  1.220022   2 1.329288\n",
      "  16  3.853352    2  2.968174    6  2.468361    1 1.876393    0  1.008905    0  0.598679   1 1.363469\n",
      "   0  2.019183    2  2.132137    0  1.975009    0 0.837980    0  0.555383    0  0.430926   0 1.261933\n",
      "   1  0.262450    0  0.268461    4  0.247606    1 0.350993    0  0.365484    0  0.258091   0 0.669142\n",
      "   3  3.492545    0  2.693069    2  2.665939    0 1.520247    0  0.979707    0  0.517500   2 0.891049\n",
      "   0  3.197387    1  2.933902    0  1.678970    0 1.154104    1  0.779018    0  0.445407   0 0.888536\n",
      "   0 -0.336237    0  0.214054    0  0.758271    0 0.321599    0  0.200715    0  0.293114   0 0.707753\n",
      "   0  5.143611    1  3.154139    4  1.823122    3 2.036608    1  1.292001    2  0.883666   0 1.290354\n",
      "   0 -1.260408    1 -0.031058    0  0.247606    0 0.350993    0  0.346712    2  0.258091   0 0.526305\n",
      "   0  3.197387    0  2.373203    2  1.403229    0 1.290535    2  0.779018    0  0.769716   0 0.888536\n",
      "   6  3.492545    6  2.693069    2  2.665939    0 1.520247    0  0.979707    2  0.517500   0 0.891049\n",
      "   3  3.492545    1  2.693069    0  2.665939    0 1.520247    2  1.008905    0  0.517500   0 0.891049\n",
      "   0 -0.300626    0  0.018143    4  0.247606    1 0.331528    1  0.274331    0  0.192523   3 0.101931\n",
      "   4  3.359408   21  2.245649    0  2.944665    2 1.876393    0  1.008905    2  0.543403   0 1.340466\n",
      "   4  2.718002    4  2.099455    2  1.403229    1 0.932837    0  0.779018    1  0.332611   0 0.818514\n",
      "   0  1.477873    0  1.618881    0  1.403229    0 0.927045    0  0.760246    0  0.332611   0 0.710983\n",
      "   0 -0.710316    0  0.232935    0  0.542183    0 0.350993    0  0.365484    0  0.258091   0 0.138146\n",
      "   0  3.853352    0  2.968174    0  2.468361    0 1.876393    1  1.008905    0  0.598679   0 1.363469\n",
      "   0 -3.270651    0  0.208354    0  0.468723    0 0.321777    0  0.401792    0  0.585235   0 0.533701\n",
      "   0 -0.097438    0  0.152459    0  0.835236    0 0.321599    0  0.175320    0  0.202809   0 0.203465\n",
      "   2  5.143611    6  3.362961    0  1.823122    0 1.824009    0  1.292001    7  1.126429   0 1.290354\n",
      "   0  0.298778    0  0.073010    0  1.017880    0 0.485016    0  0.541640    0  0.188661   0 1.179838\n",
      "   0  0.176433    0  0.788858    9  1.806073    4 0.853273    1  0.781856    1  0.254601   1 1.119750\n",
      "   0  0.360319    0  0.636043    0  1.584957    0 0.875257    0  0.760246    0  0.332611   2 1.112354\n",
      "   2  3.986489    2  3.415594    3  2.189635    0 1.796222    0  1.008905    3  0.517500   0 1.363469\n",
      "   0  2.512208    0  1.279782    0  1.384394    0 1.189861    0  0.735837    0  0.291486   0 1.337953\n",
      "   0 -1.579381    0  0.426195    0  0.468723    0 0.321777    0  0.368321    0  0.215321   0 0.533701\n",
      "   1  1.882594    3  1.578015    0  3.002400    1 2.302388    1  0.804220    0  0.332611   0 0.724195\n",
      "   0  2.640450    2  0.955150    0  1.823122    0 0.679813    0  1.008905    0  0.482463   0 1.244289\n",
      "   1  1.279115    3  1.415581    3  2.299425    0 1.392264    1  1.235378    1  0.427188   0 1.221286\n",
      "   2  1.743660    1  1.192492    4  3.278140    1 1.301944    0  0.833420    0  0.357054   3 1.314950\n",
      "   1  3.197387    0  2.373203    2  1.678970    0 1.154104    2  0.779018    1  0.445407   1 0.888536\n",
      "   3 -0.300626    2  0.018143    0  0.247606    0 0.350993    0  0.346712    0  0.258091   0 0.526305\n",
      "   1  3.197387    0  2.373203    0  1.403229    0 1.290535    0  0.779018    0  0.936505   0 0.888536\n",
      "   0  0.772312    0  1.134263    0  1.806073    0 1.094649    0  0.394658    0  0.395538   0 0.956728\n",
      "   6  4.649667   11  3.794479    6  2.299425    0 2.036608    0  1.712668    0  1.043697   0 1.306285\n",
      "   0  3.677784    0  2.373203    3  1.403229    2 0.932837    4  0.779018    4  0.332611   0 0.818514\n",
      "   3  2.842377    1  1.851763    2  1.879533    1 0.875257    2  0.779018    0  0.332611   0 0.724195\n",
      "   0  3.197387    0  2.030138    0  1.678970    0 1.391922    0  0.808218    0  0.357054   0 1.337953\n",
      "   0  0.877196    0  0.976699    1  1.584957    2 0.875257    1  0.779018    0  0.332611   1 1.219885\n",
      "   0  0.490012    0  0.843494    2  1.788761    0 0.992453    0  1.034690    0  0.266742   0 1.195770\n",
      "   0 -1.457036    0 -0.096275    3 -0.319470    0 0.275611    0  0.128106    0  0.112597   0 0.593790\n",
      "  71  3.986489   31  3.415594    7  2.189635    1 1.796222    2  1.008905    1  0.517500   1 1.363469\n",
      "   2  2.376539    0  2.099455    1  2.526096    0 2.302388    0  0.804220    1  0.332611   0 0.747198\n",
      "   0  3.492545    4  2.693069    0  2.665939    0 1.520247    0  1.008905    1  0.517500   0 0.891049\n",
      "   0  3.853352    0  2.968174    1  2.468361    0 1.876393    0  1.008905    0  0.598679   0 1.363469\n",
      "   2  1.913521    0  0.353309    4  1.619317    8 0.782583    0  0.614249    0  0.367634   2 1.388121\n",
      "   7  4.820016    1  3.410518    5  1.403229    2 0.927045    2  0.760246    1  0.332611   0 0.710983\n",
      "  13  3.986489   14  3.415594    3  2.189635   17 1.796222    6  1.008905    3  0.517500   3 1.363469\n",
      "  17  2.703443    8  1.307613    0  2.155274    2 1.140133    2  0.808218    0  0.357054   0 0.865533\n",
      "   0  1.627704    0  0.156178    0  1.823122    0 0.367404    1  0.814710    0  0.334616   1 1.081267\n",
      "   0  3.359408    0  1.939853    0  2.944665    0 1.482718    0  1.008905    0  0.642964   0 1.340466\n",
      "   2  1.836978    4  1.025899    0  1.584957    0 0.855792    0  0.706637    0  0.267043   1 0.795511\n",
      "   2  3.986489    3  3.415594    1  2.189635    4 1.796222    2  1.008905    0  0.517500   0 1.363469\n",
      "   0 -0.300626    0  0.018143    0  0.247606    0 0.350993    0  0.346712    0  0.258091   0 0.526305\n",
      "   1  2.703443    3  1.851763    3  1.879533   15 1.191854    3  0.779018    1  0.634224   2 0.865533\n",
      "  10  4.649667    3  3.794479   32  2.299425    6 2.036608    3  1.292001    0  1.043697  19 1.267350\n",
      "   1 -0.300626    0  0.018143    0  0.247606    0 0.331528    0  0.274331    0  0.192523   0 0.101931\n",
      "   0  0.575108    0  0.330119    1 -0.228698    0 0.350862    2  0.346712    0  0.258091   0 0.549308\n",
      "   0  4.998256    0  2.635898    0  1.823122    0 1.329135    0  1.292001    0  0.707487   0 1.166266\n",
      "   0  1.279115    1  1.415581    0  2.299425    0 1.828869    0  1.235378    0  0.427188   0 1.221286\n",
      "   4  4.649667    9  3.794479    0  2.299425    0 2.036608    1  1.712668    0  1.043697   1 1.306285\n",
      "   3  3.492545    4  2.693069    0  2.665939    0 1.520247    0  1.008905    0  0.517500   0 0.891049\n",
      "   1  0.193318    0  0.018143    0 -0.228698    0 0.350862    0  0.346712    0  0.258091   0 0.549308\n",
      "   8  2.703443    1  1.851763    3  2.155274    2 1.159101   10  0.779018    0  0.467436   0 0.865533\n",
      "   1  2.703443    2  2.211377   29  2.155274    3 1.159101   14  0.779018    1  0.467436   1 0.865533\n",
      "   0  0.081164    0  0.268461    1  0.247606    1 0.331528    0  0.293103    0  0.192523   0 0.138146\n",
      "   1  5.143611    0  3.154139    0  1.823122    0 2.036608    0  1.292001    0  0.883666   0 1.290354\n",
      "   1  6.011001    0  5.512024    3  1.823122    8 2.735617    1  1.712668    0  1.060333   0 1.329288\n",
      "   0  2.224057    5  1.578015    3  3.002400    0 2.302388    0  0.804220    0  0.332611   3 0.795511\n",
      "   1  2.863620    0  1.851763    1  1.879533    0 1.058686    0  0.779018    0  0.363067   0 0.830229\n",
      "   0  2.703443    0  2.211377    0  2.155274    1 1.159101    1  0.779018    0  0.467436   0 0.865533\n",
      "   0  3.359408    0  2.245649    0  2.944665    0 1.876393    0  1.008905    0  0.543403   0 1.340466\n",
      "   0  0.623257    0  0.034681    4  0.325770    0 0.311831    0  0.322302    0  0.112597   0 0.717187\n",
      "   0  3.986489    0  3.415594    0  2.189635    1 1.796222    0  1.008905    0  0.517500   1 1.363469\n",
      "   9  3.853352    4  4.852853    0  2.468361    4 1.716176    0  1.008905    0  0.929348   0 1.363469\n"
     ]
    }
   ],
   "source": [
    "dfs = []\n",
    "\n",
    "complist_vars = [complist_ya1,\n",
    "                 complist_ya2,\n",
    "                 complist_yb1,\n",
    "                 complist_yb2,\n",
    "                 complist_yb3,\n",
    "                 complist_yb4,\n",
    "                 complist_yc]\n",
    "\n",
    "for i, complist in enumerate(complist_vars):\n",
    "    df = pd.DataFrame(complist, columns=[variables[i],\"\"])\n",
    "    dfs.append(df)\n",
    "\n",
    "result = pd.concat(dfs, axis=1)\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "\n",
    "print(result.to_string(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
