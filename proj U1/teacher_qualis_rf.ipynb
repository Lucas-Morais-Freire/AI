{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning para Previsão de Taxas de Qualis de Professores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliotecas Importadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings as wrn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importação de Bibliotecas de Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import balanced_accuracy_score, roc_auc_score, make_scorer\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importação de Bibliotecas de Otimização de Hiperparâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Integer, Categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leitura e Seleção de Colunas do Arquivo CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>siape</th>\n",
       "      <th>sexo</th>\n",
       "      <th>formacao</th>\n",
       "      <th>tipo_jornada_trabalho</th>\n",
       "      <th>vinculo</th>\n",
       "      <th>id_unidade_lotacao</th>\n",
       "      <th>lotacao</th>\n",
       "      <th>admissao</th>\n",
       "      <th>categoria</th>\n",
       "      <th>classe_funcional</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1543339</td>\n",
       "      <td>F</td>\n",
       "      <td>MESTRADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Ativo Permanente</td>\n",
       "      <td>1452</td>\n",
       "      <td>NÚCLEO DE EDUCAÇÃO DA INFÂNCIA</td>\n",
       "      <td>2006/07/24 00:00:00.000000000</td>\n",
       "      <td>PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO</td>\n",
       "      <td>DIV                                           ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1554468</td>\n",
       "      <td>M</td>\n",
       "      <td>DOUTORADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Ativo Permanente</td>\n",
       "      <td>351</td>\n",
       "      <td>ESCOLA AGRÍCOLA DE JUNDIAÍ</td>\n",
       "      <td>2008/09/12 00:00:00.000000000</td>\n",
       "      <td>PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO</td>\n",
       "      <td>DV                                            ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1177821</td>\n",
       "      <td>M</td>\n",
       "      <td>MESTRADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Ativo Permanente</td>\n",
       "      <td>284</td>\n",
       "      <td>ESCOLA DE MÚSICA</td>\n",
       "      <td>1998/04/28 00:00:00.000000000</td>\n",
       "      <td>PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO</td>\n",
       "      <td>DIV                                           ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2360824</td>\n",
       "      <td>M</td>\n",
       "      <td>MESTRADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Ativo Permanente</td>\n",
       "      <td>351</td>\n",
       "      <td>ESCOLA AGRÍCOLA DE JUNDIAÍ</td>\n",
       "      <td>2017/01/25 00:00:00.000000000</td>\n",
       "      <td>PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO</td>\n",
       "      <td>DIII                                          ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2364334</td>\n",
       "      <td>F</td>\n",
       "      <td>DOUTORADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Ativo Permanente</td>\n",
       "      <td>351</td>\n",
       "      <td>ESCOLA AGRÍCOLA DE JUNDIAÍ</td>\n",
       "      <td>2009/10/13 00:00:00.000000000</td>\n",
       "      <td>PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO</td>\n",
       "      <td>DIV                                           ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2765</th>\n",
       "      <td>4246363</td>\n",
       "      <td>M</td>\n",
       "      <td>DOUTORADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Professor Visitante</td>\n",
       "      <td>1824</td>\n",
       "      <td>INSTITUTO DE POLÍTICAS PÚBLICAS</td>\n",
       "      <td>2023/05/23 00:00:00.000000000</td>\n",
       "      <td>PROFESSOR MAGISTERIO SUPERIOR - VISITANTE</td>\n",
       "      <td>Adjunto                                       ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2766</th>\n",
       "      <td>3304576</td>\n",
       "      <td>M</td>\n",
       "      <td>DOUTORADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Professor Visitante</td>\n",
       "      <td>4885</td>\n",
       "      <td>ESCOLA DE CIÊNCIAS E TECNOLOGIA</td>\n",
       "      <td>2022/08/12 00:00:00.000000000</td>\n",
       "      <td>PROFESSOR MAGISTERIO SUPERIOR - VISITANTE</td>\n",
       "      <td>Titular                                       ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2767</th>\n",
       "      <td>1056188</td>\n",
       "      <td>M</td>\n",
       "      <td>DOUTORADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Professor Visitante</td>\n",
       "      <td>179</td>\n",
       "      <td>DEPARTAMENTO DE BIOLOGIA CELULAR E GENÉTICA</td>\n",
       "      <td>2022/10/03 00:00:00.000000000</td>\n",
       "      <td>PROFESSOR MAGISTERIO SUPERIOR - VISITANTE</td>\n",
       "      <td>A                                             ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2768</th>\n",
       "      <td>3330361</td>\n",
       "      <td>F</td>\n",
       "      <td>DOUTORADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Professor Visitante</td>\n",
       "      <td>6069</td>\n",
       "      <td>INSTITUTO METROPOLE DIGITAL</td>\n",
       "      <td>2023/02/15 00:00:00.000000000</td>\n",
       "      <td>PROFESSOR MAGISTERIO SUPERIOR - VISITANTE</td>\n",
       "      <td>A                                             ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2769</th>\n",
       "      <td>3309092</td>\n",
       "      <td>M</td>\n",
       "      <td>DOUTORADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Professor Visitante</td>\n",
       "      <td>4894</td>\n",
       "      <td>DEPARTAMENTO DE GEOFÍSICA</td>\n",
       "      <td>2022/09/06 00:00:00.000000000</td>\n",
       "      <td>PROFESSOR MAGISTERIO SUPERIOR - VISITANTE</td>\n",
       "      <td>Titular                                       ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2770 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        siape sexo   formacao           tipo_jornada_trabalho  \\\n",
       "0     1543339    F   MESTRADO  Dedicação exclusiva              \n",
       "1     1554468    M  DOUTORADO  Dedicação exclusiva              \n",
       "2     1177821    M   MESTRADO  Dedicação exclusiva              \n",
       "3     2360824    M   MESTRADO  Dedicação exclusiva              \n",
       "4     2364334    F  DOUTORADO  Dedicação exclusiva              \n",
       "...       ...  ...        ...                             ...   \n",
       "2765  4246363    M  DOUTORADO  Dedicação exclusiva              \n",
       "2766  3304576    M  DOUTORADO  Dedicação exclusiva              \n",
       "2767  1056188    M  DOUTORADO  Dedicação exclusiva              \n",
       "2768  3330361    F  DOUTORADO  Dedicação exclusiva              \n",
       "2769  3309092    M  DOUTORADO  Dedicação exclusiva              \n",
       "\n",
       "                  vinculo  id_unidade_lotacao  \\\n",
       "0        Ativo Permanente                1452   \n",
       "1        Ativo Permanente                 351   \n",
       "2        Ativo Permanente                 284   \n",
       "3        Ativo Permanente                 351   \n",
       "4        Ativo Permanente                 351   \n",
       "...                   ...                 ...   \n",
       "2765  Professor Visitante                1824   \n",
       "2766  Professor Visitante                4885   \n",
       "2767  Professor Visitante                 179   \n",
       "2768  Professor Visitante                6069   \n",
       "2769  Professor Visitante                4894   \n",
       "\n",
       "                                          lotacao  \\\n",
       "0                  NÚCLEO DE EDUCAÇÃO DA INFÂNCIA   \n",
       "1                      ESCOLA AGRÍCOLA DE JUNDIAÍ   \n",
       "2                                ESCOLA DE MÚSICA   \n",
       "3                      ESCOLA AGRÍCOLA DE JUNDIAÍ   \n",
       "4                      ESCOLA AGRÍCOLA DE JUNDIAÍ   \n",
       "...                                           ...   \n",
       "2765              INSTITUTO DE POLÍTICAS PÚBLICAS   \n",
       "2766              ESCOLA DE CIÊNCIAS E TECNOLOGIA   \n",
       "2767  DEPARTAMENTO DE BIOLOGIA CELULAR E GENÉTICA   \n",
       "2768                  INSTITUTO METROPOLE DIGITAL   \n",
       "2769                    DEPARTAMENTO DE GEOFÍSICA   \n",
       "\n",
       "                           admissao  \\\n",
       "0     2006/07/24 00:00:00.000000000   \n",
       "1     2008/09/12 00:00:00.000000000   \n",
       "2     1998/04/28 00:00:00.000000000   \n",
       "3     2017/01/25 00:00:00.000000000   \n",
       "4     2009/10/13 00:00:00.000000000   \n",
       "...                             ...   \n",
       "2765  2023/05/23 00:00:00.000000000   \n",
       "2766  2022/08/12 00:00:00.000000000   \n",
       "2767  2022/10/03 00:00:00.000000000   \n",
       "2768  2023/02/15 00:00:00.000000000   \n",
       "2769  2022/09/06 00:00:00.000000000   \n",
       "\n",
       "                                             categoria  \\\n",
       "0     PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO   \n",
       "1     PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO   \n",
       "2     PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO   \n",
       "3     PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO   \n",
       "4     PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO   \n",
       "...                                                ...   \n",
       "2765         PROFESSOR MAGISTERIO SUPERIOR - VISITANTE   \n",
       "2766         PROFESSOR MAGISTERIO SUPERIOR - VISITANTE   \n",
       "2767         PROFESSOR MAGISTERIO SUPERIOR - VISITANTE   \n",
       "2768         PROFESSOR MAGISTERIO SUPERIOR - VISITANTE   \n",
       "2769         PROFESSOR MAGISTERIO SUPERIOR - VISITANTE   \n",
       "\n",
       "                                       classe_funcional  \n",
       "0     DIV                                           ...  \n",
       "1     DV                                            ...  \n",
       "2     DIV                                           ...  \n",
       "3     DIII                                          ...  \n",
       "4     DIV                                           ...  \n",
       "...                                                 ...  \n",
       "2765  Adjunto                                       ...  \n",
       "2766  Titular                                       ...  \n",
       "2767  A                                             ...  \n",
       "2768  A                                             ...  \n",
       "2769  Titular                                       ...  \n",
       "\n",
       "[2770 rows x 10 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# selecionar atributos dos professores que sao de interesse\n",
    "\n",
    "tp_cols = [\"siape\", \"sexo\", \"formacao\", \"tipo_jornada_trabalho\",\n",
    "           \"vinculo\", \"id_unidade_lotacao\", \"lotacao\", \"admissao\", \"categoria\",\n",
    "           \"classe_funcional\"]\n",
    "\n",
    "tp_df = pd.read_csv(\"./perfis/docentes.csv\", sep=\";\")\n",
    "tp_df = tp_df[tp_cols]\n",
    "\n",
    "tp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tipos de Dados das Colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "siape                     int64\n",
       "sexo                     object\n",
       "formacao                 object\n",
       "tipo_jornada_trabalho    object\n",
       "vinculo                  object\n",
       "id_unidade_lotacao        int64\n",
       "lotacao                  object\n",
       "admissao                 object\n",
       "categoria                object\n",
       "classe_funcional         object\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resumo Estatístico do DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>siape</th>\n",
       "      <th>id_unidade_lotacao</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.770000e+03</td>\n",
       "      <td>2770.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.114588e+06</td>\n",
       "      <td>2821.146209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.142222e+06</td>\n",
       "      <td>5617.495694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.274600e+04</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.297595e+06</td>\n",
       "      <td>142.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.810985e+06</td>\n",
       "      <td>202.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.722937e+06</td>\n",
       "      <td>4890.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.350807e+06</td>\n",
       "      <td>31231.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              siape  id_unidade_lotacao\n",
       "count  2.770000e+03         2770.000000\n",
       "mean   2.114588e+06         2821.146209\n",
       "std    1.142222e+06         5617.495694\n",
       "min    1.274600e+04            2.000000\n",
       "25%    1.297595e+06          142.000000\n",
       "50%    1.810985e+06          202.000000\n",
       "75%    2.722937e+06         4890.000000\n",
       "max    9.350807e+06        31231.000000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparação dos Dados de Qualis das Revistas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>siape</th>\n",
       "      <th>revista_a1</th>\n",
       "      <th>revista_a2</th>\n",
       "      <th>revista_b1</th>\n",
       "      <th>revista_b2</th>\n",
       "      <th>revista_b3</th>\n",
       "      <th>revista_b4</th>\n",
       "      <th>revista_b5</th>\n",
       "      <th>revista_c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.756000e+03</td>\n",
       "      <td>2756.000000</td>\n",
       "      <td>2756.000000</td>\n",
       "      <td>2756.000000</td>\n",
       "      <td>2756.000000</td>\n",
       "      <td>2756.000000</td>\n",
       "      <td>2756.000000</td>\n",
       "      <td>2756.000000</td>\n",
       "      <td>2756.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.112227e+06</td>\n",
       "      <td>2.634978</td>\n",
       "      <td>1.933599</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>1.269231</td>\n",
       "      <td>0.818215</td>\n",
       "      <td>0.568578</td>\n",
       "      <td>0.054790</td>\n",
       "      <td>0.889332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.137681e+06</td>\n",
       "      <td>6.073799</td>\n",
       "      <td>3.917333</td>\n",
       "      <td>5.375914</td>\n",
       "      <td>2.891393</td>\n",
       "      <td>2.413658</td>\n",
       "      <td>1.778480</td>\n",
       "      <td>0.330389</td>\n",
       "      <td>3.855806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.274600e+04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.296285e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.808676e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.721404e+06</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.350807e+06</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>124.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              siape   revista_a1   revista_a2   revista_b1   revista_b2  \\\n",
       "count  2.756000e+03  2756.000000  2756.000000  2756.000000  2756.000000   \n",
       "mean   2.112227e+06     2.634978     1.933599     1.750000     1.269231   \n",
       "std    1.137681e+06     6.073799     3.917333     5.375914     2.891393   \n",
       "min    1.274600e+04     0.000000     0.000000     0.000000     0.000000   \n",
       "25%    1.296285e+06     0.000000     0.000000     0.000000     0.000000   \n",
       "50%    1.808676e+06     0.000000     0.000000     0.000000     0.000000   \n",
       "75%    2.721404e+06     3.000000     2.000000     2.000000     1.000000   \n",
       "max    9.350807e+06    71.000000    51.000000    99.000000    46.000000   \n",
       "\n",
       "        revista_b3   revista_b4   revista_b5    revista_c  \n",
       "count  2756.000000  2756.000000  2756.000000  2756.000000  \n",
       "mean      0.818215     0.568578     0.054790     0.889332  \n",
       "std       2.413658     1.778480     0.330389     3.855806  \n",
       "min       0.000000     0.000000     0.000000     0.000000  \n",
       "25%       0.000000     0.000000     0.000000     0.000000  \n",
       "50%       0.000000     0.000000     0.000000     0.000000  \n",
       "75%       1.000000     0.000000     0.000000     1.000000  \n",
       "max      41.000000    32.000000     8.000000   124.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# selecionar atributos que desejamos prever. o siape é incluso para unir as tabelas.\n",
    "\n",
    "qualis = [\"siape\", \"revista_a1\", \"revista_a2\", \"revista_b1\",\n",
    "          \"revista_b2\", \"revista_b3\", \"revista_b4\", \"revista_b5\", \"revista_c\"]\n",
    "\n",
    "ti_df_list = []\n",
    "for year in range(2010, 2021):\n",
    "    ti_df_y = pd.read_csv(\n",
    "        \"./indicadores/indicadores-pesquisa-\" + str(year) + \".csv\", sep=\";\")\n",
    "    ti_df_y = ti_df_y[qualis]\n",
    "    ti_df_list.append(ti_df_y)\n",
    "\n",
    "ti_df = pd.concat(ti_df_list)\n",
    "ti_df = ti_df.groupby(\"siape\", as_index=False).sum()\n",
    "ti_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fusão de Dados e Remoção da Coluna \"siape\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sexo</th>\n",
       "      <th>formacao</th>\n",
       "      <th>tipo_jornada_trabalho</th>\n",
       "      <th>vinculo</th>\n",
       "      <th>id_unidade_lotacao</th>\n",
       "      <th>lotacao</th>\n",
       "      <th>admissao</th>\n",
       "      <th>categoria</th>\n",
       "      <th>classe_funcional</th>\n",
       "      <th>revista_a1</th>\n",
       "      <th>revista_a2</th>\n",
       "      <th>revista_b1</th>\n",
       "      <th>revista_b2</th>\n",
       "      <th>revista_b3</th>\n",
       "      <th>revista_b4</th>\n",
       "      <th>revista_b5</th>\n",
       "      <th>revista_c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F</td>\n",
       "      <td>MESTRADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Ativo Permanente</td>\n",
       "      <td>1452</td>\n",
       "      <td>NÚCLEO DE EDUCAÇÃO DA INFÂNCIA</td>\n",
       "      <td>2006/07/24 00:00:00.000000000</td>\n",
       "      <td>PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO</td>\n",
       "      <td>DIV                                           ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>DOUTORADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Ativo Permanente</td>\n",
       "      <td>351</td>\n",
       "      <td>ESCOLA AGRÍCOLA DE JUNDIAÍ</td>\n",
       "      <td>2008/09/12 00:00:00.000000000</td>\n",
       "      <td>PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO</td>\n",
       "      <td>DV                                            ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "      <td>MESTRADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Ativo Permanente</td>\n",
       "      <td>284</td>\n",
       "      <td>ESCOLA DE MÚSICA</td>\n",
       "      <td>1998/04/28 00:00:00.000000000</td>\n",
       "      <td>PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO</td>\n",
       "      <td>DIV                                           ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>MESTRADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Ativo Permanente</td>\n",
       "      <td>351</td>\n",
       "      <td>ESCOLA AGRÍCOLA DE JUNDIAÍ</td>\n",
       "      <td>2017/01/25 00:00:00.000000000</td>\n",
       "      <td>PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO</td>\n",
       "      <td>DIII                                          ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F</td>\n",
       "      <td>DOUTORADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Ativo Permanente</td>\n",
       "      <td>351</td>\n",
       "      <td>ESCOLA AGRÍCOLA DE JUNDIAÍ</td>\n",
       "      <td>2009/10/13 00:00:00.000000000</td>\n",
       "      <td>PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO</td>\n",
       "      <td>DIV                                           ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2748</th>\n",
       "      <td>M</td>\n",
       "      <td>DOUTORADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Professor Visitante</td>\n",
       "      <td>1824</td>\n",
       "      <td>INSTITUTO DE POLÍTICAS PÚBLICAS</td>\n",
       "      <td>2023/05/23 00:00:00.000000000</td>\n",
       "      <td>PROFESSOR MAGISTERIO SUPERIOR - VISITANTE</td>\n",
       "      <td>Adjunto                                       ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2749</th>\n",
       "      <td>M</td>\n",
       "      <td>DOUTORADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Professor Visitante</td>\n",
       "      <td>4885</td>\n",
       "      <td>ESCOLA DE CIÊNCIAS E TECNOLOGIA</td>\n",
       "      <td>2022/08/12 00:00:00.000000000</td>\n",
       "      <td>PROFESSOR MAGISTERIO SUPERIOR - VISITANTE</td>\n",
       "      <td>Titular                                       ...</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2750</th>\n",
       "      <td>M</td>\n",
       "      <td>DOUTORADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Professor Visitante</td>\n",
       "      <td>179</td>\n",
       "      <td>DEPARTAMENTO DE BIOLOGIA CELULAR E GENÉTICA</td>\n",
       "      <td>2022/10/03 00:00:00.000000000</td>\n",
       "      <td>PROFESSOR MAGISTERIO SUPERIOR - VISITANTE</td>\n",
       "      <td>A                                             ...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2751</th>\n",
       "      <td>F</td>\n",
       "      <td>DOUTORADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Professor Visitante</td>\n",
       "      <td>6069</td>\n",
       "      <td>INSTITUTO METROPOLE DIGITAL</td>\n",
       "      <td>2023/02/15 00:00:00.000000000</td>\n",
       "      <td>PROFESSOR MAGISTERIO SUPERIOR - VISITANTE</td>\n",
       "      <td>A                                             ...</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2752</th>\n",
       "      <td>M</td>\n",
       "      <td>DOUTORADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Professor Visitante</td>\n",
       "      <td>4894</td>\n",
       "      <td>DEPARTAMENTO DE GEOFÍSICA</td>\n",
       "      <td>2022/09/06 00:00:00.000000000</td>\n",
       "      <td>PROFESSOR MAGISTERIO SUPERIOR - VISITANTE</td>\n",
       "      <td>Titular                                       ...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2753 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sexo   formacao           tipo_jornada_trabalho              vinculo  \\\n",
       "0       F   MESTRADO  Dedicação exclusiva                Ativo Permanente   \n",
       "1       M  DOUTORADO  Dedicação exclusiva                Ativo Permanente   \n",
       "2       M   MESTRADO  Dedicação exclusiva                Ativo Permanente   \n",
       "3       M   MESTRADO  Dedicação exclusiva                Ativo Permanente   \n",
       "4       F  DOUTORADO  Dedicação exclusiva                Ativo Permanente   \n",
       "...   ...        ...                             ...                  ...   \n",
       "2748    M  DOUTORADO  Dedicação exclusiva             Professor Visitante   \n",
       "2749    M  DOUTORADO  Dedicação exclusiva             Professor Visitante   \n",
       "2750    M  DOUTORADO  Dedicação exclusiva             Professor Visitante   \n",
       "2751    F  DOUTORADO  Dedicação exclusiva             Professor Visitante   \n",
       "2752    M  DOUTORADO  Dedicação exclusiva             Professor Visitante   \n",
       "\n",
       "      id_unidade_lotacao                                      lotacao  \\\n",
       "0                   1452               NÚCLEO DE EDUCAÇÃO DA INFÂNCIA   \n",
       "1                    351                   ESCOLA AGRÍCOLA DE JUNDIAÍ   \n",
       "2                    284                             ESCOLA DE MÚSICA   \n",
       "3                    351                   ESCOLA AGRÍCOLA DE JUNDIAÍ   \n",
       "4                    351                   ESCOLA AGRÍCOLA DE JUNDIAÍ   \n",
       "...                  ...                                          ...   \n",
       "2748                1824              INSTITUTO DE POLÍTICAS PÚBLICAS   \n",
       "2749                4885              ESCOLA DE CIÊNCIAS E TECNOLOGIA   \n",
       "2750                 179  DEPARTAMENTO DE BIOLOGIA CELULAR E GENÉTICA   \n",
       "2751                6069                  INSTITUTO METROPOLE DIGITAL   \n",
       "2752                4894                    DEPARTAMENTO DE GEOFÍSICA   \n",
       "\n",
       "                           admissao  \\\n",
       "0     2006/07/24 00:00:00.000000000   \n",
       "1     2008/09/12 00:00:00.000000000   \n",
       "2     1998/04/28 00:00:00.000000000   \n",
       "3     2017/01/25 00:00:00.000000000   \n",
       "4     2009/10/13 00:00:00.000000000   \n",
       "...                             ...   \n",
       "2748  2023/05/23 00:00:00.000000000   \n",
       "2749  2022/08/12 00:00:00.000000000   \n",
       "2750  2022/10/03 00:00:00.000000000   \n",
       "2751  2023/02/15 00:00:00.000000000   \n",
       "2752  2022/09/06 00:00:00.000000000   \n",
       "\n",
       "                                             categoria  \\\n",
       "0     PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO   \n",
       "1     PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO   \n",
       "2     PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO   \n",
       "3     PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO   \n",
       "4     PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO   \n",
       "...                                                ...   \n",
       "2748         PROFESSOR MAGISTERIO SUPERIOR - VISITANTE   \n",
       "2749         PROFESSOR MAGISTERIO SUPERIOR - VISITANTE   \n",
       "2750         PROFESSOR MAGISTERIO SUPERIOR - VISITANTE   \n",
       "2751         PROFESSOR MAGISTERIO SUPERIOR - VISITANTE   \n",
       "2752         PROFESSOR MAGISTERIO SUPERIOR - VISITANTE   \n",
       "\n",
       "                                       classe_funcional  revista_a1  \\\n",
       "0     DIV                                           ...           0   \n",
       "1     DV                                            ...           1   \n",
       "2     DIV                                           ...           0   \n",
       "3     DIII                                          ...           0   \n",
       "4     DIV                                           ...           0   \n",
       "...                                                 ...         ...   \n",
       "2748  Adjunto                                       ...           0   \n",
       "2749  Titular                                       ...           8   \n",
       "2750  A                                             ...           4   \n",
       "2751  A                                             ...          44   \n",
       "2752  Titular                                       ...           4   \n",
       "\n",
       "      revista_a2  revista_b1  revista_b2  revista_b3  revista_b4  revista_b5  \\\n",
       "0              0           0           0           0           0           0   \n",
       "1              1           5           0           0           4           0   \n",
       "2              0           0           0           0           0           0   \n",
       "3              0           0           0           0           0           0   \n",
       "4              0           0           1           0           0           0   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "2748           0           0           1           0           0           0   \n",
       "2749           4           7           0           2           0           0   \n",
       "2750           2           5           0           0           0           0   \n",
       "2751           1           0           0           0           0           0   \n",
       "2752           0           0           0           0           0           0   \n",
       "\n",
       "      revista_c  \n",
       "0             0  \n",
       "1             0  \n",
       "2             0  \n",
       "3             0  \n",
       "4             0  \n",
       "...         ...  \n",
       "2748          1  \n",
       "2749          0  \n",
       "2750          0  \n",
       "2751          0  \n",
       "2752          0  \n",
       "\n",
       "[2753 rows x 17 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unir ambas as tabelas e manter apenas as entradas que possuem siapes em comum\n",
    "\n",
    "df = tp_df.merge(ti_df, on=\"siape\", how=\"inner\")\n",
    "del df[\"siape\"]\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapeamento e Contagem dos Sexos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 1269\n",
      "1: 1484\n"
     ]
    }
   ],
   "source": [
    "sex_map = {\"F\": 0, \"M\": 1}\n",
    "df[\"sexo\"].replace(sex_map, inplace=True)\n",
    "\n",
    "for sexo in df[\"sexo\"].unique():\n",
    "    print(sexo, \": \", len(df[df[\"sexo\"] == sexo]), sep=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapeamento de unidade acadêmica para município"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lot_df = pd.read_csv(\"unidades/unidades.csv\", sep=\";\")\n",
    "\n",
    "lot_df = lot_df[[\"id_unidade\", \"municipio\"]]\n",
    "\n",
    "lot_df.loc[len(lot_df.index)] = [-1, \"DESCONHECIDO\"]\n",
    "\n",
    "\n",
    "lot_df.set_index(\"id_unidade\", inplace=True)\n",
    "lot_df\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    df.loc[index, \"id_unidade_lotacao\"] = lot_df.loc[row[\"id_unidade_lotacao\"] if row[\"id_unidade_lotacao\"] in lot_df.index else -1][\"municipio\"]\n",
    "\n",
    "df.rename(columns={\"id_unidade_lotacao\":\"municipio\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DEPARTAMENTO DE SAÚDE COLETIVA' 'PRÓ-REITORIA DE GRADUAÇÃO'\n",
      " 'DEPARTAMENTO DE ENGENHARIA DE COMUNICAÇÕES'\n",
      " 'DEPARTAMENTO DE ENGENHARIA MECANICA' 'DEPARTAMENTO DE ODONTOLOGIA'\n",
      " 'DEPARTAMENTO DE COMUNICAÇÃO SOCIAL' 'DEPARTAMENTO DE PSICOLOGIA'\n",
      " 'DEPARTAMENTO DE SERVIÇO SOCIAL - DESSO' 'DEPARTAMENTO DE ESTATISTICA'\n",
      " 'DEPARTAMENTO DE OCEANOGRAFIA E LIMNOLOGIA'\n",
      " 'SECRETARIA DE EDUCAÇÃO BÁSICA, TÉCNICA E TECNOLÓGICA DA UFRN'\n",
      " 'ADMINISTRAÇÃO DO CB']\n"
     ]
    }
   ],
   "source": [
    "temp_df = df[df['municipio'] == 'DESCONHECIDO']\n",
    "\n",
    "print(temp_df[\"lotacao\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Não há muitas lotações com municípios desconhecidos, portanto, iremos completar estas informações manualmente. Verificamos que todas as lotações com município desconhecido são de Natal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NATAL: 2295\n",
      "MACAÍBA: 121\n",
      "CAICÓ: 177\n",
      "SANTA CRUZ: 104\n",
      "CURRAIS NOVOS: 56\n"
     ]
    }
   ],
   "source": [
    "unknown_map = {\n",
    "    'DESCONHECIDO':'NATAL'\n",
    "}\n",
    "\n",
    "df['municipio'].replace(unknown_map, inplace=True)\n",
    "\n",
    "for municipio in df[\"municipio\"].unique():\n",
    "    print(municipio, \": \", len(df[df[\"municipio\"] == municipio]), sep=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cálculo dos Semestres na Universidade e Seleção de Colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sexo</th>\n",
       "      <th>formacao</th>\n",
       "      <th>tipo_jornada_trabalho</th>\n",
       "      <th>vinculo</th>\n",
       "      <th>categoria</th>\n",
       "      <th>classe_funcional</th>\n",
       "      <th>municipio</th>\n",
       "      <th>num_semestres</th>\n",
       "      <th>revista_a1</th>\n",
       "      <th>revista_a2</th>\n",
       "      <th>revista_b1</th>\n",
       "      <th>revista_b2</th>\n",
       "      <th>revista_b3</th>\n",
       "      <th>revista_b4</th>\n",
       "      <th>revista_c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>MESTRADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Ativo Permanente</td>\n",
       "      <td>PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO</td>\n",
       "      <td>DIV                                           ...</td>\n",
       "      <td>NATAL</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>DOUTORADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Ativo Permanente</td>\n",
       "      <td>PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO</td>\n",
       "      <td>DV                                            ...</td>\n",
       "      <td>MACAÍBA</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>MESTRADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Ativo Permanente</td>\n",
       "      <td>PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO</td>\n",
       "      <td>DIV                                           ...</td>\n",
       "      <td>NATAL</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>MESTRADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Ativo Permanente</td>\n",
       "      <td>PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO</td>\n",
       "      <td>DIII                                          ...</td>\n",
       "      <td>MACAÍBA</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>DOUTORADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Ativo Permanente</td>\n",
       "      <td>PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO</td>\n",
       "      <td>DIV                                           ...</td>\n",
       "      <td>MACAÍBA</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2748</th>\n",
       "      <td>1</td>\n",
       "      <td>DOUTORADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Professor Visitante</td>\n",
       "      <td>PROFESSOR MAGISTERIO SUPERIOR - VISITANTE</td>\n",
       "      <td>Adjunto                                       ...</td>\n",
       "      <td>NATAL</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2749</th>\n",
       "      <td>1</td>\n",
       "      <td>DOUTORADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Professor Visitante</td>\n",
       "      <td>PROFESSOR MAGISTERIO SUPERIOR - VISITANTE</td>\n",
       "      <td>Titular                                       ...</td>\n",
       "      <td>NATAL</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2750</th>\n",
       "      <td>1</td>\n",
       "      <td>DOUTORADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Professor Visitante</td>\n",
       "      <td>PROFESSOR MAGISTERIO SUPERIOR - VISITANTE</td>\n",
       "      <td>A                                             ...</td>\n",
       "      <td>NATAL</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2751</th>\n",
       "      <td>0</td>\n",
       "      <td>DOUTORADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Professor Visitante</td>\n",
       "      <td>PROFESSOR MAGISTERIO SUPERIOR - VISITANTE</td>\n",
       "      <td>A                                             ...</td>\n",
       "      <td>NATAL</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2752</th>\n",
       "      <td>1</td>\n",
       "      <td>DOUTORADO</td>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Professor Visitante</td>\n",
       "      <td>PROFESSOR MAGISTERIO SUPERIOR - VISITANTE</td>\n",
       "      <td>Titular                                       ...</td>\n",
       "      <td>NATAL</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2753 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sexo   formacao           tipo_jornada_trabalho              vinculo  \\\n",
       "0        0   MESTRADO  Dedicação exclusiva                Ativo Permanente   \n",
       "1        1  DOUTORADO  Dedicação exclusiva                Ativo Permanente   \n",
       "2        1   MESTRADO  Dedicação exclusiva                Ativo Permanente   \n",
       "3        1   MESTRADO  Dedicação exclusiva                Ativo Permanente   \n",
       "4        0  DOUTORADO  Dedicação exclusiva                Ativo Permanente   \n",
       "...    ...        ...                             ...                  ...   \n",
       "2748     1  DOUTORADO  Dedicação exclusiva             Professor Visitante   \n",
       "2749     1  DOUTORADO  Dedicação exclusiva             Professor Visitante   \n",
       "2750     1  DOUTORADO  Dedicação exclusiva             Professor Visitante   \n",
       "2751     0  DOUTORADO  Dedicação exclusiva             Professor Visitante   \n",
       "2752     1  DOUTORADO  Dedicação exclusiva             Professor Visitante   \n",
       "\n",
       "                                             categoria  \\\n",
       "0     PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO   \n",
       "1     PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO   \n",
       "2     PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO   \n",
       "3     PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO   \n",
       "4     PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO   \n",
       "...                                                ...   \n",
       "2748         PROFESSOR MAGISTERIO SUPERIOR - VISITANTE   \n",
       "2749         PROFESSOR MAGISTERIO SUPERIOR - VISITANTE   \n",
       "2750         PROFESSOR MAGISTERIO SUPERIOR - VISITANTE   \n",
       "2751         PROFESSOR MAGISTERIO SUPERIOR - VISITANTE   \n",
       "2752         PROFESSOR MAGISTERIO SUPERIOR - VISITANTE   \n",
       "\n",
       "                                       classe_funcional municipio  \\\n",
       "0     DIV                                           ...     NATAL   \n",
       "1     DV                                            ...   MACAÍBA   \n",
       "2     DIV                                           ...     NATAL   \n",
       "3     DIII                                          ...   MACAÍBA   \n",
       "4     DIV                                           ...   MACAÍBA   \n",
       "...                                                 ...       ...   \n",
       "2748  Adjunto                                       ...     NATAL   \n",
       "2749  Titular                                       ...     NATAL   \n",
       "2750  A                                             ...     NATAL   \n",
       "2751  A                                             ...     NATAL   \n",
       "2752  Titular                                       ...     NATAL   \n",
       "\n",
       "      num_semestres  revista_a1  revista_a2  revista_b1  revista_b2  \\\n",
       "0                34           0           0           0           0   \n",
       "1                30           1           1           5           0   \n",
       "2                51           0           0           0           0   \n",
       "3                13           0           0           0           0   \n",
       "4                28           0           0           0           1   \n",
       "...             ...         ...         ...         ...         ...   \n",
       "2748              1           0           0           0           1   \n",
       "2749              2           8           4           7           0   \n",
       "2750              2           4           2           5           0   \n",
       "2751              1          44           1           0           0   \n",
       "2752              2           4           0           0           0   \n",
       "\n",
       "      revista_b3  revista_b4  revista_c  \n",
       "0              0           0          0  \n",
       "1              0           4          0  \n",
       "2              0           0          0  \n",
       "3              0           0          0  \n",
       "4              0           0          0  \n",
       "...          ...         ...        ...  \n",
       "2748           0           0          1  \n",
       "2749           2           0          0  \n",
       "2750           0           0          0  \n",
       "2751           0           0          0  \n",
       "2752           0           0          0  \n",
       "\n",
       "[2753 rows x 15 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converter a data de admissao para quantos semestres o professor está na universidade.\n",
    "\n",
    "def num_semestres(data: str, data_atual: str):\n",
    "    data = data[:10]\n",
    "    anos = int(data_atual[6:]) - int(data[:4])\n",
    "    if int(data_atual[3:5]) < 7 and int(data[5:7]) < 7 or int(data_atual[3:5]) >= 7 and int(data[5:7]) >= 7:\n",
    "        return 2*anos\n",
    "    elif int(data_atual[3:5]) < 7 and int(data[5:7]) > 7:\n",
    "        return 2*anos - 1\n",
    "    else:\n",
    "        return 2*anos + 1\n",
    "\n",
    "data_atual = \"18/10/2023\"\n",
    "\n",
    "df['num_semestres'] = df['admissao'].apply(lambda x: num_semestres(x, data_atual))\n",
    "df = df[[\"sexo\", \"formacao\", \"tipo_jornada_trabalho\", \"vinculo\", \"categoria\",\"classe_funcional\", \"municipio\", \"num_semestres\", \"revista_a1\",\n",
    "         \"revista_a2\", \"revista_b1\", \"revista_b2\", \"revista_b3\", \"revista_b4\", \"revista_c\"]]\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tipos de Dados das Colunas do DataFrame Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sexo                      int64\n",
       "formacao                 object\n",
       "tipo_jornada_trabalho    object\n",
       "vinculo                  object\n",
       "categoria                object\n",
       "classe_funcional         object\n",
       "municipio                object\n",
       "num_semestres             int64\n",
       "revista_a1                int64\n",
       "revista_a2                int64\n",
       "revista_b1                int64\n",
       "revista_b2                int64\n",
       "revista_b3                int64\n",
       "revista_b4                int64\n",
       "revista_c                 int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise de Dados no DataFrame Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "existem 2753 entradas diferentes;\n",
      "existem 6 formacoes diferentes;\n",
      "existem 3 tipos de jornada de trabalho diferentes;\n",
      "existem 8 tipos de vinculo diferentes;\n",
      "existem 18 classes funcionais diferentes;\n",
      "existem 7 categorias diferentes;\n",
      "existem 89 datas de admissao diferentes;\n",
      "existem 5 municipios diferentes;\n"
     ]
    }
   ],
   "source": [
    "print(\"existem\", len(df), \"entradas diferentes;\")\n",
    "print(\"existem\", len(df[\"formacao\"].unique()), \"formacoes diferentes;\")\n",
    "print(\"existem\", len(df[\"tipo_jornada_trabalho\"].unique()),\n",
    "      \"tipos de jornada de trabalho diferentes;\")\n",
    "print(\"existem\", len(df[\"vinculo\"].unique()), \"tipos de vinculo diferentes;\")\n",
    "print(\"existem\", len(df[\"classe_funcional\"].unique()),\"classes funcionais diferentes;\")\n",
    "print(\"existem\", len(df[\"categoria\"].unique()),\"categorias diferentes;\")\n",
    "# print(\"existem\", len(df[\"lotacao\"].unique()), \"lotacoes diferentes;\")\n",
    "print(\"existem\", len(df[\"num_semestres\"].unique()),\"datas de admissao diferentes;\")\n",
    "print(\"existem\", len(df[\"municipio\"].unique()),\"municipios diferentes;\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contagem de Professores por Formação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MESTRADO: 431\n",
      "DOUTORADO: 2189\n",
      "ESPECIALIZAÇÃO: 120\n",
      "GRADUAÇÃO: 11\n",
      "PÓS-DOUTORADO: 1\n",
      "DESCONHECIDA: 1\n"
     ]
    }
   ],
   "source": [
    "for formacao in df[\"formacao\"].unique():\n",
    "    print(formacao, \": \", len(df[df[\"formacao\"] == formacao]), sep=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remoção de Professores com Formação Desconhecida e Contagem por Formação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MESTRADO: 431\n",
      "DOUTORADO: 2189\n",
      "ESPECIALIZAÇÃO: 120\n",
      "GRADUAÇÃO: 11\n",
      "PÓS-DOUTORADO: 1\n"
     ]
    }
   ],
   "source": [
    "# retirar professores de formação desconhecida.\n",
    "\n",
    "df = df[df[\"formacao\"] != \"DESCONHECIDA\"]\n",
    "for formacao in df[\"formacao\"].unique():\n",
    "    print(formacao, \": \", len(df[df[\"formacao\"] == formacao]), sep=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classificação por Nível de Formação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3: 431\n",
      "4: 2189\n",
      "2: 120\n",
      "1: 11\n",
      "5: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lucas\\AppData\\Local\\Temp\\ipykernel_27016\\852662980.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"formacao\"].replace(nivel_formacao, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# colocar uma ordem de classificacao. pos-doc > doc > mestrado > esp > grad\n",
    "\n",
    "nivel_formacao = {\"GRADUAÇÃO\":1, \"ESPECIALIZAÇÃO\":2, \"MESTRADO\":3,\"DOUTORADO\":4,\"PÓS-DOUTORADO\":5}\n",
    "\n",
    "df[\"formacao\"].replace(nivel_formacao, inplace=True)\n",
    "for formacao in df[\"formacao\"].unique():\n",
    "    print(formacao, \": \", len(df[df[\"formacao\"] == formacao]), sep=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contagem de Professores por Tipo de Jornada de Trabalho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dedicação exclusiva           : 2155\n",
      "20 horas semanais             : 307\n",
      "40 horas semanais             : 290\n"
     ]
    }
   ],
   "source": [
    "for tipo_jornada_trabalho in df[\"tipo_jornada_trabalho\"].unique():\n",
    "    print(tipo_jornada_trabalho, \": \", len(\n",
    "        df[df[\"tipo_jornada_trabalho\"] == tipo_jornada_trabalho]), sep=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contagem de Professores por Tipo de Vínculo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ativo Permanente: 2376\n",
      "Celetista: 1\n",
      "Colaborador PCCTAE e Magistério Federal: 2\n",
      "Excedente de lotação: 3\n",
      "Exercicio provisorio: 18\n",
      "Professor Substituto: 260\n",
      "Professor Temporario: 50\n",
      "Professor Visitante: 42\n"
     ]
    }
   ],
   "source": [
    "for vinculo in df[\"vinculo\"].unique():\n",
    "    print(vinculo, \": \", len(df[df[\"vinculo\"] == vinculo]), sep=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remoção de Vínculos com Poucas Entradas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ativo Permanente: 2376\n",
      "Exercicio provisorio: 18\n",
      "Professor Substituto: 260\n",
      "Professor Temporario: 50\n",
      "Professor Visitante: 42\n"
     ]
    }
   ],
   "source": [
    "# há poucas pessoas com esses atributos:\n",
    "\n",
    "df = df[df[\"vinculo\"] != \"Celetista\"]\n",
    "df = df[df[\"vinculo\"] != \"Colaborador PCCTAE e Magistério Federal\"]\n",
    "df = df[df[\"vinculo\"] != \"Excedente de lotação\"]\n",
    "for vinculo in df[\"vinculo\"].unique():\n",
    "    print(vinculo, \": \", len(df[df[\"vinculo\"] == vinculo]), sep=\"\")\n",
    "\n",
    "# então decidi retirá-los"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contagem de Professores por Categoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO: 215\n",
      "PROFESSOR DO MAGISTERIO SUPERIOR: 2178\n",
      "PROFESSOR 3 GRAU                        : 1\n",
      "PROF ENS BAS TEC TECNOLOGICO-SUBSTITUTO: 29\n",
      "PROFESSOR DO MAGISTERIO SUPERIOR - SUBSTITUTO: 231\n",
      "PROFESSOR DO MAGISTERIO SUPERIOR - TEMPORARIO: 50\n",
      "PROFESSOR MAGISTERIO SUPERIOR - VISITANTE: 42\n"
     ]
    }
   ],
   "source": [
    "for categoria in df[\"categoria\"].unique():\n",
    "    print(categoria, \": \", len(df[df[\"categoria\"] == categoria]), sep=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veja que a informação de \"SUBSTITUTO\", \"TEMPORARIO\" e \"VISITANTE\" já está informada na coluna \"vínculo\". Então, irei retirá-la dos dados, assim como o único professor de terceiro grau."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Atualização e Simplificação de Categorias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO: 244\n",
      "PROFESSOR DO MAGISTERIO SUPERIOR: 2501\n"
     ]
    }
   ],
   "source": [
    "retirar_vinculo = {\"PROF ENS BAS TEC TECNOLOGICO-SUBSTITUTO\":\"PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO\",\n",
    "                   \"PROFESSOR DO MAGISTERIO SUPERIOR - SUBSTITUTO\":\"PROFESSOR DO MAGISTERIO SUPERIOR\",\n",
    "                   \"PROFESSOR DO MAGISTERIO SUPERIOR - TEMPORARIO\":\"PROFESSOR DO MAGISTERIO SUPERIOR\",\n",
    "                   \"PROFESSOR MAGISTERIO SUPERIOR - VISITANTE\":\"PROFESSOR DO MAGISTERIO SUPERIOR\"}\n",
    "\n",
    "df = df[df[\"categoria\"] != \"PROFESSOR 3 GRAU                        \"]\n",
    "\n",
    "df[\"categoria\"].replace(retirar_vinculo, inplace=True)\n",
    "\n",
    "for categoria in df[\"categoria\"].unique():\n",
    "    print(categoria, \": \", len(df[df[\"categoria\"] == categoria]), sep=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verifique que a soma de elementos de uma mesma categoria se manteve. Agora, iremos ranquear os professores com base em sua classe funcional:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classificação de Professores por Classe Funcional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DIV                                                                                                 : 75\n",
      "DV                                                                                                  : 32\n",
      "DIII                                                                                                : 78\n",
      "DI                                                                                                  : 47\n",
      "D                                                                                                   : 7\n",
      "DII                                                                                                 : 4\n",
      "Classe A - Adjunto A                                                                                : 141\n",
      "Classe C - Adjunto                                                                                  : 757\n",
      "Classe A - Auxiliar                                                                                 : 46\n",
      "Classe E - Titular                                                                                  : 307\n",
      "Classe D - Associado                                                                                : 834\n",
      "Classe B - Assistente                                                                               : 59\n",
      "Classe A - Assistente A                                                                             : 22\n",
      "Não Informada                                                                                       : 16\n",
      "Auxiliar                                                                                            : 278\n",
      "A                                                                                                   : 20\n",
      "Titular                                                                                             : 13\n",
      "Adjunto                                                                                             : 9\n"
     ]
    }
   ],
   "source": [
    "for classe_funcional in df[\"classe_funcional\"].unique():\n",
    "    print(classe_funcional, \": \", len(df[df[\"classe_funcional\"] == classe_funcional]), sep=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver, há 17 professores com classes não-informadas, e algmas estão repetidas e com outros nomes. Ainda, há 20 professores de classe A sem uma subclasse. O mapeamento, segundo a [PROGESP](https://progesp.ufrn.br/secao/carreira), se dá da seguinte maneira:\n",
    "\n",
    "| Original | Mapeamento |\n",
    "|-|-|\n",
    "|DV|1|\n",
    "|DIV|2|\n",
    "|DIII|3|\n",
    "|DII|4|\n",
    "|DI|5|\n",
    "|Classe E - Titular<br>Titular|6|\n",
    "|Classe D - Associado<br>D|7|\n",
    "|Classe C - Adjunto<br>Adjunto|8|\n",
    "|Classe B - Assistente|9|\n",
    "|Classe A - Auxiliar<br>Auxiliar|10|\n",
    "|Classe A - Assistente A<br>A|11|\n",
    "|Classe A - Adjunto A|12|\n",
    "\n",
    "É importante notar também que iremos retirar professores sem categoria. E professores classe A sem denominação específica serão tratados como Assistentes, pois têm o valor médio da classe A."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapeamento e Classificação das Classes Funcionais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapear_class_func = {\n",
    "    \"DV                                                                                                  \":1,\n",
    "    \"DIV                                                                                                 \":2,\n",
    "    \"DIII                                                                                                \":3,\n",
    "    \"DII                                                                                                 \":4,\n",
    "    \"DI                                                                                                  \":5,\n",
    "    \"Classe E - Titular                                                                                  \":6,\n",
    "    \"Titular                                                                                             \":6,\n",
    "    \"Classe D - Associado                                                                                \":7,\n",
    "    \"D                                                                                                   \":7,\n",
    "    \"Classe C - Adjunto                                                                                  \":8,\n",
    "    \"Adjunto                                                                                             \":8,\n",
    "    \"Classe B - Assistente                                                                               \":9,\n",
    "    \"Classe A - Auxiliar                                                                                 \":10,\n",
    "    \"Auxiliar                                                                                            \":10,\n",
    "    \"Classe A - Assistente A                                                                             \":11,\n",
    "    \"A                                                                                                   \":11,\n",
    "    \"Classe A - Adjunto A                                                                                \":12,\n",
    "}\n",
    "\n",
    "df = df[df[\"classe_funcional\"] != \"Não Informada                                                                                       \"]\n",
    "\n",
    "df[\"classe_funcional\"].replace(mapear_class_func, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contagem de Professores por Classe Funcional Após Classificação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2: 75\n",
      "1: 32\n",
      "3: 78\n",
      "5: 47\n",
      "7: 841\n",
      "4: 4\n",
      "12: 141\n",
      "8: 766\n",
      "10: 324\n",
      "6: 320\n",
      "9: 59\n",
      "11: 42\n"
     ]
    }
   ],
   "source": [
    "for classe_funcional in df[\"classe_funcional\"].unique():\n",
    "    print(classe_funcional, \": \", len(df[df[\"classe_funcional\"] == classe_funcional]), sep=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reset do Índice e Resumo Estatístico do DataFrame Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sexo</th>\n",
       "      <th>formacao</th>\n",
       "      <th>classe_funcional</th>\n",
       "      <th>num_semestres</th>\n",
       "      <th>revista_a1</th>\n",
       "      <th>revista_a2</th>\n",
       "      <th>revista_b1</th>\n",
       "      <th>revista_b2</th>\n",
       "      <th>revista_b3</th>\n",
       "      <th>revista_b4</th>\n",
       "      <th>revista_c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2729.000000</td>\n",
       "      <td>2729.000000</td>\n",
       "      <td>2729.000000</td>\n",
       "      <td>2729.000000</td>\n",
       "      <td>2729.000000</td>\n",
       "      <td>2729.000000</td>\n",
       "      <td>2729.000000</td>\n",
       "      <td>2729.000000</td>\n",
       "      <td>2729.000000</td>\n",
       "      <td>2729.000000</td>\n",
       "      <td>2729.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.540857</td>\n",
       "      <td>3.744229</td>\n",
       "      <td>7.521803</td>\n",
       "      <td>25.477831</td>\n",
       "      <td>2.646757</td>\n",
       "      <td>1.939538</td>\n",
       "      <td>1.755955</td>\n",
       "      <td>1.270429</td>\n",
       "      <td>0.814584</td>\n",
       "      <td>0.569073</td>\n",
       "      <td>0.890070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.498419</td>\n",
       "      <td>0.548749</td>\n",
       "      <td>2.113959</td>\n",
       "      <td>20.856943</td>\n",
       "      <td>6.095930</td>\n",
       "      <td>3.929876</td>\n",
       "      <td>5.398132</td>\n",
       "      <td>2.900249</td>\n",
       "      <td>2.394411</td>\n",
       "      <td>1.780601</td>\n",
       "      <td>3.868675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>124.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              sexo     formacao  classe_funcional  num_semestres   revista_a1  \\\n",
       "count  2729.000000  2729.000000       2729.000000    2729.000000  2729.000000   \n",
       "mean      0.540857     3.744229          7.521803      25.477831     2.646757   \n",
       "std       0.498419     0.548749          2.113959      20.856943     6.095930   \n",
       "min       0.000000     1.000000          1.000000       0.000000     0.000000   \n",
       "25%       0.000000     4.000000          7.000000      10.000000     0.000000   \n",
       "50%       1.000000     4.000000          7.000000      24.000000     0.000000   \n",
       "75%       1.000000     4.000000          8.000000      30.000000     3.000000   \n",
       "max       1.000000     5.000000         12.000000      97.000000    71.000000   \n",
       "\n",
       "        revista_a2   revista_b1   revista_b2   revista_b3   revista_b4  \\\n",
       "count  2729.000000  2729.000000  2729.000000  2729.000000  2729.000000   \n",
       "mean      1.939538     1.755955     1.270429     0.814584     0.569073   \n",
       "std       3.929876     5.398132     2.900249     2.394411     1.780601   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       2.000000     2.000000     1.000000     1.000000     0.000000   \n",
       "max      51.000000    99.000000    46.000000    41.000000    32.000000   \n",
       "\n",
       "         revista_c  \n",
       "count  2729.000000  \n",
       "mean      0.890070  \n",
       "std       3.868675  \n",
       "min       0.000000  \n",
       "25%       0.000000  \n",
       "50%       0.000000  \n",
       "75%       1.000000  \n",
       "max     124.000000  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.reset_index(drop=True, inplace=True)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resumo Estatístico das Colunas de Texto no DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tipo_jornada_trabalho</th>\n",
       "      <th>vinculo</th>\n",
       "      <th>categoria</th>\n",
       "      <th>municipio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2729</td>\n",
       "      <td>2729</td>\n",
       "      <td>2729</td>\n",
       "      <td>2729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Dedicação exclusiva</td>\n",
       "      <td>Ativo Permanente</td>\n",
       "      <td>PROFESSOR DO MAGISTERIO SUPERIOR</td>\n",
       "      <td>NATAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>2133</td>\n",
       "      <td>2376</td>\n",
       "      <td>2486</td>\n",
       "      <td>2274</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 tipo_jornada_trabalho           vinculo  \\\n",
       "count                             2729              2729   \n",
       "unique                               3                 5   \n",
       "top     Dedicação exclusiva             Ativo Permanente   \n",
       "freq                              2133              2376   \n",
       "\n",
       "                               categoria municipio  \n",
       "count                               2729      2729  \n",
       "unique                                 2         5  \n",
       "top     PROFESSOR DO MAGISTERIO SUPERIOR     NATAL  \n",
       "freq                                2486      2274  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include=\"object\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparação dos Dados para Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep = ['revista_a1',\n",
    "        'revista_a2',\n",
    "        'revista_b1',\n",
    "        'revista_b2',\n",
    "        'revista_b3',\n",
    "        'revista_b4',\n",
    "        'revista_c']\n",
    "\n",
    "X = df.drop(keep, axis=1).copy()\n",
    "\n",
    "[ya1,\n",
    " ya2,\n",
    " yb1,\n",
    " yb2,\n",
    " yb3,\n",
    " yb4,\n",
    " yc] = [df[col].copy() for col in keep]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Codificação de Variáveis Categóricas em Dados Numéricos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sexo</th>\n",
       "      <th>formacao</th>\n",
       "      <th>classe_funcional</th>\n",
       "      <th>num_semestres</th>\n",
       "      <th>tipo_jornada_trabalho_20 horas semanais</th>\n",
       "      <th>tipo_jornada_trabalho_40 horas semanais</th>\n",
       "      <th>tipo_jornada_trabalho_Dedicação exclusiva</th>\n",
       "      <th>vinculo_Ativo Permanente</th>\n",
       "      <th>vinculo_Exercicio provisorio</th>\n",
       "      <th>vinculo_Professor Substituto</th>\n",
       "      <th>vinculo_Professor Temporario</th>\n",
       "      <th>vinculo_Professor Visitante</th>\n",
       "      <th>categoria_PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO</th>\n",
       "      <th>categoria_PROFESSOR DO MAGISTERIO SUPERIOR</th>\n",
       "      <th>municipio_CAICÓ</th>\n",
       "      <th>municipio_CURRAIS NOVOS</th>\n",
       "      <th>municipio_MACAÍBA</th>\n",
       "      <th>municipio_NATAL</th>\n",
       "      <th>municipio_SANTA CRUZ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>51</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2724</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2725</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2726</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2727</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2728</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2729 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sexo  formacao  classe_funcional  num_semestres  \\\n",
       "0        0         3                 2             34   \n",
       "1        1         4                 1             30   \n",
       "2        1         3                 2             51   \n",
       "3        1         3                 3             13   \n",
       "4        0         4                 2             28   \n",
       "...    ...       ...               ...            ...   \n",
       "2724     1         4                 8              1   \n",
       "2725     1         4                 6              2   \n",
       "2726     1         4                11              2   \n",
       "2727     0         4                11              1   \n",
       "2728     1         4                 6              2   \n",
       "\n",
       "      tipo_jornada_trabalho_20 horas semanais               \\\n",
       "0                                                 False      \n",
       "1                                                 False      \n",
       "2                                                 False      \n",
       "3                                                 False      \n",
       "4                                                 False      \n",
       "...                                                 ...      \n",
       "2724                                              False      \n",
       "2725                                              False      \n",
       "2726                                              False      \n",
       "2727                                              False      \n",
       "2728                                              False      \n",
       "\n",
       "      tipo_jornada_trabalho_40 horas semanais               \\\n",
       "0                                                 False      \n",
       "1                                                 False      \n",
       "2                                                 False      \n",
       "3                                                 False      \n",
       "4                                                 False      \n",
       "...                                                 ...      \n",
       "2724                                              False      \n",
       "2725                                              False      \n",
       "2726                                              False      \n",
       "2727                                              False      \n",
       "2728                                              False      \n",
       "\n",
       "      tipo_jornada_trabalho_Dedicação exclusiva             \\\n",
       "0                                                  True      \n",
       "1                                                  True      \n",
       "2                                                  True      \n",
       "3                                                  True      \n",
       "4                                                  True      \n",
       "...                                                 ...      \n",
       "2724                                               True      \n",
       "2725                                               True      \n",
       "2726                                               True      \n",
       "2727                                               True      \n",
       "2728                                               True      \n",
       "\n",
       "      vinculo_Ativo Permanente  vinculo_Exercicio provisorio  \\\n",
       "0                         True                         False   \n",
       "1                         True                         False   \n",
       "2                         True                         False   \n",
       "3                         True                         False   \n",
       "4                         True                         False   \n",
       "...                        ...                           ...   \n",
       "2724                     False                         False   \n",
       "2725                     False                         False   \n",
       "2726                     False                         False   \n",
       "2727                     False                         False   \n",
       "2728                     False                         False   \n",
       "\n",
       "      vinculo_Professor Substituto  vinculo_Professor Temporario  \\\n",
       "0                            False                         False   \n",
       "1                            False                         False   \n",
       "2                            False                         False   \n",
       "3                            False                         False   \n",
       "4                            False                         False   \n",
       "...                            ...                           ...   \n",
       "2724                         False                         False   \n",
       "2725                         False                         False   \n",
       "2726                         False                         False   \n",
       "2727                         False                         False   \n",
       "2728                         False                         False   \n",
       "\n",
       "      vinculo_Professor Visitante  \\\n",
       "0                           False   \n",
       "1                           False   \n",
       "2                           False   \n",
       "3                           False   \n",
       "4                           False   \n",
       "...                           ...   \n",
       "2724                         True   \n",
       "2725                         True   \n",
       "2726                         True   \n",
       "2727                         True   \n",
       "2728                         True   \n",
       "\n",
       "      categoria_PROFESSOR DE ENSINO BASICO TECNICO E TECNOLOGICO  \\\n",
       "0                                                  True            \n",
       "1                                                  True            \n",
       "2                                                  True            \n",
       "3                                                  True            \n",
       "4                                                  True            \n",
       "...                                                 ...            \n",
       "2724                                              False            \n",
       "2725                                              False            \n",
       "2726                                              False            \n",
       "2727                                              False            \n",
       "2728                                              False            \n",
       "\n",
       "      categoria_PROFESSOR DO MAGISTERIO SUPERIOR  municipio_CAICÓ  \\\n",
       "0                                          False            False   \n",
       "1                                          False            False   \n",
       "2                                          False            False   \n",
       "3                                          False            False   \n",
       "4                                          False            False   \n",
       "...                                          ...              ...   \n",
       "2724                                        True            False   \n",
       "2725                                        True            False   \n",
       "2726                                        True            False   \n",
       "2727                                        True            False   \n",
       "2728                                        True            False   \n",
       "\n",
       "      municipio_CURRAIS NOVOS  municipio_MACAÍBA  municipio_NATAL  \\\n",
       "0                       False              False             True   \n",
       "1                       False               True            False   \n",
       "2                       False              False             True   \n",
       "3                       False               True            False   \n",
       "4                       False               True            False   \n",
       "...                       ...                ...              ...   \n",
       "2724                    False              False             True   \n",
       "2725                    False              False             True   \n",
       "2726                    False              False             True   \n",
       "2727                    False              False             True   \n",
       "2728                    False              False             True   \n",
       "\n",
       "      municipio_SANTA CRUZ  \n",
       "0                    False  \n",
       "1                    False  \n",
       "2                    False  \n",
       "3                    False  \n",
       "4                    False  \n",
       "...                    ...  \n",
       "2724                 False  \n",
       "2725                 False  \n",
       "2726                 False  \n",
       "2727                 False  \n",
       "2728                 False  \n",
       "\n",
       "[2729 rows x 19 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_encoded = pd.get_dummies(X, columns=[\"tipo_jornada_trabalho\",\n",
    "                                       \"vinculo\",\n",
    "                                       \"categoria\",\n",
    "                                       \"municipio\"])\n",
    "\n",
    "X_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cálculo das Médias das Taxas por Categoria de Revista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ya1': 2.646757053865885,\n",
       " 'ya2': 1.939538292414804,\n",
       " 'yb1': 1.7559545621106631,\n",
       " 'yb2': 1.2704287284719677,\n",
       " 'yb3': 0.8145840967387321,\n",
       " 'yb4': 0.5690729204836936,\n",
       " 'yc': 0.8900696225723709}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\"ya1\": (sum(ya1) / len(ya1)),\n",
    " \"ya2\": (sum(ya2) / len(ya2)),\n",
    " \"yb1\": (sum(yb1) / len(yb1)),\n",
    " \"yb2\": (sum(yb2) / len(yb2)),\n",
    " \"yb3\": (sum(yb3) / len(yb3)),\n",
    " \"yb4\": (sum(yb4) / len(yb4)),\n",
    " \"yc\": (sum(yc) / len(yc))}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparação dos Conjuntos de Treinamento e Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_vars = [(ya1, \"ya1\"),\n",
    "               (ya2, \"ya2\"),\n",
    "               (yb1, \"yb1\"),\n",
    "               (yb2, \"yb2\"),\n",
    "               (yb3, \"yb3\"),\n",
    "               (yb4, \"yb4\"),\n",
    "               (yc, \"yc\")]\n",
    "\n",
    "train_test_sets = {}\n",
    "\n",
    "for var, var_name in target_vars:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_encoded, var, random_state=42)\n",
    "    train_test_sets[var_name] = (X_train, X_test, y_train, y_test)\n",
    "\n",
    "# Agora, você pode acessar os conjuntos de treinamento e teste usando o nome da variável alvo desejada\n",
    "X_train_ya1, X_test_ya1, ya1_train, ya1_test = train_test_sets[\"ya1\"]\n",
    "X_train_ya2, X_test_ya2, ya2_train, ya2_test = train_test_sets[\"ya2\"]\n",
    "X_train_yb1, X_test_yb1, yb1_train, yb1_test = train_test_sets[\"yb1\"]\n",
    "X_train_yb2, X_test_yb2, yb2_train, yb2_test = train_test_sets[\"yb2\"]\n",
    "X_train_yb3, X_test_yb3, yb3_train, yb3_test = train_test_sets[\"yb3\"]\n",
    "X_train_yb4, X_test_yb4, yb4_train, yb4_test = train_test_sets[\"yb4\"]\n",
    "X_train_yc, X_test_yc, yc_train, yc_test = train_test_sets[\"yc\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Médias das Taxas nas Partições de Treinamento e Teste por Categoria de Revista (TRAIN & TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ya1': (2.639784946236559, 2.6676427525622253),\n",
       " 'ya2': (1.9472140762463344, 1.916544655929722),\n",
       " 'yb1': (1.6715542521994136, 2.0087847730600292),\n",
       " 'yb2': (1.1901270772238515, 1.5109809663250366),\n",
       " 'yb3': (0.8093841642228738, 0.8301610541727672),\n",
       " 'yb4': (0.5650048875855328, 0.5812591508052709),\n",
       " 'yc': (0.9496578690127078, 0.7115666178623719)}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test_pairs = {\n",
    "    \"ya1\": (sum(ya1_train) / len(ya1_train), sum(ya1_test) / len(ya1_test)),\n",
    "    \"ya2\": (sum(ya2_train) / len(ya2_train), sum(ya2_test) / len(ya2_test)),\n",
    "    \"yb1\": (sum(yb1_train) / len(yb1_train), sum(yb1_test) / len(yb1_test)),\n",
    "    \"yb2\": (sum(yb2_train) / len(yb2_train), sum(yb2_test) / len(yb2_test)),\n",
    "    \"yb3\": (sum(yb3_train) / len(yb3_train), sum(yb3_test) / len(yb3_test)),\n",
    "    \"yb4\": (sum(yb4_train) / len(yb4_train), sum(yb4_test) / len(yb4_test)),\n",
    "    \"yc\" : (sum(yc_train) / len(yc_train), sum(yc_test) / len(yc_test))\n",
    "}\n",
    "\n",
    "train_test_pairs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Espaço de Parâmetros para Otimização do Modelo Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_space = {\n",
    "    \"max_depth\": Integer(1,20),\n",
    "    \"n_estimators\":Integer(10,10000),\n",
    "    \"min_samples_split\":Integer(2,100),\n",
    "    \"max_features\":Integer(1,19),\n",
    "    \"max_leaf_nodes\":Integer(2,100),\n",
    "    \"bootstrap\":[0]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinamento e Otimização do Modelo Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo Random Forest para \"ya1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BayesSearchCV(cv=5, estimator=RandomForestRegressor(), n_iter=40, n_jobs=8,\n",
       "              random_state=42, scoring=&#x27;neg_root_mean_squared_error&#x27;,\n",
       "              search_spaces={&#x27;bootstrap&#x27;: [0],\n",
       "                             &#x27;max_depth&#x27;: Integer(low=1, high=20, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;max_features&#x27;: Integer(low=1, high=19, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;max_leaf_nodes&#x27;: Integer(low=2, high=100, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;min_samples_split&#x27;: Integer(low=2, high=100, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;n_estimators&#x27;: Integer(low=10, high=10000, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;)},\n",
       "              verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BayesSearchCV</label><div class=\"sk-toggleable__content\"><pre>BayesSearchCV(cv=5, estimator=RandomForestRegressor(), n_iter=40, n_jobs=8,\n",
       "              random_state=42, scoring=&#x27;neg_root_mean_squared_error&#x27;,\n",
       "              search_spaces={&#x27;bootstrap&#x27;: [0],\n",
       "                             &#x27;max_depth&#x27;: Integer(low=1, high=20, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;max_features&#x27;: Integer(low=1, high=19, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;max_leaf_nodes&#x27;: Integer(low=2, high=100, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;min_samples_split&#x27;: Integer(low=2, high=100, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;n_estimators&#x27;: Integer(low=10, high=10000, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;)},\n",
       "              verbose=True)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "BayesSearchCV(cv=5, estimator=RandomForestRegressor(), n_iter=40, n_jobs=8,\n",
       "              random_state=42, scoring='neg_root_mean_squared_error',\n",
       "              search_spaces={'bootstrap': [0],\n",
       "                             'max_depth': Integer(low=1, high=20, prior='uniform', transform='normalize'),\n",
       "                             'max_features': Integer(low=1, high=19, prior='uniform', transform='normalize'),\n",
       "                             'max_leaf_nodes': Integer(low=2, high=100, prior='uniform', transform='normalize'),\n",
       "                             'min_samples_split': Integer(low=2, high=100, prior='uniform', transform='normalize'),\n",
       "                             'n_estimators': Integer(low=10, high=10000, prior='uniform', transform='normalize')},\n",
       "              verbose=True)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrn.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "reg_rf_ya1 = RandomForestRegressor()\n",
    "\n",
    "rf_bayes_ya1 = BayesSearchCV(reg_rf_ya1,\n",
    "                              param_space,\n",
    "                              n_iter=40,\n",
    "                              scoring=\"neg_root_mean_squared_error\",\n",
    "                              verbose=True,\n",
    "                              cv=5,\n",
    "                              n_jobs=8,\n",
    "                              random_state=42)\n",
    "\n",
    "rf_bayes_ya1.fit(X_train_ya1, ya1_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo Random Forest para \"ya2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BayesSearchCV(cv=5, estimator=RandomForestRegressor(), n_iter=40, n_jobs=8,\n",
       "              random_state=42, scoring=&#x27;neg_root_mean_squared_error&#x27;,\n",
       "              search_spaces={&#x27;bootstrap&#x27;: [0],\n",
       "                             &#x27;max_depth&#x27;: Integer(low=1, high=20, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;max_features&#x27;: Integer(low=1, high=19, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;max_leaf_nodes&#x27;: Integer(low=2, high=100, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;min_samples_split&#x27;: Integer(low=2, high=100, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;n_estimators&#x27;: Integer(low=10, high=10000, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;)},\n",
       "              verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BayesSearchCV</label><div class=\"sk-toggleable__content\"><pre>BayesSearchCV(cv=5, estimator=RandomForestRegressor(), n_iter=40, n_jobs=8,\n",
       "              random_state=42, scoring=&#x27;neg_root_mean_squared_error&#x27;,\n",
       "              search_spaces={&#x27;bootstrap&#x27;: [0],\n",
       "                             &#x27;max_depth&#x27;: Integer(low=1, high=20, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;max_features&#x27;: Integer(low=1, high=19, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;max_leaf_nodes&#x27;: Integer(low=2, high=100, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;min_samples_split&#x27;: Integer(low=2, high=100, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;n_estimators&#x27;: Integer(low=10, high=10000, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;)},\n",
       "              verbose=True)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "BayesSearchCV(cv=5, estimator=RandomForestRegressor(), n_iter=40, n_jobs=8,\n",
       "              random_state=42, scoring='neg_root_mean_squared_error',\n",
       "              search_spaces={'bootstrap': [0],\n",
       "                             'max_depth': Integer(low=1, high=20, prior='uniform', transform='normalize'),\n",
       "                             'max_features': Integer(low=1, high=19, prior='uniform', transform='normalize'),\n",
       "                             'max_leaf_nodes': Integer(low=2, high=100, prior='uniform', transform='normalize'),\n",
       "                             'min_samples_split': Integer(low=2, high=100, prior='uniform', transform='normalize'),\n",
       "                             'n_estimators': Integer(low=10, high=10000, prior='uniform', transform='normalize')},\n",
       "              verbose=True)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrn.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "reg_rf_ya2 = RandomForestRegressor()\n",
    "\n",
    "rf_bayes_ya2 = BayesSearchCV(reg_rf_ya2,\n",
    "                              param_space,\n",
    "                              n_iter=40,\n",
    "                              scoring=\"neg_root_mean_squared_error\",\n",
    "                              verbose=True,\n",
    "                              cv=5,\n",
    "                              n_jobs=8,\n",
    "                              random_state=42)\n",
    "\n",
    "rf_bayes_ya2.fit(X_train_ya2, ya2_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo Random Forest para \"yb1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BayesSearchCV(cv=5, estimator=RandomForestRegressor(), n_iter=40, n_jobs=8,\n",
       "              random_state=42, scoring=&#x27;neg_root_mean_squared_error&#x27;,\n",
       "              search_spaces={&#x27;bootstrap&#x27;: [0],\n",
       "                             &#x27;max_depth&#x27;: Integer(low=1, high=20, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;max_features&#x27;: Integer(low=1, high=19, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;max_leaf_nodes&#x27;: Integer(low=2, high=100, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;min_samples_split&#x27;: Integer(low=2, high=100, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;n_estimators&#x27;: Integer(low=10, high=10000, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;)},\n",
       "              verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BayesSearchCV</label><div class=\"sk-toggleable__content\"><pre>BayesSearchCV(cv=5, estimator=RandomForestRegressor(), n_iter=40, n_jobs=8,\n",
       "              random_state=42, scoring=&#x27;neg_root_mean_squared_error&#x27;,\n",
       "              search_spaces={&#x27;bootstrap&#x27;: [0],\n",
       "                             &#x27;max_depth&#x27;: Integer(low=1, high=20, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;max_features&#x27;: Integer(low=1, high=19, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;max_leaf_nodes&#x27;: Integer(low=2, high=100, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;min_samples_split&#x27;: Integer(low=2, high=100, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;n_estimators&#x27;: Integer(low=10, high=10000, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;)},\n",
       "              verbose=True)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "BayesSearchCV(cv=5, estimator=RandomForestRegressor(), n_iter=40, n_jobs=8,\n",
       "              random_state=42, scoring='neg_root_mean_squared_error',\n",
       "              search_spaces={'bootstrap': [0],\n",
       "                             'max_depth': Integer(low=1, high=20, prior='uniform', transform='normalize'),\n",
       "                             'max_features': Integer(low=1, high=19, prior='uniform', transform='normalize'),\n",
       "                             'max_leaf_nodes': Integer(low=2, high=100, prior='uniform', transform='normalize'),\n",
       "                             'min_samples_split': Integer(low=2, high=100, prior='uniform', transform='normalize'),\n",
       "                             'n_estimators': Integer(low=10, high=10000, prior='uniform', transform='normalize')},\n",
       "              verbose=True)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrn.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "reg_rf_yb1 = RandomForestRegressor()\n",
    "\n",
    "rf_bayes_yb1 = BayesSearchCV(reg_rf_yb1,\n",
    "                              param_space,\n",
    "                              n_iter=40,\n",
    "                              scoring=\"neg_root_mean_squared_error\",\n",
    "                              verbose=True,\n",
    "                              cv=5,\n",
    "                              n_jobs=8,\n",
    "                              random_state=42)\n",
    "\n",
    "rf_bayes_yb1.fit(X_train_yb1, yb1_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo Random Forest para \"yb2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BayesSearchCV(cv=5, estimator=RandomForestRegressor(), n_iter=40, n_jobs=8,\n",
       "              random_state=42, scoring=&#x27;neg_root_mean_squared_error&#x27;,\n",
       "              search_spaces={&#x27;bootstrap&#x27;: [0],\n",
       "                             &#x27;max_depth&#x27;: Integer(low=1, high=20, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;max_features&#x27;: Integer(low=1, high=19, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;max_leaf_nodes&#x27;: Integer(low=2, high=100, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;min_samples_split&#x27;: Integer(low=2, high=100, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;n_estimators&#x27;: Integer(low=10, high=10000, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;)},\n",
       "              verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BayesSearchCV</label><div class=\"sk-toggleable__content\"><pre>BayesSearchCV(cv=5, estimator=RandomForestRegressor(), n_iter=40, n_jobs=8,\n",
       "              random_state=42, scoring=&#x27;neg_root_mean_squared_error&#x27;,\n",
       "              search_spaces={&#x27;bootstrap&#x27;: [0],\n",
       "                             &#x27;max_depth&#x27;: Integer(low=1, high=20, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;max_features&#x27;: Integer(low=1, high=19, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;max_leaf_nodes&#x27;: Integer(low=2, high=100, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;min_samples_split&#x27;: Integer(low=2, high=100, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;n_estimators&#x27;: Integer(low=10, high=10000, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;)},\n",
       "              verbose=True)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "BayesSearchCV(cv=5, estimator=RandomForestRegressor(), n_iter=40, n_jobs=8,\n",
       "              random_state=42, scoring='neg_root_mean_squared_error',\n",
       "              search_spaces={'bootstrap': [0],\n",
       "                             'max_depth': Integer(low=1, high=20, prior='uniform', transform='normalize'),\n",
       "                             'max_features': Integer(low=1, high=19, prior='uniform', transform='normalize'),\n",
       "                             'max_leaf_nodes': Integer(low=2, high=100, prior='uniform', transform='normalize'),\n",
       "                             'min_samples_split': Integer(low=2, high=100, prior='uniform', transform='normalize'),\n",
       "                             'n_estimators': Integer(low=10, high=10000, prior='uniform', transform='normalize')},\n",
       "              verbose=True)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrn.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "reg_rf_yb2 = RandomForestRegressor()\n",
    "\n",
    "rf_bayes_yb2 = BayesSearchCV(reg_rf_yb2,\n",
    "                              param_space,\n",
    "                              n_iter=40,\n",
    "                              scoring=\"neg_root_mean_squared_error\",\n",
    "                              verbose=True,\n",
    "                              cv=5,\n",
    "                              n_jobs=8,\n",
    "                              random_state=42)\n",
    "\n",
    "rf_bayes_yb2.fit(X_train_yb2, yb2_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo Random Forest para \"yb3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BayesSearchCV(cv=5, estimator=RandomForestRegressor(), n_iter=40, n_jobs=8,\n",
       "              random_state=42, scoring=&#x27;neg_root_mean_squared_error&#x27;,\n",
       "              search_spaces={&#x27;bootstrap&#x27;: [0],\n",
       "                             &#x27;max_depth&#x27;: Integer(low=1, high=20, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;max_features&#x27;: Integer(low=1, high=19, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;max_leaf_nodes&#x27;: Integer(low=2, high=100, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;min_samples_split&#x27;: Integer(low=2, high=100, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;n_estimators&#x27;: Integer(low=10, high=10000, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;)},\n",
       "              verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BayesSearchCV</label><div class=\"sk-toggleable__content\"><pre>BayesSearchCV(cv=5, estimator=RandomForestRegressor(), n_iter=40, n_jobs=8,\n",
       "              random_state=42, scoring=&#x27;neg_root_mean_squared_error&#x27;,\n",
       "              search_spaces={&#x27;bootstrap&#x27;: [0],\n",
       "                             &#x27;max_depth&#x27;: Integer(low=1, high=20, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;max_features&#x27;: Integer(low=1, high=19, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;max_leaf_nodes&#x27;: Integer(low=2, high=100, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;min_samples_split&#x27;: Integer(low=2, high=100, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;n_estimators&#x27;: Integer(low=10, high=10000, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;)},\n",
       "              verbose=True)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "BayesSearchCV(cv=5, estimator=RandomForestRegressor(), n_iter=40, n_jobs=8,\n",
       "              random_state=42, scoring='neg_root_mean_squared_error',\n",
       "              search_spaces={'bootstrap': [0],\n",
       "                             'max_depth': Integer(low=1, high=20, prior='uniform', transform='normalize'),\n",
       "                             'max_features': Integer(low=1, high=19, prior='uniform', transform='normalize'),\n",
       "                             'max_leaf_nodes': Integer(low=2, high=100, prior='uniform', transform='normalize'),\n",
       "                             'min_samples_split': Integer(low=2, high=100, prior='uniform', transform='normalize'),\n",
       "                             'n_estimators': Integer(low=10, high=10000, prior='uniform', transform='normalize')},\n",
       "              verbose=True)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrn.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "reg_rf_yb3 = RandomForestRegressor()\n",
    "\n",
    "rf_bayes_yb3 = BayesSearchCV(reg_rf_yb3,\n",
    "                              param_space,\n",
    "                              n_iter=40,\n",
    "                              scoring=\"neg_root_mean_squared_error\",\n",
    "                              verbose=True,\n",
    "                              cv=5,\n",
    "                              n_jobs=8,\n",
    "                              random_state=42)\n",
    "\n",
    "rf_bayes_yb3.fit(X_train_yb3, yb3_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo Random Forest para \"yb4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BayesSearchCV(cv=5, estimator=RandomForestRegressor(), n_iter=40, n_jobs=8,\n",
       "              random_state=42, scoring=&#x27;neg_root_mean_squared_error&#x27;,\n",
       "              search_spaces={&#x27;bootstrap&#x27;: [0],\n",
       "                             &#x27;max_depth&#x27;: Integer(low=1, high=20, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;max_features&#x27;: Integer(low=1, high=19, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;max_leaf_nodes&#x27;: Integer(low=2, high=100, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;min_samples_split&#x27;: Integer(low=2, high=100, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;n_estimators&#x27;: Integer(low=10, high=10000, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;)},\n",
       "              verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BayesSearchCV</label><div class=\"sk-toggleable__content\"><pre>BayesSearchCV(cv=5, estimator=RandomForestRegressor(), n_iter=40, n_jobs=8,\n",
       "              random_state=42, scoring=&#x27;neg_root_mean_squared_error&#x27;,\n",
       "              search_spaces={&#x27;bootstrap&#x27;: [0],\n",
       "                             &#x27;max_depth&#x27;: Integer(low=1, high=20, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;max_features&#x27;: Integer(low=1, high=19, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;max_leaf_nodes&#x27;: Integer(low=2, high=100, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;min_samples_split&#x27;: Integer(low=2, high=100, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;n_estimators&#x27;: Integer(low=10, high=10000, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;)},\n",
       "              verbose=True)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "BayesSearchCV(cv=5, estimator=RandomForestRegressor(), n_iter=40, n_jobs=8,\n",
       "              random_state=42, scoring='neg_root_mean_squared_error',\n",
       "              search_spaces={'bootstrap': [0],\n",
       "                             'max_depth': Integer(low=1, high=20, prior='uniform', transform='normalize'),\n",
       "                             'max_features': Integer(low=1, high=19, prior='uniform', transform='normalize'),\n",
       "                             'max_leaf_nodes': Integer(low=2, high=100, prior='uniform', transform='normalize'),\n",
       "                             'min_samples_split': Integer(low=2, high=100, prior='uniform', transform='normalize'),\n",
       "                             'n_estimators': Integer(low=10, high=10000, prior='uniform', transform='normalize')},\n",
       "              verbose=True)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrn.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "reg_rf_yb4 = RandomForestRegressor()\n",
    "\n",
    "rf_bayes_yb4 = BayesSearchCV(reg_rf_yb4,\n",
    "                              param_space,\n",
    "                              n_iter=40,\n",
    "                              scoring=\"neg_root_mean_squared_error\",\n",
    "                              verbose=True,\n",
    "                              cv=5,\n",
    "                              n_jobs=8,\n",
    "                              random_state=42)\n",
    "\n",
    "rf_bayes_yb4.fit(X_train_yb4, yb4_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo Random Forest para \"yc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BayesSearchCV(cv=5, estimator=RandomForestRegressor(), n_iter=40, n_jobs=8,\n",
       "              random_state=42, scoring=&#x27;neg_root_mean_squared_error&#x27;,\n",
       "              search_spaces={&#x27;bootstrap&#x27;: [0],\n",
       "                             &#x27;max_depth&#x27;: Integer(low=1, high=20, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;max_features&#x27;: Integer(low=1, high=19, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;max_leaf_nodes&#x27;: Integer(low=2, high=100, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;min_samples_split&#x27;: Integer(low=2, high=100, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;n_estimators&#x27;: Integer(low=10, high=10000, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;)},\n",
       "              verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BayesSearchCV</label><div class=\"sk-toggleable__content\"><pre>BayesSearchCV(cv=5, estimator=RandomForestRegressor(), n_iter=40, n_jobs=8,\n",
       "              random_state=42, scoring=&#x27;neg_root_mean_squared_error&#x27;,\n",
       "              search_spaces={&#x27;bootstrap&#x27;: [0],\n",
       "                             &#x27;max_depth&#x27;: Integer(low=1, high=20, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;max_features&#x27;: Integer(low=1, high=19, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;max_leaf_nodes&#x27;: Integer(low=2, high=100, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;min_samples_split&#x27;: Integer(low=2, high=100, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;n_estimators&#x27;: Integer(low=10, high=10000, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;)},\n",
       "              verbose=True)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" ><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "BayesSearchCV(cv=5, estimator=RandomForestRegressor(), n_iter=40, n_jobs=8,\n",
       "              random_state=42, scoring='neg_root_mean_squared_error',\n",
       "              search_spaces={'bootstrap': [0],\n",
       "                             'max_depth': Integer(low=1, high=20, prior='uniform', transform='normalize'),\n",
       "                             'max_features': Integer(low=1, high=19, prior='uniform', transform='normalize'),\n",
       "                             'max_leaf_nodes': Integer(low=2, high=100, prior='uniform', transform='normalize'),\n",
       "                             'min_samples_split': Integer(low=2, high=100, prior='uniform', transform='normalize'),\n",
       "                             'n_estimators': Integer(low=10, high=10000, prior='uniform', transform='normalize')},\n",
       "              verbose=True)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrn.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "reg_rf_yc = RandomForestRegressor()\n",
    "\n",
    "rf_bayes_yc = BayesSearchCV(reg_rf_yc,\n",
    "                              param_space,\n",
    "                              n_iter=40,\n",
    "                              scoring=\"neg_root_mean_squared_error\",\n",
    "                              verbose=True,\n",
    "                              cv=5,\n",
    "                              n_jobs=8,\n",
    "                              random_state=42)\n",
    "\n",
    "rf_bayes_yc.fit(X_train_yc, yc_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lista de Variáveis Alvo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = [\"ya1\",\n",
    "             \"ya2\",\n",
    "             \"yb1\",\n",
    "             \"yb2\",\n",
    "             \"yb3\",\n",
    "             \"yb4\",\n",
    "             \"yc\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Melhores Parâmetros e Pontuações dos Modelos XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ya1 params: OrderedDict([('bootstrap', 0), ('max_depth', 20), ('max_features', 4), ('max_leaf_nodes', 26), ('min_samples_split', 87), ('n_estimators', 3446)])\n",
      "    score : 5.5284847230851675\n",
      "\n",
      "ya2 params: OrderedDict([('bootstrap', 0), ('max_depth', 12), ('max_features', 6), ('max_leaf_nodes', 32), ('min_samples_split', 100), ('n_estimators', 5934)])\n",
      "    score : 3.6487759564961193\n",
      "\n",
      "yb1 params: OrderedDict([('bootstrap', 0), ('max_depth', 9), ('max_features', 1), ('max_leaf_nodes', 59), ('min_samples_split', 2), ('n_estimators', 10000)])\n",
      "    score : 4.83622772175197\n",
      "\n",
      "yb2 params: OrderedDict([('bootstrap', 0), ('max_depth', 19), ('max_features', 2), ('max_leaf_nodes', 29), ('min_samples_split', 2), ('n_estimators', 9620)])\n",
      "    score : 2.584175981435089\n",
      "\n",
      "yb3 params: OrderedDict([('bootstrap', 0), ('max_depth', 4), ('max_features', 7), ('max_leaf_nodes', 33), ('min_samples_split', 70), ('n_estimators', 468)])\n",
      "    score : 2.406465317166934\n",
      "\n",
      "yb4 params: OrderedDict([('bootstrap', 0), ('max_depth', 6), ('max_features', 8), ('max_leaf_nodes', 100), ('min_samples_split', 2), ('n_estimators', 10)])\n",
      "    score : 1.5682785133123782\n",
      "\n",
      "yc params: OrderedDict([('bootstrap', 0), ('max_depth', 5), ('max_features', 1), ('max_leaf_nodes', 99), ('min_samples_split', 9), ('n_estimators', 10)])\n",
      "    score : 3.783033990261429\n",
      "\n"
     ]
    }
   ],
   "source": [
    "estimator_ya1 = rf_bayes_ya1.best_estimator_\n",
    "estimator_ya2 = rf_bayes_ya2.best_estimator_\n",
    "estimator_yb1 = rf_bayes_yb1.best_estimator_\n",
    "estimator_yb2 = rf_bayes_yb2.best_estimator_\n",
    "estimator_yb3 = rf_bayes_yb3.best_estimator_\n",
    "estimator_yb4 = rf_bayes_yb4.best_estimator_\n",
    "estimator_yc  = rf_bayes_yc.best_estimator_\n",
    "\n",
    "bayes_estimators = [rf_bayes_ya1,\n",
    "                    rf_bayes_ya2,\n",
    "                    rf_bayes_yb1,\n",
    "                    rf_bayes_yb2,\n",
    "                    rf_bayes_yb3,\n",
    "                    rf_bayes_yb4,\n",
    "                    rf_bayes_yc]\n",
    "\n",
    "for var, estimator in zip(variables, bayes_estimators):\n",
    "    best_params = estimator.best_params_\n",
    "    best_score = -estimator.best_score_\n",
    "    print(f\"{var} params: {best_params}\\n    score : {best_score}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaliação das Previsões do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ya1: 6.134399260561661\n",
      "ya2: 3.534065712377234\n",
      "yb1: 5.80810437452829\n",
      "yb2: 3.335022944013672\n",
      "yb3: 2.0859571900423983\n",
      "yb4: 1.9804082186043457\n",
      "yc: 2.587578101130556\n"
     ]
    }
   ],
   "source": [
    "wrn.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "estimators = [estimator_ya1,\n",
    "              estimator_ya2,\n",
    "              estimator_yb1,\n",
    "              estimator_yb2,\n",
    "              estimator_yb3,\n",
    "              estimator_yb4,\n",
    "              estimator_yc]\n",
    "\n",
    "X_tests = [X_test_ya1,\n",
    "           X_test_ya2,\n",
    "           X_test_yb1,\n",
    "           X_test_yb2,\n",
    "           X_test_yb3,\n",
    "           X_test_yb4,\n",
    "           X_test_yc]\n",
    "\n",
    "y_tests = [ya1_test,\n",
    "           ya2_test,\n",
    "           yb1_test,\n",
    "           yb2_test,\n",
    "           yb3_test,\n",
    "           yb4_test,\n",
    "           yc_test]\n",
    "\n",
    "predict = {}\n",
    "\n",
    "for var, estimator, X_test, y_test in zip(variables, estimators, X_tests, y_tests):\n",
    "    predict[var] = estimator.predict(X_test)\n",
    "    rmse = np.sqrt(mean_squared_error(predict[var], y_test))\n",
    "    print(f\"{var}: {rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listas de Comparação entre Valores Reais e Previsões"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "complist_ya1 = [(true, pred) for true, pred in zip(ya1_test, predict[\"ya1\"])]\n",
    "complist_ya2 = [(true, pred) for true, pred in zip(ya2_test, predict[\"ya2\"])]\n",
    "complist_yb1 = [(true, pred) for true, pred in zip(yb1_test, predict[\"yb1\"])]\n",
    "complist_yb2 = [(true, pred) for true, pred in zip(yb2_test, predict[\"yb2\"])]\n",
    "complist_yb3 = [(true, pred) for true, pred in zip(yb3_test, predict[\"yb3\"])]\n",
    "complist_yb4 = [(true, pred) for true, pred in zip(yb4_test, predict[\"yb4\"])]\n",
    "complist_yc  = [(true, pred) for true, pred in zip(yc_test, predict[\"yc\"])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tabela de Comparação entre Valores Reais e Previsões"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ya1           ya2           yb1            yb2           yb3           yb4            yc         \n",
      "   0 0.384914    1 0.141091    0  0.449279    0 0.398621    0 0.194029    0  0.077085   0 0.700124\n",
      "   8 7.186669    4 4.606526    7  3.923454    0 1.096536    2 1.129455    0  0.414844   0 0.635292\n",
      "   0 1.075287    2 0.619329    0  1.045445    5 0.715296    0 0.497832    0  0.205629   0 0.904425\n",
      "   8 4.568848    3 3.618705    1  2.279980    0 1.692140    0 1.072738    0  0.589657   0 1.389634\n",
      "   1 0.708606    0 0.500650    0  0.865938    0 0.629982    0 0.270832    3  0.865491   1 1.149144\n",
      "   0 0.290302    0 0.105513    0  0.441938    0 0.401084    0 0.168103    0  0.087518   0 0.575224\n",
      "  11 4.023621    9 3.482561    6  2.337476    3 1.688056    5 1.072738    0  0.730465   0 1.389634\n",
      "   0 0.263181    0 0.381144    0  0.490155    0 0.448465    0 0.264289    0  0.316360   0 0.471408\n",
      "   1 0.349552    0 0.163705    0  0.832063    0 0.565945    0 0.340990    0  0.056006   0 0.677810\n",
      "   4 7.757658    0 4.470228    0  2.066864    0 1.443968    0 1.211176    4  0.410848   0 0.935489\n",
      "   1 2.519641    0 2.489485    1  2.184896    2 1.212500    2 0.804833    3  0.526443   0 0.924427\n",
      "   5 4.923468    3 2.539329    0  1.351110    0 1.075940    0 0.793818    0  0.284242   1 0.892584\n",
      "   1 2.823878    1 1.719446    0  1.906049    1 1.054160    1 0.808505    0  0.342685   0 0.881522\n",
      "   3 4.244412    2 4.176336    0  3.435105    4 0.872827    1 0.742846    0  0.404192   3 0.774262\n",
      "   3 8.204555    5 6.280259    3  2.311901    8 1.577434    3 1.444777    1  1.230827   0 1.389634\n",
      "   1 3.363647    0 2.481848    1  1.427158    3 1.237943    1 0.793711    0  0.526443   0 0.935489\n",
      "   0 1.432587    0 1.422469    0  1.488040    2 0.932826    0 0.882362    0  0.526443   0 1.013311\n",
      "   0 2.255047    6 1.733255    0  1.781531    0 1.115486    0 0.804833    5  0.526443   1 0.924427\n",
      "   0 0.662336    0 0.416911    0  1.022685    0 0.623455    0 0.248392    0  0.339758   3 1.039866\n",
      "  46 7.255758   14 6.499648    3  2.199667    1 1.935395    1 1.614029   13  1.230827   2 1.261561\n",
      "   0 3.425600    0 3.626353    0  2.011477    1 1.513154    0 0.925197    0  0.549996   0 0.935489\n",
      "   0 0.256742    1 0.167028    1  0.356025    0 0.393443    0 0.203214    0  0.037824   0 0.444814\n",
      "   0 1.966926    0 1.971373   14  2.308643    5 1.772372    1 0.888993    0  0.230008   4 0.946606\n",
      "   1 4.889295    2 3.439465    0  2.199502    1 1.820498    1 1.589943    7  1.129690   0 1.261561\n",
      "   1 5.935766    2 3.482388    5  2.225844    4 2.743556    0 1.589943    0  1.261508   3 1.261561\n",
      "   0 5.918789    2 4.507665    0  2.452381    3 1.659500    2 1.591473    0  0.867916   0 1.072688\n",
      "   4 0.719865    4 0.634266    9  0.576891    8 0.618793    5 0.441816    3  0.069719   5 0.590295\n",
      "   0 4.097843    2 2.737836    3  2.656730    4 1.602971    0 1.030550    0  0.549996   0 0.924427\n",
      "   1 1.948163    0 1.516357    1  1.599403    0 1.395178    0 0.807805    0  0.406794   2 1.389634\n",
      "   0 5.935766    0 3.482388    0  2.225844    0 2.743556    0 1.589943    0  1.261508   4 1.261561\n",
      "   0 4.648301    0 3.629438    2  2.047386    1 1.536702    2 1.021016    0  0.549996   1 0.935489\n",
      "   0 4.023621    0 3.482561    2  2.337476    1 1.688056    1 1.072738    0  0.730465   0 1.389634\n",
      "   0 4.097843    2 2.737836    0  2.656730    2 1.602971    2 1.030550    0  0.549996   0 0.924427\n",
      "   0 6.291527    0 1.441621    0  2.098637    0 1.526635    0 1.072738    0  0.730465   0 1.261561\n",
      "   0 0.712560    1 0.605090    1  0.562695    0 0.618737    0 0.426878    0  0.069719   0 0.590295\n",
      "   1 5.115740    0 1.464006    1  2.101305    0 1.642988    0 1.072738    0  0.730465   0 1.389634\n",
      "   3 2.651290    5 2.255319    9  2.685245   11 1.570134    2 0.934731    1  0.549996   5 0.924427\n",
      "   0 4.648301    2 3.629438    0  2.047386    0 1.536702    1 1.021016    0  0.549996   0 0.935489\n",
      "   1 2.651290    5 2.255319   21  2.685245    3 1.570134    6 0.934731    1  0.549996   9 0.924427\n",
      "  15 7.242338    4 6.201956    1  2.197774    0 2.128165    0 1.614029    0  1.230827   0 1.261561\n",
      "   0 4.023621    0 3.482561    2  2.337476    0 1.688056    3 1.072738    0  0.730465   0 1.389634\n",
      "   2 4.567787    1 3.618596    0  2.063079    3 1.693779    0 1.035685    0  0.549996   0 1.389634\n",
      "   1 1.572727    8 1.261454    1  3.032110    0 1.843435    0 1.069963    0  6.905299   1 0.822736\n",
      "   0 0.797444    0 0.408253    2  0.871932    1 0.651502    0 0.297411    0  0.172703   0 0.688589\n",
      "   1 0.261743    0 0.129988    0  0.377076    1 0.410172    0 0.144905    0  0.109438   0 0.275857\n",
      "  18 8.118266    2 5.960171    0  2.059368    2 1.593500    0 1.393494    0  0.456062   0 1.389634\n",
      "   0 0.465654    0 0.274560    0  0.685721    0 0.477728    0 0.243948    0  0.204511   0 0.401938\n",
      "   0 0.347871    0 0.153132    0  0.774994    0 0.507261    0 0.260630    0  0.107157   0 0.677810\n",
      "   0 3.251646    0 2.500685    3  2.603626    1 1.673686    0 1.073014    6  0.629549   0 1.072688\n",
      "   0 0.297604    0 0.112661    0  0.370933    0 0.382103    0 0.197083    0  0.030844   0 0.940488\n",
      "   0 1.757712    1 0.920111   37  2.253906    8 1.317489    0 0.894490    2  0.416398   8 1.072688\n",
      "   0 0.270625    0 0.445404    0  0.666982    0 0.762324    0 0.378840    0  0.170139   0 0.421842\n",
      "   0 2.346705    1 1.709791    0  1.769838    1 1.080296    3 0.805321    1  0.393600   0 0.924427\n",
      "   0 0.457647    0 0.160442    0  0.791086    2 0.556362    2 0.340825    0  0.133855   0 0.625068\n",
      "   0 2.012414    0 1.427048    0  2.098637    0 1.525006    0 1.072738    0  0.658343   0 1.261561\n",
      "   0 0.465654    0 0.274079    0  0.681770    0 0.476968    0 0.243948    0  0.024693   0 0.401938\n",
      "   0 0.294453    0 0.103490    0  0.383120    0 0.408498    0 0.207061    0  0.067255   0 0.721793\n",
      "   0 5.119774    6 2.580053    0  2.198443    0 1.642988    0 1.072738    0  0.730465   0 1.389634\n",
      "   0 0.271636    0 0.182096    1  0.777489    0 0.589232    0 0.356312    0  0.209421   0 0.560760\n",
      "   6 4.567787    1 3.618596    4  2.063079    2 1.693779    4 1.035685    3  0.549996  37 1.389634\n",
      "   0 0.687194    2 0.408782    0  0.851181    0 0.704498    0 0.276883    0  0.151386   0 0.678589\n",
      "   0 0.290386    0 0.103117    0  0.419157    0 0.405457    0 0.166648    0  0.083097   0 0.817627\n",
      "   0 0.259857    0 0.367505    0  0.518534    0 0.598115    0 0.280520    0  0.137134   0 0.257198\n",
      "   1 6.584422    1 1.535281    0  2.104116    0 1.686032    0 1.072738    0  0.730465   0 1.261561\n",
      "   4 7.186669    0 4.606526    0  3.923454    0 1.096536    0 1.129455    0  0.414844   0 0.635292\n",
      "   1 1.499213    0 1.460169    0  1.208927    0 1.080458    0 0.861280    0  0.526443   1 0.847441\n",
      "   2 3.251646    0 2.500685    0  2.603626    1 1.673686    1 1.073014    0  0.629549   0 1.072688\n",
      "   1 3.408975    0 1.174083   11  2.501747   19 1.538739    0 1.073014    1  0.557427   1 1.072688\n",
      "   0 0.294632    0 0.105421    0  0.415561    0 0.406274    1 0.218251    0  0.111859   0 0.485844\n",
      "   4 0.725739    0 0.511426    0  0.518623    1 0.608989    0 0.428535    0  0.137328   0 0.541078\n",
      "   0 1.859811    2 1.628183    4  3.356117    3 1.693618    0 0.899396    0  0.526443   1 0.902817\n",
      "   2 3.251646    2 2.500685    6  2.603626    8 1.673686    5 1.073014    0  0.629549   2 1.072688\n",
      "   3 2.519641    4 2.489485    0  2.184896    0 1.212500    0 0.804833    0  0.526443   0 0.924427\n",
      "   0 0.496503    0 0.215030    0  0.901060    0 0.589789    0 0.332200    0  0.132715   0 0.517854\n",
      "   0 1.765810    0 1.507371    3  1.419198    0 1.017158    1 0.938769    0  0.356793   1 0.935260\n",
      "   0 0.313487    0 0.130277    0  0.551001    0 0.459164    0 0.216551    0  0.010083   0 0.776269\n",
      "   0 0.256972    0 0.193378    1  0.390493    1 0.394893    0 0.210589    0  0.256824   0 0.324998\n",
      "   3 1.342245    1 1.066848    1  2.087941    0 1.495132    0 0.913841    0  0.504570   0 1.261561\n",
      "   7 2.505283    5 2.504779    0  2.135463    0 1.216646    0 0.804833    0  0.526443   0 0.924427\n",
      "  42 4.923468   35 2.539329    0  1.351110    0 1.075940    0 0.793818    0  0.284242   2 0.892584\n",
      "   1 4.568848    3 3.618705    7  2.279980    5 1.692140    6 1.072738    0  0.589657   0 1.389634\n",
      "   0 4.526164    0 2.460464    0  1.394063    0 1.157356    0 0.794199    0  0.376192   0 0.935489\n",
      "   1 3.225480    0 2.630619    0  1.497989    0 1.173247    0 0.793711    0  0.422583   0 0.892584\n",
      "   0 1.329301    0 0.968133    3  1.004209    0 1.132257    0 0.786944    0  0.637195   1 1.383058\n",
      "   0 1.733903    4 1.768520    8  1.959555    2 3.941146    0 0.852663    3  1.373571   1 1.183342\n",
      "   0 3.251646    0 2.500685    1  2.603626    1 1.673686    0 1.073014    0  0.629549   0 1.072688\n",
      "   0 3.328357    7 1.806977    3  1.741070    9 1.328766    0 0.925686    4  0.515087   0 0.935489\n",
      "   0 0.333501    0 0.107610    2  0.472631    3 0.401663    0 0.193740    0  0.077085   0 0.804291\n",
      "   5 4.784037    5 3.038017    2  2.393954    3 0.880626    2 0.731864   32  0.248495   2 0.617337\n",
      "   1 1.844284    1 1.595672    0  2.357265    1 1.575870    2 0.899396    0  0.619619   2 0.902817\n",
      "   0 2.311909    4 1.744584   15  1.762042    4 1.083257    0 0.805321    2  0.393600   2 0.924427\n",
      "   5 3.363647    9 2.533327    1  1.427336    0 1.189283    0 0.793711    0  0.526443   0 0.935489\n",
      "   3 3.377310    1 2.460133    1  1.573117    0 1.190138    0 0.793711    0  0.526443   0 0.935489\n",
      "   4 7.186669    6 4.606526    4  3.923454    2 1.096536    4 1.129455    1  0.414844   1 0.635292\n",
      "   0 3.707263    2 1.827138    0  1.736729    0 1.322000    1 0.925686    4  0.418008   0 0.935489\n",
      "   0 2.255047    2 1.733255    2  1.781531    5 1.115486    0 0.804833    0  0.526443   8 0.924427\n",
      "   0 2.255047    2 1.748993    1  1.781931    2 1.119627    5 0.804833    1  0.619619   0 0.924427\n",
      "   0 1.703989    1 1.881544    0  1.363058    0 1.345007    1 1.049979    2  0.974325  12 1.741476\n",
      "  49 5.935766    7 3.483425   11  2.146807    7 2.821371    0 1.589943    0  1.071075   4 1.261561\n",
      "   0 0.286518    0 0.175183    0  0.832618    0 0.452543    0 0.129853    0  0.156790   0 0.522554\n",
      "   0 0.797481    0 0.917819    0  0.697895    0 0.699735    0 0.666942    0  0.268746   0 0.846854\n",
      "   8 4.818370   11 3.629438   13  2.047101   12 1.531230    1 1.021016    1  0.549996   2 0.935489\n",
      "   0 1.948163    0 1.516357    0  1.599403    0 1.395178    0 0.807805    0  0.406794   0 1.389634\n",
      "   1 1.638676    0 1.100076    0  2.422907    0 1.491120    0 0.913832    0  0.461599   0 1.072688\n",
      "   0 0.354227    0 0.425582    0  0.749661    1 0.604429    1 0.367822    0  0.245898   0 0.432829\n",
      "   0 0.293500    0 0.181979    0  0.428657    2 0.411510    4 0.207663    0  0.201416   0 0.346895\n",
      "   2 2.231806    1 1.587537    2  1.624836    2 1.032175    2 0.808505    0  0.303887   0 0.881522\n",
      "   0 0.708606    0 0.500650    0  0.865938    0 0.629982    0 0.270832    4  0.865491   0 1.149144\n",
      "   0 3.251646    1 2.500685   12  2.603626    7 1.673686    3 1.073014    0  0.629549   0 1.072688\n",
      "   0 0.700434    0 0.410380    6  1.771689    0 0.697346    0 0.324730    1  0.115475   4 0.713602\n",
      "   0 0.687265    1 0.408244    1  0.873028    0 0.726080    0 0.296670    0  0.123856   0 0.630256\n",
      "   0 0.347799    0 0.200515    0  0.444673    0 0.420154    0 0.076235    0  0.299405   0 0.439232\n",
      "   0 0.279145    0 0.145211    0  0.506617    0 0.426624    0 0.094754    0  0.037382   0 0.316973\n",
      "   0 0.510460    0 0.253006    0  0.658376    0 0.559865    0 0.279589    0  0.218686   0 0.533347\n",
      "   0 1.015600    3 0.621474    1  1.509241    0 0.814711    0 0.563051    0  0.393888   3 0.875367\n",
      "   0 0.814525    0 0.407919    1  2.625107    2 0.733967    0 0.378007    0  0.132790   0 0.570834\n",
      "   0 0.277161    0 0.299707    1  0.472656    0 0.514584    0 0.258150    0  0.142443   0 0.274497\n",
      "   0 0.588424    0 0.194542    0  0.827260    0 0.579674    0 0.339549    0  0.298113   0 0.625068\n",
      "   0 1.099694    0 0.711303    0  0.888688    0 0.773173    0 0.499107    0  0.586826   0 0.978750\n",
      "   0 0.308253    0 0.116875    0  0.419435    0 0.404748    0 0.211423    0  0.041786   0 0.718399\n",
      "   1 4.761705    2 3.629438    0  2.045978    0 1.531230    2 0.925197    0  0.549996   3 0.935489\n",
      "   2 3.317652    1 2.524100    0  2.565318    1 1.635799    2 1.073014    0  0.563829   1 1.072688\n",
      "   3 4.568848    0 3.618705    0  2.279980    0 1.692140    0 1.072738    0  0.589657   0 1.389634\n",
      "   0 3.328357    0 1.806977    1  1.741070    1 1.328766    0 0.925686    0  0.515087   0 0.935489\n",
      "   6 1.966926    1 1.971373    0  2.308643    0 1.772372    0 0.888993    0  0.230008   0 0.946606\n",
      "   0 2.255047    0 1.748993    0  1.781931    1 1.119627    1 0.804833    0  0.619619   0 0.924427\n",
      "   1 3.707263    3 1.833708   10  1.738736   14 1.315020    6 0.927482    4  0.418008   2 0.935489\n",
      "   0 0.374594    0 0.319639    0  0.574766    0 0.464454    0 0.275252    0  0.116266   0 1.076966\n",
      "   2 1.606643    1 1.273533   11  1.998299   17 1.532219    3 1.026935    5  4.481282   0 0.904055\n",
      "   4 3.363647    3 2.533327    7  1.427336    0 1.189283    2 0.793711    6  0.526443   0 0.935489\n",
      "   5 2.196885    3 1.566294    1  1.611500    1 1.029398    3 0.808505    2  0.303887   2 0.841383\n",
      "   0 0.341853    1 0.120036    0  0.419166    0 0.404759    0 0.188986    0  0.066399   1 0.718399\n",
      "   0 5.119774    0 2.580053    0  2.198443    3 1.642988    0 1.072738    0  0.730465   0 1.389634\n",
      "   4 2.505283   15 2.504779    3  2.135463    2 1.216646    5 0.804833    0  0.526443   4 0.924427\n",
      "   2 1.621038    0 1.591389    7  2.105812   16 1.702490    3 1.109158    1  0.367144   1 1.154418\n",
      "   2 6.584422    3 1.535281    3  2.104116    1 1.686032    1 1.072738    0  0.730465   0 1.261561\n",
      "   3 1.589691    4 1.755013    3  1.191125    6 1.098667    1 0.849666    0  0.619619   0 1.021526\n",
      "   0 0.256972    0 0.152142    0  0.369336    0 0.393848    0 0.147195    0  0.235207   0 0.324998\n",
      "   0 2.476009    0 0.798443    0  3.017184    0 1.454113    0 0.934731    0  0.515087   0 0.924427\n",
      "   0 0.725739    0 0.511426    0  0.518623    0 0.608989    0 0.428535    0  0.137328   0 0.541078\n",
      "   0 0.430464    0 0.194949    0  0.782543    1 0.537591    0 0.216430    0  0.078878   0 0.522554\n",
      "   0 0.311972    0 0.121087    0  0.479504    0 0.425535    0 0.233084    0  0.032273   0 0.550853\n",
      "   1 0.313681    0 0.130277    0  0.545481    0 0.459164    0 0.216551    0  0.010083   0 0.776269\n",
      "   1 0.309662    0 0.123310    0  0.404458    0 0.410320    0 0.215167    0  0.165610   0 1.065168\n",
      "   2 0.676044    2 0.407788    1  1.046947    0 0.695818    0 0.309985    1  0.106973   0 0.630256\n",
      "   2 4.648301    2 3.629438    2  2.047386    0 1.536702    0 1.021016    0  0.549996   0 0.935489\n",
      "   4 3.317652    1 2.524100    0  2.565318    4 1.635799    0 1.073014    0  0.563829   1 1.072688\n",
      "   0 1.099694    0 0.711303    0  0.888688    0 0.773173    0 0.499107    0  0.586826   0 0.978750\n",
      "   0 6.320093    3 5.253680    0  2.446242    0 1.524521    0 1.445572    0  0.886048   0 1.072688\n",
      "   0 0.256742    0 0.136011    0  0.348624    0 0.392723    0 0.155402    0  0.049573   0 0.535367\n",
      "   5 2.255047    6 1.733255    1  1.781531    1 1.115486    0 0.804833    0  0.526443   0 0.924427\n",
      "   0 1.820512    4 1.941667    0  2.360628    0 1.124686    0 0.927616    0  0.619619   1 1.109311\n",
      "   0 0.350224    0 0.355330    0  0.309215    0 0.420620    0 0.317573    0  0.114286   0 0.264580\n",
      "   0 2.205922    1 1.674823    0  1.604887    1 1.020560    2 0.806369    0  0.303887   0 0.841383\n",
      "   0 1.202582    0 0.473728    0  2.276918    1 0.847826    0 0.566698    0  0.167596   0 0.689534\n",
      "   6 1.827488    0 1.981634    1  1.540712    2 1.091617    1 0.927616    0  0.526443   0 1.013311\n",
      "   0 5.451617    0 4.698985    0  2.340679    0 1.685391    1 1.072738    0  0.730465   0 1.389634\n",
      "   0 1.658886    0 1.737510    0  1.305167    0 1.087077    0 0.849462    0  0.380187   1 0.960544\n",
      "  31 4.889295    5 3.439465   16  2.199502    5 1.820498    3 1.589943    0  1.129690   0 1.261561\n",
      "   0 2.651290    0 2.255319    1  2.685245    0 1.570134    0 0.934731    0  0.549996   0 0.924427\n",
      "  14 3.363647    8 2.533327    1  1.427336    0 1.189283    1 0.793711    0  0.526443   0 0.935489\n",
      "   4 2.842777    1 1.157384    0  2.495887    2 1.533169    1 1.073014    0  0.557427   0 1.072688\n",
      "   0 2.765947    0 2.712354    0  0.916931    0 0.853174    0 0.991533    0  1.181661   1 1.193138\n",
      "   0 3.377310    2 2.460133    2  1.618968    0 1.190303    0 0.793711    0  0.526443   0 0.935489\n",
      "   0 2.505283    0 2.504779    0  2.135463    2 1.216646    3 0.804833    0  0.526443   3 0.924427\n",
      "   1 2.823878    1 1.719446    1  1.906049    1 1.054160    0 0.808505    0  0.342685   0 0.881522\n",
      "   4 4.648301    9 3.629438    3  2.047386    0 1.536702    1 1.021016    2  0.549996   1 0.935489\n",
      "   0 8.132836    4 5.961535    5  2.039383    0 1.501437    3 1.365243    3  0.456062   1 0.935489\n",
      "   0 1.040466    0 0.621474    2  1.397023    1 0.798528    0 0.495240    0  0.393888   0 0.875367\n",
      "   0 3.330319    0 2.655329    1  1.604375    1 1.236730    0 0.793711    0  0.526443   0 0.935489\n",
      "   6 4.203643   12 2.749225    5  2.563126    3 1.635214    4 1.042820    1  0.549996   4 1.130124\n",
      "   1 4.575056    0 3.619960    0  2.042082    1 1.539791    2 1.021016    0  0.549996   0 0.935489\n",
      "   0 0.712560    0 0.605090    2  0.562695    0 0.618737    1 0.426878    0  0.069719   0 0.590295\n",
      "   6 4.575056    0 3.619960    2  2.042082    0 1.539791    0 1.021016    0  0.549996   0 0.935489\n",
      "   0 2.141220    0 1.932949    0  1.047961    0 1.145300    0 0.777843    0  0.449928   0 1.165874\n",
      "   0 2.586974    0 1.157384    0  2.498718    0 1.541879    0 1.073014    0  0.557427   0 1.072688\n",
      "   0 1.387629    0 0.936698    0  0.898881    0 0.938845    0 0.649266    0  0.232846   0 2.088077\n",
      "   0 2.255047    0 1.748993    0  1.781931    0 1.119627    0 0.804833    0  0.619619   0 0.924427\n",
      "   6 1.931126    4 1.452409    0  0.911543    2 1.003013    0 0.773664    5  0.695659   2 1.208780\n",
      "   0 2.519641    0 2.489485    0  2.184896    0 1.212500    0 0.804833    0  0.526443   0 0.924427\n",
      "   0 0.434332    0 0.223716    0  0.475192    0 0.524467    0 0.233136    0  0.163299   0 1.266984\n",
      "  13 7.242338    0 6.201956    0  2.197774    0 2.128165    0 1.614029    0  1.230827   0 1.261561\n",
      "   1 1.691938    1 1.795418    3  1.485016    0 1.116599    0 0.925325    0  0.526443   0 1.013311\n",
      "   0 0.298832    0 0.110303    0  0.418059    0 0.404690    0 0.211423    0  0.041786   0 0.718399\n",
      "   2 1.720592    1 1.505694    1  1.344203    0 1.108681    0 0.938281    0  0.526443   0 0.839260\n",
      "   0 0.360773    0 0.175193    0  1.296907    0 0.461573    0 0.129853    0  0.216343   0 0.522554\n",
      "   0 0.791176    1 0.982407    0  0.752730    1 0.712251    0 0.759319    1  0.177220   0 0.419744\n",
      "   0 1.770617    0 1.121065    0  2.056970    0 1.205166    0 0.809407    0  0.453853   0 0.924427\n",
      "   4 6.561447    2 1.464006    0  2.101305    0 1.686032    1 1.072738    0  0.730465   0 1.389634\n",
      "   1 1.131736    0 0.624310    0  1.731187    0 0.755511    0 0.496887    0  0.487064   0 0.947331\n",
      "   2 3.622654    0 2.524105    0  1.300042    0 1.068365    0 0.793818    0  0.230008   0 0.892584\n",
      "   1 2.346705    0 1.709791    9  1.769838    3 1.080296    1 0.805321    0  0.393600   4 0.924427\n",
      "   1 0.907668    0 0.693299    0  0.866759    0 0.787498    0 0.661792    0  0.409028   0 1.193138\n",
      "   3 4.023621    0 3.482561    0  2.337476    0 1.688056    0 1.072738    0  0.730465   0 1.389634\n",
      "   0 0.266947    0 0.421784    0  0.486407    0 0.433826    0 0.273151    0  0.155545   0 0.550249\n",
      "   5 2.656764    3 2.254501    1  2.712112    5 1.598012    6 1.030550    1  0.549996   1 0.924427\n",
      "   0 0.313487    0 0.130277    0  0.551001    0 0.459164    0 0.216551    0  0.010083   0 0.776269\n",
      "  13 8.133985   10 5.602098    0  2.030938    0 1.479119    0 1.208891    0  0.456062   0 0.935489\n",
      "   0 3.317652    2 2.524100    0  2.565318    2 1.635799    0 1.073014    1  0.563829   0 1.072688\n",
      "   0 4.074191    0 2.737311    0  2.656730    2 1.596589    0 1.030550    0  0.549996   0 0.924427\n",
      "   0 0.271636    0 0.182096    0  0.771897    0 0.585266    0 0.358305    0  0.209421   0 0.560760\n",
      "   3 1.633263    0 0.946894    0  1.897218    0 1.277320    0 0.894499    0  0.389643   0 1.261561\n",
      "   0 0.277563    0 0.144397    0  0.602699    0 0.475453    0 0.258333    0  0.084307   0 0.776269\n",
      "   0 0.276371    0 0.169720    0  0.413606    0 0.478800    0 0.112051    0  0.064826   0 0.370275\n",
      "   4 3.059018    0 1.045971    2  2.498538    0 1.572499    1 1.073014    1  0.629549   0 1.072688\n",
      "   1 3.251646    0 2.500685   17  2.603626   16 1.673686    2 1.073014    0  0.629549   0 1.072688\n",
      "   0 2.311909    0 1.744584    1  1.762042    0 1.083257    0 0.805321    1  0.393600   0 0.924427\n",
      "   3 4.203643    2 2.749225    2  2.563126    1 1.635214    0 1.042820    0  0.549996   5 1.130124\n",
      "  18 5.943970    9 4.540270    7  2.452661    1 1.717806    6 1.591473    4  0.886048   1 1.072688\n",
      "   2 4.097843    3 2.737836    0  2.656730    0 1.602971    2 1.030550    0  0.549996   0 0.924427\n",
      "   0 2.255047    0 1.754710    9  1.781441    0 1.117018    0 0.804833    0  0.526443   6 0.924427\n",
      "   2 1.858670    0 1.969483    0  2.213031    0 1.024153    0 0.928505    0  0.395822   0 0.968571\n",
      "   0 0.649109    0 0.430006    0  0.784140    0 0.593592    0 0.202440    3  1.402820   0 1.100921\n",
      "   3 4.023621    8 3.482561    0  2.337476    1 1.688056    1 1.072738    0  0.730465   1 1.389634\n",
      "   0 0.270813    0 0.171800    0  0.391680    0 0.411673    0 0.131607    0  0.071460   0 0.605990\n",
      "   6 1.658409    0 1.258139    0  4.191163    0 1.562447    0 1.109434    0  0.710774   0 0.814570\n",
      "  28 4.530754    2 2.491547    0  1.396718    1 1.179927    0 0.794199    0  0.376192   0 0.935489\n",
      "   1 0.731615    1 0.406933   25  2.620210   14 0.818204    1 0.378007    0  0.121025   0 0.570834\n",
      "   0 0.279075    0 0.146486    0  0.459501    0 0.425834    0 0.093724    0  0.018215   0 0.301973\n",
      "   9 6.366457    3 5.795934   11  2.451500   11 1.765209    2 1.615560    1  0.886048   2 1.072688\n",
      "   0 0.294292    0 0.121498    0  0.392034    0 0.406076    0 0.224646    0  0.165610   0 1.065168\n",
      "   0 3.317652    0 2.524100    0  2.565318    1 1.635799    0 1.073014    2  0.563829   0 1.072688\n",
      "  34 3.317652   13 2.524100    0  2.565318    0 1.635799    1 1.073014    1  0.563829   1 1.072688\n",
      "   0 0.438191    0 0.229697    0  0.472781    0 0.509124    0 0.219985    0  0.163299   0 1.266984\n",
      "   2 3.051773    3 1.157384    2  2.495887    2 1.531545    2 1.073014    0  0.629549   0 1.072688\n",
      "   0 1.342245    0 1.092889    0  2.095597    0 1.495257    0 0.913841    0  0.672102   0 1.261561\n",
      "   2 1.446776    0 1.150430    1  3.643006    4 1.504926    1 0.886519    0  0.453853   2 0.902817\n",
      "   2 1.820512    0 1.941667   12  2.421884    3 1.127680    0 0.928104    0  0.619619   1 1.109311\n",
      "   0 2.542516    0 1.718676    0  1.808514    0 1.069855    0 0.805321    0  0.393600   0 0.924427\n",
      "   0 4.097843    0 2.737836    0  2.656730    2 1.602971    0 1.030550    0  0.549996   0 0.924427\n",
      "   1 1.333855    4 1.002070    0  1.537046    0 1.070791    0 1.198907    0  0.352633   0 0.867769\n",
      "   0 2.311909    2 1.744584    0  1.762042    0 1.083257    1 0.805321    0  0.393600   0 0.924427\n",
      "   0 4.203643    1 2.749225    1  2.563126    0 1.635214    0 1.042820    0  0.549996   0 1.130124\n",
      "   5 3.317652    1 2.524100    0  2.565318    0 1.635799    0 1.073014    0  0.563829   0 1.072688\n",
      "   0 1.797641    0 1.109944    5  2.113723    0 1.196814    0 0.837767    0  0.526443   1 0.924427\n",
      "   0 1.784006    0 2.045561    0  1.819350    0 1.543946    0 0.864766    0  1.559405   0 1.132338\n",
      "   0 0.366798    0 0.212486    0  0.971725    0 0.444276    0 0.190372    0  0.359923   0 0.834719\n",
      "   7 3.251646    9 2.500685    0  2.603626    2 1.673686    0 1.073014    0  0.629549   2 1.072688\n",
      "   0 1.172829    0 1.117162    0  1.057744    0 1.000053    0 0.854059    3  0.797261   0 1.167508\n",
      "   2 2.255047    9 1.733255    3  1.781531    2 1.115486    0 0.804833    1  0.526443   3 0.924427\n",
      "   0 0.426225    0 0.198555    0  0.478093    3 0.482397    0 0.192420    0  0.016132   0 0.811752\n",
      "   5 0.292499    0 0.100534    0  0.478720    0 0.412405    0 0.168247    0  0.087471   0 0.688345\n",
      "   0 0.347918    0 0.201599    0  0.366917    0 0.420122    0 0.064962    0  0.418421   0 0.247756\n",
      "   0 0.267980    0 0.372812    0  0.429078    0 0.436093    0 0.261868    0  0.155545   0 0.532141\n",
      "   0 0.257130    0 0.153817    0  0.352934    0 0.392704    0 0.163288    0  0.087785   0 0.535367\n",
      "   1 0.727783    0 0.407538    0  2.072579    0 0.762046    0 0.364032    0  0.121025   1 0.570834\n",
      "   6 2.359680    3 1.707966    3  1.729496    3 1.053891    9 0.808505    1  0.303887   1 0.881522\n",
      "   0 0.256742    0 0.167028    0  0.356025    0 0.393443    0 0.203214    0  0.037824   0 0.444814\n",
      "   1 1.638676    0 1.100076    0  2.423311    0 1.491173    0 0.913832    0  0.461599   1 1.072688\n",
      "   0 2.149157    1 1.583803    2  1.662241    0 1.047504    0 0.805321    0  0.376832   0 0.884288\n",
      "   0 2.519641    0 2.489485   21  2.184896    6 1.212500    3 0.804833    0  0.526443   0 0.924427\n",
      "   5 8.118266    9 5.960171    0  2.269301    0 1.592212    0 1.442511    0  1.128790   0 1.389634\n",
      "   8 5.943970    2 4.540270    0  2.452661    1 1.717806    4 1.591473    2  0.886048   4 1.072688\n",
      "   1 0.719865    1 0.634266    1  0.576891    0 0.618793    0 0.441816    0  0.069719   0 0.590295\n",
      "   2 1.870800    6 1.716237    0  1.266141    2 0.946029    0 0.920648    0  0.230008   0 0.888977\n",
      "   0 2.492784    0 5.908441    1  2.614784    0 1.546984    0 0.934731    0  0.549996   1 0.924427\n",
      "   2 3.317652    6 2.524100    2  2.565318    0 1.635799    0 1.073014    0  0.563829   1 1.072688\n",
      "   0 1.351957    0 1.078940    0  2.087941    0 1.505043    0 0.913841    0  0.504570   0 1.261561\n",
      "   0 4.530754    0 2.491547    0  1.396718    0 1.179927    0 0.794199    0  0.376192   0 0.935489\n",
      "   0 3.622654    0 2.524105    0  1.300042    0 1.068365    0 0.793818    0  0.230008   0 0.892584\n",
      "  26 3.133345    6 2.481214    0  1.418960    0 1.166313    0 0.793711    0  0.619619   0 0.935489\n",
      "   0 4.568848    5 3.618705    1  2.279980    0 1.692140    0 1.072738    0  0.589657   0 1.389634\n",
      "   6 0.814525    3 0.407919   36  2.625107   17 0.733967    1 0.378007    0  0.132790   1 0.570834\n",
      "   0 2.656764    0 2.254501    0  2.712112    0 1.598012    0 1.030550    0  0.549996   0 0.924427\n",
      "   2 5.918789   10 4.516306    4  2.460704    1 1.668232    3 1.591473    2  0.894839   1 1.072688\n",
      "   0 1.714138    1 1.514613    0  1.448822    0 1.042925    1 0.938769    0  0.393600   0 0.935260\n",
      "   4 1.770617    0 1.121065    1  2.056970    0 1.205166    0 0.809407    0  0.453853   2 0.924427\n",
      "   1 0.286295    0 0.169360    0  0.604452    0 0.494552    0 0.116647    0  0.078878   0 0.403854\n",
      "   6 6.348216    1 5.474996   19  2.449818   11 1.716036   28 1.615560    5  0.886048   4 1.072688\n",
      "   0 0.261862    0 0.330959    0  0.472599    1 0.452581    0 0.254198    0  0.199264   0 0.471408\n",
      "   0 6.656068    0 4.106204    0  2.475699    0 1.483882    0 1.572131    0  1.127999   0 1.072688\n",
      "   8 4.543756    4 2.734961   25  1.907356   16 0.858949    8 0.725187    1  0.362132   1 0.585519\n",
      "   0 4.761705    0 3.629438    0  2.045978    0 1.531230    0 0.925197    0  0.549996   0 0.935489\n",
      "   0 0.447547    1 0.244652    0  0.571414    0 0.531524    0 0.264561    0  0.260038   1 0.801915\n",
      "   0 0.360161    0 0.404321    0  0.566132    0 0.466055    0 0.285401    0  0.290219   0 0.504366\n",
      "   1 4.526164    3 2.456264    1  1.393274    0 1.173463    0 0.794199    0  0.376192   0 0.935489\n",
      "  22 4.889295   14 3.439465    3  2.199502    7 1.820498    0 1.589943    3  1.129690   1 1.261561\n",
      "   3 4.895995    9 3.439465    2  2.199502    9 1.829596    0 1.589943    0  1.129690   0 1.261561\n",
      "   1 5.451617    2 4.698985    1  2.340679    0 1.685391    0 1.072738    0  0.730465   0 1.389634\n",
      "  30 4.023621    0 3.482561    0  2.337476    1 1.688056    0 1.072738    0  0.730465   0 1.389634\n",
      "   3 3.244399    4 3.039663    6  1.337931    4 1.166035   10 1.240144    6  1.108336   5 2.088077\n",
      "   0 2.656110    0 2.254501    0  2.676207    0 1.582309    0 1.030550    1  0.549996   0 0.924427\n",
      "   0 5.918789    5 4.507665    0  2.452381    0 1.659500    1 1.591473    0  0.867916   0 1.072688\n",
      "   0 1.417393    0 1.159427    5  3.638074    0 1.496228    1 0.898237    2  0.453853   2 0.832140\n",
      "   0 0.864619    0 0.543029    0  0.732548    2 0.617040    0 0.452776    0  0.848413   2 0.899757\n",
      "   3 0.782183    1 0.920631    2  0.727879    0 0.719330    0 0.744327    0  0.177220   0 0.419744\n",
      "   4 2.255047    6 1.748993    2  1.781931   12 1.119627    4 0.804833    0  0.619619   0 0.924427\n",
      "   1 8.126671    0 5.602623    0  2.045259    2 1.494491    2 1.365243    0  0.456062   0 0.935489\n",
      "   0 0.312810    0 0.103565    0  0.531690    0 0.427962    0 0.214831    0  0.136425   0 0.635417\n",
      "   0 0.345228    0 0.209917    1  0.400578    0 0.422754    0 0.079266    0  0.681207   0 0.588867\n",
      "   0 0.459553    0 0.198695    0  0.445618    0 0.464314    0 0.189459    0  0.011802   0 1.138910\n",
      "   0 0.295009    0 0.094388    0  0.376258    3 0.406135    0 0.156291    0  0.108160   0 0.546558\n",
      "   0 2.519641    0 2.489485    0  2.184896    0 1.212500    0 0.804833    0  0.526443   0 0.924427\n",
      "   5 3.317652    2 2.524100    1  2.565318    2 1.635799    0 1.073014    0  0.563829   0 1.072688\n",
      "   2 6.320093    1 5.253680    2  2.442810    2 1.525171    1 1.445572    0  0.886048   5 1.072688\n",
      "   4 1.891568    9 1.559160    4  1.466671    1 0.966697    0 0.946386    6  0.342685   0 0.892355\n",
      "  12 3.251646    0 2.500685    0  2.603626    1 1.673686    0 1.073014    0  0.629549   0 1.072688\n",
      "  12 3.350488    9 2.564606    0  1.599007    0 1.192565    0 0.793711    0  0.526443   0 0.935489\n",
      "   2 2.081256    1 2.197802    6  1.625343   11 1.484363    1 0.853152   12  0.886071   3 1.198926\n",
      "   2 2.656764    5 2.254501    0  2.712112    0 1.598012    0 1.030550    0  0.549996   0 0.924427\n",
      "   0 0.430464    0 0.194949    0  0.782543    0 0.537591    0 0.216430    3  0.078878   0 0.522554\n",
      "   0 3.251646    0 2.500685    0  2.603626    2 1.673686    0 1.073014    0  0.629549   0 1.072688\n",
      "   0 1.468278    0 1.114275    1  1.302251    0 1.391065    0 1.046622    1  1.262592   1 1.383058\n",
      "   0 2.823878    0 1.719446    1  1.906049    0 1.054160    0 0.808505    1  0.342685   1 0.881522\n",
      "   3 3.478368    0 2.006769    0  1.289037    1 1.051780    0 0.786833    0  0.230008   0 0.865986\n",
      "   2 3.330319    2 2.655329    0  1.604375    0 1.236730    0 0.793711    0  0.526443   0 0.935489\n",
      "   0 0.598688    0 0.291642    0  0.883690    0 0.696500    0 0.377468    0  0.222246   0 0.613968\n",
      "   1 4.203643    0 2.749225    2  2.563126    1 1.635214    0 1.042820    2  0.549996   0 1.130124\n",
      "   0 0.272863    0 0.130028    0  0.573765    0 0.466014    0 0.221625    0  0.032696   0 0.776269\n",
      "   7 8.066777    5 6.218966    2  2.231540    0 1.595731    1 1.444777    0  1.230827   0 1.389634\n",
      "   1 3.425600    4 3.626353    0  2.011477    3 1.513154    0 0.925197    0  0.549996   2 0.935489\n",
      "   0 1.342245    0 1.066848    0  2.087941    0 1.495132    0 0.913841    0  0.504570   0 1.261561\n",
      "   1 1.793993    6 2.030664    3  1.805988    7 1.562108    0 0.864766    1  1.559405   0 1.132338\n",
      "   6 2.253197    1 1.748993    1  1.768434    0 1.086785    0 0.804833    0  0.619619   0 0.924427\n",
      "   0 4.023621    0 3.482561    0  2.337476    0 1.688056    0 1.072738    0  0.730465   0 1.389634\n",
      "   0 0.359567    0 0.145710    0  0.709811    0 0.493536    0 0.220694    0  0.016412   0 0.677810\n",
      "  11 4.100287   17 2.554591    2  2.602563    0 1.604343    2 1.073014    0  0.629549   0 1.072688\n",
      "   2 4.648408    0 3.627105    0  2.043541    0 1.535815    0 1.021016    0  0.549996   0 0.935489\n",
      "   9 0.787591    1 0.844408    2  0.655930    0 0.705702    0 0.650732    0  0.268746   0 0.846854\n",
      "   0 0.697725    0 0.504517    0  0.837219    0 0.603182    0 0.201243    0  0.902756   0 1.100921\n",
      "   0 4.023621    0 3.482561    0  2.337476    0 1.688056    0 1.072738    0  0.730465   0 1.389634\n",
      "  16 5.933228   12 3.483425    4  2.145096    4 1.489797    4 1.589943    2  1.071075   1 1.261561\n",
      "   1 1.828180    1 1.941762    0  1.543676    0 1.114772    0 0.927616    0  0.526443   0 1.013311\n",
      "   0 0.294453    0 0.102983    0  0.416610    0 0.409640    0 0.219029    0  0.083097   0 0.721793\n",
      "   1 4.097843    0 2.737836    5  2.656730    2 1.602971    1 1.030550    0  0.549996   1 0.924427\n",
      "   8 3.377310    2 2.460133    0  1.618968    1 1.190303    9 0.793711    1  0.526443   2 0.935489\n",
      "   0 4.203643    2 2.749225    1  2.563126    1 1.635214    0 1.042820    0  0.549996   0 1.130124\n",
      "   0 4.575056    0 3.619960    0  2.042082    0 1.539791    0 1.021016    1  0.549996   2 0.935489\n",
      "   0 4.567787    0 3.618596    0  2.063079    0 1.693779    0 1.035685    0  0.549996   0 1.389634\n",
      "   0 2.505283    0 2.504779    0  2.135463    2 1.216646    2 0.804833    3  0.526443   0 0.924427\n",
      "   0 3.350488    1 2.564606    0  1.599007    2 1.192565    0 0.793711    0  0.526443   0 0.935489\n",
      "   2 1.917416    4 1.762565    5  1.231049    6 1.058508    0 0.854205    0  0.284242   2 0.990617\n",
      "   4 4.023621    8 3.482561    3  2.337476    6 1.688056    0 1.072738    1  0.730465   0 1.389634\n",
      "  13 4.567787    1 3.618596    2  2.063079    3 1.693779    2 1.035685    0  0.549996  42 1.389634\n",
      "   0 1.654848    1 1.145655    0  2.746888    0 1.672738    0 1.073014    0  0.557427   0 1.072688\n",
      "   0 5.943970    0 4.540270    0  2.471263    0 1.714287    0 1.605877    0  0.886048   0 1.072688\n",
      "   0 0.341449    0 0.117705    1  0.377459    1 0.399889    0 0.226068    0  0.045270   0 0.469891\n",
      "   0 0.313487    0 0.130277    0  0.551596    0 0.459164    0 0.216551    0  0.010083   0 0.776269\n",
      "   1 1.849377    0 1.594546    1  2.949596    1 1.694401    2 0.899396    0  0.526443   0 0.902817\n",
      "   2 4.889295    6 3.464016    3  2.225413    4 1.820016    3 1.589943    0  1.261508   2 1.261561\n",
      "   0 0.807126    0 0.431579    0  1.477208    0 0.667419    0 0.440087    0  0.629743   0 1.047421\n",
      "   2 3.377310    1 2.460133    3  1.618968    1 1.190303    0 0.793711    0  0.526443   5 0.935489\n",
      "   2 1.638676    1 1.100076    0  2.422907    3 1.491120    0 0.913832    0  0.461599   0 1.072688\n",
      "   0 0.929999    0 0.963151    0  1.005930    0 0.856659    2 0.788451    0  0.590511   0 1.321211\n",
      "   6 5.451617    6 4.698985    4  2.340679    6 1.685391    1 1.072738    1  0.730465   0 1.389634\n",
      "   0 0.256296    0 0.240416    0  0.376475    1 0.393772    0 0.222042    0  0.160830   0 0.512218\n",
      "  37 8.066777   21 6.218966    0  2.231540    0 1.595731    1 1.444777    0  1.230827   0 1.389634\n",
      "   0 5.156161    1 2.649391    2  2.196997    4 1.642988    4 1.072738    0  0.730465   0 1.389634\n",
      "   8 6.348216    8 5.474996    3  2.449818    1 1.716036    1 1.615560    0  0.886048   0 1.072688\n",
      "   0 0.262148    1 0.430182    0  0.593672    0 0.445823    0 0.275572    0  0.316360   0 0.514374\n",
      "   3 4.889295    9 3.439465    3  2.199502    6 1.820498    1 1.589943    1  1.129690   1 1.261561\n",
      "   3 0.654718    1 0.334056   42 10.260032    8 1.127436    1 0.326981    8  0.144181  11 0.708971\n",
      "   0 0.714888    0 0.407472    0  1.810316    1 0.696415    0 0.320774    0  0.125732   0 0.619168\n",
      "   0 0.784228    0 0.903339    1  0.888292    2 1.371398    0 0.713144    0  0.248707   1 0.836142\n",
      "   0 0.318948    0 0.112339    0  0.466669    0 0.412571    0 0.186422    0  0.083669   0 0.715845\n",
      "   1 3.319053    0 3.155421    0  1.594255    3 1.236465    0 0.788390    0  0.526443   3 0.935489\n",
      "  44 6.291527   20 1.441621    9  2.098637    5 1.526635    5 1.072738    1  0.730465   1 1.261561\n",
      "   2 1.163582    1 1.146146    0  1.420902    0 1.108946    0 1.191314    0  0.256473   0 0.956830\n",
      "   0 1.901972    0 2.196260    0  1.683847    3 1.298228    8 0.852663    5  1.323571   0 1.198926\n",
      "   0 1.351957    0 1.078940    0  2.087941    0 1.505043    0 0.913841    0  0.504570   0 1.261561\n",
      "   3 2.505283    3 2.504779   14  2.135463    5 1.216646    4 0.804833    0  0.526443   2 0.924427\n",
      "   0 1.183533    0 1.073626   23  1.272753   10 1.255365    1 1.003070    0  0.612775   1 0.770975\n",
      "   0 0.514806    0 0.294436    0  0.752726    0 0.630600    0 0.354239    0  0.385804   2 0.690708\n",
      "   0 0.935368    0 0.659642    0  0.731377    0 0.736455    0 0.545096    0  0.438123   0 1.193138\n",
      "   1 4.575056    1 3.619960    6  2.042082    4 1.539791    0 1.021016    0  0.549996   0 0.935489\n",
      "   0 4.575056    0 3.619960    1  2.042082    0 1.539791    8 1.021016    0  0.549996   0 0.935489\n",
      "   0 0.277161    0 0.299707    0  0.472656    0 0.514584    0 0.258150    0  0.142443   0 0.274497\n",
      "   5 4.526164    2 2.456264    0  1.393274    0 1.173463    0 0.794199    0  0.376192   0 0.935489\n",
      "   7 5.943970    6 4.540270    0  2.489567    2 1.717087    0 1.605877    0  0.886048   0 1.072688\n",
      "   1 0.700434    0 0.410380    0  1.771689    0 0.697346    0 0.324730    0  0.115475   0 0.713602\n",
      "   0 4.023621    0 3.482561    0  2.337476    0 1.688056    1 1.072738    0  0.730465   0 1.389634\n",
      "   6 4.181475    4 3.629438    1  2.047101    0 1.523040    0 1.021016    0  0.549996   0 0.935489\n",
      "   0 4.375756    0 2.587847    0  1.095812    1 0.874937    0 0.724696    0  0.367861   1 0.526807\n",
      "  19 4.784037   15 3.038017    0  2.393954    9 0.880626    1 0.731864    2  0.248495   0 0.617337\n",
      "   0 1.433634    0 1.466130    6  1.507480    1 0.899962    0 0.837331    0  0.425544   0 1.013311\n",
      "   0 4.567787    0 3.618596    0  2.063079    0 1.693779    0 1.035685    1  0.549996   0 1.389634\n",
      "   0 4.074191    4 2.737311    2  2.656730    2 1.596589    2 1.030550    0  0.549996   0 0.924427\n",
      "   0 2.346705    1 1.709791   11  1.769838    1 1.080296    0 0.805321    2  0.393600   1 0.924427\n",
      "   1 8.128241    4 5.602623    1  2.045544    1 1.498486    0 1.365243    0  0.456062   0 0.935489\n",
      "  16 8.126671    8 5.602623    0  2.045259    0 1.494491    1 1.365243    0  0.456062   0 0.935489\n",
      "   0 2.255047    0 1.733255    1  1.781531    1 1.115486    1 0.804833    0  0.526443   0 0.924427\n",
      "   4 5.119774    2 2.580053    0  2.198443    0 1.642988    0 1.072738    1  0.730465   3 1.389634\n",
      "   0 1.615194    0 0.800618    0  1.830430    0 1.041415    0 0.700333    0  0.183379   0 1.072688\n",
      "   4 2.099761    3 2.017757    0  1.097464    3 1.274083    6 0.776935   12  0.602483   1 1.208780\n",
      "   6 3.425600   27 3.626353    6  2.011477    6 1.513154    7 0.925197    6  0.549996   2 0.935489\n",
      "   0 1.631924    0 0.956348    0  2.042950    0 1.623156    0 0.913841    0  0.389643   0 1.261561\n",
      "   1 0.829388    1 1.102217    0  0.663858    0 0.677395    0 0.662874    1  0.177220   0 0.914179\n",
      "   0 3.131078    1 2.481214    0  1.404831    0 1.205361    0 0.794199    0  0.619619   0 0.935489\n",
      "   0 5.939976    4 4.507665    1  2.452661    4 1.754609    0 1.591473    0  0.867916   0 1.072688\n",
      "   2 2.508438    4 2.145928    0  2.183409    1 1.217810    0 0.804833    0  0.526443   2 0.924427\n",
      "   3 3.251646    1 2.500685    2  2.603626    2 1.673686    0 1.073014    0  0.629549   2 1.072688\n",
      "   4 3.251646    0 2.500685    3  2.603626    1 1.673686    0 1.073014    0  0.629549   0 1.072688\n",
      "  11 2.255047    1 1.733255    2  1.781531    0 1.115486    2 0.804833    0  0.526443   2 0.924427\n",
      "   0 0.327888    0 0.114120    0  0.456564    0 0.416030    0 0.192222    0  0.252764   0 0.715845\n",
      "   1 1.844284    0 1.595672    7  2.357265    9 1.575870    0 0.899396    1  0.619619   0 0.902817\n",
      "   5 1.719330    0 1.452230    1  2.820802    0 1.654960    0 0.898571    0  0.283847   0 0.783055\n",
      "   2 2.823878    2 1.719446    1  1.906049    0 1.054160    1 0.808505    0  0.342685   0 0.881522\n",
      "  22 3.330319   12 2.655329    8  1.604375   11 1.236730   15 0.793711    1  0.526443   2 0.935489\n",
      "   0 1.947063    0 1.504462    1  1.561031    0 1.282598    0 0.815682    0  0.469117   0 1.389634\n",
      "   0 0.295301    0 0.245350    0  0.585532    0 0.407191    4 0.219500    0  0.113624   3 0.400800\n",
      "   0 1.288778    0 0.861123    0  1.273235    2 0.929634    0 0.873889    0  0.384712   0 0.714874\n",
      "   0 1.770617    0 1.121065    4  2.056970    2 1.205166    0 0.809407    1  0.453853   0 0.924427\n",
      "   0 6.291527    0 1.441621    0  2.098637    0 1.526635    1 1.072738    0  0.730465   2 1.261561\n",
      "   4 6.366457    0 5.795934    0  2.451500    0 1.765209    1 1.615560    0  0.886048   0 1.072688\n",
      "   4 0.664126    0 0.399137    6  2.299311    3 0.695875    0 0.326995    1  0.144181   3 0.713602\n",
      "  13 7.186669    5 4.606526    4  3.923454    3 1.096536    0 1.129455    0  0.414844   1 0.635292\n",
      "   2 1.631924    5 0.956348    4  2.042736    1 1.404635    1 0.913841    1  0.389643   0 1.261561\n",
      "   0 0.735628    2 0.407894    6  1.894452    4 0.685545    0 0.363618    0  0.137909   0 0.689534\n",
      "   0 7.255758    0 6.201956    1  2.199667    1 1.823923    0 1.614029    0  1.230827   0 1.261561\n",
      "   0 0.318479    0 0.128009    0  0.396311    0 0.420792    0 0.202218    0  0.459728   4 0.937094\n",
      "   0 0.311972    0 0.121087    0  0.479504    0 0.425535    0 0.233084    0  0.032273   0 0.550853\n",
      "   0 1.947036    0 1.516627    0  1.569510    0 1.218626    0 0.793136    0  0.406794   0 0.935489\n",
      "   0 1.946645    0 1.521320    0  1.601745    0 1.217185    0 0.823530    0  0.526443   0 0.935489\n",
      "  23 5.943970   13 4.540270    1  2.452661    1 1.717806    1 1.591473    0  0.886048   0 1.072688\n",
      "   2 4.648408    5 3.627105    1  2.043541    5 1.535815    0 1.021016    0  0.549996   1 0.935489\n",
      "   0 1.631924    0 0.956348    0  2.042950    0 1.623156    0 0.913841    1  0.389643   0 1.261561\n",
      "   0 0.261862    0 0.330959    0  0.472599    0 0.452581    0 0.254198    0  0.199264   0 0.471408\n",
      "   0 0.261862    0 0.330959    0  0.472599    1 0.452581    0 0.254198    0  0.199264   0 0.471408\n",
      "   0 0.267980    0 0.372812    0  0.429078    0 0.436093    0 0.261868    0  0.155545   0 0.532141\n",
      "   1 4.567787    1 3.618596    3  2.063079    0 1.693779    0 1.035685    0  0.549996   1 1.389634\n",
      "   0 0.262148    0 0.430182    0  0.593672    0 0.445823    0 0.275572    0  0.316360   0 0.514374\n",
      "   0 0.294632    0 0.094363    0  0.405205    0 0.406246    0 0.156291    0  0.142160   0 0.485844\n",
      "  27 4.575056    1 3.619960    0  2.042082    0 1.539791    1 1.021016    1  0.549996   2 0.935489\n",
      "   2 7.255758    2 6.201956    3  2.199667    8 1.823923    1 1.614029    1  1.230827   3 1.261561\n",
      "   0 4.023621    0 3.482561    0  2.337476    0 1.688056    0 1.072738    0  0.730465   0 1.389634\n",
      "   0 1.820512    5 1.941667    0  2.421884    0 1.127680    0 0.928104    0  0.619619   1 1.109311\n",
      "   3 3.377310   11 2.460133   13  1.573117   14 1.190138    9 0.793711    1  0.526443   3 0.935489\n",
      "   0 1.292256    0 0.804703    0  1.452104    0 1.144627    0 0.696183    0  0.232186   0 1.261561\n",
      "   0 3.317652    0 2.524100    0  2.565318    0 1.635799    0 1.073014    0  0.563829   0 1.072688\n",
      "   0 2.255047    0 1.748993    0  1.781931    1 1.119627    0 0.804833    0  0.619619   0 0.924427\n",
      "   3 4.784037    0 3.038017    0  2.393954    4 0.880626    0 0.731864    0  0.248495   0 0.617337\n",
      "   0 2.021795    0 2.182589    1  1.512434    0 1.363579    2 0.852460    3  0.886071   0 1.198926\n",
      "   0 4.023621    0 3.482561    0  2.337476    0 1.688056    0 1.072738    0  0.730465   0 1.389634\n",
      "   0 1.757712    1 0.920111    0  2.253906    0 1.317489    0 0.894490    0  0.416398   2 1.072688\n",
      "   0 3.363647    0 2.481848    0  1.427158    0 1.237943    0 0.793711    0  0.526443   0 0.935489\n",
      "   0 1.947063    0 1.504462    0  1.561031    0 1.282598    0 0.815682    0  0.469117   0 1.389634\n",
      "   0 0.348414    0 0.315312    0  0.508899    0 0.515093    0 0.272424    0  0.178206   0 0.302303\n",
      "   0 2.311909    0 1.744584    0  1.762042    0 1.083257    0 0.805321    0  0.393600   3 0.924427\n",
      "  10 3.133345    0 2.481214    0  1.418960    0 1.166313    0 0.793711    0  0.619619   0 0.935489\n",
      "   0 4.648408    0 3.627105    1  2.043541    1 1.535815    0 1.021016    0  0.549996   0 0.935489\n",
      "   0 1.947063    0 1.504462    1  1.561031    0 1.282598    1 0.815682    1  0.469117   0 1.389634\n",
      "   1 3.363647    3 2.481214    0  1.428995    1 1.242047    0 0.793711    0  0.619619   0 0.935489\n",
      "   0 3.251646    0 2.500685    0  2.603626    0 1.673686    0 1.073014    0  0.629549   0 1.072688\n",
      "   0 1.658409    0 1.258139    0  4.191163    0 1.562447    0 1.109434    1  0.710774   0 0.814570\n",
      "   0 0.824750    1 0.617945    1  1.009916    2 1.058676    1 0.511562    2  0.457569   2 0.663340\n",
      "   1 4.761705    8 3.629438    5  2.045978    6 1.531230    1 0.925197    0  0.549996   0 0.935489\n",
      "   0 0.917013    0 0.777467    0  0.705708    0 0.687073    0 0.578767    0  0.344696   0 0.880237\n",
      "   2 4.761705    3 3.629438   12  2.045978    6 1.531230    1 0.925197    0  0.549996   0 0.935489\n",
      "   0 1.500475    1 1.441051    2  1.351855    0 1.066539    0 0.861768    0  0.393600   0 0.847441\n",
      "   1 5.943970    1 4.540270    1  2.471263    0 1.714287    1 1.605877    0  0.886048   1 1.072688\n",
      "   2 0.822919    1 1.025666    0  0.557546    0 0.685361    3 0.644620    0  0.177220   1 0.896071\n",
      "   1 1.186781    0 1.119564    0  1.048208    0 1.059620    0 0.874693    0  0.526443   3 1.021526\n",
      "   0 0.397369    0 0.192724    0  0.621364    0 0.537813    0 0.277941    0  0.162128   0 0.365880\n",
      "   0 0.665552    0 0.326800    0  2.239415    0 0.654982    0 0.318351    0  0.101108   0 0.551773\n",
      "   3 8.006658    0 5.900819    4  2.313319    0 1.585962    0 1.444777    0  2.236549   2 1.389634\n",
      "   7 1.645728   13 1.354757    0  1.048714    3 1.243321    8 0.796781    0  0.602483   1 1.208780\n",
      "   0 3.349586    3 1.815084    0  2.015639    3 1.438157    1 0.925197    0  0.515087   0 0.935489\n",
      "   0 4.074191    0 2.737311    0  2.656730    0 1.596589    0 1.030550    0  0.549996   0 0.924427\n",
      "   0 0.256972    0 0.193378    0  0.390493    0 0.394893    0 0.210589    0  0.256824   0 0.324998\n",
      "   0 2.253197    2 1.748993    1  1.768434    0 1.086785    0 0.804833    0  0.619619   0 0.924427\n",
      "   6 4.023621    3 3.482561    2  2.337476    0 1.688056    0 1.072738    0  0.730465   0 1.389634\n",
      "   0 7.255758    2 6.499648    0  2.199667    5 1.935395    0 1.614029    0  1.230827   0 1.261561\n",
      "   4 5.920181    0 3.186475    0  2.005938    0 1.372148    0 1.570601    0  1.071075   0 1.261561\n",
      "   1 1.669239    2 2.773434    0  1.838833    0 1.284732    0 1.398165    0  2.295385   0 1.175854\n",
      "   1 2.823878    0 1.719446    0  1.906049    3 1.054160    0 0.808505    0  0.342685   1 0.881522\n",
      "   0 5.920181    1 3.186475    0  2.017357    1 1.372066    0 1.570601    0  1.071075   0 1.261561\n",
      "   0 0.256742    0 0.136011    0  0.348624    0 0.392723    0 0.155402    0  0.049573   0 0.535367\n",
      "   0 2.255047    2 1.748993    1  1.781931    0 1.119627    0 0.804833    0  0.619619   0 0.924427\n",
      "   0 0.295555    0 0.300125    0  0.883970    0 0.374096    0 0.250027    0  0.369344   0 0.531349\n",
      "   9 4.567787    5 3.618596   40  2.063079   11 1.693779    7 1.035685    1  0.549996   0 1.389634\n",
      "   3 0.649109    0 0.406140    0  0.603888    2 0.577872    0 0.212658    0  0.712228   0 0.651575\n",
      "   3 3.363647    1 2.481214    0  1.428995    0 1.242047    1 0.793711    0  0.619619   0 0.935489\n",
      "  13 4.568848    1 3.618705    5  2.279980    3 1.692140   11 1.072738    0  0.589657   0 1.389634\n",
      "   0 0.277161    0 0.260089    0  0.470443    1 0.499643    0 0.204782    0  0.142443   0 0.274497\n",
      "   0 0.728909    3 0.407538    0  2.072299    0 0.761730    0 0.364032    0  0.137909   0 0.570834\n",
      "   0 1.118954    0 1.059959    0  1.358773    0 1.190633    0 1.003070    0  0.612775   0 0.770975\n",
      "   0 4.889295    0 3.439465    0  2.252490    2 1.848533   10 1.589943    1  1.129690   0 1.261561\n",
      "   0 3.330319    0 2.655329    0  1.604375    0 1.236730    0 0.793711    3  0.526443   0 0.935489\n",
      "   0 3.377310    3 2.460133   25  1.573117    4 1.190138   13 0.793711    1  0.526443   1 0.935489\n",
      "   0 0.309512    0 0.296870    0  0.427173    1 0.369337    1 0.275875    0  0.293742   0 0.315368\n",
      "   0 1.828100    0 1.110420    0  2.114910    0 1.196261    0 0.799511    0  0.526443   0 0.924427\n",
      "  44 4.020991    1 4.044308    0  3.276864    0 0.860171    0 0.736169    0  0.404192   0 0.742444\n",
      "   2 1.771490    3 1.411929    0  1.703951    1 1.020219    0 0.937800    0  0.582704   0 0.760688\n",
      "   0 3.012433    0 2.403952    0  1.364711    1 1.171124    0 1.230461    8  1.108336   0 2.088077\n",
      "   0 1.680867    0 1.271004    4  1.334913    0 1.178581    0 1.002611    0  0.721897   0 2.088077\n",
      "   0 0.289998    0 0.096200    0  0.439578    0 0.404747    0 0.170987    0  0.127784   0 0.620243\n",
      "   0 0.292490    0 0.195080    0  0.260597    0 0.366403    0 0.125401    1  0.100000   0 0.278639\n",
      "   3 2.505283   12 2.504779    2  2.135463    0 1.216646    0 0.804833    0  0.526443   1 0.924427\n",
      "   1 4.203643    1 2.749225    0  2.563126    2 1.635214    1 1.042820    0  0.549996   0 1.130124\n",
      "   0 3.317652    1 2.524100    0  2.565318    0 1.635799    0 1.073014    0  0.563829   0 1.072688\n",
      "  10 3.881117    5 3.929198    4  1.240433    3 0.866234    0 0.735678    0  0.446324   1 0.537899\n",
      "   2 1.849377    4 1.594546    5  2.949596    1 1.694401    2 0.899396    0  0.526443   2 0.902817\n",
      "   4 1.851601    5 1.590596    2  2.316047    0 1.575356    0 0.899885    0  0.393600   0 0.902817\n",
      "   0 1.805863    0 1.129659    0  2.060711    1 1.255136    0 0.821677    0  0.453853   0 1.130124\n",
      "   2 7.242338    3 6.201956   98  2.197774   32 2.128165    5 1.614029    1  1.230827   1 1.261561\n",
      "   0 4.181475    4 3.629438    0  2.047101    0 1.523040    0 1.021016    0  0.549996   0 0.935489\n",
      "   0 3.133345    0 2.481214    1  1.418960    1 1.166313    2 0.793711    1  0.619619   2 0.935489\n",
      "   2 3.317652    2 2.524100    0  2.565318    0 1.635799    0 1.073014    3  0.563829   0 1.072688\n",
      "   0 2.367611    1 0.794945    0  2.201323    0 1.298832    0 0.935219    0  0.515087   2 0.924427\n",
      "   1 2.823878    2 1.719446    3  1.906049    0 1.054160    1 0.808505    2  0.342685   2 0.881522\n",
      "   0 1.575542    0 1.939780    4  5.436691    0 9.574854    0 1.069687    3 11.393970   0 1.171732\n",
      "  31 5.451617   19 4.698985    2  2.340679    0 1.685391    3 1.072738    4  0.730465   1 1.389634\n",
      "   0 3.377310    0 2.460133    0  1.618968    0 1.190303    0 0.793711    3  0.526443   0 0.935489\n",
      "   3 3.985385    2 2.480211    5  2.596714    0 1.572650    0 1.073014    8  0.629549   5 1.072688\n",
      "  26 4.899374   11 3.463540    4  2.199372    9 1.933345    0 1.604346    7  1.230827   4 1.261561\n",
      "   0 0.345811    0 0.201571    0  0.372266    0 0.417464    0 0.068235    0  0.418421   0 0.247756\n",
      "  14 8.118266   14 5.960171    0  2.269301   13 1.592212    0 1.442511    0  1.128790   0 1.389634\n",
      "   0 4.203643    1 2.749225    0  2.563126    0 1.635214    0 1.042820    0  0.549996   0 1.130124\n",
      "   0 2.346705    0 1.709791    0  1.769838    2 1.080296    1 0.805321    0  0.393600   0 0.924427\n",
      "   0 1.654848    0 1.109600    0  2.422907    9 1.520032    0 0.913832    0  0.515446   0 1.072688\n",
      "   0 4.097843    2 2.737836    0  2.656730    0 1.602971    0 1.030550    0  0.549996   0 0.924427\n",
      "   0 0.263181    0 0.381144    0  0.490155    0 0.448465    0 0.264289    0  0.316360   0 0.471408\n",
      "   0 3.363647    1 2.481214    0  1.428995    0 1.242047    0 0.793711    0  0.619619   0 0.935489\n",
      "   2 1.672965    6 1.840065    1  1.802919    2 1.587734    0 0.857385    0  2.984405   0 1.057814\n",
      "   1 3.363647    0 2.533327    0  1.427336    0 1.189283    0 0.793711    0  0.526443   0 0.935489\n",
      "   0 1.575542    4 1.939780    1  5.436691    3 9.574854    1 1.069687    0 11.393970   1 1.171732\n",
      "   0 0.286518    0 0.175183    0  0.832618    0 0.452543    0 0.129853    0  0.156790   0 0.522554\n",
      "   1 3.622654    0 2.524105    0  1.300042    0 1.068365    0 0.793818    0  0.230008   0 0.892584\n",
      "   0 0.256742    0 0.136011    0  0.348624    0 0.392723    3 0.155402    0  0.049573   0 0.535367\n",
      "   1 2.196885    0 1.566294    0  1.611500    0 1.029398    0 0.808505    0  0.303887   0 0.841383\n",
      "   0 1.131626    0 1.031726    2  1.127222    3 1.027002    0 0.845829    0  0.439270   1 0.847441\n",
      "   0 4.097843    1 2.737836    3  2.656730    0 1.602971    0 1.030550    0  0.549996   2 0.924427\n",
      "   0 1.351732    0 1.101983    0  2.100278    0 1.524177    0 1.072738    0  0.608490   0 1.261561\n",
      "   0 3.377310    1 2.460133    0  1.618968    0 1.190303    0 0.793711    0  0.526443   0 0.935489\n",
      "   1 1.966950    1 2.052607    0  2.264897    0 1.662339    3 0.887782    0  0.526443   0 1.007588\n",
      "   2 7.527536    0 5.357527    2  2.521479    7 1.535411    5 1.445572   11  1.017794  12 1.072688\n",
      "   1 4.100287    0 2.554591    0  2.602563    0 1.604343    0 1.073014    0  0.629549   0 1.072688\n",
      "   1 0.627294    0 0.299199    0  0.681713    0 0.586292    0 0.234820    0  0.174437   0 0.813109\n",
      "   7 1.859811    3 1.628183    1  3.356117    5 1.693618    0 0.899396    1  0.526443   3 0.902817\n",
      "   1 2.492784    1 5.908441    0  2.614784    0 1.546984    0 0.934731    2  0.549996   0 0.924427\n",
      "   2 3.363647    0 2.533327    0  1.427336    0 1.189283    0 0.793711    0  0.526443   0 0.935489\n",
      "   1 0.256742    0 0.167028    0  0.356025    0 0.393443    0 0.203214    0  0.037824   0 0.444814\n",
      "   0 2.126602    0 1.470352    0  1.615439    0 1.012330    0 0.801521    0  0.303887   0 0.841383\n",
      "   0 0.266461    0 0.320948    0  0.421023    0 0.440888    0 0.252022    0  0.069185   1 0.532141\n",
      "   3 6.798616    0 4.391935    0  1.425282    1 1.055987    0 1.133471    1  0.321174   0 0.537899\n",
      "   0 2.298978    1 1.726108    1  1.762342    0 1.083257    0 0.805321    0  0.393600   1 0.924427\n",
      "   1 0.286078    0 0.112025    0  0.423000    1 0.409605    0 0.211134    0  0.075786   0 0.790363\n",
      "   0 3.251646    0 2.500685    0  2.603626    0 1.673686    0 1.073014    0  0.629549   0 1.072688\n",
      "   0 1.351957    0 1.078940    0  2.087941    0 1.505043    0 0.913841    0  0.504570   0 1.261561\n",
      "   0 0.261926    0 0.330985    1  0.472253    0 0.458719    0 0.255114    0  0.199264   0 0.471408\n",
      "  16 4.023621    4 3.482561    0  2.337476    2 1.688056    0 1.072738    0  0.730465   0 1.389634\n",
      "   0 0.313487    0 0.143553    0  0.551094    0 0.464503    0 0.234115    0  0.010083   0 0.776269\n",
      "   0 4.648301    0 3.629438    0  2.047386    0 1.536702    0 1.021016    1  0.549996   0 0.935489\n",
      "   3 6.348216    4 5.474996    0  2.449818    0 1.716036    0 1.615560    1  0.886048   0 1.072688\n",
      "   1 4.023621    0 3.482561    0  2.337476    0 1.688056    0 1.072738    0  0.730465   0 1.389634\n",
      "   1 0.712560    0 0.605116    2  0.593038    1 0.717859    1 0.426878    0  0.069719   0 0.590295\n",
      "   4 4.648301    1 3.629438    0  2.047386    0 1.536702    2 1.021016    0  0.549996   0 0.935489\n",
      "   0 0.296098    0 0.119404    0  0.429533    0 0.419183    0 0.223215    0  0.086575   0 0.550853\n",
      "   1 1.535040    0 1.050340    3  1.035515    0 0.975495    1 0.775126    0  0.695659   0 1.177361\n",
      "   0 1.500199    0 1.352303    0  1.220995    1 1.119680    0 0.859858    0  0.283847   0 0.742008\n",
      "   3 3.534155    0 2.090793    0  1.483567    0 1.107952    0 0.786724    0  0.326854   0 0.908891\n",
      "   3 5.115740    0 1.464006    0  2.101305    0 1.642988    0 1.072738    0  0.730465   2 1.389634\n",
      "   5 7.186669    1 4.606526    0  3.923454    1 1.096536    0 1.129455    1  0.414844   0 0.635292\n",
      "   2 3.363647    0 2.481848    0  1.427158    0 1.237943    0 0.793711    0  0.526443   0 0.935489\n",
      "   0 0.290790    0 0.106274    0  0.453698    0 0.400607    0 0.219262    0  0.075200   0 0.804291\n",
      "   0 2.036135    0 1.944674    1  1.301441    0 0.956817    0 0.932155    0  0.230008   0 0.949959\n",
      "   1 2.231806    8 1.587537    2  1.624836    1 1.032175    0 0.808505    0  0.303887   0 0.881522\n",
      "   1 4.526164    6 2.456264    5  1.393274    3 1.173463    0 0.794199    0  0.376192   0 0.935489\n",
      "   0 3.133345    0 2.481214    0  1.418960    0 1.166313    0 0.793711    0  0.619619   0 0.935489\n",
      "   0 3.881117    5 3.929198    1  1.240433    0 0.866234    1 0.735678    0  0.446324   0 0.537899\n",
      "  14 4.568848    6 3.618705    9  2.279980    1 1.692140    2 1.072738    0  0.589657   1 1.389634\n",
      "   0 4.567787    0 3.618596    0  2.063079    0 1.693779    0 1.035685    0  0.549996   0 1.389634\n",
      "   0 4.737624    0 2.516627    0  1.396191    0 1.179927    0 0.794199    0  0.376192   0 0.935489\n",
      "  10 3.330319    6 2.655329    0  1.604375    0 1.236730    0 0.793711    0  0.526443   0 0.935489\n",
      "   0 3.363647    0 2.481848    0  1.427158    0 1.237943    0 0.793711    0  0.526443   0 0.935489\n",
      "   2 4.526164    0 2.456264    6  1.393274    2 1.173463    2 0.794199    3  0.376192   0 0.935489\n",
      "   0 2.250446    0 1.741063    0  1.768606    0 1.085619    0 0.805321    0  0.619619   0 0.924427\n",
      "   0 0.290493    0 0.109425    0  0.492322    1 0.412161    0 0.208590    0  0.093056   0 0.688345\n",
      "   0 0.350326    0 0.223062    0  0.420332    0 0.462927    2 0.090488    0  0.075744   0 0.512261\n",
      "   1 2.370270    1 0.797560    0  2.155738    0 1.353767    0 0.934731    0  0.515087   0 0.924427\n",
      "   0 0.313487    0 0.130277    0  0.551001    0 0.459164    0 0.216551    0  0.010083   1 0.776269\n",
      "   0 1.633263    0 0.946894    1  1.897218    0 1.277320    0 0.894499    0  0.389643   0 1.261561\n",
      "  15 4.899374    3 3.463540    5  2.199372    3 1.933345    0 1.604346    0  1.230827   2 1.261561\n",
      "   0 0.279893    0 0.165870    0  0.596900    0 0.444337    0 0.135490    0  0.042194   0 0.403854\n",
      "   2 3.363647    4 2.481214    0  1.428995    0 1.242047    0 0.793711    0  0.619619   0 0.935489\n",
      "   0 4.923468    2 2.539329    0  1.351110    1 1.075940    2 0.793818    1  0.284242   0 0.892584\n",
      "   0 2.253197    0 1.748993    0  1.768434    0 1.086785    0 0.804833    1  0.619619   0 0.924427\n",
      "   1 2.657220    1 2.254501    0  2.676207    0 1.570134    0 1.030550    2  0.549996   1 0.924427\n",
      "   0 0.318948    0 0.112457    0  0.469266    0 0.412684    0 0.186422    0  0.117669   0 0.715845\n",
      "   0 1.095771    0 0.729259    0  0.768499    0 0.752951    0 0.612787    0  0.422222   0 0.995995\n",
      "   0 1.615644    0 1.299700    7  3.671223   15 1.580085    4 1.063977    2  0.432619   1 0.942684\n",
      "   0 1.585579    3 1.457206    1  1.203458    0 1.034926    0 0.866057    0  0.283847   0 0.742008\n",
      "   0 2.255047    0 1.754710    0  1.781441    0 1.117018    0 0.804833    0  0.526443   0 0.924427\n",
      "   0 4.023621    0 3.482561    0  2.337476    1 1.688056    1 1.072738    0  0.730465   1 1.389634\n",
      "   0 2.255047    0 1.754710   11  1.781441   32 1.117018    3 0.804833    2  0.526443   0 0.924427\n",
      "   0 0.346399    0 0.229242    0  0.437662    0 0.422728    0 0.079266    0  0.681207   0 0.588867\n",
      "   2 3.349586    1 1.881200    0  2.004818    0 1.428793    0 0.925197    0  0.515087   0 0.935489\n",
      "   0 1.720592    0 1.505694    0  1.344203    1 1.108681    1 0.938281    4  0.526443   1 0.839260\n",
      "   0 4.526164    1 2.456264    1  1.393274    0 1.173463    2 0.794199    0  0.376192   0 0.935489\n",
      "   2 0.971450    1 0.714199    0  0.911481    1 0.656111    0 0.816813    0  0.152196   0 0.597612\n",
      "   0 0.299752    0 0.113397    0  0.366520    0 0.383365    0 0.214094    0  0.008231   0 0.940488\n",
      "  17 1.567866    6 1.199645   13  1.335161    4 1.164675    0 1.002611    0  0.649774   0 2.088077\n",
      "   0 2.346705    0 1.711136    0  1.769366    0 1.074489    0 0.805321    0  0.393600   1 0.924427\n",
      "   0 1.948163    0 1.516357    0  1.599403    0 1.395178    0 0.807805    0  0.406794   0 1.389634\n",
      "  18 2.255047   18 1.733255    1  1.781531    2 1.115486    3 0.804833    1  0.526443   0 0.924427\n",
      "   0 0.263181    1 0.381144    0  0.490155    2 0.448465    0 0.264289    0  0.316360   0 0.471408\n",
      "   6 7.123107    4 4.806495    2  2.529222    0 1.532673    8 1.218944    0  0.383155   2 0.924427\n",
      "   0 0.282006    0 0.175773    0  0.244791    0 0.338832    0 0.128248    0  0.026899   0 0.278092\n",
      "   5 4.568848    3 3.618705    0  2.279980    0 1.692140    0 1.072738    0  0.589657   0 1.389634\n",
      "   0 1.851601    1 1.590596    1  2.316047    2 1.575356    1 0.899885    3  0.393600   1 0.902817\n",
      "   0 0.256742    0 0.167028    0  0.356025    0 0.393443    0 0.203214    0  0.037824   0 0.444814\n",
      "  14 8.204555   14 6.280259    3  2.229572    9 1.577434    1 1.444777    2  1.230827   1 1.389634\n",
      "   0 0.725739    2 0.511426    0  0.518623    0 0.608989    0 0.428535    0  0.137328   0 0.541078\n",
      "   3 7.242338    8 6.192016    6  2.181729    0 1.570338    1 1.444777    1  1.230827   0 1.261561\n",
      "   0 1.571318    2 1.245350    4  4.069395    3 1.570930    0 1.109434    0  0.510774   1 0.814570\n",
      "   1 1.532589    1 1.348530    0  1.376991    0 0.813533    0 0.973865    1  0.500515   1 0.656443\n",
      "   0 0.256911    0 0.167021    0  0.385818    0 0.408650    0 0.203355    0  0.154542   0 0.324998\n",
      "   8 5.507676    5 4.890603    1  2.199372    1 1.933345    3 1.614029    1  1.230827   2 1.261561\n",
      "  16 4.023621    2 3.482561    6  2.337476    1 1.688056    0 1.072738    0  0.730465   1 1.389634\n",
      "   0 0.652847    2 0.413843    0  1.914977    0 0.634909    0 0.248378    0  0.339758   0 1.103012\n",
      "   1 0.403856    0 0.219586    4  0.530853    1 0.517211    0 0.266828    0  0.147940   0 0.759009\n",
      "   3 2.651290    0 2.255319    2  2.685245    0 1.570134    0 0.934731    0  0.549996   2 0.924427\n",
      "   0 3.350488    1 2.564606    0  1.599007    0 1.192565    1 0.793711    0  0.526443   0 0.935489\n",
      "   0 0.294910    0 0.382211    0  5.823161    0 0.376147    0 0.261350    0  1.405810   0 1.026349\n",
      "   0 4.899989    1 3.477912    4  2.199502    3 1.836037    1 1.589943    2  1.129690   0 1.261561\n",
      "   0 0.277161    1 0.299707    0  0.472656    0 0.514584    0 0.258150    2  0.142443   0 0.274497\n",
      "   0 3.363647    0 2.481848    2  1.427158    0 1.237943    2 0.793711    0  0.526443   0 0.935489\n",
      "   6 2.651290    6 2.255319    2  2.685245    0 1.570134    0 0.934731    2  0.549996   0 0.924427\n",
      "   3 4.097843    1 2.737836    0  2.656730    0 1.602971    2 1.030550    0  0.549996   0 0.924427\n",
      "   0 0.256848    0 0.166995    4  0.383898    1 0.394834    1 0.202439    0  0.154542   3 0.324998\n",
      "   4 3.251646   21 2.500685    0  2.603626    2 1.673686    0 1.073014    2  0.629549   0 1.072688\n",
      "   4 2.113422    4 1.944674    2  1.305210    1 0.956156    0 0.932155    1  0.284242   0 0.949959\n",
      "   0 1.657487    0 1.528623    0  1.317553    0 1.180654    0 0.844677    0  0.230008   0 0.929635\n",
      "   0 0.579874    0 0.289282    0  0.806874    0 0.624159    0 0.336944    0  0.591131   0 0.482568\n",
      "   0 4.023621    0 3.482561    0  2.337476    0 1.688056    1 1.072738    0  0.730465   0 1.389634\n",
      "   0 0.347799    0 0.206794    0  0.459992    0 0.431317    0 0.085276    0  0.349405   0 0.450997\n",
      "   0 0.279893    0 0.160535    0  0.592437    0 0.443922    0 0.126976    0  0.042194   0 0.403854\n",
      "   2 4.889295    6 3.464016    0  2.225413    0 1.820016    0 1.589943    7  1.261508   0 1.261561\n",
      "   0 0.935172    0 0.639821    0  0.728594    0 0.724631    0 0.471180    0  0.319918   0 1.193138\n",
      "   0 0.656063    0 0.323732    9  4.176185    4 0.754324    1 0.337200    1  0.101108   1 0.614919\n",
      "   0 0.739992    0 0.868291    0  0.561808    0 0.775975    0 0.697205    0  0.248707   2 0.806038\n",
      "   2 4.568848    2 3.618705    3  2.279980    0 1.692140    0 1.072738    3  0.589657   0 1.389634\n",
      "   0 0.992020    0 0.780203    0  0.755771    0 0.811092    0 0.554163    0  0.421857   0 1.321211\n",
      "   0 0.279075    0 0.148250    0  0.779339    0 0.429522    0 0.111414    0  0.025358   0 0.301973\n",
      "   1 1.819951    3 1.556821    0  2.711646    1 1.656010    1 0.904173    0  0.283847   0 0.783055\n",
      "   0 1.406931    2 1.341326    0  1.376991    0 0.813443    0 0.973865    0  0.459062   0 0.656443\n",
      "   1 2.775741    3 1.145655    3  2.516115    0 1.538333    1 1.073014    1  0.557427   0 1.072688\n",
      "   2 1.417393    1 1.159427    4  3.638074    1 1.496228    0 0.898237    0  0.453853   3 0.832140\n",
      "   1 3.377310    0 2.460133    2  1.573117    0 1.190138    2 0.793711    1  0.526443   1 0.935489\n",
      "   3 0.261862    2 0.330959    0  0.472599    0 0.452581    0 0.254198    0  0.199264   0 0.471408\n",
      "   1 3.363647    0 2.481214    0  1.428995    0 1.242047    0 0.793711    0  0.619619   0 0.935489\n",
      "   0 0.798581    0 0.328093    0  2.031923    0 0.672966    0 0.336711    0  0.270833   0 0.503440\n",
      "   6 5.943970   11 4.540270    6  2.489567    0 1.717087    0 1.605877    0  0.886048   0 1.072688\n",
      "   0 4.923468    0 2.539329    3  1.351110    2 1.075940    4 0.793818    4  0.284242   0 0.892584\n",
      "   3 2.196885    1 1.566294    2  1.611500    1 1.029398    2 0.808505    0  0.303887   0 0.841383\n",
      "   0 1.948163    0 1.516864    0  1.600790    0 1.307473    0 0.837037    0  0.446455   0 1.389634\n",
      "   0 0.791492    0 0.799488    1  0.699357    2 0.716387    1 0.764936    0  0.248707   1 0.511766\n",
      "   0 1.706425    0 0.907954    2  1.956117    0 1.137947    0 0.817848    0  0.291493   0 1.072688\n",
      "   0 0.312700    0 0.120661    3  0.383051    0 0.384490    0 0.199004    0  0.188049   0 0.937094\n",
      "  71 4.568848   31 3.618705    7  2.279980    1 1.692140    2 1.072738    1  0.589657   1 1.389634\n",
      "   2 1.966926    0 1.971373    1  2.308643    0 1.772372    0 0.888993    1  0.230008   0 0.946606\n",
      "   0 2.656764    4 2.254501    0  2.712112    0 1.598012    0 1.030550    1  0.549996   0 0.924427\n",
      "   0 4.023621    0 3.482561    1  2.337476    0 1.688056    0 1.072738    0  0.730465   0 1.389634\n",
      "   2 0.754614    0 0.654351    4  2.374410    8 0.531969    0 0.442529    0  0.505616   2 1.114365\n",
      "   7 4.784037    1 3.038017    5  2.393954    2 0.880626    2 0.731864    1  0.248495   0 0.617337\n",
      "  13 4.568848   14 3.618705    3  2.279980   17 1.692140    6 1.072738    3  0.589657   3 1.389634\n",
      "  17 1.770617    8 1.121065    0  2.056970    2 1.205166    2 0.809407    0  0.453853   0 0.924427\n",
      "   0 1.633263    0 0.946894    0  1.896000    0 1.277320    1 0.894499    0  0.389643   1 1.261561\n",
      "   0 3.985385    0 2.480211    0  2.596714    0 1.572650    0 1.073014    0  0.629549   0 1.072688\n",
      "   2 0.748079    4 0.533716    0  0.565663    0 0.604532    0 0.442803    0  0.165899   1 0.628458\n",
      "   2 4.567787    3 3.618596    1  2.063079    4 1.693779    2 1.035685    0  0.549996   0 1.389634\n",
      "   0 0.261862    0 0.330959    0  0.472599    0 0.452581    0 0.254198    0  0.199264   0 0.471408\n",
      "   1 2.250446    3 1.741063    3  1.768606   15 1.085619    3 0.805321    1  0.619619   2 0.924427\n",
      "  10 5.943970    3 4.540270   32  2.452661    6 1.717806    3 1.591473    0  0.886048  19 1.072688\n",
      "   1 0.256848    0 0.166995    0  0.383898    0 0.394834    0 0.202439    0  0.154542   0 0.324998\n",
      "   0 0.377354    0 0.315767    1  0.499537    0 0.465847    2 0.245459    0  0.152469   0 0.589299\n",
      "   0 5.920181    0 3.186475    0  2.017357    0 1.372066    0 1.570601    0  1.071075   0 1.261561\n",
      "   0 1.654848    1 1.145655    0  2.746888    0 1.672738    0 1.073014    0  0.557427   0 1.072688\n",
      "   4 5.943970    9 4.540270    0  2.489567    0 1.717087    1 1.605877    0  0.886048   1 1.072688\n",
      "   3 2.657220    4 2.254501    0  2.676207    0 1.570134    0 1.030550    0  0.549996   0 0.924427\n",
      "   1 0.266398    0 0.320923    0  0.419974    0 0.436189    0 0.251107    0  0.069185   0 0.532141\n",
      "   8 2.508438    1 2.145928    3  2.183409    2 1.217810   10 0.804833    0  0.526443   0 0.924427\n",
      "   1 2.519641    2 2.489485   29  2.184896    3 1.212500   14 0.804833    1  0.526443   1 0.924427\n",
      "   0 0.256138    0 0.240000    1  0.411869    1 0.394284    0 0.219319    0  0.285395   0 0.367965\n",
      "   1 4.899989    0 3.477912    0  2.199502    0 1.836037    0 1.589943    0  1.129690   0 1.261561\n",
      "   1 1.844275    0 3.871642    3  1.834992    8 1.287328    1 1.422251    0  2.295385   0 1.175854\n",
      "   0 1.877317    5 1.586605    3  2.486741    0 1.645229    0 0.907502    0  0.283847   3 0.840912\n",
      "   1 2.311909    0 1.744584    1  1.762042    0 1.083257    0 0.805321    0  0.393600   0 0.924427\n",
      "   0 2.519641    0 2.489485    0  2.184896    1 1.212500    1 0.804833    0  0.526443   0 0.924427\n",
      "   0 3.251646    0 2.500685    0  2.603626    0 1.673686    0 1.073014    0  0.629549   0 1.072688\n",
      "   0 0.294292    0 0.121498    4  0.392034    0 0.406076    0 0.224646    0  0.165610   0 1.065168\n",
      "   0 4.568848    0 3.618705    0  2.279980    1 1.692140    0 1.072738    0  0.589657   1 1.389634\n",
      "   9 5.451617    4 4.698985    0  2.340679    4 1.685391    0 1.072738    0  0.730465   0 1.389634\n"
     ]
    }
   ],
   "source": [
    "dfs = []\n",
    "\n",
    "complist_vars = [complist_ya1,\n",
    "                 complist_ya2,\n",
    "                 complist_yb1,\n",
    "                 complist_yb2,\n",
    "                 complist_yb3,\n",
    "                 complist_yb4,\n",
    "                 complist_yc]\n",
    "\n",
    "for i, complist in enumerate(complist_vars):\n",
    "    df = pd.DataFrame(complist, columns=[variables[i],\"\"])\n",
    "    dfs.append(df)\n",
    "\n",
    "result = pd.concat(dfs, axis=1)\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "\n",
    "print(result.to_string(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
